Introduction DOI: 10.4324/9780429269035-1 that linguists may have a hard time imagining, and corpus linguistics also has this kind of explorative data-driven facet. In regard to targeted elicitations, it underscores how difficult it can be for speakers to imagine usages of some structure out of contextas is the case for out-of-contexts elicitations and judgements -but that the relevant forms may come up promptly once the relevant context has been brought up. It is in this way that the corpus linguistic approach bears great potential not only for the study of language use but also for the demarcation of possible structures.

Corpus linguistics and usage-oriented linguistics

The core concern of corpus linguistics is with patterns of language use and their variation. Language use involves numerous decision-taking processes whereby users choose between alternative ways of expressing the same thing during test production and recipients choose between different ways of interpreting the structures they perceive. The more specific concern of corpus linguistics is to account for these decisions by systematically investigating related variants and conditions on their choice. For instance, whether a copular verb like is is realised in its full form or appears as a clitic 's is subject to numerous factors, and corpus linguists seek to identify these and relate them to one another in modelling the variation at hand (cf.

A major concern with language use is shared by a range of sub-disciplines in linguistics. One of these is sociolinguistics. Sociolinguistics is concerned with the variability of language use and seeks to correlate these with the social features of language users and their interlocutors. For instance, the choice between the two variants of the copula, is and 's, in spoken discourse is related to the preceding and the following words, speech rate, and other aspects of discourse context. But it is also influenced by demographic characteristics of speakers and their audiences, the social and physical setting, and other general aspects of the communicative situation. We will turn to the role of corpus linguistics in sociolinguistics in Chapter 9.

Other areas of linguistics where details of language use are of central concern are psycho-and neurolinguistics. These fields are interested in how language is processed, for example, how language users encode and decode discourse and what structures pose particular problems, reflected in processing delays. For the most part, these fields of linguistics target processing during perception and deploy various methods of measuring aspects of processing, for example, neurological EEG measures of processing delays (N400, P600) (cf.

An area related to sociolinguistics, psycholinguistics, and acquisition research is that of language change and language evolution. A major idea here is that experience with linguistic behaviour shapes aspects of (abstract) linguistic representation. This is true for acquired language not only in an individual (L1 or L2) learner but also throughout communities, so that linguistic representations (phonologies, grammars, lexica) change over time. These changes can then lead to increasing differences across groups of speakers, leading to diversification into distinct dialects and eventually also distinct languages. Corpus linguists' concern with variation is key to this programme, labelled language variation and change within variationist sociolinguistics after William Labov, since variation is a necessary condition of change. In a broader perspective, corpus-based research then also links to linguistic typology where researchers have over recent decades become more and more interested in explaining the greater likelihood and distribution of certain systems

Alongside the relatively narrow field of academic linguistic research, corpora can serve various other purposes; for instance, records of linguistic performance can be relevant in anthropological studies of cultural aspects or in studies of political discourse in a society. Moreover, in some contexts the texts compiled in a corpus for originally academic purposes can form the basis for publications with somewhat different purposes, for instance, where texts are used in educational material for a language community to help support their language in the light of language endangerment

RUNDOWN OF THIS BOOK

The first half of this textbook focuses on the basics of corpus linguistics (Chapter 2) and types of corpora, including what is relevant for assessing the make-up of a corpus (Chapter 3). We give examples of corpus linguistic research in Chapter 4, showing that the corpus linguistic approach is possible for many levels of linguistic analysis and diverse languages. The second part of the book focuses on some of the tasks you might do in conducting your own corpus study including querying a corpus and evaluating the results (Chapter 5), and composing and building your own corpus (Chapter 6). In this vein, we also introduce various corpus annotation schemata which give various kinds of information that cannot be read from the corpus text itself (

Each chapter includes a few exercises and some include recommended further reading to help you engage with and think more deeply about the issues presented. We hope this textbook provides a good first foundation for corpus linguistics and generates your excitement about this large and diverse field.

NOTE

1. We will see that probably any variation of expression comes with specific meaning differences, which can be semantic or pragmatic, and which may be very nuanced. Yet, there do seem to be endless possibilities to express the same core meanings through different expressions; Chapter 4 will outline a range of examples that will make this point clearer.

WHAT IS A CORPUS AND WHAT IS IT GOOD FOR?

In linguistics, a corpus is a collection of texts that serves as the empirical basis for the study of natural languages. A text is any instance of recorded language use that can be treated as a discrete unit: a newspaper article, a recorded university lecture, or dinner table conversation. You can see from these examples that 'text' in this sense is broader than a document or what you produce when typing in a text editor. Moreover, the texts in a corpus must be machine-readable so that they can be collated and investigated with the help of computers. Corpora are not defined in terms of specific properties of texts, so texts can be of any type and may exhibit a large range of diverse properties (cf. Chapter 3 on corpus composition).

In linguistics we distinguish between linguistic knowledge and language use. For instance, speakers of a given language know what sounds distinguish words, what words or constructions mean, or on what occasion to use which expression. Language use refers to what speakers do with language and how they act in a given society by using language. In contrast to linguistic knowledge, language use is directly observable and recordable, and the texts in a corpus essentially comprise such records of language use. The corpus-linguistic approach is the systematic study of language use represented by the texts in corpora, which targets both linguistic knowledge and language use. The insights into linguistic knowledge that we gain from corpora are highly relevant in lexicography (the compilation and writing of dictionaries and lexical databases), for the writing of descriptive grammars of languages, or in anthropological linguistics where one aim of researchers is to establish the connections between linguistic and cultural knowledge

Our definition of corpus and characterisation of corpus linguistics does not specify any properties of the texts included. Some corpus linguists may restrict definitions of corpora to 'authentic' texts, those produced in non-academic contexts

DEFINITION AND CHARACTERISTICS OF TEXTS IN CORPUS LINGUISTICS

What is a text in corpus linguistics?

In corpus linguistics, a text is a record of any stretch of language as produced on a specific occasion at some point in time, at some place, and as received or receivable at some place and time. Text production and reception take place in different modes, that is, texts can be written, signed, or spoken and are received accordingly, being read, seen, or heard. In this textbook, we attempt to counter-balance the traditional focus on written texts and refer to corpora of non-written language texts as much as possible. It is important to keep in mind that written language use is historically derivative of spoken language use in the sense that writing conventions developed after spoken language.

Basic concepts in corpus linguistics

In order to be machine-readable (and for easier consideration by human analysts), spoken and signed texts are considered in corpus linguistics in a written form. This means that spoken and signed texts are not immediately available for inclusion in a corpus, but are transcribed, that is, what is being said or signed is written down according to specific conventions, for example, the conventions of the International Phonetic Association (IPA), which are in turn based on specific writing systems. Linguistic transcriptions are more or less exact renditions of spoken texts and constitute one form of linguistic annotations which will be discussed in Chapter 7 on annotation. Transcription of signed texts also requires conventionalisation of annotation (cf. Auslan Corpus

Spoken language production is accompanied by gestures and facial expressions, and these can be captured in the form of video recordings of spoken texts so that these can be analysed by linguists as well. In modern corpus linguistics, transcriptions are linked to audio or audio-visual recordings of texts so that a spoken and signed language corpus consists of transcription text files as well as audio and/or video files.

We concentrate primarily on spoken and written corpora in this textbook but recommend

Both written and spoken texts consist of wordforms. Transcribed wordforms are identifiable as strings of letters between spaces or before punctuation. In this sense, texts are strings of words. Strings of words are how texts are represented prior to any further corpus annotation (cf. Stefanowitsch 2020:353). 2 But a string of words only forms a text as long as it represents content-forming abstract units, namely phrases, sentences, and utterances related to one another in such a way that language users interpret them coherently. A text is in this sense equivalent to discourse which

Exercise 2.1 A first foray into corpora

Let's look at the Corpus of Contemporary American English (COCA)

2.2.2

What is a word in a text?

In corpus linguistics a fundamental unit of reference is the wordform. In the following, we briefly explain what wordforms are and how this notion relates to that of word. Consider the following excerpt from Barack Obama's speech at the United States of Women summit that took place at the White House on 14 June 2016:

But our country is not just all about the Benjamins -it's about the Tubmans, too. We need all our young people to know that Clara Barton and Lucretia Mott and Sojourner Truth and Eleanor Roosevelt and Dorothy Height, those aren't just for Women's History Month. They're the authors of our history, women who shaped their destiny. They need to know that…That's the story that's still being written, today, by our modern-day heroes like Nancy Pelosi or Sonia Sotomayor or Billie Jean King or Laverne Cox or Sheryl Sandberg or Oprah Winfrey or Mikaila Ulmer or Michelle Obama, the countless ordinary people every day who are bringing us closer to our highest ideals. That's the story we're going to keep on telling, so our girls see that they, too, are America -confident and courageous and, in the words of Audre Lorde, 'deliberate and afraid of nothing. ' (Barack Obama, United State of Women summit, 14 June 2016)

A first distinction relevant here is that between wordform(s) and lexeme:

wordform -these are forms that are directly observable and reflect any inflexions appropriate for their context: 'go' , 'going' , 'goes' , 'went' , 'women' , 'woman' , 'women's' .

lexeme -the abstraction underlying inflectionally related groups of wordforms that share lexical meaning; often one wordform is used to represent a lexeme, for example, GO or WOMAN, as the head word in a dictionary. The all-caps writing is intended to indicate that this is the name of an abstract unit.

Treatment of clitic forms

Clitics are morphemes that have syntactic properties like a word, but that are not phonologically independent, meaning they adjoin to a previous or following word like an affix. Now try the Brown corpus

Basic concepts in corpus linguistics

In corpus linguistics we have to keep the lexeme-wordform distinction in mind when performing corpus queries: if we are interested in the use of any given lexeme in a corpus, we have to make sure that we are going to capture all its wordforms when searching for it. In the case of GO we may have to search for all four wordforms listed above. We will explain in Chapter 5 how you can design smart corpus queries that will do searches of alternate forms like this. Many modern corpora of well-studied languages, however, include the technical feature of lemmatisation, that is, the information about which wordforms belong to which lexemes

Lemmatisation is a layer of corpus annotation, and we will come back to this in Chapter 7. Moreover, while the term lemmatisation is derived from the term lemma which in corpus linguistics (but not necessarily in lexicography) is used fairly often as an equivalent of lexeme.

Types and tokens

A further notion central to corpus linguistics is the distinction between types and tokens, and related to this is the procedure of tokenisation. 3 Tokens are all the

Exercise 2.2 Lemma search

Go back to the COCA and the Brown corpus.

Try to find forms of the lexeme BE. How can you check whether your query returned all forms that belong to the lexeme? Check out different query options in COCA and Sketch Engine. What would you do in the case of the Brown corpus?

How do you find the clitic form 's in either corpus? (You can read 2.

first).

There is no general consensus on how clitic forms should be treated in corpora. For instance, the COCA treats all clitics as separate wordforms whereas the Brown corpus (and other corpora developed in that tradition) treat clitics plus their host as a wordform. This difference does not necessarily reflect the analytic view of corpus compilers, but can often be due to technical conditions. It is therefore important that we always ensure we understand how the text of a corpus is internally structured, and to critically relate these to our linguistic analyses and categories.

individual wordforms in a text. There are 145 word tokens in the Obama excerpt above if we take a space as the delimiter (separator) between wordforms. The three occurrences of that's are counted as three tokens, but as one type. Type frequencies are then lower than token frequencies, and the type/token ratio can reveal interesting insights into properties of texts, essentially telling us how lexically variable a text or corpus is. Counting word tokens in a text is far from trivial even in a language like English, where the question arises whether forms like It's or aren't should be counted as a single word token (taking the delimiter criterion, as we have done above) or two tokens. Different corpora follow different procedures here; for example, the Brown corpus follows the space-delimiter as we have done, counting aren't etc. as single tokens whereas the COCA treats such forms as two tokens (which means that in COCA you have to search for a two-word expression are n't in order to find instances of aren't). Identifying tokens correctly and consistently in a corpus is another aspect of pre-processing and annotation of corpora. In corpus linguistics the procedure identifying and marking the boundaries of word tokens is called tokenisation. Hence, as with lemmatisation, we have to check whether and according to which criteria any given corpus has been tokenised before we can perform informed queries (see also

Measures of frequency for types and tokens

One often sees three common measures of central tendency that can be derived from frequency: arithmetic mean (average), mode (most common value), and median (middle of the range); range is the difference between the minimum and maximum values of a set of measurements. Ranges are useful for understanding the distribution of frequency data, although often minimum and maximum values are provided rather than the mathematical range. They did not finish NEG-3pl.S-sleep-TERM-R:I:PFV sleeping 6 2 3 ti-ngai-tai-yo-ndop I will not be seeing NEG-1sg.S-see-2sg.P-IRR:D you and…

Basic concepts in corpus linguistics

Let's say we have a small corpus of Matukar Panau 4 that has been parsed and glossed. 5  From this, we can get some information about typical kinds of word structures. Although Matukar Panau is an agglutinating language, we see that by token frequency, most words are monomorphemic or bimorphemic in an 8,961-word annotated corpus. However, by type frequency, bimorphemic and 3-morpheme word types are most frequent. This means there are fewer kinds of monomorphemic words, but they occur much more often.

Textual and contextual properties of texts

Above we defined a text as a string of words that form a structured whole. An important notion in corpus linguistics is that of context. By context we refer to all those structures that are relevant for the interpretation of texts as a whole and the linguistic expressions therein, such as wordforms and morphemes. Scholars of discourse distinguish different types of context, all of which influence the production and comprehension of texts.

Linguistic, text-internal context

While wordforms constitute a text on the surface, they also form abstract units, namely phrases which in turn form more complex phrases and clauses and sentences. Wordforms themselves have internal structures, consisting of morphs and syllables, which in turn consist of individual sounds. And higher order phrase, clause and sentence structures are likewise paralleled by a layer of sound structure which form intonational units of different types. Linguistic context is thus multifold and can be viewed in relation to these different levels.

In a converse, bottom-up perspective, each level of representation (mentioned above) defines a structural context in which a given unit occurs. For instance, whether we identify a surface form like need as a verb or a noun form will depend on

Exercise 2.3 Mean, median mode and range

The mean token frequency for Matukar Panau morpheme counts is 1.65 morphemes and the mean type frequency is 1.30 morphemes. The median token frequency is 1 morpheme, the median type frequency is 2 morphemes. Now your turn. What are the modes, minimums, maximums, and ranges for token and type morpheme counts based on this sample? syntagmatic context -which words come before and after it: we need to versus a need for constructional context -what position it has, for instance, in the higher order construction.

If we were investigating the distribution of specific sounds, relevant contexts would be defined by other sounds occurring in the same syllable or (phonological) word, and so forth.

Of particular prominence in corpus linguistics is the contexts of words, and related to this the corpus linguistic concepts of collocations. The term collocation refers to the co-occurrence of multiple lexemes, often two lexemes, called a bigram and a cooccurrence of three lexemes is called a trigram. We can search for a specific lexeme in a corpus and determine its collocates, that is, a list of lexemes that co-occurs with it. A collocate refers to the "next door neighbour" of a lexeme, which may be on either side of the lexeme.

The lexeme of interest will often be referred to as w, the lexeme before a lexeme of interest will often be referred to as w-1 and the lexeme after it will often be referred to as w+1. You may also see L1 (one lexeme to the left of a lexeme of interest) or R1 (one lexeme to the right of a lexeme of interest).

It should be noted that we should generally be sceptical of an all too clearcut conception of linguistic levels, and it is corpus-linguistic research that has advanced our understanding of interactions between, for instance, syntax, morphology and phonology in the area of clitics (some examples of which we observed above) and affixation.

For instance, the copula verb is occurs in various sentences in Obama's speech, and with different words preceding or following it; where in some cases it is reduced in form to 's this may at least to some extent depend on the word that precedes it, and its various morphological and phonological properties. Moreover, the clitic forms a phonological word with whatever element precedes it, so that an account of their occurrence needs to refer not only to syntactic but also to morphological and phonological structure.

How structural contexts are defined depends not only on the type of linguistic unit under discussion but also on the linguistic (and often theoretical) conceptualisations a corpus linguist will bring to the playing field: for instance, some linguists think of syntactic structures in terms of dependencies between words whereas others rely primarily on aspects of constituency, and many (if not most today) combine these two notions (see

Basic concepts in corpus linguistics

Collocates can be ranked according to their token frequency. Collocational strength is particularly relevant in corpus-based studies of lexical relations, for example, where collocations point to semantic differences between lexemes that are often thought of as synonyms (cf.

Colligation is the co-occurrence of specific parts of speech (verbs, nouns, adjectives, etc.) with each other; for example, we can estimate that articles in English show different colligational patterns with nouns, adjectives, and adverbs.

Collostruction is the systematic occurrence of a lexeme in a specific grammatical construction, for example, specific lexical verbs in English occur more frequently in the double object construction as opposed to the indirect construction (cf. 4.2.5).

Language-external context

Given that the above excerpt from Obama's speech is literally "taken out of context", namely, the entire speech, we do not have here information available about its wider context. In this case, this would be whatever came before and after Obama's own speech, and this will still basically belong to the wider linguistic or language-internal context to which the structural context that we just discussed also belongs. It captures the observation that the whole of the text, comprised of linguistic

Exercise 2.4 Token labels

Your lexeme of interest is world. What is the w-1 and w+1 in the sentence FIFA Women's World Cup 2019 winner was the USA? How would you refer to FIFA using this kind of label? How would you refer to winner? List all the bigram tokens in the sentence above in alphabetical order. Hint: the number bigram tokens in a corpus/string will always be one less than the number of lexeme tokens.

Exercise 2.5 Collocate search

Many corpora provide a specific collocation query function where users can specify the orientation and distance of collocates of a search expression. Using COCA and the Brown corpus, find collocates for duckling (only in COCA) and farmer. What is the most common w+1? Include part-of-speech (PoS) filters to find the most common adjective and determiner w-1 and the most common verb and noun w+1 in each corpus.

structures, is in turn embedded in a larger chunk of text, also made up of linguistic structures. All texts also have language-external contexts, which comprise all physical, social, and cultural aspects of the situation in which texts are situated. For instance, Obama's speech took place at the White House, on 14 June 2016, in front of an audience of 5,000 people, with him on the stage speaking into a microphone so that his voice was louder than the cheering and the comments shouted out by the audience. Obama as the speaker comes with specific socially and culturally significant features: he was president of the United States at the time, he is from Hawaii, lived in Indonesia, Chicago, and elsewhere, is an adult male who natively speaks American English, is black, is a cis-gendered, straight male, among many other identifying aspects. Likewise, the members of the audience have specific social features, and it is by now well-established that the audience a language producer has in mind can bear on the way they speak, sign, or write (cf.

Situational contexts

Considerations pertaining to external features also give us a way of determining the boundaries of texts: we can -as a working hypothesis -assume that a text is a stretch of language use that can be characterised by a specific set of external features, for example, the same participants with the same roles. This essentially aligns with the definition of speech event in anthropological linguistics

Basic concepts in corpus linguistics to can shape our own linguistic behaviour. Likewise, relevant in this connection is the publication context of some written texts: for instance, newspaper articles occur next to other articles on the same page, and this may have an impact on how they are being received by a reader.

The central premise of corpus linguistics is that all of the language-internal andexternal contextual features are relevant to the way that people use language. In other words, the use of linguistic forms is always subject to certain conditions. In corpus linguistics, we are essentially interested in how various structures (sounds, words, constructions) are used in particular contexts characterised by internal and external features; how possible variation in usage and choices between alternative structures (the so-called variants of a variable) can be correlated with such features, and how the use of particular forms can then be explained in terms of specific (qualitative) mechanisms relating to such features (see 4.

CORPORA AS SAMPLES OF LANGUAGE USE

So far, we have described corpus linguistics as analysing the specific forms and their distribution in the texts in any given corpus or corpora.

Let's recall Obama's speech cited above: this is an example of a text produced in (American) English. While one could imagine there to be a specific interest in the linguistic properties of this particular speech, our interests as linguists are typically broader: we want to learn about the structure of (American) English and its use in general (i.e. the variable realisation of is as either is or 's). This brings us to the problem of representativeness: shouldn't we consider all the language use in a given language? Obviously, this is an impossible undertaking: nearly all spoken and signed texts in a given language, when not recorded, will disappear virtually upon their production (a property called ephemerality). Many written ones (emails, text messages, etc.) are not preserved either. Corpus linguists deal with a small fraction of all texts that have been produced in a language, so any corpus is always only a small sample drawn from the real-world population of texts (cf. 8.2.1). In other words, the specific texts included in a corpus are meant to stand for language use more generally, that is, represent it. We sample Obama's speech and many others that are also representative of the language population we are interested in. This is the crucial component of any corpus building or compilation project (see Chapter 6) or of carefully using the metadata of existing corpora.

Metadata is what distinguishes a corpus from a random collection of texts by giving it explicit structure: minimally any user of a corpus will know what amount of text data is contained in it, what characteristics texts have, for example, whether they are written for a newspaper or spoken during a conversation with friends or colleagues, who produced the text, and so on. This allows researchers to determine if the samples are representative of the population of interest.

CONCLUSION

To conclude, corpora are collections of texts that represent to some extent the use of a language. Texts consist of wordforms, and wordforms enter larger abstract structures.

Wordforms are immediately observable and can be searched for; larger structures can only be detected through linguistic analysis and searching for these requires further corpus annotation (Chapter 7). Wordforms and in turn the larger structures they form are embedded in text-internal contexts, and the text as a whole relates to situational context. A key concern in corpus linguistics is to explain the variable use of wordforms and other structures in dependence on both types of contextual factors.

FURTHER READING

The basic concepts explained in this chapter are explained in virtually any textbook on corpus linguistics.

NOTES

1. This includes not only constructed examples in some areas of theoretical linguistics but also self-reported structures by participants in surveys within some more recent strands of sociolinguistics and applied linguistics: in these cases, not only the example structures but also circumstances of use are imagined, approximately like 'under circumstances AB I would produce structures XY' . 2.

CORPUS CONTENT AND REPRESENTATIVENESS

Corpus size

The first question we can ask about the content of a corpus is how much text it contains: its size. Corpus size is typically reported as the number of wordform tokens. What size a given corpus has will depend to a major extent on the kinds of texts included and the resources required to compile these into structured collections. To get a better idea about corpus sizes, let's consider some specific examples of English language corpora, as listed in Table

The size of iWeb is outstanding in this list. This enormous size is achieved by (semi-) automatically compiling data from openly accessible websites, focusing on websites hosted in dominantly English-speaking countries and excluding certain websites with potentially offensive content. The current corpus (at time of writing) contains texts from 22,388,141 web pages from 94,391 websites. The smallest corpus in the list is CORE. The corpus contains 48,569 texts -which are equivalent to web pages herecomprising 52,933,543 wordform tokens. Despite the similarity between the two corpora in their web-based content, the striking difference in size is clearly related to a difference in corpus design: while iWeb includes just about any text from almost any website, CORE has been created with the idea of identifying as much and as clearly as possible the situational characteristics of all texts included which constitute the web registers mentioned in the title. Determining register properties for texts published on the web is a painstaking and resource-intensive undertaking, and this helps explain the size differences.

Corpus size is often directly dependent on limitations on resources and other more practical considerations, a point we will return to in Chapter 6 on corpus-building. Similar considerations apply to other mid-range corpora, for example, the Corpus of Contemporary American English (COCA)

Corpus linguists often create smaller sub-corpora of existing corpora for specific research purposes, and these may be much smaller yet. For instance, for our study of object pronoun use in the Oceanic language Vera' a we drew on an annotated sub-corpus of Vera' a with a total of 25,646 wordform tokens

Different issues apply to specific multilingual corpora where corpus size also depends on the number of individual languages (sub-)corpora included, and where quite elaborate procedures of corpus annotation (see Chapter 7, in particular, Section 7.3) will naturally limit the size of corpora. One prominent multilingual corpus is Universal Dependencies (UDs)

Counts of wordform tokens or corpus words is a standard measure to report corpus size, but it is not the only possible one. When discussing sizes of spoken-language corpora within documentary linguistics, the time length of primary audio and/or video data is often cited (see Thieberger 2006:7 on the corpus of Nafsan (formally South Efate)). This is obviously not immediately comparable to corpus sizes given in word tokens since time length does not relate directly to text size: texts may differ in the amount and length of pausing and the speech rate of speakers, so that texts of similar duration in time may exhibit very different numbers of wordform tokens. But the word token measure is likewise not without problems in a cross-linguistic context, since languages differ tremendously in their morphology: in some languages, words are complex and a sentence often consists only of few words, whereas in other languages words are internally relatively simple and sentences typically contain more words. This is obvious from the overview of Multi-CAST in Table

Corpus composition

The second major characteristic of corpora is their internal composition: what types of text are included and in what proportions? To categorise texts, we generally rely on the situational rather than the linguistic characteristics of texts. The inclusion of texts with different situational characteristics reflects the fact that language is used differently in different modes, in different contexts, and by different people, etc. The reason why composition is guided by these situational rather than linguistic characteristics is that the latter cannot be known before a corpus has been compiled and investigated: Corpus composition and corpus types you can select for texts based on the situational fact that they involve more than one speaker, but you cannot select texts with a particular proportion of first-and secondperson pronouns. One can expect interactional texts to contain more of these but it is impossible to know before analysis.

One means to represent different situationally defined text types evenly in a given corpus is to aim for balance. This has been done, for example, in COCA, which contains texts from different categories in roughly equal proportions. In COCA, there are six main 'sections' labelled 'tv/movies' , 'spoken' , 'fiction' , 'magazines' , 'news' , and 'academic' . These reflect rough distinctions of texts in terms of their external The rationale behind this kind of corpus composition is that each cross-category (section/year) has the same share of the overall corpus data and will thus contribute approximately equally to results from any corpus query. The major idea here is to avoid massive skewing in results by over-representing just a single or very few text types.

A somewhat different approach is taken in the famous Brown corpus of American English

The procedure described here may not seem very reliable: based on intuition how can one really estimate what the proportion of biographical texts might be among all written English texts of whatever year?

For some text types, however, matters are quite obvious: for instance, the relatively small amount of spoken texts even in large or super-large corpora of well-studied languages like English is quite clearly at odds with the reality of language use, and more recent corpus building projects have been aiming at including greater proportions of spoken texts, for example, the International Corpus of English (ICE) where 60% of texts are spoken.

Language documentation-based corpora are typically less varied in terms of text type. Depending somewhat on the region and specific projects' contexts, many LD corpora consist predominantly of spoken narrative texts, often monologues. In addition, procedural texts (how something is done or what it looks like) and performative texts like songs are common. Written texts are typically not part of LD corpora, given that most languages are only spoken (or signed). In some projects, like the ones on Teop and Vera'a, written texts have emerged alongside the documentary work in the form of edited stories or written encyclopaedic entries for a dictionary (cf.

Certain special corpora to be discussed in 3.3 are characterised by a fairly confined set of text types that researchers are particularly interested in, for instance, the oral interactions between plane pilots and air traffic controllers. Yet other corpora may

Corpus composition and corpus types

consist of texts that do not represent any text type attested in a population of texts in the given language, for instance, those collected as responses to certain stimuli (cf.

As with our conclusions on corpus size, we take all different types of corpus composition to be viable options in corpus linguistics. The adequacy of any composition is ultimately dependent on specific research agendas and goals. In this view, a corpus consisting entirely of traditional narratives from a specific indigenous 'orature' is as much a corpus as a super-varied one covering a wide range of situational characteristics, but they will be amenable to different research projects.

Authenticity, routines, and spontaneity

In addition to considerations of text type variability some corpus linguists consider further aspects of texts to be vital for the content of corpora. The first one is authenticity or naturalness which has often been considered a defining property of texts to be included in corpora

Authentic texts have speech routines and writing conventions, belonging more generally to communicative competence

Texts that are produced primarily for linguistic research purposes are designated as 'non-authentic' , such as texts elicited as part of linguistic experiments in response to stimuli. Two examples recurrently used in some strands of linguistic research are the Pear Film, a silent movie narrating a simple story of pear theft

The parameter of spontaneity or planning relates to whether texts are produced ad hoc and spontaneously or after some planning time. The turns in many conversations are often relatively spontaneous as participants will react to their interlocutors' contributions more or less immediately. In longer written text production, like a book, producers of texts may go through various rounds of pre-planning and rewriting a text before it is actually delivered. But this is not true for all written text, for example, text messages may be formulated fairly quickly and without much planning. Conversely, some spoken texts such as political or religious speeches involve a high degree of planning before their oral delivery. Basically then, both spoken and written texts can exhibit variable degrees of spontaneity/planning. Spontaneity differences are gradual, so that planning may take different amounts of time and various cycles of rehearsal.

In our view, none of the parameters of authenticity, routineness, and spontaneity constitutes a demarcation criterion for corpus text and/or corpus linguistics. As empirical linguists we are interested in investigating all instances of language use and their conditions, whatever their nature. The only type of text we do not consider corpus text is mere mentions of structures, for example, intuited example sentences. A corpus can also contain elicited texts, including even lists of elicited sentences, as long as all contextual information is preserved. The latter will allow corpus analysts to evaluate attestations of particular structures as being elicited, with such and such context, etc., and this may have specific implications for their linguistic analysis as well. Excluding such data from corpus linguistics will in a sense also deprive us of the possibility to thoroughly evaluate structures vis-à-vis certain production conditions, for example, the production of elicited texts not based on established routines. Discuss your initial observations with a partner, and vice versa, and refine your list. Do some of the expressions extend to other text types?

Exercise 3.2 Text data collection

Corpus composition and corpus types

It is worth reiterating that actual authenticity is pretty much unattainable for many types of text that are particularly "worthy" in this regard, as per

Representativeness

Representativeness refers to the identity in distribution of linguistic and situational features of language use found in the corpus (the sample) and real-life language use (the population). A corpus can be representative of all the possible linguistic features of a language (covering all possible structures that are part of language user's competence), or it can be representative of all the external or situational variables of different texts that are produced in a given language. Representativeness is essentially unattainable given that we can never know what the population really looks like (and unlike pollsters we never have anything like election results come in against which we could evaluate our sampling procedures). We, therefore, take a melioristic approach where we outline ways in which corpora can fare better or worse in regards to representativeness, focusing on the previously mentioned corpus parameters.

Representativeness and size

Generally, when it comes to size it is obvious from a representativeness point of view that bigger is better. But how much does size really matter? Given our definition of representativeness, the major issue with very small corpora is that they will hardly have a chance to achieve any reflection of a wider range of contexts of language use. This can become an issue particularly for small corpora from under-researched languages

It is conversely very clear that corpus size is not to be fetishised. We only need to consider the vast corpora like iWeb or corpora of the TenTen Family 3 to see this clearly: despite their massive sizes these corpora seem to not reflect well the large range of diverse instances of language use and, hence, fare relatively poorly in terms of representativeness.

Representativeness and composition

Approaching representativeness in terms of composition is by no means a trivial undertaking. We have seen above that the creators of the Brown corpus (and other subsequent corpora following the same design principles) sampled written English texts according to their intuitions about the proportions of different text types. This is obviously not particularly reliable.

Relating composition back to corpus size, it should be clear that composition takes precedence over size: tremendously expanding the size of a corpus may not help improve its representativeness very much, as is the case with iWeb. The fact that its metadata is very sparse here adds a further downside (cf.

A further issue is the potential imbalance between the production and reception of texts. In potentially all societies there are text varieties that are received by a large number of people but are produced by only a fraction of the societies' members.

Examples are speeches by political leaders or texts published in popular books or newspapers. This imbalanced situation contrasts with a more prototypical situation of language use in everyday conversations, where produced texts are not normally perceived by a larger public, and where producers and receivers shift roles regularly.

Given that both production and perception of previous texts can influence people's behaviour, the perception of texts is important for considerations of representativeness and balance during corpus building.

Given that the purpose of a corpus is to serve as an empirical basis for the study of human languages, it is inevitable that a corpus has to be treated as a representation of language use beyond the specific texts included in it. We do not share views here (occasionally uttered in corpus linguistics literature) that findings from any given corpus merely apply to this corpus and nothing beyond. Obviously, our motivation for building corpora in the first place and investigating them is to learn about language use in a given language more generally. Whether a corpus is adequate in terms of its representative depends on the research question(s) at hand.

Saturation

Related to the idea of corpus representativeness regarding internal linguistic features is that of saturation. Investigating saturation presupposes a dynamic perspective on corpus content and its coverage of linguistic forms available in a language variety. The idea of saturation is that in an incremental process of corpus building or processing

Corpus composition and corpus types

Corpus composition and corpus types 29 (e.g. by way of annotation), with a growing and ever more variable corpus, it becomes less and less likely to encounter new structures (words, wordforms, sounds, signs, clause structures, etc.). While there is no clear-cut limit, we can state that a corpus is more representative if it achieves higher saturation. One can test this by taking a corpus, establishing a catalogue of all structures from certain domains (sounds, words, sentence structures, etc.) attested, and then seeing to what extent the addition of any further text will expand the inventory of these structures. If the degree of expansion is high, then saturation is low (as is representativeness). If the degree of expansion is low, then the original corpus was already nearly saturated and hence reasonably representative. One important observation here is that saturation is typically reached to different degrees on different linguistic levels: usually, saturation is reached sooner for phonemes than some grammatical phenomena, whereas lexical saturation is probably unattainable.

As with representativeness, corpus size is a necessary condition for saturation but not a sufficient one. We also need to consider matters of composition, since some lexemes or constructions come up only in specific text types. This also means that -like representativeness -full saturation is not attainable but only approachable.

Text varieties: register, genre, and style

The central concern of corpus linguistics is the systematic study of language use and variation therein. An important dimension of variation comes from text varieties, which can be classified according to three parameters: register, genre, and style

Exercise 3.3 Ducklings again

Go back to the COCA, the Brown corpus, and also COHA (cf. Table

Exercise 3.4 Contraction in registers

Go back to the composition of COCA outlined in 3.1.2 and develop hypotheses as to the likelihood of certain contracted forms you can think of will occur in the different sections. Then perform the relevant queries (remember to check the description regarding tokenisation). How would you report your results?

As we have explained in Chapter 2, texts have different properties on two different dimensions, text-internal/linguistic and text-external/situational. Most relevant for corpus linguistic studies of variation in language use is the register dimension: this is characterised by the situational properties of texts. For instance, we can characterise texts in terms of their mode of production and reception, that is, spoken versus signed versus written, the participants (producers, recipients) involved (with their demographic properties and social relationships), or their communicative purpose, that is, whether they are meant to edify, inform, etc.

These differences in situational features impact the use of linguistic structures: spoken conversations contain more pronouns, including first and second person ones, since they involve the negotiation of interpersonal relations and the expressions of participants' viewpoints and evaluations. On the contrary, written academic prose is focussed on conveying dense information, excluding personal evaluations; hence, the rate of pronouns, in particular, first and second person ones, is quite low here and the use of full noun phrases (NPs) prevails instead. Also serving the transmission of complex information, academic prose is generally replete with complex NPs containing attributive adjectives and prepositional phrases. The much higher rate of complex NPs in written registers may also be due to considerations of mode and reception alone: a reader will have more time to process complex structures, and knowledge of this fact may carry over to considerations of text production. It is these kinds of interrelations between situational characteristics, linguistic features, and the functional connection between them that is the core concern of a register analysis. Note that register studies necessarily need to be comparative to be meaningful. Moreover, register analyses always start with an analysis of situational features and seek to determine the relative frequencies of a linguistic feature. Those features that are particularly frequent in a register are called pervasive linguistic features. The pervasiveness of linguistic features is then to be interpreted in terms of situational features.

Considerations of register distinctions are also relevant in the analysis of specific features in lesser-studied languages. For instance,

Corpus composition and corpus types the difference between objects that are expressed by a pronoun and those that are just zero/unexpressed/'dropped' in

The next dimension of text varieties is genre. Text genres are defined not by their situational features but by specific linguistic features that are conventionally used and not clearly motivated by communicative functions. A classic example is the genre of fairy tales in the European literary tradition: not only do these have a very clearly defined narrative structure but they also have conventionalised opening and closing formulas, as shown in

(3.1) Once upon a time (in a far-away land) there was …and they lived happily ever after. (3.2) Es war einmal … Und wenn sie nicht gestorben sind, dann leben sie noch heute.

Similarly in Vera'a a text variety called nelno vu' 'spirit voice' , that is, a customary story, is characterised as a genre by a certain narrative structure and the opening formula shown in

qōn ne vō-wal e ruwa mē-n gunu-ruod ay art.num card-one art.pers hum:du dat-cs spouse-3du 'One day there (were) two married people' .

JSU.001

Similar

genre markers are the opening of certain speeches or announcements (Ladies and gentleman, Sehr geehrte Damen und Hereren, e raga sul) or letters (and emails) (Dear …, Liebe/r …). You could object that these formulas still serve some communicative function, at the least by announcing the type of text they also prepare recipients for their task, that is, to stop talking when a speech begins! But the exact form of the expressions in question is purely conventional (although they may historically be motivated). These are genre markers: linguistic features of genres are not pervasive, rather they occur often only once, in specific positions in a text. Often text varieties with specific genre properties are recognised as such in speech communities and cultures and receive a name, as in the examples in

The style-related linguistic features of texts are similar to register-related ones in being pervasive. The major difference is that they are not motivated by communicative functions; they are due to the specific habits of language use of individual language users or groups thereof (e.g. the authors of a specific period).

Most relevant for general linguistic concerns is the register perspective on text varieties since this offers important insights into the functionality of linguistic structures in use. Even if we are not specifically interested in the genre and style features of texts, we need to keep in mind that genre and style features may play a role when we analyse the use of specific linguistic expressions, and we need to build these into our accounts and models as relevant.

LINKED DATA

In addition to the corpus text data, modern corpora are closely interlinked with two further types of data, namely raw data and metadata. Raw data are records of the originally produced and/or published data, capturing as much of its context as possible. Metadata are data about the corpus files and the structure of the corpus as a whole and the compilation process (including design decisions), as well as data about the situational characteristics of texts.

Raw data and primary data

We adopt the distinction between 'raw data' and 'primary data' from Nikolaus Himmelmann's work on language documentation. The term raw data refers to the recording of a speech event or a written text, including its paralinguistic properties (what else is happening or done by participants about the communicative event). In language documentation, raw data consists primarily of video and audio recordings of the spoken or signed text production. Video recordings capture all gestures and facial expressions and are, of course, the major type of raw data underlying sign language corpora

Exercise 3.5 Digital genres

In your first language, think of text varieties that you encounter in the form of digital writing (published or shared on websites, in social media channels, etc., or as part of private communication) and that may qualify as genres.

(1) What name does the genre have?

(2) Name possible conventional structures or genre markers.

(3) Think again: are you dealing with a genre or would it make more sense to approach the text variety from a register perspective?

Corpus composition and corpus types called corpus data, namely, the searchable text data of a corpus in a written form in digital format. For spoken texts this will be the transcription, often linked to the raw data through the so-called time-aligned transcription (cf.

Metadata

Another type of data linked to corpus data and raw data is metadata. Metadata is literally 'data about data' . In corpora, it encompasses properties of all data types, as well as data about the corpus as a whole and its creation process. Metadata capture properties of the (written) corpus text (text format, encoding, script, structure of annotations, etc.), properties of the original text, that is, the raw data linked to corpus data (audio and video formats, recording equipment, publication details, etc.), and aspects of the relationship between primary data and raw data (how do corpus text files and original publication files, in particular, video and audio files, link to each other? Is there time-alignment, and how is it encoded? etc.). In addition to these, metadata is also collected about the situational features of texts (cf. 2.2.4).

For instance, the Buckeye corpus

Metadata capturing situational features of texts is a central prerequisite for the basic representativeness of any corpus. Imagine a corpus that is overall fairly representative in terms of size and composition, but lacking metadata. How can we know it is representative since we lack this information for evaluating the results from our analyses? Metadata is also relevant to what kind of research we can do with a given corpus. For instance, to evaluate whether a language has been changing over time requires metadata not only on the time of text production but also on the demographic features of people like their age. Or one might find different frequencies of certain expressions (i.e. like first and second pronouns) in conversation versus in narratives where language is perhaps more formal or follows a certain structure. Or one may find different patterns in the speech of young speakers or women or younger women speakers. Without metadata, we cannot test whether differences between any of these categories are meaningful.

Metadata can be more or less detailed, and some details are easier to determine than others. For instance, a factor drastically lowering the representativeness of written corpora is the fact that we often do not know anything about specific circumstances of text production and editing before the written texts were published. This problem is even more drastic in the case of web corpora where -in contrast to newspaper texts or novels -we often know nothing at all about the authors.

CORPUS TYPES

Types of corpora are primarily differentiated with regard to the situational features covered so that we distinguish general corpora that intend to cover basically all situational features relevant for a given language, and special corpora that deliberately cover a subset of situational features. We will deal with these basic types in 3.3.1. In 3.3.2 we turn our attention to other variable features of corpora, for instance, what languages and/or varieties they are intended to cover, or how they are developed or developing over time. This differentiation of corpus types goes hand in hand with specific research goals as we will see.

3.3.1

Corpus types defined by situational features

General corpora

General corpora are those intended to be unrestricted in their coverage of situational features. They attempt to represent a language or variety as a whole and be appropriate for all kinds of linguistic research. One sub-type is a reference corpus: a general corpus taken to be a standard reference for corpus-based research on a given language. An example is DeReKo -Deutsches Referenzkorpus 'German Reference Corpus' , whose purpose is to make available a large corpus of German amenable to a large variety of research questions. Similar to this are national corpora, for example, the British National Corpus (BNC) (BNC Consortium 2007), the Turkish National Corpus (TNC) (TNC Team 2018), or the Russian National Corpus (

Special corpora

Special corpora are corpora that contain texts with a restricted set of situational features meant to represent only a limited range of communicative events. Such a focus in representativeness is motivated by a concomitant focused research agenda; for example, the communication during air traffic control (ATC) between pilots and air traffic controllers. The creation and use of special corpora like ATC corpora are typically motivated by specific research interests and goals, for example, to understand how verbal communication is conducted efficiently and exactly under great time pressure and embedded in other complex actions in ATC. Further scientific goals of an ATC corpus are applied ones, for example, the development of ATC-specific speech recognition systems (cf. the AIRBUS-ATC corpus;

Another prominent type of special corpus is learner corpora, which contain texts from learners of a language, typically at different stages of developing competence. Often these texts are from classroom contexts. These corpora then do not reflect the language use of a general language community, rather that of their emerging new L2

Corpus composition and corpus types

Corpus composition and corpus types 35 members. Typically, L2 texts produced by learners would not be included in a general corpus of the respective language, which in principle raises interesting questions (not to be discussed here), like who counts as a member of a language community? Several special corpora contain only specific types of text, which could also be included in a general corpus. For instance, the Corpus of Supreme Court Opinions (cf. the list in Table

Another type of special corpora defined by situational features is the experimentally elicited text corpora. Experimentally elicited texts are produced mostly or exclusively in the interest of some linguistic research programme and typically controlled in some way with a linguistic research question in mind. Examples are collections of Pear Film re-tellings

While special corpora are deliberately confined to a specific sub-population of texts in a given language, considerations of representativeness and saturation in terms of size and composition are still relevant within the specific text categories targeted. For instance, in learner corpora, we will still want to see learners of different stages, genders, age groups, L1 backgrounds, etc. represented. And again, the same sampling considerations of general corpora apply for special corpora: we sample either to achieve proportional equivalence or in order to reflect the population as closely as possible. Even for very restricted corpora in terms of text types, like ATC corpora, variability in situational features is relevant, and so these will have to contain text specimens produced by female and male pilots of different age groups, different linguistic backgrounds, and so forth. These considerations are relevant for related research goals, for example, an automatic speech recognition system needs to be trained on different articulation behaviours and voice qualities (which depend crucially on factors like sex and age). The same applies to artificial corpora of experimentally elicited texts: even where participants produce texts narrating the exact same content under the same experimental conditions, as with the Pear Film experiment, it is vital for the corpus to cover speakers with different demographic features, as the corpora are meant to represent the behavioural reaction to the stimulus characteristic of the language community as a whole.

For special corpora, it is more of an issue to determine clearly the exact limitations of the intended population of texts. This is relatively straightforward in the case of superspecialised ATC corpora: they include only those texts produced over the specific pilot-controller channel over shifting radio frequencies, which are in fact explicitly announced by controllers and confirmed by pilots. In other contexts, the situation is more intricate: an example is the work of Douglas Biber and colleagues who famously investigated English language use in US universities, their 'university language' . They describe the scope of the language use under investigation as "[…] the range of spoken and written registers that students encounter in U.S. universities and of the major academic disciplines […]"

Other parameters

There are a range of further parameters other than the situational features of the texts included that define different types of corpora. These aspects are related more closely to aspects of research design and interests as well as corpus creation and curation.

Static versus dynamic corpora

Static corpora are those that are finished when published, with content not altered thereafter; they remain exactly in the state in which they were created. Dynamic corpora grow over time as more and more texts are included (monitor corpora are a type of dynamic corpus). Both general and special corpora can be either static

Corpus composition and corpus types

or dynamic. Big reference corpora are typically monitor corpora. Since they attempt to achieve maximal representativeness for a language, they add new texts being produced with the flow of time, such as COCA mentioned above. Examples of static corpora are the corpora of the Brown family of corpora (cf.

3.3.1.3.2 Synchronic, diachronic, and historical corpora Synchronic corpora contain texts from a 'single point in time' , whereas diachronic corpora include texts recorded over a longer period of time. As a matter of convention, we would classify as diachronic only corpora that cover at least multiple decades of language use. The Brown family corpora would all be synchronic when considered individually. The Contemporary Historical Corpus of American English (COHA) is an example of a diachronic corpus. A crucial characteristic of a diachronic corpus is that the texts it contains are comparable across periods. This is because the purpose of a diachronic corpus is to enable comparison of language use across time spans, and that would hardly be possible if the texts included in each temporal section were vastly different, for example, personal diaries in some time spans and newspaper articles in others. The Brown/Frown combination, as well as their LOB/FLOB counterpart, could be considered diachronic corpora: here we have exactly the same selection of text varieties across two periods of time

Languages and/or dialects covered

Finally, we can classify corpora in terms of what languages they represent the usage of. For instance, we could in principle distinguish between corpora of European and African languages etc. (global language areas), or between those of Indo-European and Tibeto-Burman languages etc. (language families), and the like. While this is a fairly trivial reflection of groups of languages with little specific relevance for corpus linguistics, a grouping that is more important for our purposes is that between wellstudied and lesser-studied languages. This is relevant because it comes with various preconditions, and leads to different goals for corpus linguistic work. Well-studied languages often have already established large corpora, an established research tradition including descriptive and analytical work, etc. Lesser-studied languages typically lack these things, and here corpus linguistics often means to build corpora in the first instance, and these corpora will then often be relatively small, which then comes with various restrictions as to their usability in research. A further relevant distinction is that of minority language corpora, which relate to languages other than the official standard languages in big nation-states. A similar distinction is that between (standard) language and (regional or social) dialect corpora. Big reference corpora often target standard languages of big nation-states, but this need not be the case and there can also be big reference corpora of dialects or minority languages, for example, of Sorbian (a Slavic language of east Germany;

Monolingual versus multilingual corpora

Typically, reference corpora target a single language, often a standard and/or official language of a nation-state (German, Turkish, Russian, etc.). Such corpora are thus monolingual. There are also multilingual corpora that include texts from more than one language. An example we mentioned above was Multi-CAST

Research-oriented corpora

Some corpora are characterised by specific properties in terms of processing and corpus annotation (more in Chapter 7). One previously mentioned example is speech corpora, which are not only characterised by the content of their spoken texts -which is a more general characteristic of spoken corpora -but also by the

Corpus composition and corpus types

specific annotation for various phonetic properties. Typical morphosyntactic annotations are part-of-speech tagging (PoS tagging) which captures the word class and other morphological and syntactic properties of token wordforms in a corpus; such corpora can be loosely classified as tagged corpora. Corpora with so-called interlinear morphemic glossing which captures the meaning and/or grammatical functions of morpheme tokens in a corpus are sometimes labelled interlinearised corpora. Certain corpora containing specific syntactic annotations capturing either constituency or dependency relationships between wordforms and/or phrases are called treebanks. This annotation has sentence structures represented in a tree-like structure showing hierarchical dependencies, which is useful for testing assumptions of some theories of grammar.

Another type of corpus with special annotation is a speech or phonetic corpus.

One of the first speech corpora produced was the Texas Instruments/Massachusetts Institute of Technology (TIMIT)

A note on IPA versus ARPAbet and other phonetic alphabets

Phonetic corpus research necessitates that computers are involved in the production and reading of phones. However, the phonetic alphabet as represented by the International Phonetic Alphabet (IPA) is challenging for computers to read. It needs to be translated into another form, usually, one produced with ASCII characters. Vowels are usually represented by multiple letters, as are some consonants. Most of these phonetic alphabets also have characters to represent word and utterance boundaries. Speech corpora use various alphabets: ARPAbet (Advanced Research Projects Agency Alphabet) aka DARPA, MRPA (Machine Readable Phonemic Alphabet), TIMITBET (Texas Instruments/Massachusetts Institute of Technology Alphabet), SAMPA (Speech Assessment Methods Phonetic Alphabet), etc. Therefore, the metadata of a corpus will include a list of correspondences between the chosen phonetic alphabet and the IPA.

Categorisation of corpora in terms of specific annotations for certain linguistic information cross-cuts distinctions made above so that, for example, both mono-and multilingual corpora can be tagged or constitute treebanks. In practice, more specialised annotation is restricted to special corpora created for specific research purposes, but some larger corpora fall into these particular categories; for instance, COCA is a tagged corpus.

FURTHER READING

Biber (1993) is a paper discussing corpus composition and representativeness, and Gries and Berez (2017) a paper discussing various types of corpora and their properties. Biber and Conrad (

NOTES

1.

2. This figure represents the first 2,000 words in any given text, plus the number of words to complete a sentence started so that the text snippets included contain all complete sentences. 3.

LINGUISTIC STRUCTURES AND THEIR VARIANTS

Language use and contextualisation

Language use at all levels of representation is tremendously affected by a range of contextual features. As discussed in 2.2.4, corpora have external and internal features or contexts. Characteristics of the external (or situational) context are important for understanding variation. Language use can be conditioned by who is interacting to whom and when, how much interlocutors know about each other and what they are discussing, whether the language use is spontaneous speaking or signing or writing and what the genre, register and style of speaking, signing or writing are. Take for example written text found in a textbook and spoken conversational language use. We would expect to see different vocabulary choices, different average lengths of sentences, different kinds of structures and so on. Many conversations are full of spontaneous, unplanned language use, whereas the language in a textbook is produced more slowly, usually has gone through multiple drafts and is more carefully created. A conversation includes many situational clues to interpreting language such as eye gaze, gesture, facial expressions, tone of voice for spoken language, as well as means to establish common ground between conversational partners, all of which written text lacks, which should affect language choices. Academic writing also tends to be more formal than spontaneously produced spoken language (cf.

Much of the effect of context passes under our radar, especially when using natural language in spoken and signed contexts. We do not have to consciously think about the effect of context on meaning when it is congruent, but we notice when there is a mismatch. In corpora, we see trends of usage for particular contexts and when a usage has a mismatch for the context, there is often a reason why: emphasis, importance, a hesitation, a mistake, etc. However, until we actually look at multiple instances of usage in multiple contexts, it is difficult to know what is typical precisely because matches in context and meaning are processed unconsciously.

Choice of variants: possible and probable structures

When describing the characteristics of a language, a linguist might account for all of the possible ways of expressing a particular meaning, and a corpus linguist would also want to account for the probability of expressing a particular meaning, given the context. For example, when expressing a possessive relationship between two nouns in an NP, English has a genitive 's strategy (e.g. the woman's car) and a genitive prepositional of strategy (the car of the woman). For many English nouns, both strategies are possible, but the probable strategy will depend on the nouns involved, as well as other factors. A corpus study is an ideal way to find out which possessive

Exercise 4.1 Synonym context

Use the COCA, COHA, and Coronavirus corpora to compare ill and sick and their collocates. Are the collocates of the words similar or not? Are there any surprising collocates or usages? Under what conditions do these occur?

strategy is more probable and in what contexts, that is, what kinds of factors affect which strategy will be used. This particular problem of variability is well-studied, and we know that the genitive 's strategy is much more likely to be used:

• when the possessor is a person (i.e. it is animate): the boy's hat rather than the hat of the boy

• when the possessor has already been introduced or is known (also called 'given'): the university's student centre rather than the student centre of the university

• in speaking rather than writing, or in journalistic genres

The of strategy is much more likely to be used:

• when the possessor ends in a sibilant sound (fish, jazz, bass, garage): parts of a fish rather than a fish's parts

• when the possessor is expressed in a long or multi-word NP: the last paragraph of the first chapter rather than the first chapter's last paragraph

There are also many other context factors that each matter a little (cf.

Linguistic variation is the social fact that there are multiple means to express or encode content. Understanding the choice between possible variants is one of the main foci of corpus linguistics, especially variationist corpus linguistics. We do not expect people to behave completely randomly when they use language. Although people have many choices from moment to moment in their lives, they tend to follow routines or patterns. The choices they make are constrained by the people around them: to avoid offending them or to make them laugh, etc. When looking at linguistic behaviour, we know that each language has rules of use; some things are just wrong: *womans are going, *women is going, *women are go. But linguistic behaviour is also constrained beyond linguistic rules. When we research variant choice, we research the kinds of things that matter to people when making a choice (although often this choice is spontaneous and unconsidered). Regarding of and 's genitive alternation, the animacy of a possessor is the most important factor (?the hat of the boy), but phonological well-formedness (?the fish's parts) and information density (?the first chapter's last paragraph) also matter. These factors relate back to comprehension and processing: English users are much more likely to choose a genitive form that is easy to process and easy for an interlocutor to understand.

Corpus research of variant alternation is done at all linguistic levels: semantics, phonetics, phonology, morphology, syntax, and discourse. In the rest of Chapter 4, we will describe example studies from all of these levels as well as corpus studies of sign and gesture. Some kinds of research questions are easy to explore with a basic corpus. However, many kinds of questions require special kinds of corpora that have additional information or annotation, an issue we discuss further in Chapter 7.

Levels of linguistic representation

4.2 STRUCTURAL LEVELS OF VARIATION

Lexical semantics

Corpus linguistics started as an enterprise interested in words, their frequency, and their contexts. Even if a corpus is basic, simply a string of wordforms with no other annotation, it is easy to search for individual words since usually words are a kind of string of characters, separated by white space. There are many corpus studies that compare lexemes, especially near-synonyms and purported synonyms. Corpus searches of words that have similar meanings can show that synonyms can occur in quite different contexts. The differing contexts, then, should be taken into account as part of the definitions of words, as mentioned in Section 4.1.1 above.

Let's take a closer look at two studies that carefully examine the contexts of similar words. First, we will look at

"You shall know a word by the company it keeps"

The title of this section is an influential and oft-quoted insight from

• morphological features (tense, aspect, and voice)

• syntactic properties (transitivity, speech act [i.e., statement, question or command], main clause or subordinate clause)

• semantic characteristics of the subjects, objects, and complements co-occurring with run (i.e. human, animate, concrete, mass nouns, etc.)

• collocates in the same clause (collocates are the words before and after a token of interest, see more in Chapter 2)

• a paraphrase of the meaning of the word This coding results in data that can be investigated more deeply, both quantitatively and qualitatively. Gries has 252 distinct behavioural profiles across his 851 tokens. The wide diversity comes from the inclusion of different collocates. It should be immediately striking that there are many different behavioural profiles but also that there are not 851 distinct profiles, meaning there is consistency across the corpus in terms of not only the syntactic uses of run, but also the words it co-occurs with. In this set of data, Gries identified 56 senses of run. He then uses the behaviour profiles to address questions of similarity between these senses.

First, Gries finds that run with a meaning of 'fast pedestrian motion' is the most frequent sense, as well as the sense that occurs with the most different behaviour profiles. This supports its central meaning because it means that the meaning occurs across many different uses, rather than being restricted to a particular kind of use.

Gries also computes pairwise correlations (a statistic that can be used to assess strength of association) between each of the different senses using a matrix of the behaviour profiles associated with each sense. From this, he is able to identify the most similar and dissimilar senses. Most similar are the senses of 'fast pedestrian motion' and 'to escape' . Most dissimilar are the senses 'to overflow' (4.10) and 'to see

(4.10) their cups were already running over without us (4.11) He ran his eye along the roof copings

The pairwise correlations take all the behaviour profiles of two particular senses and compare them to each other, a pair at a time. In addition to many separate pairwise

Levels of linguistic representation

comparisons, similarity can also be quantitatively assessed using cluster algorithms

Finally, Gries flips the problem from polysemy to word sense disambiguation (an issue for computational linguistics and natural language processing). If one has a behavioural profile for a token, can one successfully predict which sense is being used? And are some elements of the behavioural profile more useful for sense disambiguation than others? For instance, Gries can successfully predict all cases of the sense 'fast pedestrian motion' by taking into account the combination of past tense, intransitive, followed by a to prepositional phrase, with a human subject noun. More data would be needed to fully specify which elements of the behaviour profile are most significant for word sense disambiguation, but in principle this would be possible, meaning that examinations of word profiles can be useful for both issues of semantic theory and practical applications.

Many corpus studies take a similar approach in looking at words or domains in the lexicon and comparing uses. For instance, Glynn (2014) expands upon

Synonyms and meaning clusters

We now turn from polysemy of one word to a look at near-synonyms (multiple lexemes with similar meanings).

For instance, she coded whether the cause was internal or external:

(4.12) Krawczak's results show that there is very little difference between American and British uses of ashamed, embarrassed, and humiliated. However, there are clear differences between the near-synonyms.

• Ashamed in the correspondence analysis plot is near both the atemporal and past levels of the cause time factor, and near the internal level of the cause type.

It is correlated with the violation of the social norm of emotional reaction, dubious social status, loss of social status because of financial reasons, bodily shame and failures.

• Embarrassed is also near the internal level of the cause type factor and atemporal level of the cause time factor but is closest to the present level of the cause time factor. It is correlated with causes such as the violation of social norms of politeness, insecurity, inadequacy, and violation of social norms of decency.

• Humiliated is nearer to the external level of the cause type factor and the past level of the cause time factor. It is closest to causes of mistreatment, social rejection, and failure. • The source of shame of loss of social status is in the middle of the correspondence analysis plot, showing that this level of the cause factor is shared by all the shame words.

The decision of the classification for each of these tokens from the corpora does require some subjective decision-making from the researcher, as is the case in many corpus studies. However, the overall results are robust and match well to the

Phonetics

Phonetic research is concerned with the physical, acoustic measurements of spoken language. Phonetic corpus research is concerned with the acoustic measurements of spoken language in context. Speech corpora are based on spoken language but necessitate detailed annotation including not only written transcription but transcription in phonetic alphabets and careful connections with the time course of speaking. This is usually made up of a text grid that divides the speech signal into characters that represent phones, which can be viewed or computer-processed with accompanying audio files. With this extra annotation, researchers can look at issues like word length, vowel acoustics, various phonetic realisations of words, phone realisation, speech rate, and so on. These kinds of corpora take a lot of work to produce, much more so if (portions of) the corpus have been manually inspected, checked for accuracy, and hand-corrected. Because of this, speech corpora tend to be smaller than corpora compiled for other kinds of research.

One large research area has been in the domain of speech reduction: when and how is speech reduced? And how do listeners understand vastly reduced speech segments? One well-known English speech corpus used for this line of research is the Buckeye corpus

Levels of linguistic representation

COCA, she shows that in addition to phonetic factors, duration is affected by how probable the word is in a specific context (quantified with conditional probability measures) and how probable the word normally is (quantified with informativity measures), given the particular construction it is a part of (modal, perfect, possessive). She finds that the construction with the highest average probability, the perfect construction, has the shortest durations of inflections of have and that durations are shorter when the following transitional probability is high, meaning both specific and average probabilities affect word durations (more discussion of frequency and probability measures can be found in Chapter 5). The results of this study indicate that rule-based processes affect not only word realisation but statistical tendencies built up from experience of language use affect word realisations as well. The results contribute to a body of work on the effects of frequency, probability, and informativity on word durations and word realisations. The results from these studies are used to inform theories of language organisation and language processing.

Another important research area using speech corpora has been automatic speech recognition (ASR), speech-to-text (STT), and text-to-speech (TTS) applications, that is, how can machines be trained to account for the variable productions by human speakers? Sociolinguistics is another area where researchers use speech corpora, because pronunciation, especially of vowels, often differs due to social dimensions in a language population.

Most phonetic corpora are of Standard American English speech varieties. For researchers doing work on other varieties of American English, other varieties of English, or almost any other language besides English, the recourse is to produce their own speech corpora. This has become a more viable option recently with various forced aligners available. Forced aligners match (or align) transcriptions to audio files at the phone level. They are called forced aligners because they 'force' a match between transcription and sound; they will not correct a transcription. The forced aligner will use an acoustic model of a language and a dictionary of words in a phonetic alphabet to match phone to the acoustic signal. Some forced aligners use acoustic models from English or other majority languages and some forced aligners create an acoustic

Exercise 4.2 Switchboard investigation

Take a look at the Switchboard-NXT

model of a language as part of the alignment process, such as the Montreal Forced Aligner

Phonology

Many phonological research questions will use phonemically transcribed corpora. Rather than basing analyses on acoustic measurements, like with speech corpora research, the analyses are based on the phonemic transcriptions. For some languages, the written words are similar enough to their phonemic representations that text corpora can be used to examine questions relating to phonology. Below we give an example of corpus research on Tagalog phonology

Tagalog is the official language of the Philippines and has over 70 million native and second-language speakers. It is an Austronesian language with infixes, such as -umthat marks realis aspect and infinitives (4.20).

(4.20) bago 'new' > bumago 'to change'

Whether or not speakers have the perceptual bias described by

Morphology

We now move away from sound to meaningful parts of words: morphemes. Let's look at two studies that use corpora to answer questions about morphology relating to the productivity of morphemes. Productive morphemes can be used with many words such as the -ness suffix for nouns deriving from adjectives in English (happiness, sadness, completeness). They can also be used to form novel words: 'she was overcome with upsetness' would probably be understandable to a reader. Non-productive morphemes can only be used with a smaller frozen subset of words, such as the -th suffix for nouns deriving from adjectives (warmth, length [from long + -th]). A novel word such as calmth would probably be confusing for most readers and older words such as dampth have fallen out of usage and have been replaced with dampness underscoring the productivity of -ness. We will look at two studies on morphological productivity:

Morphological productivity has impacts on both linguistic theory and computational tools. Some theories of grammar, such as early generative grammar, consider the lexicon to be split into two kinds of word creation. There are productive rules which are dynamic. Only the rule needs to be learned, not the words it generates. There are also unproductive rules that account for existing structure but are not used to create new words. The words generated through these rules need to be learned (cf.

in this emerging new theory, morphological productivity can be understood as resulting from a great many factors such as the individual language user's experience with the words of her language, her phenomenal memory capacities, her conversational skills, her command of the stylistic registers available in Levels of linguistic representation her language community, her knowledge of other languages, her communicative needs, her personal language habits and those of the people with which she interacts.

Corpora can be used to assess these factors, and all of these conditioning factors have been identified in corpora. Corpora show the probabilistic nature of morphological productivity, among other aspects of language use, and challenge traditional theories of the conception of language. Computational tools also need to take morphological productivity into account, as new words can always be created through productive word formation. If you wanted to create a computational tool to process language data, it needs to be able to process new data it has not encountered before. No training data or lexicon will be sufficient because people can always create new words, so productivity rules need to be built-in.

How can productivity be assessed? Morpheme categories with high membership (realised productivity), growing membership (expanding productivity), and potential for membership growth (potential productivity) are considered productive using different kinds of measures of productivity

Hapax legomena can be taken as a proxy for neologisms, although many will be old words that are simply too infrequent to occur in a corpus more than once. In any case, if a morpheme occurs often in the hapax legomena words, it is a hint that it can be used for new words. Potential productivity is important because if a morpheme already occurs in most of the words it can occur in, then it has little chance to grow the lexicon or be used on new words. Dutch has two suffixes used for creating agent nouns from verbs (as in English give > giver, bake > baker):

-er 'unmarked agentivising' (Dutch geef > geefer 'giver')

-ster 'female agentivising' (Dutch geef > geefster 'female giver').

There are many existing words in Dutch that already have the unmarked agentive suffix -er, and far fewer that have the female agentive suffix -ster. That means many new agent nouns could be created from verbs with the latter, but not the former. This

Hapax legomena are words that only occur once in a corpus. Hapax is a Greek word for once and legomena is the plural of legomenon meaning said, the participle of legein 'say' .

difference in expanding productivity of -er and -ster is due to a reluctance of Dutch speakers to explicitly mark gender for these kinds of nouns

Part of morpheme productivity is people's ability to segment the morphemes in a word, so that they can identify and then use a morpheme in additional words. Knowing sets of words with and without a particular morpheme helps this segmentability, as in happy and happiness. Knowing both of these forms help segment -ness from happiness. Morphemes are also more segmentable when they are in multimorphemic words that are more infrequent than their uninflected counterpart

Productive morphemes can enter a language from another language through borrowing. A commonly assumed pathway is an indirect strategy, where people borrow many words from another language with a particular morpheme and then use analogy to apply that morpheme to native words. For example, many French words with the adjective from verb deriving suffix -able were borrowed into English (profitable, honourable, deceivable) and -able was later used to derive adjectives from native verbs (knowable, speakable, workable).

Exercise 4.3 English past tense morphemes and productivity

The irregular past inflexion -t is associated with words of a certain phonological shape: sleep, weep, keep. But other and newer words of the shape (i.e. bleep) use the regular past tense inflexion -ed. Make a list of all the [eep] verbs you can think of and compare their past tense forms. Which past tense morpheme is likely to have higher realised, expanding, and potential productivity if you measured it in a corpus and why?

Levels of linguistic representation

An example of what is likely to be a direct borrowing comes from Zamboangueño Chavacano, a Spanish based creole from the Philippines with the prefix ika-. This language has cardinal numbers from Spanish (uno, dos, tres 'one, two, three'), but ordinal numbers with the prefix ika-(ika-uno, ika-dos, ika-tres 'first, second, third'). The prefix ika-is from two Visayan (larger family Austronesian) languages with which there was high contact during the 1800s. There are no complex loan words with ika-, only the hybrid forms, and there is no evidence that there were ever cardinal numbers from the Visayan languages in Zamboangueño Chavacano. Therefore, it is likely that ika-was borrowed directly, rather than as part of a set of complex words that all had replacements with hybrid forms.

A likely example of direct borrowing, but at a lower probability, comes from the noun classifier -ga used for 'plank shape' which was borrowed into Resígaro (Arawakan language of the Amazon) from Bora (Boran language of the Amazon). Many Resígaro speakers know Bora, despite the languages being unrelated. A Resígaro corpus

A likely example of a primarily indirect borrowing strategy comes from an agentivising noun deriving suffix -ero~-era borrowed into Northern Chinchay Quechua (Quechuan, Ecuador) from Spanish. An existing Quechuan corpus (cf. Bakker and Hekking 2012) of 80,000 words was used to identify 54 wordforms with -ero~-era, 47 of which were complex loan words with this suffix. This is a high ratio (47:54) of borrowed words with the morpheme to the overall number. Additionally, about 70% of the complex loan words have a simplex loan word correspondence, and 40% of these are infrequent relative to the simplex correspondence. Taken together, these distributions present a much stronger likelihood of indirect borrowing, even though most Northern Chinchay Quechua speakers probably also had knowledge of Spanish at the time of borrowing.

These two studies use a series of corpora to show and assess gradient phenomena in morphology: a cline of morphological productivity and a cline of directness in morphological borrowing. The clines are evidence against previous theories of distinctions in grammar or assumptions that a process does not exist. Corpora, then, are used to demonstrate that it is imperative to assess what actually happens in language use when constructing theories of language.

Syntax

In the sections above, we have described corpus studies that investigate phenomena at the word level or smaller. Searching for such phenomena requires some string information and some annotation. However, linguists also use corpora to look for phenomena at the constituent level in syntax. This can be difficult because string information is less useful at this level to identify tokens. Take for instance a category like subject or object. These could be any number of different nouns, NPs, or even zeros like in Spanish ø tengo la mejor madre del mundo 'I have the best mother in the world' .

One way to deal with this is special kinds of syntactic annotation (cf.

Afterwards, examples are coded for various factors. This is often hand-coding in combination with some automatisation. Below we describe a classic study that uses corpora to investigate the factors that influence the predictability of syntactic constituents: the order of recipients and themes in English

In

The authors test variables that are likely to affect the dative structures including:

• Accessibility of recipient versus theme (i.e. which is more accessible), often determined by seeing which is definite or expressed with a pronoun

• The length of the recipient versus theme

• The animacy of the recipient Interestingly, many of these variables pattern together (are correlated). For instance, pronouns are short, but they are also accessible, and often refer to animate referents. So, assessment of the contribution of these factors needs an appropriate kind of analysis.

The question of dative alternation and other structural alternations has been taken up in other varieties of English such as South Asian English varieties

Discourse

Discourse is the level of language use beyond the sentence, as there exist structures that only enfold over a text. Studies of discourse most often are of spontaneous spoken language, often conversations. As with many of the levels of usage we have described here, certain annotations help corpus linguists look for the particular kinds of phenomena relevant to their studies of discourse. For example, the Switchboard corpus has annotations of dialogue acts

There has been quite a bit of linguistic research on discourse in healthcare settings, the vast majority of it on English. This is a kind of interaction many people engage in and it can be high stakes, making it important that people understand each other. Much of this work falls under applied linguistics because it is an area where awareness of interactions can help address common problems that arise.

Levels of linguistic representation

data, particularly on which stages of the interaction featured which of these devices and to what purpose.

The health professionals were identified as using politeness strategies and language convergence. Additionally, language was used to establish relationships as part of health assessment, because this presumably leads to better outcomes and callers are more likely to give information and take healthcare advice. Researchers identified several recurrent themes:

• positive affirmation (OK, right) was used to establish that the health professional is accepting the patient's situation and concerns.

• modal verbs (may, can) were used for politeness and to avoid imposition on patients (cool baths may help itching)

• if was used both as part of the diagnostic dialogue (if you push on them…do they fade and come back again) but also as part of hypotheticals (if you are in pain…) which is part of politeness.

• or anything? was used as part of politeness (are you coughing or anything?) but is also helpful in diagnostics as it encourages patients to disambiguate or provide more information and may result in better information than just going through a checklist of symptoms.

• As part advising patients, the researchers identified strategies such as credentialing to give weight to advice but also to avoid creating an asymmetry between the caller and the health professional, allowing the caller to preserve face. So, rather than a directive coming from the health professional, they would instead give advice from manuals and books.

• Closing interactions, where the health professional has an active goal to assess if advice will be taken by the caller or not, feature multiple questions about next steps and reiterations and summaries from the conversation before allowing the call to end.

This study is a good example of how interesting and important information can quickly and easily be gleaned from even a small corpus. Keywords, a simple tool, were used as the initial assessment to build upon further. The corpus approach also helped see multiple real interactions (at least from the side of the health professionals) to assess the patterns in this institutional setting.

Exercise 4.4 Applied corpus linguistics

What benefits could a healthcare corpus have for patients and health practitioners? What about situations where people who use different languages interact? What would the corpus need to look like?

Let's turn now to a quantitative study within discourse analysis.

Factors relating to cognitive processing:

Because people in a conversation must listen and understand (mostly anyway) each other and respond quickly and appropriately, one could hypothesise that the gap between conversational turns could be shorter when everything is easier to understand (low-processing demands) and longer when there are difficult or complex things to understand (high-processing demands).

• T1/T2 turn duration -a longer turn from the speaker (T1) might be more complex, requiring more processing time before the next speaker can start, and a longer turn from the listener (T2) might require more planning, so turn duration is expected to increase FTO times.

• T1 speech rate -a faster rate of speech from T1 may lead to a shorter duration, meaning T1 turn duration and speech rate necessarily interact. Fast speech may Think about other fields where language use really makes a difference to people's lives like legal proceedings or air transportation. These are fields where corpora are used. Do a basic literature search to find how research questions have been mapped to corpora in one of these fields.

Levels of linguistic representation lead to a higher amount of speech for the interlocutor to understand in a shorter period of time, leading to a longer FTO for planning purposes. Finally, T1 speech rate might also interact with the kind of turn being taken, which may also have an effect on FTO times.

• T1 tree height -this variable was used as a proxy for complexity, by counting the number of nodes between the tree root and tip based on syntactic tree annotations and taking the largest height for the turn. More complex speech may be more difficult to process, leading to longer FTO times for planning.

• Frequency, surprisal, information density -frequency information was calculated based on Switchboard word frequency. The Surprisal measure was taken from

Factors relating to conversational sequential organisation:

A history of work on conversational analysis has shown that people are sensitive to social norms in conversations and tend to avoid both long gaps and interrupting each other. Additionally, people tend to follow patterns in conversation (as we saw above in

• T2/T1 initiating -this variable codes whether or not the turn was a question (or another kind of conversational pair beginning) that initiated an expected action from the interlocutor.

• T1/T2 responding -this variable codes whether or not the turn was the responding pair to a question or initiating a turn, showing the other side of the initiating variable. This obviously interacts with the previous variable as questions with preferred answers will likely have a short FTO because it is part of a routinised kind of sequence, but longer FTOs are expected if a listener has to work to form an appropriate response. Long FTOs may also signal that a listener does not want to comply with a request.

All of the factors that the authors hypothesise to have an effect are complicated, are expected to interact, and are expected to have non-linear effects on FTO duration.

Because of this, the authors choose to use a random forest analysis, a kind of quantitative analysis more robust to non-linear effects and interactions than linear regression (cf. 8.4.2). The authors ran analyses on just under 20,000 FTOs from the Switchboard corpus and then ranked the importance of the variables in relation to each other. The authors found that the most important variables were whether the T1 includes a responding action, T1 duration, T2 duration, and T1 speech rate. A random forest analysis provides a ranking of variables but follow-up tests need to be done to understand the directionality of effects. The authors found that FTOs were shorter when the T1 includes a responding action. This is reflecting that many T1 responses are followed also by T2 responses as both speakers show their agreement or assessment in turn (A: "that was funny, right?", B [T1]: "Oh yeah", A [T2]: "Yep"). The fastest mean FTOs were between T1 initiating and T2 responding actions, and the longest mean FTOs were between two initiating turns, showing perhaps the need for clarification.

Moving on to durations and rates, the authors found that both long T1/T2 and very short T1/T2 durations were associated with longer FTOs, and the authors take that to mean that turn duration is a covert proxy for the kind of turn with very short turns being backchannels and agreements and longer turns being statements, opinions, and questions. Faster T1 is also associated with longer FTOs, possibly reflecting a need for longer processing. Female participants were also found to have faster FTOs. Females overall had slower speech rates, so this factor may be interacting with T1 speech rate. Perhaps surprisingly, variables like frequency and surprisal were not ranked very highly in the random forest ranking, showing that these effects are small outside of a laboratory setting.

Overall the authors were able to take advantage of a well-annotated corpus and apply a fitting quantitative analysis to show that factors from both processing and conversational norms interact and have an effect on conversational interactions. Because of the many interactions and the many proxy effects, the study also provides the basis for future research looking at some categories in more detail, which may require additional annotation. Studies relating to conversational analysis are often nowhere near as large as this one, so we see the opportunity in utilising large corpus data to help bolster previous analyses and provide the springboard for future analyses.

SIGN AND GESTURE

Corpus building for the documentation and study of signed languages and gestures requires some special considerations. The primary data for such corpora are necessarily video-based. To make the data machine-readable, some kind of transcript is required. What that transcript might be can be very complicated, as the data must necessarily be annotated as multimodal: speech and gesture, manual signs, mouthing and gesture, right hand and left hand, manual signs and facial gestures and other combinations, and all of the above. A gesture-unit or a 'G-unit'

Levels of linguistic representation

(Australian signed language) corpus

Understanding manual gestures (as opposed to bodily gestures or facial gestures such as eyebrow-raising, which have received less attention) is a large area of study.

Manual gestures are present in both signed

Let's focus on a signed language study and take a closer look at

Exercise 4.5 Using a sign language corpus

Take a look at the Auslan corpus or British Sign Language Corpus

that influence the form that they take. The corpus consists of 20 retellings each of the fable The boy who cried wolf and the picture book Frog where are you?

The authors point out that the act of reference is about directing attention to something to establish it as a concept for further commentary and then using our semiotic repertoire to characterise it in some way. The repertoire of devices available will differ based on the mode of communication. For instance, pointing is available (to both signers and speakers) in face-to-face communication, but not in writing. In many studies of reference in spoken languages, researchers (including your textbook authors) have focused on distinctions between lexical NPs, pronouns, and zeros for referent expression. They tend to look at predictors such as salience, accessibility, referential distance, and animacy to explain the choice of one type of reference over another. In signed language studies of reference, researchers have looked at different strategies such as pronominal pointing, indicating signs, depicting signs, NPs, and enactment. They also focus on issues such as the grammatical role and cognitive accessibility to investigate which strategies are used.

The idea of cognitive accessibility is common to both signed and spoken language studies, that is, will the observer know what the language user is referring to when they use the referring expression? A zero or pronominal point is fine if the language user is referring to an established referent or something salient such as the signer/speaker or observer, but will be difficult to map onto a referent brought up for the first time. A 'heavier' and more informative referring expression such as a lexical NP (that big dog) can be used for something less salient.

The researchers used their corpora to quantitatively examine 4,699 referring expressions and investigated,

• the activation status of those referents: introduced, maintained, or reintroduced

• animacy of the referent: humans, animals, inanimate objects

• the form of the referring expression including, ¡¡ lexical manual sign ¡¡ mouthing (the mouth movements of speaking the referent in its spoken form)

¡¡ fingerspelling (signs for each letter of the written English form of the referent)

¡¡ partly lexical sign (i.e. maybe has a handshape or orientation like the fully lexical sign but another specification comes from how this form maps onto the dynamic signing space)

¡¡ pointing sign ¡¡ enactment (some bodily action that is conducted as if the signer were the referent)

¡¡ invisible surrogates (where a combination of actions create the impression of an entity in the signing space and the signer behaves as if that entity were present)

• phonological heaviness: operationalised as the number of strategies used in the composite utterance of a referring expression as the forms (above) can co-occur simultaneously, sequentially, or both

Composite utterances

In the researchers' study, they found phonological heaviness to range from 1 to 12, with very heavy references (8+ strategies) often a sign of disfluency or need for clarification. To assess phonological heaviness, the researchers modelled their data with mixed-effects linear regression. Their model includes a random effect for the study participants, as the researchers are looking for effects that hold beyond the variability or style contributions from particular signers (see Chapter 8 for more information on random/fixed effects and linear regression). Their model shows that referents are heaviest when first mentioned, less heavy when reintroduced and least heavy when maintained. This fits in with theoretical research that referents that are very salient (easily understood in the conversation) are expressed more minimally.

Their model also shows that human referents are expressed with fewer strategies, as human referents also tend to be very salient. Inanimate referents were more phonologically heavy and animal referents were the most phonologically heavy in their data, and this was particularly seen in the cases where animal referents were reintroduced. The kind of narrative did not show a significant contribution to phonological heaviness, showing that these patterns are robust across two (somewhat) different kinds of data.

Hodge et al. 's (2019) regression analysis of phonological

heaviness is what we classify as confirmatory statistics. The researchers had a clear hypothesis based on the theoretical literature and then tested if the hypothesis was confirmed for their data. Importantly, they add value to their overall look at reference in Auslan by pairing this with an exploratory analysis which is intended to give insight as to the kinds of strategies (lexical manual signs, English fingerspelling, invisible surrogates, etc.) used in particular circumstances. For that analysis they use principle components analysis and we recommend going to the original article for more details about how that was done and what the specific results show. Overall, their takeaway was that conventionalised signs such as lexical manual signs and English fingerspelling were used most often to introduce new referents. Next, English mouthing (easily combinable with manual signs) was used across many different circumstances. Also, humans and animals were often maintained or reintroduced with visible and invisible surrogates, meaning that after referents are introduced in a more conventional manner, less conventional kinds of strategies can be used to keep these referents in the discourse.

Finally, the researchers also discuss the importance of non-conventionalised strategies in reference, particularly invisible surrogates. Remember, these are references implicitly built up from other strategies that let the interlocutor know that something exists in the signing space.

In sum, Hodge et al. (

CONCLUSION

The aim of this chapter was to provide you with an overview of the many kinds of linguistics one can do with corpora. Corpora provide an empirical basis to explore and test hypotheses, but the kinds of questions one can ask are limitless.

FURTHER READING

Newman et al. (

NOTES

1. tho and they' d might have struck you here as strange for academic writing.

2. Although Zuraw's corpus is unpublished, there are now large, web-corpora of Tagalog available including a TenTen family corpus (

GETTING STARTED

The basic steps for corpus linguistics:

(1) put together corpus data

(2) get corpus data loaded into a program for analysis

(3) label/annotate your corpus data (4) search your data

(5) analyse frequencies and distributions of your data While it would be ideal if we could give readers one straightforward, foolproof way of doing this, we cannot. Corpus data comes in many different formats, and there are easily hundreds of methods, tools, and strategies that are possible. What we might recommend today (a certain corpus tool, a certain programming package, or module) might not be available three years from now, or might have advanced so much that our information is out-of-date. This is both the exciting and frustrating part of corpus linguistics. There is always something new being developed that can improve our work, but it means specific previous strategies eventually become obsolete. This chapter will guide you through common strategies for searching and analysing data.

CORPUS QUERIES

Frequency lies at the heart of corpus linguistics. The main reason to use a corpus is to find real examples of language use in context and count how frequent they are.

The primary aim of corpus linguistics is to understand linguistic patterns and explore how and why they occur. The first step is to obtain frequencies, and the more complicated subsequent steps of understanding what the frequency means is the job of the researcher.

To obtain frequencies or examples, one must engage with the corpus or 'query' it. Most corpus linguists will not read through an entire corpus. Usually, it is too large for us to engage with systematically. Instead, we will pull out relevant information and put it into a format that makes it possible to study it further. Some kind of software on a computer or interface on the web will be used to do this. Most text editors and word processing programs have a search function that will allow a user to find segments, words, or phrases. Specialised corpus software and web interfaces also have means of finding examples and often have ways to save those examples to a new document or spreadsheet for further analysis. Many of these programs will provide basic descriptive statistics of the data, such as number of occurrences, bigram frequency (cf. 5.6), mutual information (MI) (cf. 5.7), etc. It is worthwhile to explore various tools whether you are new to corpus linguistics or are a seasoned veteran.

Example software and what they can do

AntConc and additional Ant-programs -These are text processing programs specialised for corpus linguistics, providing concordances (examples in context) and frequency counts, as well as providing basic functions like breaking up texts into smaller parts and allowing for the export of search results to various formats.

ELAN -This software is intended for audio-visual data and allows a user to transcribe and annotate their data in a number of ways. Additionally, it has corpus search functions that can be used over one or more files to find example strings (words, phrases, parts of words, etc.) in context. It also provides n-gram statistics and can export data into a number of formats for further processing and analysis. Examples in Chapters 6, 7, 10.

Example web interfaces and what they can do

These sites have multiple corpora plus an interface to access the corpora for searches, word frequency counts, bigram counts, and more. Each of them has some corpora that have been annotated with additional information like parts of speech (cf. 7.2.3) and lexeme (cf. 2.2.2). In some cases, you can also download the corpus data for your own processing with additional software.

English Corpora -a site with several very large corpora of English, including a 14-billion-word web corpus, as well as additional corpora of specific English genres and other languages. The corpora can be purchased for a fee, or used online through a simple user interface.

Programming languages such as R (R Core -packages in the 'tidyverse' are also used for efficient data processing, particularly with specialised syntax using pipelines.

ggplot2

There are many additional specialised add-on packages.

Quanteda

stringi

Sketch Engine -a site with several large corpora from various languages. Sketch Engine (and NoSketch Engine) also allow users to upload their own corpora for 'word sketches' (detailed collocate information).

Corpus queries

Corpus queries 71

FREQUENCY LISTS

Frequency is the most basic corpus measurement. In many early corpus linguistics works, you will find frequency tables as a primary account of data. Frequency tables display the amounts of something occurring (a word, a morpheme, a word category, a construction, etc.) usually in one condition or another. Frequency tables are helpful, as they are fairly intuitive to understand. In one condition there is more of something, in another condition, there is less and then we can build hypotheses and extrapolate theories from that. In corpus linguistics, we worry about both type frequency and token frequency (cf. 2.2.3) that can tell us different things about our corpora. As a review:

Token frequency -a count of all instances of something in a corpus.

Type frequency -a count of all the unique types there are of something in a corpus So, in a corpus of a million words, there will be a million word tokens. Of these, there may only be 200,000 word types.

Further, we can make a distinction between wordforms and lexemes, which, depending on the research question can be an important distinction (cf. 2.2.2). Take a look at this sentence: He went away and then he was gone altogether. This sentence has nine separate word tokens and eight word types, as he is repeated. Capitalised He and lowercase he should be considered to be the same word type. This sentence has seven lexemes because went and gone are both inflexions or wordforms of the lexeme GO.

Example Python modules and what they can do

The Natural Language Toolkit (NLTK)

Below is a table of the top ten most frequent lexemes from the one billion word COCA

Notice that for both COCA and iWeb the most frequent words are function words. This is the case for any corpus. Because of this, sometimes stop lists are compiled of function words and any word in the stop list is not reported in frequency counts. The idea is that the less meaningful words are excluded, giving someone more insight into the corpus. Exercise 5.1 Stop words

(1) Compile an example stop list for English and one other language by listing out all the stop words you can think of.

(2) Look on the internet if you can find stop lists for your additional language. You will certainly find stop lists for English.

(3) How did your stop lists compare to the ones you found online?

(4) How different are the stop lists for English and the other language? What are the differences and why do you think that is the case?

(5) Think of a research question where it would be important to not exclude stop words.

Corpus queries

Keywords

Keywords are used in some kinds of corpus linguistics to show differences between corpora or between sub-parts of a corpus. Keywords are calculated by assessing all the word frequencies in each of the two (sub)corpora and doing either chi-squared tests or log-likelihood measurements to assess what words are statistically more frequent in one (sub)corpus than in another. These are then the keywords. Usually, these kinds of keywords are lexical items (nouns, adjectives, verbs) that give us an idea of the topics in the corpus. However, the keywords could be, say, pronouns if one corpus is conversational and another is from monologic or written sources.

GRAPHICAL FREQUENCY DESCRIPTIONS

Frequency plots

Corpus word frequencies are often plotted on graphs, and as seen below in Figure

Dispersion plots

Corpora are not random bags of words. They consist more or less coherent texts, and these texts consist of ordered strings of words (cf. 2.2.1). There are multiple ways to measure the dispersion of a word or collocate. One option is a dispersion plot. This is a visualisation of where a word or collocate occurs in a corpus. Two words with the same frequency might occur often only in a handful of texts, or more consistently across the entire corpus. These words would have equal frequency, but different dispersions. Within a text, some words may be restricted to particular sections, which is also useful to know. For instance, we might see the end most often at the end of a corpus of children's stories and rarely at the beginning or in the middle of the texts in that corpus. Take a look at Gries (2010b) for more on measures of dispersion.

ZIPFIAN DISTRIBUTION

An early trailblazer of corpus linguistics is George Kingsley Zipf. One of the first things many corpus linguists plot is the frequency of the words in a given corpus to see which words are most and least frequent and to examine the frequency distribution. Often that distribution follows Zipf 's law.

Many distributions of corpus data follow the Zipfian distribution, where there is a 1-to-1 logarithmic (log) relationship between the rank and frequency of events (i.e. words). In Figure

Logarithmic transformation is converting a measure to a log scale. A log scale puts a wide range of values on a more compact scale, where the next value on the scale is a multiple of the previous value.

Log 10 scale increases: 0.1, 1, 10, 100, 1000, 10,000, 100,000 and so on Log 2 scale (binary logarithm) increases:

Note that the tables below display information about bigrams, not trigrams. That is, the tables report information about two-word co-occurrences, not three-word cooccurrences. While there will certainly be instances of a woman who in the SOAP, the table is reporting separate frequencies of a woman and woman who. You can check for yourself the frequency of a woman who in the SOAP and SCOTUS.

Exercise 5.2 Corpus laws

Look up information about George Kingsley Zipf. Who was he and what were his most important contributions?

What is the Zipf-Mandelbrot distribution?

What is Heap's law? It should be obvious to you that the w-1 frequencies are higher than the w+1 frequencies for the most frequent preceding words in both corpora. This shows a very strong likelihood for woman to be preceded by a, meaning the collocation of these words is highly predictable. This kind of predictability can be captured with measures such as conditional probability, entropy, and MI scores (cf. 5.7).

Just like with word frequencies, bigram frequencies may sometimes be calculated using stop lists so that common function words are excluded. The idea being that the word a in the sentence You want to be a woman of mystery is not actually giving much information about woman because although a co-occurs with woman very often, a also co-occurs with so many other different words. Whether stop lists should be used in calculating bigram frequencies really depends on the research question. For instance, researchers interested in semantic connections between words will probably want to exclude many function words through a stop list, but researchers interested in processing sequential information may not.

Bigrams can also be limited to certain kinds of combinations. One noticeable difference in the words preceding woman in the SOAP versus the SCOTUS is the adjectives used. This is a clue that adjectives may be a place where we see more register effects than with function words. So, we can look at the most frequent bigrams of adjective + woman in our two corpora to see if these are very different. In the english-corpora.org query language, this would be done with a search for _j* woman, as _j* is a shorthand to mean all adjective types. There are numerous measures of association that can be used to capture these kinds of differences, including conditional probability, MI, and informativity among

Below are some common measures that can be used to measure the association between words. There are many more and some strains of corpus linguistic research favour different measurements, either due to historical development of the sub-field or due to specific research goals.

Joint probability P(xy) -Joint probability is simply bigram probability: how often do words co-occur with each other? It is usually normalised by the corpus frequency (note that in scientific notation, e is used for very large or very small numbers. e-5 means move the decimal rightwards 5 digits). Because we are sometimes working with very small numbers, probabilities are often logarithmically transformed (cf. 5.5). This puts the numbers on a different scale, making probabilities and frequencies more comparable. Comparing these probabilities, we see that the backward transitional probability is larger than the forward transitional probability. This matches the intuition we should have from above, where beautiful woman is more predictable given woman than given beautiful.

Here are some good resources on kinds of association measures and examples of their use:

•

•

Analogous to conditional probability, conditional entropy is a measure of uncertainty of x when y is known. To compare how different corpora are, one can use relative entropy, also called Kullback-Leibler Divergence

•

• Gries (2010b) on useful statistics for corpus linguistics

CONCORDANCES AND KEYWORDS IN CONTEXT

Concordances give contextual information about a word, showing the context in which it occurs. Often a concordance display gives information about the word by putting that word in the middle of a line with a certain amount of words preceding and following it. This kind of display is called keyword in context or KWIC. This is a good method for a heuristic or first-pass look at data. Concordances are usually more understandable for a human than a list of bigram frequencies. Some corpus programs will highlight collocates of a word of interest with different colours depending on their parts of speech. This can help a researcher start to identify patterns.

A KWIC can usually be sorted alphabetically or by frequency of co-occurrence of w-1, w-2, w-3, w+2, w+3 etc.

Below is an example concordance from COCA of adjective + woman, showing the first five lines. The data is sorted alphabetically by w-1.

Exercise 5.4 A KWIC look

Using COHA, find the KWIC view and return results of woman. Sort by w-1 and then by w-2. What kinds of contexts are occurring in each of these instances?

Now try again using _j* woman and see that you can return contexts on various bigrams (cf. Figure

TRIGRAMS AND N-GRAMS

A bigram refers to two words that occur next to each other and a trigram refers to three words that occur together sequentially. The term n-gram can be used for any number, that is, n of words that occur in a sequence. Usually we do not use the term n-gram to refer to single words (which would be 1-grams) or bigrams (2-grams). However, for sequences of three and especially four or more words, researchers often use this shorthand: 4-grams, 5-grams, and so on.

In a large corpus, you will see many bigrams that occur more than once. However, you will see far fewer 3-grams (a lot of) or 4-grams (a lot of people) repeated, as in

COLLIGATIONS AND GRAMMATICAL CATEGORIES

Finding strings of characters or words is relatively easy in a corpus. However, many times researchers are interested in sets of words or 'kinds' of words that may Exercise 5.5 n-grams -quotidian or unique?

Write three 5-gram sequences in English that you think may have a chance of being repeated more than once in a corpus. Use the 14 billion word iWeb to test your theory and see how often each occurs (if at all). You may need to change the sort/limit options to return results with a minimum frequency of 1. Also try putting 5-gram sequences into an internet search engine surrounded by quotes.

If you cannot find any repeated 5-grams, try 4-grams. Also, look for 6-grams or higher n-grams using a web search.

What kinds of n-grams were you able to find that were repeated? encompass many different strings. For instance, if you wanted to examine noun modification by adjectives in English, or even qualitative adjectival modification of human nouns, there are many different nouns and adjectives to search for (cf. 2.2.4 on colligations and collostructions). So how do we find these? Or, for instance, if you were interested in investigating the dative alternation

A corpus that has at least some level of annotation will be very helpful in finding categories of words. One of the most common types of annotation is PoS tagging (cf. 7.2.3), which indicates the part of speech of each word in the corpus (also called grammatical tagging). Depending on how the tagging was done, there may just be simple categories such as verb, noun, adjective, or the categories may be more refined such as past tense verb, present tense verb, etc. One thing to watch out for with PoS tagging is that it is often automated. Hand-tagging an entire corpus, even a small one, is a monumental effort. Therefore, rules are often used to describe to a computer when to label a word with a particular category or another and then a tagger is run over the corpus. Usually a tagger is trained on a smaller hand-annotated sample and then applied (tested) on a larger corpus. This means that you get a lot of coverage quickly, but that there may be incorrect labels given to words. Some words may also get more than one possible label. This happens when a word is ambiguous and the tagger's rules cannot unambiguously determine the word category. There are also semantic taggers that give meaning information, among others. Tags are often somewhere 'in the background' , so if you are using an interface to query your corpus, you may not see the tags, although they will constrain your results. If you are using any tagged corpus, it is good to look through a portion of the actual tagged data before you start your searches so that you can adapt your search to what is really available in the corpus, not just what you expect or hope to be available. Searching for some constructions or grammar phenomena may require more than PoS tagged corpora.

For many languages there are no tagged corpora available, so to find grammatical phenomena, corpus linguists may have to rely on string searchers. Many constructions use particular words or strings or a limited set of these. When this is a small number, regular expressions can be helpful (cf. 5.11). Another way one can find grammatical constructions or search for grammatical patterns is to first identify the possible structures in a smaller tagged corpus and then use string information in a larger corpus (à la

Some kinds of grammatical phenomena are difficult to find with string searches. In that case, additional annotation for specific categories is probably needed. That is why many corpora are hand-annotated for a limited set of phenomena, although this can be time-consuming (cf.

Corpus queries

We have put a chart below of common regular expressions. Online you can find websites that help you practice your regular expressions on sample data.

In some, but not all, regex implementations, there are special regex character classes called POSIX character classes. These are written in lower case between brackets and colons and can be very helpful shorthand, but also always have an alternative regular expression.

Corpus queries

Corpus queries 87

Corpus queries

(1) every capitalised word in the text You need to be able to return/find:

(2) the last word of every question in the text

(3) all the text strings between punctuation

To do this (A) determine what it is that you need to return with a regex, then (B) in the regular expression part of the webpage type in appropriate regular expressions to return 1-3. Adjust/debug your expressions as needed. Answers at the end of this chapter. This does not mean that the original question has to be abandoned entirely, but you may have to confine yourself to certain aspects, or ask the question somewhat differently. In carefully documenting your queries, you also make your research accountable and replicable by others.

WORKFLOW

ANSWERS FOR EXERCISE 5.6 ON REGEXES

(1) Match every capitalised word in the corpus:

(A) All strings starting with an uppercase letter, followed by zero or more lowercase letters

Where is Bob? He's in the office. Could you call him? Sure, no problem.

(2) Match the last word of every question in the corpus:

(A) any number of letters, upper or lower case, followed by a question mark (B) [a-zA-Z]*\? or \w*\? 2  = Where is Bob? He's in the office. Could you call him? Sure, no problem.

(3) Find all text chunks between punctuation: FURTHER READING

NOTES

1. In Information Theory, MI can be used to measure the mutual dependence between any two random variables, not just words. In corpus linguistics, it is also often used to measure the strength of association between phonemes or between a word and a construction it can occur in. 2. For our example text, these regexes return the same information. \w also includes _ so if the example had an underscore, then they would no longer return the same information.

STEPS FOR AN IDEALISED CORPUS

Corpus types and goals

We have so far considered mostly pre-existing corpora, whether those from large, wellresearched languages or those stemming from smaller-scale documentation. In this chapter we turn our attention to the process of corpus building (or corpus compilation) itself. Often, especially at more junior stages of your career, you will not be in a position to build an entirely new, large corpus of a language, especially not if that language has a long research tradition and hence a large academic community. However, when it comes especially to the documentation and description of smaller languages that have not previously been investigated in much depth, you may be involved in corpus compilation to a considerable degree, including having to make relevant decisions on corpus design and structure. Finally, whether you work on well-researched or lesser-studied languages, considerations of corpus design will also apply to compilations of small, focused research corpora which may or may not draw on larger, pre-existing corpora.

The following sections are arranged along these three basic types of scenarios. We will present the issues of this chapter from a practical perspective, assuming that we are the compilers of a corpus. Many of the considerations involved here are also relevant for the reverse perspective of a corpus user or analyst who needs to understand considerations of corpus compilation (both theoretical and practical ones) in order to properly evaluate their corpus findings. While this typology is quite selective, leaving aside many of the corpus types we mentioned in 3.3, the three scenarios presented here (summarised in Table

Corpus building 92

A Type 1 corpus in Table

A Type 3 corpus is created with a fairly narrow research focus in mind, possibly in an attempt to answer a single research question, or a small set of interrelated questions. Such corpora may draw on pre-existing texts, including those contained in a larger, general corpus, or include specifically collected texts, for example, texts elicited during controlled experiments. While Type 1 and Type 2 are normally dynamic corpora (and in principle often monitor corpora [cf.

For any of these types, corpus building involves the selection and/or collection of texts or text excerpts and their inclusion in some form of data infrastructure. The latter term is to be understood here in a broad and non-technical sense, meaning simply that in order for a range of texts to form a corpus they need to be compiled in some form and accessible in some way. In other words, the texts need to form some framed whole, a collection rather than a series of texts.

A very first step for a corpus builder is to identify texts that are relevant for the envisaged corpus and should be considered for selection or collection. This initial step crucially depends on the corpus and its goals, for example, which language or variety and which situational features thereof should be represented (cf.

Corpus building

Corpus building 94

Any corpus building project is influenced by two competing sets of factors: the first are represented by certain design principles that take into consideration ideals of representativeness and balance given the intended purposes of the corpus (cf. 3.1). The second set of factors are essentially those concerning practicalities of data availability and necessary efforts of data processing and representation vis-à-vis confined resources and other considerations. These two sets of factors actually create a tension between the ideal representative corpus and a deviation thereof. In practice, the process of data collection and/or selection will ultimately be guided by the latter considerations. We will first outline general corpus design principles and then turn to the more practical issues of data collection and/or selection in Section 6.2.

Identification, selection, and evaluation

A principled problem for corpus compilation lies in the fact that we can never be entirely sure about the entire range of text varieties found in the community of users of any given variety. For better-studied languages, we will often have at least some common-knowledge idea of attested text varieties, but corpus compilers will also need to draw on relevant findings from studies of text varieties (e.g.

For hitherto under-studied languages, this stage may involve much more research and identification of text varieties as part of linguistic and/or ethnographic fieldwork of a language community. As discussed in 3.1.6, a good first step in this process is to elicit names for text varieties or speech events from native speakers. Think of ways to collect maximally spontaneous, spoken texts from speakers of any language or variety. How would you go about doing this? What can you do to minimise planning opportunities? Write down different steps in your collection.

Once we have identified all text varieties that should be included, we need to decide how to collect relevant specimens and which ones of these to select for inclusion. Collection is chiefly relevant from a practical point of view, and we take it up again in the following section. Text selection is a non-trivial aspect of corpus building for general corpora: since we aim at a high degree of general representativeness, we need to consider carefully the composition of our corpus. One way to go is to approximate the composition of the population as estimated in some way (cf. Brown corpus) whereas the alternative is to aim for a balance of text varieties (cf.

What scientific considerations do suggest for a general corpus is that we should include a large range of text varieties with different situational characteristics, including large proportions of spoken and/or signed text varieties in the interest of greater representativeness. Moreover, although authenticity is not a demarcation criterion for corpora, spoken texts in particular should come from common text varieties as well and not be restricted to scripted or semi-scripted TV, radio, or otherwise broadcasted texts or texts elicited in experimental setups.

In order to be able to determine the size of our text collection and relevant proportion in subsections, we need to evaluate it accordingly. As we have discussed in 3.1.1, determination of corpus size is a non-trivial issue: we need to set the unit of measurement we find most appropriate -for example, orthographic or grammatical words -and then make sure that we can actually count tokens thereof -which may require tokenisation processes before counting can take place (cf.

Corpus building

Corpus building 96 compilation and processing/annotation in fact go hand in hand for most general modern corpora. After evaluation, you may determine that additional texts or text types are necessary to achieve better representativeness.

In a final step, we need to make the corpus accessible to the scientific community in order to fulfil the scientific imperative of accountability and to enable further scientific developments based thereupon. A further feature desirable from a scientific point of view may be modifiability or manipulability, that is, we may want to offer the opportunity to add further texts to the corpus as appropriate in given research contexts or to modify the corpus composition in other ways (e.g. by removing some texts, etc.). We will discuss different ways to achieve these goals in the following section.

Considerations of mode and script differences

General corpora are required to contain large proportions of spoken and/or signed texts, and likewise other more specialised corpora will contain texts of these modes. These modes differ from written texts in that the raw data is not readily amenable to inclusion in our corpus. For one thing, both require initial audio/audio-visual recording, which in turn brings about a myriad of situational considerations that we have to consider. These texts also need to be processed. In particular they need to be annotated, at least transcribed, and it is the transcription that will eventually resemble our corpus text. An essential requirement for corpus building is that all aspects of text production be available in some way to the users of the corpus. For instance, it may be relevant to know where pauses, disfluencies, or construction restarts occur in order to evaluate the use of a particular structure properly. This means that the transcription of spoken/signed texts needs to contain fairly meticulous special annotations for characteristics of text production. Furthermore, the corpus text should be linked to the recording media of the primary spoken/signed text in a time-aligned format. In 21st-century corpora this means that the corpus text and the linked media file be accessible from a single entry point, for example, a website or a corpus query software.

Corpus builders have to consider the use of different scripts. Since mainstream corpus linguistics focuses on English and other Western European languages, the Latinbased script used in these languages is most common, and relevant corpus software and query mechanisms are based on it. For languages with other scripts, for example, Cyrillic scripts in many languages of Eastern Europe and Central Asia or various scripts of East Asian languages (Mandarin, Japanese, etc.) corpus builders will either need to use encoding such as Unicode (cf. 5.11) or add a layer of transliteration to the corpus text. Solutions will depend on specific circumstances, and we merely point out the general requirements here.

CORPUS BUILDING IN CONTEXT

In practice, corpus building can never fully comply with the design principles just outlined. In this section, we will go through a number of scenarios and conditions that pose restrictions on corpus design as desirable from a purely scientific point of view. This does not mean, however, that considerations of corpus design become irrelevant on the ground, and we will point out what can be done better even under difficult circumstances. Finally, the shaping of any specific corpus-building project will ultimately depend on its purposes.

Whole-population corpora

While we will mostly be talking about restrictions on text data availability and usability for corpus building in this section, there is also the reverse deviation from the corpus design ideal, where a corpus can indeed be an exact copy of the population under consideration. Such population corpora are restricted to specific research contexts where a restricted set of texts is also the object of the research agenda. We mentioned this possibility in Chapter 2, namely, that someone interested in the specific properties of Obama' s published speeches could indeed consider all these speeches, and thus sampling is not necessary. A real example is

Availability of texts: copyright and privacy

According to our design criteria and our generalised corpus-building scheme, we select and collect texts carefully following considerations of representativeness. This ideal is confronted by restrictions on data availability. Data availability can be restricted in all sorts of ways. Consider again the major difference between published and private texts: where a text is published it is fixed to some medium in some basic format, whether digital or analogue. Although the texts are accessible, there are copyright restrictions in both cases, which limits the availability of published texts for corpus-building enterprises severely. Even some texts available through the internet may have some copyright protection or restrictions on usage. Private texts, on the other hand, are not subject to copyright restrictions, but here participants who have produced the texts may be much less willing to make these publicly accessible. Often private texts will, therefore, never make it into a corpus. Where they are included, permission needs to be obtained and documented, often under the umbrella of a university's ethics administration and in the form of informed consent. Sometimes,

Corpus building

Corpus building 98 when authors have waived their right to privacy (whether knowingly or not) this data can be used to compile corpora, such as the Multilingual Amazon Reviews Corpus

Technical, methodological, and other considerations

Restriction on resources, availability, and technical considerations -written texts that exist in digital format prior to any considerations of corpus building are fairly easily included in the corpus from a technical point of view. Web-crawlers can help compile massive amounts of written data for languages with a web presence. Texts that exist only in printed or even handwritten form on paper require work on digitisation so that the text is machine-readable. Options for dealing with this include optical character recognition (OCR) systems and manual typist work. For many languages, there are no written forms until language documentation projects start, so time-consuming transcription of spoken or signed texts are necessary.

Vera'a encyclopaedic texts about flora and fauna

Vera' a community members expressed concern over younger generations not having any knowledge of the names of floral and faunal species and the details of their specific features and uses. So, in addition to the more common texts from oral literature (myths, legends, fables) we also collected more than 100 plants and over 200 fish descriptions. We first recorded spoken texts, and one community linguist created edited versions based on the original recording together with its transcription. Similarly, two community linguists wrote up descriptions of bird species, and a smaller group of speakers created a mono-lingual encyclopaedic dictionary with definitions of parts of a house. Descriptive texts of this kind are not part of the traditional verbal behaviour of the community. Yet, their inclusion in the corpus does serve the community' s interest. Crucially, the descriptive texts formed part of the basis of our comparative study of object realisation in Vera' a

A corpus-building project can be explorative, and the encounter of new text varieties may be part of the evaluative step that may trigger further text collection. Specific scientific requirements -corpus linguists may need to manipulate, randomise, or control for different situations, often particularly relevant in experimental or comparative research designs. Options include elicitation, stimuli-based tasks, narrations of picture books or short movies (well-known examples include Mercer Myer's

Matukar Panau interactional texts

Matukar Panau research focuses on spontaneous speech and interaction between people of different ages, genders, and clans. This research programme requires the inclusion of larger amounts of conversational data, whose collection has been supported with stimuli-based tasks, including San Roque et al. ' s (2012) Family Problem set which combines individual picture description, a discussion between participants, and storytelling. Our project then has much more conversational texts, albeit about some specific topics, than mythical or procedural texts. (While this may seem like a fairly superficial exercise in a textbook, note that these kinds of formulation are in fact part of a grant proposal, for example, in the area of language documentation, where researchers have to demonstrate that they can plan a corpus project not only in terms of their research goals but also in consideration of other stakeholders.)

Corpus building

Corpus building 100

PRE-PROCESSING: TRANSCRIPTION, TRANSLATION, AND DIGITISATION OF TEXT

As pointed out above, spoken and signed texts need to be transcribed before they can be included in a corpus. And where the corpus text is in a language that is not known to the scientific community it needs to be translated to a more widely known language. We will explain both steps and related protocols in turn.

Spoken data transcription

Raw spoken-language texts cannot generally be analysed as such with standard corpus-linguistic tools and are therefore transcribed, that is, transposed into a written form, before they are included in a corpus. This written form is what we treat as the corpus text since this is what can be searched and further annotated. The major goal is to provide an accurate rendition of the spoken text in written form, including certain paralinguistic aspects. Transcription may be at a low level of granularity, transcribing only speech streams, or highly detailed including laughter, lengthening, breathiness, etc.

Let's look at an example from a prominently spoken corpus of English, the Santa Barbara Corpus of Spoken American English (SBC) (Du

(1) (6. The primary purpose of the transcription is to make the spoken text searchable. Without the transcription it would still be possible to find the same instances, but this would involve re-listening to the recordings and noting all relevant instances, a painstaking and unreliable procedure. The same applies to specific properties of speech production, for example, overlapping of speech or pausing: since these are captured as part of the transcription they are likewise searchable, for example, by using query expressions like the square brackets to extract instances of overlap or triple dots to find shorter pauses. Obviously in order to use these annotations, familiarity with the conventions is essential.

The task of transcription is by no means trivial and the decisions taken -where to note a pause or whether and where a word is truncated or not etc. -are not incontestable since human transcribers are always led -and potentially misled -by their understanding of the text and their expectations (cf.

Corpus building

Corpus building 102

These decisions, once fixated in the form of the written text that serves as the basis for corpus analyses, will carry over to all kinds of subsequent analyses. 2 Furthermore, a fundamental question is whether the transcribed word forms should be represented according to the conventional phonetic alphabet of the IPA or the more or less standard orthography of the language under consideration (cf.

We saw in (6.1) that in order to render the spoken text adequately, the transcriber needed to deviate from strict orthographic conventions. This better reflects the raw data. However, sometimes deviations may in fact be problematic.

Linking transcriptions to raw data

Since transcription is a non-trivial task that raises numerous analytical and even theoretical questions, it is vital for corpus users to have the possibility to consult the original raw data. There are different ways in which the raw data -the audio and/ or video recordings of the speech event -can be made accessible to corpus users: in the SBC, the solution is to store two types of file for each corpus text, one audio file containing the text recording in WAV format and a text file containing the transcription thereof. As we saw in (6.1), individual passages in the text refer to passages in the recording through time code information that allows users to navigate across the two files. A more sophisticated way of establishing a direct link between the recorded speech signal and its annotation is offered by specialised software that is designed to build up time-aligned annotation of media files. Time-alignment means that the annotation -of whatever kind -is directly linked to the rendition of the speech signal. The media file is also linked so that the signal can be played back and navigated from within the software. One example of such software is ELAN (ELAN Version 6.0 2020). ELAN has been developed by the Max-Planck Institute for Psycholinguistics in Nijmegen (Netherlands) and can be downloaded free from their website. 3 It has become one of the standard tools for working on lesser-studied languages and building corpora thereof. Like the SBC, a corpus created with ELAN will have two components, namely, a set of media files with the raw audio and/or audio-visual data and a corresponding set of ELAN document files (a special kind of XML file). But the key feature of ELAN is that users can create annotations while navigating and playing back the linked media file. Figure

Leaving aside all the detail in functionalities, the centre of the window consists of a sonographic rendition of the recorded speech signal. This information is taken from the accompanying WAV audio file which is linked to the ELAN file. Underneath this waveform are two annotation tiers. Both are cut up into chunks, and these segments are where annotation values are placed. Their borders correspond to begin and end time of a corresponding stretch in the sound files, and in this way, they create a direct link between a specific passage in the media and its transcription. This has several advantages. First, it relieves the burden on transcription to represent the raw data in maximal detail since the original recording can be accessed directly. This latter possibility has further advantages, for instance, research into the prosodic properties of spoken texts relies on phonetic measurements -for example, of pauses and speech rate; cf. Seifart (In Press) and references therein for an example -that will have to draw on such direct scrutiny rather than rough estimation according to acoustic impressions by human transcribers. Second, subsequent corpus users can much more easily re-evaluate the accuracy of annotations and potentially modify them or add further annotation detail, as required for any research agenda. Finally, it can be advantageous when working on hitherto lesser-studied languages if speakers of the language do the transcription, and do it in the form of a working orthography that deliberately abstracts away from all the phonetic detail. Phonetic detail can more easily and often better be determined objectively and through the use of specialised software. Hence, it can be strategic to separate these two transcription tasks and this can be done best if the media recording is directly linked with its annotation.

Corpus building

Corpus building 104

Rendering corpus text

We said in 6.3.1 that spoken texts are commonly transcribed in orthographic form. Typical for LD corpora is what could be called working orthographies which emerge as a result of the collaborative documentation project. Some kinds of orthography would be easier or more difficult for community members to learn and teach others. For corpus building efforts, in particular, one needs to consider character encoding. Unicode is easier to work with than characters with diacritics, for instance. One also needs to consider what a character represents. Having a series such as <ng> to represent a single sound may be easier for input than an engma character (ŋ), but will require consideration later on of what character counts mean for measures such as word length or consonant to vowel ratios, etc., or processes such as forced alignment (cf. Gippert 2006 for a discussion of textual encoding of language documentations and Seifart 2006 for a discussion of orthography development).

If the corpus-building effort is for a language that has been documented by different people or even by the same person over several years, there may be multiple orthographies that will require standardisation. This should be documented, describing what changes have been made. Variable spelling may be of potential research interest at some point, so copies of files should be made and stored separately.

Considerations of space preclude more detailed discussion here, but it should be kept in mind that transcription is not a theory-free undertaking and that the way it is done will have bearings on the further processing and analysis of the data (see Ochs 1979 for a classic paper,

Translation

A further layer of annotation vital for many corpora is a free translation into a major world language (Schultze-Berndt 2006). The purpose here is obvious: with our interest in modern languages encompassing thousands of different languages no corpus user can be expected to have command over every language under study. A free

Enriching time-aligned annotations

A sub-corpus of the Vera'a corpus was contributed to a larger collaborative cross-corpus project researching prosodic properties of speech in different languages (PI Frank Seifart, ZAS Berlin)

Choice of metalanguage

The term metalanguage refers to the language we use to describe language and linguistic structures, as well as the metadata thereof. This encompasses both natural languages, as well as various formalisms and various symbols, like the @ to indicate laughter in the Du

Free translations and some other types of annotation essentially involve a natural language as a metalanguage. The general rule of course is that this should be a language that all potential corpus users understand. Depending on the field of study and the area where the language(s) under study is spoken, this may be, for example, Spanish, French, Mandarin, or English since scientific communities working in these respective areas often share these respective languages. For our purposes, the metalanguage

Corpus building

Corpus building 106 is always English. This is not because we think that English is linguistically fittest for this purpose -this can surely not be said for any language in the world -but simply because it does appear to be the language that everybody interested at least in principle in any language(s) in the world know, at least at the time of writing. It is obviously also the language all readers of this book know, so we generally take English to be the metalanguage used in free translations and other annotations that involve natural language expressions. For many LD corpora, it may be advisable to create multiple versions in different languages so that the corpus be accessible to people of relevant regions.

DATA FORMATS

Once we have decided what to include in our corpus, we have to actually put together the different texts in such a way that we can analyse all data in essentially the same way concerning any particular research question. This requires that texts be similar in two regards: text data format and pre-processing and annotation. Moreover, compilers need to think of the use of their corpus through some kind of interface: this can include fairly simplistic general methods of text searches (as found in text editors), more specific simple search engines (like AntConc; Anthony 2020), or specific corpus software and interfaces like ANNIS

There are a number of options, and we do not provide any specific suggestions here. The main point that you need to be aware of is the fact that any digital text is encoded in some form. This means you have to make sure that when working with different software or on different machines the text and letters that look the same really are the same in terms of their encoding. If encoding does not match, you will potentially not find relevant text. Moreover, you should consider differences in format: if data remain in different formats that cannot be combined for a search, then multiple searches will have to be used for corpus queries. For some purposes, such as finding an illustrative example for a paper, this may be fine. However, if you want frequency tables, n-gram counts, or proportions (cf. Chapter 5), compiling the corpus data into a standard format is an important step. If you are dealing with multiple file formats, exporting or converting everything to plain text format is probably the simplest way to compile it all together. Further options include exporting/importing texts to a single software to give the data a unified format. Also possible is compiling the corpus in multiple formats. Multi-CAST is an example where both options are available: users can work with the data in ELAN (where multiple files can be queried) or load it into R as the package multicastR (Schiborr 2018).

INCLUDING METADATA

Alongside corpus text data we have to integrate metadata. Metadata is generated at various parts of the documentation process, as discussed above. Participant metadata, data about each individual, including names, ages, genders, languages they use, and perhaps, occupation, education level, and other characteristics. Each text that is part of the corpus will also have metadata such as the date and place it was recorded, who spoke or signed, who else was present, and what media files are associated with the text. Metadata will also provide information about other situational characteristics, for instance, what register and genre properties a text has, what its global topic is, etc. One of the simplest ways to record metadata is as a simple table, which can be stored in a comma or tab-delimited value format (CSV or TSV). These formats are easy to read for many computer programs and are non-proprietary, unlike, for example, Microsoft Excel, which means they will last longer and can be easily converted to other formats.

Metadata can be integrated into a corpus in various ways. If you are writing your own computer scripts to build your corpus, you can integrate (or merge in) your metadata, bringing in all the metadata for each participant and all the metadata for each file for every token in the corpus. Metadata can be used to limit searches to a particular subsection of the corpus, or can be used for examining variation due to some aspect of the individuals (i.e. gender, education, second-language influence) or the files (i.e. register, time period).

For language archives, one will either have to fill in metadata forms, for instance, the metadata catalogue of PARADISEC (catalog.paradisec.org.au/), or adhere to a standard metadata format, for instance in the DoBeS (tla.mpi.nl/project/dobes/) or the ELAR (soas. ac.uk/elar/) archive. The latter two use a standard called IMDI. IMDI files can be generated easily via an online interface called CMDI Maker (cmdi-maker.uni-koeln.de/) where one can fill in the information relating to participants, circumstances of individual sessions, overall project, etc. as discussed above. This gives standardised metadata results, among other things, in the data appearing on the archive' s website in a structured way.

Exercise 6.3 Metadata search

Go to the Matukar Panau collections in PARADISEC and ELAR and find the item "Kadagoi Lovinea Rapalau Ambrose and Ambrose Kainor describe Bilums" (DGB1-crafts02) in both collections. What metadata can be seen for (

Corpus building

Corpus building 108

Some software programs used for corpus research, such as some concordancers, may not be able to integrate metadata. In fact, if metadata is included at the top or bottom of the file, it may be read as text rather than meta-information about the text. Because of this, corpus compilers will often use special characters in a special way so that metadata is regarded as such. Here are some examples: @speaker: Megan, <speaker>Megan</speaker>, speaker_Megan. Some researchers will include basic metadata in file names (i.e. Megan_19991103_monologue_Canberra) and use the names, often in combination with a file folder structure, to organise their data.

PUBLICATION OF THE CORPUS

The final step in corpus compilation is publication. In the 21st century, this is understood as published online. There are always reasons why it may be difficult to get data published, and of course, this step also requires some resources if the corpus is to be presented in a well-structured and well-designed way. Webpublished corpora do not necessarily need to have query interfaces. The main point really is that interested users have access to the data and can understand how it can be used, which in turn requires metadata on the corpus as a whole. As mentioned above, Multi-CAST is available in various formats, and all data can be downloaded from the corpus website. 4 A corpus website should also have all relevant information on the corpus and its various texts or in this case subcorpora. Part of this information about the corpus is a citation so that it can be referenced, as we do in this book. All these aspects of corpus publication are intended to make the use of corpora by multiple parties, and that of any linguistic data more generally, the norm in the language sciences.

CONCLUSION

The main point of this chapter is to understand the tensions between the principles of corpus design, as discussed in Chapter 3, and specific considerations of actual corpus building. In particular, LD corpora may come with severe limitations on corpus design, given that related projects have limited funding, and also because such projects are often undertaken by individual academics (though in collaboration with community members). This is the typical constellation for corpus building today, and it is a major reason why only a few larger corpora are web-accessible to date. However, we can hope for an increase of recognition of the usefulness and importance of corpora from a range of diverse languages, even if they are still relatively small and will be so for a long time, at least in comparison with the large corpora of well-studied languages. This will hopefully also spur further efforts in this area.

FURTHER READING

Mosel (

NOTES

1. Note, however, that large-scale descriptive work is not precluded here, as is evident from the seminal work by

CORPUS ANNOTATIONS AND RESEARCH AGENDAS

In this chapter we will be dealing with corpus annotation. Corpus annotations are special types of additional text added to the corpus text that encodes interpretative linguistic information

[…] watching as the woman entered her living room, kicked off her shoes, and sat down in her chair.

COCA.FIC The Antioch Review 1996(winter), 54.1, p. 60: Kenneth J. Emberly: Whole days and nights.

In this excerpt from a written fictional text in COCA, any human reader will understand that both instances of her refer back to 'the woman' . But this is not directly encoded by any means here: the possessor of the living room or the shoes could be someone else. Our understanding of these co-reference relations is the result of our interpretation of the wider discourse context, which is in turn guided by world and cultural knowledge -it would be less plausible that someone kicks off their shoes in someone else's living room in many English-speaking and other cultures. But even more basic aspects of this example are not directly extractable from the corpus text; for example, the grouping of words into phrases: how do we know which words belong together, for example, her living room, and form what kind of relationships with other words and phrases? Various types of corpus annotation can make these aspects explicit and searchable.

Standards of corpus annotation

Corpus annotations should follow a set of general standards. First of all, they should be linked to the corpus text data and their metadata so that corpus users can evaluate how annotators arrived at their annotation decisions; at the same time the annotations are ideally extractable in order to be analysed outside the corpus infrastructure itself, for example, by programmes for statistical analysis. Second, the annotation practices need to be documented. This can be done in the form of an annotation manual that outlines the conventions that have been applied in creating a set of annotations and at the same time serves as guidelines for users who intend to implement the annotations themselves on their own corpus data. Moreover, this enables users of the corpus to plan the construction of their queries targeting these annotations. The documentation should also outline what research can be or has been undertaken with them, and refer to this research so that users understand their theoretical context.

In Section 7.2 we present a selection of conventions for annotation that target different linguistic levels. We will refer to additional literature in the further reading section for more exhaustive overviews. Our main purpose here is to explain the basic implementation of corpus annotations and how they add value to a corpus by enhancing its amenability to a wider range of research questions. We will repeatedly refer back to Chapters 4 and 5 where different types of annotation were relevant. Section 7.3 is devoted to comparative corpus annotations in the context of corpus-based typology. This section is tightly connected with Chapter 11 where we will explain various types of research that builds on these or similar types of annotation systems.

The transcription of spoken raw data and idiomatic translations of corpus texts are dealt with in Chapter 6 as part of corpus building.

Corpus annotation involves enormous amounts of work. This means that when we decide to use an annotation system or devise one ourselves, we need to make sure that the work is worthwhile, that is, the information we require cannot be extracted in some other way using data that is readily available, such as smarter ways of querying.

TYPES OF ANNOTATION AND ANNOTATION SCHEMES

Corpus annotations capture different types of information pertaining to different levels of linguistic representation. The specific design of annotation systems is codetermined by the specific research interests involved and therefore, we will need to refer to various research projects time and again.

Corpus annotation

Corpus annotation 112

Annotation for phonetics and prosody

Phonetic and prosodic annotation is fairly specialised: while it is obviously only relevant for spoken language corpora, it is not usually undertaken in many spoken language corpora. Speech corpora are a special type of spoken corpus (see 4.2.2) that are intended for corpus-based investigations into the phonetic and phonological structure of spoken language use. The first type of annotation targets individual sound segments and is essentially a type of transcription of spoken language raw data, phonetically a very close and exact one. In principle this can be done by using the symbols of the IPA to render the corpus text. In corpus linguistic practice, however, annotators have often resorted to alternative renditions of IPA conventions. Various phonetic alphabets consist of ASCII characters or Latin letters and combinations thereof. These are often easier to input, display, and search than IPA symbols (cf. 3.2.2).

Prosodic information is also rendered in more general spoken language corpus annotation conventions like Du

As for prosodic annotations, language documentation-based corpora often contain basic information about prosodic chunking in the form of time-aligned transcription according to IUs and by including pauses as well as disfluency phenomena

Morphological annotation

Morphological annotation captures the meanings of word forms and their component meaningful units, that is, morphs (rather than syllables for instance). It is applied to a corpus text which has already been annotated and translated, as required. As in the example from Vera'a in Figure

The most common set of conventions for morphological glossing are the so-called Leipzig Glossing Rules (LGR)

Corpus annotation

Corpus annotation 114

[2010:27-29] for a succinct explanation). The following examples from Japanese illustrates how the system works: As you can see from this example, morphological glossing requires the segmentation of word forms in the first instance so that individual morphs can be given their meaning or function glosses. By convention affixes are separated by hyphens, for example, the causative (CAUS) and the past tense (PST) suffix. Grammatical functions are captured by a set of more-or-less standardised abbreviations (i.e. NOM -nominative, ACC -accusative). The basic purpose of morphological glossing is making explicit the component parts of the meaning of the utterance provided in the free translation. In

Another challenge related to the morphology of word forms is to determine what lexeme they belong to, as was discussed in Chapter 2.2.2. The addition of information about word form-lexeme relations is called lemmatisation, and this essentially constitutes a layer of annotation of the form shown in

Parts-of-speech tagging

One of the most prevalent types of corpus annotation applied to corpora from betterstudied languages is parts-of-speech (PoS) tagging or simply tagging. As the name suggests the annotation picks up the word class membership of word forms, traditionally called parts of speech. Many of the classic and larger corpora of English contain PoS tagging, for example, COCA or the Brown family corpora. The motivation for PoS tagging in English follows from observations that parts-of-speech membership cannot be read off the form of word forms themselves, as is clear from textbook examples that illustrate the ambiguity resulting from this indeterminacy,

Corpus annotation

Corpus annotation 116

for example, Fruit flies like a banana. Surface word forms in English often have multiple parts-of-speech membership which means that just searching for these will potentially return false positives, that is, hits that are in fact not what we were searching for. For instance, searching for like in the interest of finding verbs that are semantically similar to love, enjoy, or appreciate can return the false positives of preposition tokens in similative constructions where it contrasts semantically with alternatives like equivalent to, akin to.

The annotations are called 'tags' because they are appended to corpus words, as shown in example (7.5) from the Brown corpus.

(7.5) on_IN other_AP matters_NNS, _, the_AT jury_NN recommended_VBD that_CS :_:

In this example we see that the word form matters is identified as belonging to the part-of-speech 'nouns' indicated by the initial N rather than a verb form (which would have a tag beginning with V). Thus, where a corpus user is interested only in instances of matters that are plural forms of nouns they can search for a string <mat-ters_NNS> rather than just <matters>. Let's consider relevant instances of our case example like in the Brown corpus, given in (7.6): Tagging of corpora is done with a clearly defined and confined inventory of tags (a controlled vocabulary) that is called a tagset. Tagsets are developed for specific languages, and often indeed for individual corpora, so that when you use a corpus, you need to consult the corpus metadata, manual, or other documentation.

Brown tagset

The Brown corpus comes with its own tagset comprising 87 different tags. As you will have realised when considering the examples above, tags pick up more information about word forms than just parts-of-speech membership. For instance, the tag <_NNS> classifies the word form as a common noun in its plural form. Further, tags are clearly marked as such by their preceding underscore. This makes it possible to search just for tags, for example, _NNS to find all instances of plural nouns. A crucial property of tags is that they have a hierarchical and decomposable structure, as can be seen from the subset of tags for nominal word forms in Table

Tagset designers typically construct tags to be mnemonic, that is, you should be able to recognise and memorise their meaning fairly easily based on the letters used. While the Brown tagset seems to achieve this goal to some extent, there are obvious limits given the possible variation in single-letter abbreviations for any number of distinctions, as is visible in the abbreviation R for 'adverbial' .

The Brown tagset also picks up specific forms that are particularly relevant for the analysis of grammatical (sentence) structure, thus breaching strict assumptions of word class membership; this is typical of tagsets for English. For instance, different forms of the verbs be, have, and do receive their own specific tags lacking an initial V for classification as verbs, as shown in Table

Corpus annotation

Corpus annotation 118

In modern corpora from English, tagging is often done automatically by a so-called tagger which is a software programme that automatically appends tags to word forms based on a computer-linguistic analysis of their morphological properties and their syntagmatic environment, that is, which other word forms precede and/or follow each word form. For the London-Oslo/Bergen Corpus (LOB) a tagger known as CLAWS was used which stands for 'Constituent Likelihood Automatic Word-tagging System' . CLAWS was further developed over seven versions, and the most current version of the FLOB and FROWN corpora have been tagged with CLAWS7

London-Lund tagset

Half of the London-Lund Corpus (LLC) (LLC; Svartvik 1990) consists of spoken texts, and for this a tagset was designed specifically to capture some features of words in spoken texts. 3 The LLC tagset is much larger than the Brown tagset, comprising 204 tags, reflecting finer-grained and additional grammatical distinctions, for example, the case forms of pronouns, and including cliticised forms whereby clitic and host are treated as one 'contracted' token word (cf 2.2.2). Tagging of contracted forms combines the two underlying word forms with a <*>, resulting in tags like <BHdem*VB+3>, where the latter part <VB+3> stands for '3rd person form of the verb be' thus differentiating that's from that. In addition to tags for these, the LLC tagset contains tags for expression -including multi-word expressions -that the authors consider characteristic of spoken language, as listed in Table

The actual distribution of such forms across texts of different modes is beyond the discussion in this chapter and is more a matter of systematic register studies, such as those mentioned in 3.1.6. What is relevant for our purposes here is that corpus and tagset developers entertain a considerable degree of freedom in designing tagsets to serve their specific needs, so that tags do not necessarily reflect the absolute exactness of linguistic analysis and classification. In other words, the maxim for the development of tagsets -and annotation systems more generally -is not that they are linguistically 100% accurate but that they are useful and overall consistent in their operationalisation.

PoS tagging has been applied to corpora other than from English; a famous tagset for German is the Stuttgart-Tübingen tagset (STTS)

Syntactic annotation

We have seen that PoS tagging often also includes information relevant for syntactic analysis, and PoS tagging is part of all syntactic annotation systems that we are aware of. But in addition to PoS tagging syntactic annotations also pick up more aspects of a syntactic structure. Reflecting the two basic conceptions of syntactic structure in modern linguistics, the systems can be classified as either annotating constituent

Corpus annotation

Corpus annotation 120 structure or dependencies. Corpora containing syntactic annotation for constituent or dependency structure are called treebanks since syntactic structure is commonly visualised in the form of trees in models of syntax. Treebanks typically have PoS tagging and also semantic annotation of argument structure

A famous example of a treebank with constituent structure annotation is the Penn Treebank developed at the University of Pennsylvania, first released in 1992 comprising texts with 2.8 million token words

(7.7) Penn Treebank I: skeletal bracketing annotation of phrase structure

Recalling your introductory course in syntax you will notice that this phrase structure annotation skips any terminal nodes with lexical categories and only contains phrasal projections. Remember, however, that lexical category information will be contained in the PoS tagging that we have discussed above in its original Brown version, so that, for example, the NP-embedded PP would be fully annotated as in (7.8) (note that the separator in Penn tagging is forward slash / rather than underscore _): These searches will thus give us a count of NPs with and without recursive structures, that is, where an NP occurs embedded in a higher-order NP either as an initial possessor NP or as the complement of a preposition of an NP-embedded PP. We could also further investigate which types of PPs occur as embedded ones, for example, what the proportion of possessor PPs with of is, searching for

The first query should return all instances of of PPs, and the second query all instances of PPs where the preposition is not of.

The bracketing annotation of its second release

(7.9) Penn Treebank II enriched bracketing PS annotation

Corpus annotation

Corpus annotation 122

In (7.9) the first NP represents the subject of the matrix clause, and this is noted by the functional tag -SBJ (cf.

The second type of treebank annotations encodes dependency relations. Probably the best-known example is the Prague Dependency Treebank (PDT) (cf.

Semantic annotation

Compared to other types of annotation discussed thus far semantic annotation is lesser developed and practised in corpus linguistics. One major concern in the corpus-based semantic analysis is word sense disambiguation which is not inferable from the surface structure of the corpus text itself and needs to be determined by a human interpreter. Recall Gries' (

Other potential requirements for semantic annotation of corpora pertain to the assignment of semantic categories and semantic fields, as well as annotations for specific semantic domains, for example, events classes, temporal or aspectual distinctions, or semantic roles. Various annotation systems have been developed for these different domains. Annotation of semantic categorisation is useful, for example, for various investigations of text content. Given that semantic annotation systems can be exceedingly complex by comparison to grammatical annotation, given the huge range of distinctions, we will not discuss these here in greater detail. We do provide further reading suggestions at the end of the chapter. Moreover, some semantic aspects are part of the typologically oriented annotation systems, and we will outline these in 7.3.

Discourse and reference annotation

Language use does not consist merely in the production of individual utterances; instead, utterances are interrelated with each other in what is called text or discourse (cf. 2.2.1). The various interrelations between utterances in a discourse lead to (text/discourse) coherence so that interlocutors (or writers/readers) share the meaning built up during production and reception. Most of these coherence relations are not marked overtly, and language users infer these based on their interpretation of preceding discourse in connection with world knowledge and their expectations concerning the continuation of the discourse. Two aspects of discourse coherence are particularly relevant for which corpus annotation systems have been developed. First, the relationships between utterances/propositions (e.g.

Corpus annotation

Discourse coherence is partially established through co-reference relations. A hugely prominent topic in this area is anaphora resolution (which relates mainly to perception) and referential choice. The latter relates to production and has been investigated with corpus-linguistic methods. Co-reference relations are probably the prime example of implicit information that can only be determined by human interpreters and that for this reason require corpus annotation to make them explicit. An annotation system developed to these ends is the University Centre for Computer Corpus Research on Language (UCREL) discourse annotation system, as documented in

English UCREL discourse annotation (a) (6 the married couple 6) said that <REF=6 they were happy with <REF=6 their lot

(b) There are nine categories in PGA Tour statistical service. Assists isn't (6 among them 6). If it were <ELLIP=6, Ben Crenshaw …

Exercise 7.2

Consider the UCREL discourse annotation system just outlined. How could you use these annotations to investigate questions of reference tracking? Do the following:

• Download a plain text from English (or another language you know well).

• Read through the text and add the reference tags exemplified in

• Note what analytical problems you encounter during the annotation process. What questions do you have to ask yourself?

• Complete a text of minimally 10,000 words. Now search for instances of • (a) Full NPs (b) pronouns (c) zero

• How can you construct queries with regular expressions that give you these instances?

• Now write up your results. How many instances of each category do you find? What are the ratios?

The annotation system has two basic facets: (1) it captures the identity of referents mentioned by different referring expressions, (2) it captures various aspects of the anaphoric relation. The symbol '<' signals that the co-referent is an antecedent and the relation is anaphoric (rather than cataphoric). 'REF' stands for an exact co-referent, so that the pronoun they refers to the same entity as the antecedent the married couple in

CORPUS ANNOTATION IN LINGUISTIC TYPOLOGY

Recent years have seen a surge in cross-linguistic typological research based on corpora. We devote an entire chapter to this emerging field in linguistics (see Chapter 11).

In this section we outline annotation procedures that have been developed with a comparative perspective in mind. For some of the annotations discussed thus far, corpus linguists have developed dedicated comparative perspectives. One of the most prominent of these is the EAGLES standard for PoS tagging in different languages which yields basically comparable annotations (cf. e.g.

Corpus annotation

Corpus annotation 126

UDs: Universal dependencies

Currently probably the largest and most influential effort in corpus-based typological research draws on universal dependency treebanks, better known as UDs. UDs are extensively annotated with PoS tags and syntactic dependencies (cf.

The first column has numerical identifiers of each corpus word form. The next one has the word form followed by lemma annotation. The fourth column hosts the universal PoS tag followed by a language-specific PoS tag, followed, in turn, by a list of language-specific grammatical features of the word form. The next column contains a number cross-referencing the word form ID in column 1 that identifies the head of which the word form in question is the dependent. For instance, in Table

The captivating aspect of UD annotations is that they are relatively easy to implement but enable a huge range of investigations. For instance, you can easily determine the expression of subjects and objects by pronouns and NPs (cf. our investigation of Vera'a). You can also determine the relative length and complexity of phrases (understood as dependency structures) by considering the number of head indices in the head column cross-referencing the head word of the phrase in question, or all phrases dependent on the verb node. These findings can then be related to the function of these phrases -or their dependency relation to the verb -comparing, for example, subject and object NPs. Similarly, phrase length can be related to their linear position within the clause by relating these to the ID numbers of their constituents; in this way NP complexity can be related to their ordering in the clause, a prominent research question in typology (see Chapter 11). Finally, constituent order in terms of grammatical relations can be determined in relation to the word form IDs. These questions link to a range of well-established research agendas on constituent order and languages processing, and we will outline some UD-based research in this area in Chapter 11 on typology.

This brings us to the crucial feature of UDs, namely their cross-linguistic comparability. This is achieved primarily by including very general PoS tags as well as general definitions of dependency relations; specific dependencies as cross-referenced to heads, are not language-specific anyway. In this way, the research questions just outlined can be undertaken across any number of UDs. One can then, for example, compare the extent to which the order of say subject and object varies across languages, or to what extent their ordering is interrelated with their relative length and complexity.

SCOPIC: Social cognition parallax interview corpus

The Social Cognition project led by Danielle Barth and Nick Evans is an example of a cross-linguistic corpus with annotations targeting specific research questions.

The project tackles the interconnections between cultural backgrounds of users of different languages and the way they construe and verbalise the entities and events they talk about in connected discourse

The social cognition project is based on a specific corpus-building project, the parallax corpus SCOPIC

Corpus annotation

Corpus annotation 128 set of pictures that conjointly form a little narrative, the Family Problem Picture Task

In order for the data to be analysable for the project, specific corpus annotations are required. We illustrate this with one of the first research questions that have been addressed in this project, namely, how users of diverse languages preferably make reference to various human beings during the task. The focus here is on lexical choices, that is, which lexical nouns are used as heads of respective NPs with human reference. Users of any language have many choices available to refer to a human being in a given context. For instance, one of the pictures in the Family Problem set figures a policeman who returns personal belongings to a recurring male character. People can refer to this man with nouns like 'man' , '(her) husband' , '(his) father' , 'prisoner' , or many other nouns. The project aims at identifying whether languages show specific preferences. For instance, some languages may have an abundance of kinship term expressions, including the use of 'uncle' for the policeman in some languages from the Pacific area, thus ascribing a specific respectful relationship to the social role.

The multiple annotation schemes of SCOPIC are organised along functional categories. Each language in the study is annotated for expressions that relate to many functional categories relevant to social cognition. Within each broad functional category, researchers code a "TAG" and a "TERM" for each instance of the phenomenon. A TAG comes from a closed and cross-linguistically fixed list of category choices and indicates the type of expression being used for the relevant instantiation of a particular functional category. A TERM is the citation form of a language-specific instance of that phenomenon. The same tag, for example, KN (kin term) can be used with many different language-specific terms, such as KN_mom, KN_mother, KN_dad, KN_spouse. The same TERM (i.e. linguistic form) may also sometimes appear in different tagged categories, as in: KN_boy, GN_boy, GKN_boy where the noun boy might be used as a kinship term, a generic term (GN) or a term that is ambiguous as to whether it is kin or generic (GKN), or in a possessed NP like our boy, the kinship status would be clear and we would use the label PKN_boy.1pl for a possessed kinship term. This reflects the widespread many-to-many mapping between function and form in language.

Multi-CAST: Multilingual corpus of annotated spoken texts

Our third example of an annotated cross-linguistic corpus is Multi-CAST which stands for multilingual corpus of annotated spoken texts

Corpus annotation

Corpus annotation 130 of each utterance. On the 'grammatical word' tier the text is divided into grammatical words which is essentially a step of tokenisation. In the Vera'a example you can see that it includes the separation of clitics from their host word forms. It is also on this level that clause boundaries are inserted that mark the beginning of clauses, represented by '##' or '#' , depending on the type of clause. The grammatical word tier forms the basis for all further annotation, that is, morphological glossing, GRAID and RefIND which are all successively symbolically associated. This is important because it enables systematic analysis of annotations across these layers. The free translation is presented at the bottom here, but structurally it depends on the utterance tier. Given this structure, the transcriptions entered in ELAN exhibit explicitly marked up structure in the XML output that can then be imported into other platforms and also is further analysed based on a more common vertical format, as will be shown shortly below.

Turning now to the content of the annotations, the main part of GRAID annotations targets the form, function, and semantic properties of syntactic constituents, in particular, verbal arguments. These are constituents that typically enter syntactic relations like subject, object, etc. GRAID expressions are three-barrelled, with the generalised form as given in (

The first position registers the form of a linguistic expression, for example, <pro> for 'pronoun' or <v> for 'verb' . The final position registers the function, for example, <pred> for 'predicate' or <s> and <a> for typological categories that denote the subject of intransitive and transitive clauses, respectively. The function position is separated by a colon <:>, hence yielding, for example, <v:pred> for a verb form with predicative function. The second, medial position is reserved for semantic properties of the expression, for example, <1> for first person or <h> for human reference. Since first and second person are taken to entail human reference (only humans can speak or think), the human/non-human distinction applies only to third person where 'human' is overtly annotated as <h>. Semantic feature annotation is separated from the form slot by a <.>. The absence of an annotation in the second slot is read as 'non-human' . For instance, <np:p> is a NP in P function with a non-human referent. Note that this convention is quite parallel to what we observed in tagsets where an element in a particular position of a tag contrasts with absence of any symbol. An important aspect of form annotations in GRAID is that it includes zero (covert) forms. GRAID differs from other syntactic annotation system like the Treebank II annotations discussed in 7.2.4 in that zeroes are confined to instances where they contrast with a possible overt form, so that, for example, notional subjects of infinitive clause constructions in English do not receive a regular zero annotation. Moreover, zeroes have to have a specific referent that is retrievable from the discourse context.

Appended to the layer of GRAID annotations are the two layers of RefIND annotations. The first one of these is a layer of referent indices quote similar to those in the UCREL scheme discussed above. Note that while the annotation as such seems simplistic, the operationalisation of underlying categories is particularly complex in this area. For instance, it can be quite difficult to decide whether a particular nominal construction does really have a referent so that a new index needs to be used.

The second layer of RefIND annotations is a rough classification of new referents, distinguishing, for example, <new> from <bridging> corresponding roughly to a distinction between 'brand-new' and 'evoked/implied' referents. These latter annotations are applied only to the first mentions of a referent where they are introduced into the discourse. Now let's have a look at a set of examples that illustrate the annotation practice and the rationale behind the system. Examples (7.13) -(

(

Corpus annotation

Corpus annotation 132

In all three examples you also find the referent indices that pick up each referent at their successive mentions.

The GRAID annotations alone enable a number of corpus queries on the annotations as presented here, and as they appear in the ELAN files. For instance, you can determine the number of all instances of annotations with A function annotations and then only those with pronoun and A function annotations to then calculate the proportion of pronouns within the A function. You could then compare this proportion to that in the P function. And you can basically do the same thing with any other property, for example, humanness, instead of the form of expression. These and similar considerations have been at the centre of attention in some research within linguistic typology, and we will explain more about all this in Chapter 11. The crucial feature of these annotations is that they are applied in the same way across languages, and they look exactly the same for what are the same categories in a typological perspective. That is to say that annotators of any given language corpus are asked to annotate structures in a typological comparative perspective. For instance, the form gloss <pro> is understood here to also include pronominally used demonstratives and not just all members of the pronoun form class in a given language. These annotations thus abstract away from the language-specific structures that morphological glossing and most PoS-tagging capture. As such, it is much more straightforward for users not familiar with each language to cross-linguistically analyse patterns like the ones just outlined. Combining the levels of GRAID and RefIND annotations will open up further possibilities: for instance, we can search for all instances where an annotation appears on the RefIND tier combined with a search for a syntactic function on the GRAID tier to get all functions in which a discourse referent is introduced. This question is relevant in some areas of typology, as will be explained in Chapter 11.

Exercise 7.3 Multi-CAST searches and quantification

Download at least two corpora from Multi-CAST (after you have installed the free software ELAN) and design a number of queries, using regex (cf. 5.11) to determine:

(1) What is the proportion of zero arguments within all "core" argument functions S, A, P?

(2) How do the different functions differ?

(3) What cross-linguistic differences do you observe? Taking a closer look at the clause structures by going back to the corpus data, try to develop some ideas as to what may potentially explain these differences, or at least be part of the story. structure. This means, for instance, that for each referent index we can calculate the distance to its antecedent mention by finding that instance and determining either the number of hashes (which represent clause boundaries) which equals number of clauses or the number of word forms, that is, all lines excluding those for hashes. In the same way, the form and function of the antecedent can be determined. All these are relevant for an analysis of referential choice (see 8.4). But given that all this can be readily done across languages, this system in fact enables large-scale cross-linguistic research in this area, as is done in

You may realise that this system of annotation is easier to handle for annotators than a system where various aspects of anaphoric relations and the like have to be entered during annotations; for example, for many instances of given referents addition of the relevant index is pretty easy and therefore, very quick. At the same time, the system is also maximally flexible and versatile, so that we can analyse, for example, anaphoric distance in terms of different units of measurement.

CONCLUSION

The purpose of annotations is to provide extra value to corpora. They allow for queries and calculations that would otherwise be difficult or impossible to obtain. As we saw above, a myriad of annotation schemes exist and they can range from very general applicability to appropriate for ultra-specific research questions.

Exercise 7.4 Annotation scheme effort

Design your own annotation scheme for a particular problem that is interesting to you, such as tracking contraction (or not) or positive or negative affect of adjectives. Brainstorm what needs to be included to capture the main aspects of this problem?

Find a short text and trial your system. To start, you can use a simple tabular format:

Tokens (words, morphs, sentences, etc.)

Aspect 1 Aspect 2 Aspect 3 Etc…

Token 1

Token 2

Token 3

What adjustments are needed?

Now trade annotation schemas with a classmate or trial it on a different language or text type. Do new kinds of decisions need to be made?

What aspects of this activity were the most difficult or time consuming?

Corpus annotation 135 FURTHER READING

NOTES 8.1 INTRODUCTION

Corpus linguistics, at its heart, involves counting things. This can be very simple, like counting all the words in a corpus or a specific word within a corpus, but can also become very complicated. For instance, counting the number of times something happens under various conditions and then seeing if that is different from what we would expect if the distribution was completely random. This chapter will focus on a few kinds of statistical analyses that are often used in corpus linguistics and will try to get you in a position to turn a research question into something specific and testable. This chapter will explain some of the most frequently used quantitative techniques in corpus linguistics today, such as logistic mixed-effects regression, as well as focus on some newer techniques becoming more popular, such as classification trees (and random forests) which are types of recursive partitioning. We also present some basic types of clustering.

We present some means of displaying frequency distributions in corpora before moving on to inferential statistics. There, we concentrate on our strength: variationist corpus linguistics. There are many means to evaluate corpus-level variation (such as Kullback-Leibler divergence) in order to compare corpora with each other. However, our work focuses more on issues of linguistic analysis: when would you use structure X versus structure Y? Based on what aspects of the context? Corpora are extremely useful for these kinds of questions, as are quantitative approaches. Below we focus on some of the main means to assess data to help answer these questions. In principle, we are interested in what humans do with language (cf. 2.3). Often, we are interested in a more specific population, such as American English-speaking 2-5-year-old children or speakers of Matukar Panau (cf.

However, we never have information from an entire population. What we have are samples. We have a sample, for instance, of 30 Matukar Panau speakers, speaking for a total of 40 hours in a specific setting. We can describe characteristics of that sample, such as the frequency with which people use serial verb constructions. We can also infer characteristics about the whole Matukar Panau speaking population in all instances of speech from that sample, that is, how frequently all speakers under all circumstances will use serial verb constructions. However, we are also aware, when we do this, that we cannot be certain about the population, only about the sample.

There are different kinds of sampling methods: random sampling, representative sampling, convenience sampling. Based on how we conduct research projects, sampling may be more or less representative (equal amounts of ages, genders, clan membership, etc.). In corpus linguistics, sampling is rarely truly random (a random person from a population, or a random text from all existing texts), and is more often a convenience sample (who we can record, what we can find on the web, which newspapers we have access to, etc.) (cf. Chapters 6 and 10).

We sample to estimate parameters. Parameters are values that characterise an entire population and statistics are estimates of those parameters within a specific sample.

Dependent and independent variables

In statistics, the term variable has a specialised meaning. It is the property of something that can be classified or measured.

Numerical aka Quantitative:

Interval -ordered variable with equal intervals, lacking a zero point or having an arbitrary zero point. 1 We can add and subtract interval variables but not multiply or divide them. Interval variables are uncommon in corpus linguistics.

Ratio -ordered variable that includes zero and what we normally use when we are working with numerical variables. Zero is meaningful for ratio variables (zero token counts of parsimonious in a corpus signal an absence of that word in the corpus).

For numerical variables we can also distinguish between continuous and discrete. Continuous variables have meaningful points between all numbers, like word duration in milliseconds. Usually, continuous variables will have decimal points. Discrete variables have measurements that cannot be divided, like token counts or word lengths in characters.

Distributions

Statistical tests have 'assumptions' about the data they are used to evaluate. Parametric tests need to meet assumptions like following a normal distribution and independence. Otherwise non-parametric tests need to be used. If you use a statistical test on data that is not meeting the assumptions about the data, it might work, but your evaluation of that data will be misleading. Before carrying out statistical tests, you need to check the assumptions of the test, check your data, and make sure they match.

Normal distribution

If you have heard of any distribution it will likely be the normal distribution. This is also called the bell curve in less technical terms and a Gaussian distribution in more technical terms. Data that follows the normal distribution has many data points in the middle and fewer data points at the lower and higher end of whatever scale is being used. It is often used when talking about scores on tests: Few students will fail, few students will excel, and most will do fine or they will be "average". This use of "average" to mean acceptable, but not great, comes from the fact that most people/scores/whatever will be in the middle of a distribution and so will reflect the mathematical mean. Corpus data are rarely normally distributed though.

Exercise 8.1 Variable types

Generate your own list of appropriate variables. Brainstorm nominal, continuous, discrete variables you might really use for a corpus study. List 5 IVs and 5 DVs for each variable type. Can you also think of some ordinal or interval IVs or DVs that might be used in corpus research?

The spread of a distribution is how far away the lowest and highest numbers on the scale are from the mean. Spreads can be narrow (maybe scores on an assignment range from 70 to 95) or wide (maybe scores on a final exam range from 0 to 100). We use standard deviations (SDs) to help us understand the average distance from the mean (i.e. how many SDs a data point is away from the mean). Larger SDs are associated with wider spreads of a distribution and vice-versa. Sometimes data points that fall too many deviations away from the mean (higher or lower) are thrown out of analyses as outliers because they are too different from the mean. This can mean that they disproportionately affect analyses, giving us something we cannot trust, or it may mean that they were spurious data points in the first place (Did a student in fact not sit for the test, or did he completely misunderstand the assignment? Did something go wrong with the corpus-building process and result in something funky that needs to be thrown out?). Checking your outliers can be a good sanity check to make sure everything is going as expected. Outliers can also indicate that there is something really interesting going on with your data, which is another good reason to check them.

The parameters of a normal distribution are its mean and standard deviation.

A handy way to understand distributions is by plotting them using histograms. Histograms are a special kind of bar plot that display counts of continuous variable measurements (the figures in Section 5.4.1 on frequency were bar plots but not histograms because they were counting categorical data). The data in histograms are usually binned, and each bar represents a bin of data that falls within that range. The bin width (range) can be changed depending on what makes sense for your data: do you need a bin width of 3 for data with a range of 1-12? Or a bin width of 10 for data with a range of 1-100? Figure

Poisson Distribution

Poisson distributions are a common distribution of data seen in corpus linguistics. This distribution has to do with the average rate of occurrence in a population. We expect higher rates (or counts of something like a type of word) when there is more opportunity to observe the event being counted (i.e., longer texts have more words).

The assumption of the Poisson process is that we know the average time between events, but not their exact timing (i.e., we have an expectation of how many verbs should occur in a text, but not whether they are evenly distributed or more at the end, or beginning, or occur close together in chunks, etc.). Further assumptions of the Poisson process are that events are independent of each other, do not occur at the same time, and that the variance is equal to the mean and the average rate is constant.

The parameter of the Poisson distribution is lambda (λ): the rate of change

You can think of lambda as the expected number of events in a specific interval. Do we expect 800 or 80 verbs in a 1,000-word text? Some recent corpus linguistic questions using a Poisson distribution are by

Other kinds of distributions you may encounter include Gamma, Beta, and Bernoulli.

Range and spread

An important measure of spread is range (defined in Chapter 2.2.3). For more detail, we can turn to quantiles, a common way of breaking up distributions into ordered chunks, often four chunks, each of which are called a quartile. The first quartile is made up of 0-25% of the scale, the second is made up of 25-50%, etc. The interquartile range (IQR) is the difference between the 75th and 25th percentiles of the data, giving us the range of the middle of the distribution. This is an additional way to understand the spread of the distribution, like with the SD of a distribution.

Boxplots are a common graphical way of depicting the spread of the data and use the IQR. The data that falls within the IQR will be in the box in the centre of the plot. The horizontal line across the box indicates the median. The so-called whiskers (made up of the dotted vertical lines and solid horizontal lines that go out from the box) mark the 1.5 IQR above the third quartile and below the first quartile. In a normal distribution, the whiskers will be of the same length; if they have different lengths then it is a sign that the distribution is skewed.

Skewness is the measure of asymmetry in a distribution. The skewness of a normal distribution is near zero. When plotted, a skewed distribution will appear to be squished on the left or right of zero.

In Figure

Null hypothesis

The null hypothesis is a starting point for many types of hypothesis testing (aka confirmatory) statistics: it states that there is no difference between either samples or characteristics of a population. We then test this hypothesis against our data and usually hope to disprove it. If we find that there is a significant difference in, say, pronoun usage in newspaper versus narrative texts, then we reject the null hypothesis (that pronoun usage is the same) and then can confirm an alternative hypothesis: that there are proportionally more pronouns in, say, narrative texts.

Chi-squared test

The chi-squared test is a test of independence between categorical variables. In doing a chi-squared test, you are evaluating whether the number of observed frequencies of something is significantly different, that is independent, from expected frequencies if the null hypothesis were true. You can use a chi-squared test if you have a random sample from the population of interest, these observations are independent, you have a minimum of five observations, and observations fall into clear categories (these are the assumptions of the chi-squared test that need to be met; the minimum requirement of 5+ observations is a rule of thumb for robustness sake). You would use a chi-squared test if you have two or more groups of observations that you can put into two (or more) categories. Usually, this is the kind of information you would put in a table of counts. As an example, let's look at counts of Matukar Panau morphemes. The main word classes in Matukar Panau are nouns and verbs. From a parsed and glossed sub-corpus 2 of 8,961 words, verbs and nouns make up 5,375 word tokens. Table

Statistical description and analysis

Statistical description and analysis 144

Take for example the same dataset, but also including the next two most frequently observed word classes, pronouns, and adverbs and classifying them as monomorphemic or multimorphemic. Our counts are in Table

Pearson's Chi-squared test results for Table

Finally, it is worth noting that you can certainly run chi-squared tests on groups with more than two categories, just like you can run this test on data with more than two groups.

Correlations

Correlations are measures of two quantitative measures, rather than categorical ones. They show the degree of linear association between the variables. 5 Positive correlations are when two variables increase with each other: as a child' s age increases, their height increases as well. Negative correlations are when one variable increases as another variable decreases: the hotter it is outside, the fewer the layers of clothing you may wear. If these measures increase or decrease together, the correlation will be strong, and closer to 1 or -1. If measures have no real relation to each other, the correlation will be closer to 0: the temperature outside has no relation to a child' s height.

There are different statistical tests to measure correlations that are more or less appropriate for your data. A very common measure of correlation is r, or Pearson's product-moment correlation coefficient. It is a parametric test, meaning it is appropriate for normally distributed data. Kendall's tau and Spearman's rho are appropriate for non-normally distributed data (so be sure to check your data distribution!). Plotting the data is a helpful way to see the relationship between the variables. In

Statistical description and analysis

Statistical description and analysis 146

It is helpful to know the relationship between variables in your corpus generally. When conducting certain kinds of multivariate predictive analyses (cf. 8.4), it is important to make sure that predictor variables are not too strongly correlated with one another. In these cases, they are labelled as collinear (they show multicollinearity) and it means that they predict each other (as well as/instead of) the dependent variable. This makes estimating the fit of generalised regression models mathematically difficult because it is difficult to correctly attribute the contribution of each predictor when they are similar. Likewise, theoretically, it does not make sense to do so. Why would you include both a child's age and their school year as predictors of their vocabulary size? One might predict vocabulary size better than the other, but including both is probably superfluous. Sometimes you do want to test collinear variables at the same time, and then you are better off with something like recursive partitioning than logistic regression models. We look at both of these kinds of multivariate approaches in Section 8.4.

MULTIVARIATE PREDICTIVE APPROACHES

One of the main advantages of using a corpus is that it gives you a lot of information about the data you are examining. You have rich information about the context and often will have information about the speaker as well. You are at a disadvantage if you do not take this information into account when doing statistical tests. Therefore, much of the statistics we see for corpus linguistic data are multivariate rather than univariate as in Section 8.3. Multivariate means that multiple IVs are being assessed for their contribution to a single DV (there are ways of assessing multiple DVs simultaneously, but we won't be covering them here). We will discuss here one very common kind of multivariate statistical model called mixed-effects multiple regression, which has various implementations depending on the kind of DV you are examining. We will completely skip non-mixed-effects regression (fixed-effects only) because it is almost never appropriate for corpus data. If you are doing multiple regression, you are capable of and should be doing mixed-effects multiple regression. We will also discuss a newer method that is becoming popular in corpus linguistics and linguistics more widely, called recursive partitioning, which includes analyses like classification trees and random forests. Finally, we will take a look at clustering.

To illustrate both regression and recursive partitioning methods, we take as an example one linguistic problem that we, the authors, have looked at together, namely, what predicts the form of subjects and objects in the Oceanic language Exercise 8.

Correlations

Looking at Figure

Are the correlations for each word class positive or negative?

Which word class has the strongest correlation? Vera'a of Vanuatu

Let's take a sample of the factors we looked at and apply them to our data to help understand the statistical methods. Take a look at the articles for more information on the theoretical applications, more factors, and more details! In our list of factors, it should be clear that there are several kinds: inherent properties of the referent (expressed as either pronoun or zero), properties that stem from how the referent is used in a particular clause, and wider contextual properties. A corpus is useful to observe the variation of these properties in constellation with each other and see how each of these independent variables tend to affect our dependent variable. Further, a multivariate analysis is needed to be able to assess the contribution of each independent variable. All of our variables are categorical rather than continuous.

Form of the referent: is the referent a (1) pronoun or (2) a zero. Later on, we'll look at a more complex DV where there is a three-way division between (1) pronoun, (2) zero, (3) lexical NP for a portion of our data. For now, the table below shows our token numbers for a 2-way DV. Function of the antecedent (same or different): Antecedents are any reference to the same referent before the reference being looked at. So, if our token is she, in the sentence the cat jumped on the couch and then she went to sleep, and has the same referent as the cat, the antecedent of she is the cat. In our example, both the cat and she both have S function. But antecedents can also have a different function, as in this example, where the cat has the function P: I fed the cat and then she went to sleep. In data coding, we kept track of the function of the antecedent, and then created a variable comparing the function of the referent and antecedent so we can assess if having (1) the same or (2) a different function has a bearing on the form of the referent. For this variable, S and A functions of antecedents were combined, in line with Vera' a grammar treating these conjointly as 'subjects' . In looking at the table below, it should be apparent that while there are many more cases of different functions, there are some clear patterns in that the same functions are more likely to result in zero expression of referents and different functions are more likely to result in pronominal referent expression. Distance of the antecedent (aka anaphoric distance): Antecedents may be one clause previous to the referent (as in both of the cat examples above), or further away (I fed the cat and then I put the food away. She went to sleep then). The first time a referent is mentioned, it has no antecedent, and these cases were excluded in the original studies. We collapse all possible distances into two levels: (1) antecedent 1 clause away (

Pronominal referent Zero expression

Pronominal referent Zero expression Total

Pronominal referent Zero expression

Text:

As with speakers, we may expect that differences in the use of the DV across different texts, so we code for the 16 different texts that our tokens come from. Now let's take a look at some specific multivariate methods.

Mixed-effects multiple regression

When you look at journal articles reporting on corpus linguistic studies where researchers are using multiple regression, you will see many ways to describe it. Some of these are different analyses, and some are just different names for the same kinds of analyses. Multiple regression can be 'linear' or 'generalized linear' . Linear regression is appropriate when the dependent variable you are trying to predict is continuous (like the duration of a word in milliseconds) and the data is conditionally normally distributed (normally distributed around its predicted values). In linear regression, we assume that there is a linear relationship between the DV and the IVs: the value of the DV is increased or decreased as there is more of (some level of) an IV. Linear regression can be used when the distribution of the DV is Gaussian (i.e., normal or following a bell curve when plotted).

Also common in corpus linguistics is generalized linear regression. This type of regression has subtypes such as logistic or multinomial and this distinction has to do with the distribution of the data and the type of DV, whether it is numeric or 2-way categorical or 2+-way categorical among other possibilities. We will discuss this a bit more further on. Logistic regression models are easier to fit and easier to interpret than multinomial regression, and are what you will see most commonly in multivariate quantitative corpus linguistics. Sometimes this requires adjusting research questions so that you can operationalise your question as X versus Y rather than A

Statistical description and analysis

versus B versus C versus D and so on. To take the Vera'a example above, our analyses

Another meaningful distinction to be on the lookout for is whether the analysis is labelled as 'mixed-effects' or not. Most analyses of corpus data should, rightly, be labelled and conducted as mixed-effects regression. Not only does multiple regression involve multiple IVs but these IVs are conceptualised as one of two different types: fixed-effect or random-effect. A regression analysis that uses both types is mixedeffects. The main difference between fixed and random effects is that we are interested in the contributions of the different levels of the fixed effects. We expect that the fixed effects would show similar patterns, even if we added new data or applied our model to a different dataset. Random effects reflect a random sample of the population we are interested in, for instance, a particular group of speakers from a population of all speakers, or a handful of texts from all texts that could be produced. A regression model fits a coefficient to each level of the fixed-effects predictor (how much change from the mean does each level reflect). The model fits an SD for the entire set of coefficients associated with different levels of the random-effects predictors.

The random effects predictors are treated as random deflections from the population mean. Mixed-effects models provide better estimates of coefficients associated with the predictors of interest compared to fixed-effects-only logistic regression and help avoid the spurious significance of fixed effects

Each regression model has an intercept. You can think of the intercept as a baseline estimate of the DV that will be affected by adding or changing IVs. For categorical IVs, one level of the IV will be part of the estimate of the intercept (depending on how variables are coded) and this is called the reference level. For continuous IVs, the intercept reflects the estimate if the IV was zero. Sometimes analysts centre their IVs (which tells us how far from the mean each IV datapoint is), and in that case, the intercept reflects the centre value of the IV.

Coefficients (sometimes called the estimate or beta) show how much change from the intercept (or baseline) happens in the prediction of the DV for an IV and are log odds ratios. Log odds ratios, as opposed to odds ratios, are centred around zero (cf.

Levshina 2015:261-263 for more on this). The coefficients will be either positive or negative. In a linear regression model, positive and negative values have clear mappings: IVs or levels of the IV that make the DV smaller (for instance make a word shorter) will be negative, IVs or levels of the IV that make the DV larger will be positive. For logistic regression, positive or negative will reflect either an increase or decrease (respectively) of the probability of the reference level of the outcome variable. With our Vera'a argument expression, positive coefficients show an increase in the probability of the IV being associated with pronoun use.

A standard display of a model output will show the effects of levels of the IV aside from the reference level. 6 This is because the reference level is already part of the intercept estimate.

Let's make this more concrete and apply a mixed-effects logistic regression model to our Vera'a data. Our DV is the form (pronoun vs. zero) of the argument (all S, A, P); our fixed-effects IVs are (1) Animacy, (2) Number, (3) Person, (4) Function/Grammatical Role, (5) Same or Different function of the antecedent, and (6) Distance of the antecedent; and our random-effects are (1) Speaker and (

Here we use the package {lme4}

There is a lot of information in these two tables, so let's take them bit by bit. First, we have Table

Table

Statistical description and analysis

Statistical description and analysis 152 standard errors are really high, then that is a sign that something has gone wrong, like not having enough data to estimate properly or there is no effect.

The p-value represents the chance that the null hypothesis would be true if we observed this sample of data. The 0.002 value of the A function means that there is a 0.02% chance that we would see an association this strong if the null hypothesis were true (meaning we can reject the null hypothesis). A high p-value like 0.823 for the P function, means that this result could easily be obtained by chance. There is a tradition of considering p-values below a certain threshold, like 0.05 or 0.01 to be significantly unlikely to occur by chance, and then these IVs or levels are then deemed "statistically significant". It is important to remember that even if a result is significantly unlikely to be obtained by chance, it is still possible to be randomly obtained, and that statistical significance in a model does not directly translate to real-world importance. The p-values we obtain in statistical modelling are never 0 or below 0. Therefore in the summary table or results, we can report these as being less than 0.01 or 0.001 or so on.

We can interpret our results as showing:

Arguments in Vera'a are significantly more likely to be pronouns when they are animate, in S function, first person and non-singular, with a different antecedent function with an antecedent two or more clauses away.

Alternately:

Arguments in Vera'a are significantly more likely to be zeros when they are inanimate, in A function, singular third person referents, when the referent is mentioned for the first time or the antecedent is only one clause away, and when that antecedent has the same function. Theoretically, this is an interesting result because, first, we see some effects of accessibility and attention as pronouns are more likely when the antecedent is a different function and a few clauses away. Additionally, the P function showed no significant difference from the S function, which is surprising as these are quite different functions. We know from other research that patients -the typical role of P arguments -are often inanimate while agents -the typical role of A arguments -are often animate, so this is something we can explore further with adjustments to our model. One kind of adjustment we could do is include an interaction between two (or more) of the IVs.

Interactions

Interactions are useful in modelling when we want to hypothesise that some of our IVs have a relationship with each other and therefore, a more complicated one with the DV. Say we have two continuous IVs such as transitional probability and word rate and are thinking about their effect on word durations. We know that words that are highly probable in a given context can get shorter, and we know that high speech rates (articulation speed) can also make words shorter. But perhaps when words are highly probably in context AND speech rate is generally high, they get especially short (not just in an additive way). That would mean there is a positive interaction, and we would see this reflected with a positive coefficient for an interaction term in a model with a high standardised score and low p-value. If the effect was additive, then we would see either a positive or negative coefficient but with a low standardised score and p-value that lets us know the result is likely to be by chance. If, however, the coefficient for the interaction term was negative with a high standardised score when the fixed effects were positive, that would let us know that the interaction results in an inverse relationship: words that are both quickly spoken AND highly probable are relatively longer.

For categorical variables, the outcome can be a bit more complicated. Say we have two IVs that both have a negative coefficient like Grammatical Function and Animacy in our example model. We can take a look at a table to see how these variables interact with our DV:

Statistical description and analysis

Statistical description and analysis 154 Table

We include the interaction between animacy and function in our model specification and our new model is summarised below. Like Table

Some other aspects of mixed-effects regression

• Random Slopes -Random intercepts are included in models when we expect (or want to test) that all levels of the random effect reflect different baselines in behaviour that will be similarly affected by the IVs. A random slope, on the other hand, would be included for a random effect where we expect that some variables will have differing effects on its levels. For instance, we might expect different speakers to be affected by the time of day differently: morning people  may be more talkative early in the day and night owls may be less talkative until later on. You would include random intercepts and random slopes for predictors where you expect both the baselines AND the directions or effect sizes to vary (and you have enough data to test this). Like all aspects of modelling, whether or not you include a random slope has to do with the nature of your research question and what you think is going on with your data. For more discussion of random slopes and how necessary (or not) they are, there are some wellknown articles such as

• Linear regression -appropriate in corpus linguistics when you are delving into a problem that should be modelled with a continuous IV: word duration, speech rate, vowel duration, F1 or F2 height for vowels. Note that a continuous DV is not the only thing necessary for linear regression: the data must be conditionally normally distributed (if not, a generalised linear regression such as Poisson regression may be more appropriate). DVs may need to be transformed before modelling including the exclusion of outliers, normalisation, or centring. Also, note that linear regression copes better with collinear predictors than logistic regression. However, you still need to check for multicollinearity between your IVs. Take a look at

• Multinomial regression -appropriate when you are interested in modelling a DV that is categorical with three or more levels. For instance, going back to our Vera'a problem, if we were interested in modelling the outcome of pronouns versus zeros versus lexical NP referent expression, we might choose to use multinomial regression. Multinomial regression can be complicated to interpret and often quite large datasets are required in order for models to converge (fit the data and give a result) (cf.

Statistical description and analysis

Statistical description and analysis 156

Recursive partitioning

Recursive partitioning is about dividing up data (partitioning it) over and over (recursively) to create sub-groups of data that are similar to each other. In seeing what divisions divide the data, we get insight into what kinds of meaningful distinctions can be used to classify our data into different sub-groups. Recursive partitioning as a methodology started in the medical sciences testing the impact of pieces of DNA sequences on illness, but has been adapted to many other research areas including corpus linguistics

Trees

Recursive partitioning can be applied to a continuous DV, and in these cases it is called a regression tree. The tree will bin the data into sections of the DV that are most similar to each other. A categorical DV will use a classification tree and be implemented for a 2-way or 3+-way DV in a reasonably straightforward way. Binary classification trees use binary splits to classify data (data goes into either this group or that) and multiclass (or multinomial) classification trees will use multiple-level splits to classify the data. Binary classification is much more common and what we will focus on here, just be aware that other options exist. The important thing to remember is that for classification trees, the term binary is used for the splits made at each decision stage, not for the structure of the DV.

A binary classification tree divides the data into two groups based on which data points are most different from each other, using the given variables. The analysis determines which IVs, at which level(s), makes the best differentiation of the data's dependent variable. For each node (or sub-group), the data is then split into two more sections based on which data points are most different from each other using the remaining independent variables and remaining levels of independent variables. Because each set of data under a node is looked at anew, the same variable can be used again in a lower level of the tree, with whatever levels are still relevant for that node. This feature of the classification makes it useful to explore non-monotonic (non-linear) relationships between the IV and DV, and predictors that impact only a portion of the data. This splitting (division of the data) continues until a stopping criterion is reached, at which point the data in each node should be relatively homogenous. Some implementations of classification trees, such as those produced by the {party}

The algorithm for creating the tree model will not necessarily use all the IVs available as part of the model specification. If there are IVs that would not make a significant split in the data, they go unused. This makes recursive partitioning a reasonable way to explore whether or not some predictors are influential or not for your data, although this needs to be done with some care.

Let' s apply a binary classification tree to our Vera' a data, excluding here Speaker and Text because their many levels may cause too many splits in the tree, making it difficult to read. We put in a criterion for our stopping threshold at 0.99 and we also specify that the maximum depth of the splitting should be 3, that is the tree should stop splitting (if there continue to be significant differences) after three splits. We do this to keep the tree from splitting very small amounts of data and to keep the visualisation reasonable to read. 8  Our tree is more conservative in what variables it includes: Animacy, Function, Number, Person. However, by adjusting the depth, we have to be careful about how we talk about variables that are not included since our specification removed some IVs that would have been in place if we had not made this adjustment (for us, Antecedent Distance and Antecedent Function). There are many different parameters one can adjust (in the {party} implementation or others), so it is always important to read the documentation and make reasonable choices that reflect your research question and data.

When describing decision trees in text, you can refer to the node numbers (found in our figure at the top of each section/bin of the data, followed by the number of tokens in that group) and the split numbers (the numbers at the top of the circles). The nodes show the proportion of zero or pronominal expression for the final partitions of the data. We would describe our tree as follows:

This classification tree has five splits and five nodes. Figure

The right side of the tree shows three splits for the animate referent data. Split 5 and split 9 are splits in the person data. Speech act participants (the first and second person) are significantly more likely to be expressed by a pronoun, and the first person even more so, as seen in node 10. We see that the third person referents are further

Statistical description and analysis

Statistical description and analysis 158 split into singular and non-singular referents under split 6, with non-singular referents significantly more likely to be expressed as pronouns.

Other predictors (Antecedent Distance and Antecedent Function) do not appear in the tree in Figure

We can also take a look at our data with a 3-way DV, bringing back lexical NPs. We will not go through the description of the tree here but include the plot to show that it is relatively easy to create a tree for a multiple-level categorical DV. In the Figure

Forests

In a random forest analysis, many classification trees are computed based on different subsections of the data and subsets of IVs, creating a "forest" of trees. We do not look at the whole forest tree-by-tree, rather we average across them to get a sense of our data. When many classification trees are averaged, factors can be ranked by their importance, determined by which factors most often make a significant split in the data, especially at higher levels in the tree. The analysis resamples across subsections of the data, and uses different samples of the IVs (here four out of eight possible ones) to increase the variation in the possible trees. Slightly different data subsets

Statistical description and analysis

Statistical description and analysis 160 and variable combinations will result in potentially different variables performing well (sometimes animacy of the referent, sometimes person, etc.); one will be the best factor most often for predicting the outcome of the DV. This one factor will be ranked higher than the others in a variable importance ranking. A conditional permutation of the variable importance ranking, although computationally costly, ensures that the evaluation of a variable's importance takes into consideration its behaviour in relation to other variables in its ranking

The forest in Figure

Clustering methods

Clustering is another quantitative method that is found in corpus linguistics reasonably often. Clustering is about grouping together data points that are more similar to each other, as distinct from less similar data points. Good clusters have low intracluster distance and higher intercluster distance. Different kinds of data and questions require different kinds

Statistical description and analysis

Statistical description and analysis 162 of clustering, but methods can calculate the appropriate number of clusters, how data is grouped, and then gives some kind of visualisation of the data. As an example, we show clustering (Figures 8.8 and 8.9) of a set of six languages by how their benefactive construction is used in multilingual SCOPIC (cf. Chapters 7 and 11).

We will not focus on clustering here, but we list below some of the main clustering types and some resources to find out more about clustering corpus data.

• Hierarchical clustering: builds a tree-like structure, putting together leaves (objects/languages/tokens/groups) that are most similar based on a similarity or dissimilarity matrix of numeric data

• k-means: determines the number of clusters appropriate for the data based on a dissimilarity matrix of numeric data, with a theoretical central point for each cluster, based on a dissimilarity matrix. Data points in the cluster have the least Euclidean distance from that centroid as opposed to other centroids

• k-medoids: similar to k-means, but with a medoid (a data point is selected as the central member of a category) rather than a (theoretical) centroid

• Correspondence Analysis and Multiple Correspondence Analysis: used for categorical, non-numeric dependent variables, plots dependent variables, as well as independent variables associations measured as chi-square distances.

Useful to group data that show similar profiles of use (cf. example in 4.2.1)

Refer to the further readings section for more resources on clustering.

MAKING STATISTICAL CLAIMS

Not everyone worries about the details of statistical analyses, and when some people read through statistical analysis, they often skip over a lot of the details and just look at the p-values. Despite this, reporting only a p-value is not sufficient if you want to accurately report your results. Minimally, you need to provide the test statistic (e.g. r or χ 2 ) and the p-value if there is one, degrees of freedom if possible, as well as the amounts of tokens you looked at (n); you can enhance this by reporting some confidence intervals or error rates, so people can evaluate the test statistics themselves. When reporting multivariate analyses, it often makes sense to present data in a table, as well as in a paragraph format to guide people in interpreting the results. When stating an outcome, include the statistic in addition to stating that something is significant. Statistical abbreviations and indicators should be italicised. Here are some examples:

High following transitional probability (β = -0.25; z = 5.63; p < 0.001) and high Preceding Joint Probability (β = -1.66; z = 39.65; p < 0.001) are associated with lower levels of contraction, meaning the less probable the particular context, the less likely contraction is to occur.

̅ ̅

When subjects are humans, they are more likely to be expressed with a pronoun than when they are non-human animates (β = 0.58, p < 0.05).

Statistical description and analysis 163

CONCLUSION

Corpus linguistics can use a variety of statistical methods, from very simple to very complex. Understanding more about why and how these methods are used will help you to better understand and conduct studies. See below for more resources to help you get started.

FURTHER READING

For information on a range of descriptive and predictive statistics, we recommend looking at

NOTES

1. Temperature in Celsius or Fahrenheit is an interval variable, as 0˚ does not mean no temperature so it is arbitrary in this sense. 2. Available at:

Informally you can imagine for Table

A BRIEF INTRODUCTION TO SOCIOLINGUISTICS

Overlap in studies of variation

Sociolinguistics and corpus linguists have many of the same goals. Both are fields that are interested in people's real usage of language and how it is affected by context. And both seek explanations for observed patterns and variations of usage, acknowledging that both internal and external context play a role. The main difference is that in sociolinguistics, there is a stronger focus on the social factors that condition linguistic behaviour. The most important ones are the characteristics of the language user and their community (age, gender, sexual orientation, class, region, etc.) in conjunction with the communicative situation. Sociolinguistics is a subfield of linguistics where corpus studies are a possible methodology, alongside surveys and experiments and more. The most common kind of data source for variationist sociolinguistics is the sociolinguistic interview, which often includes having participants read a list of words and passages of text as well as a conversational component

Here are some other differences in the foci between sociolinguistic corpus research and other kinds of corpus linguistics:

(1) Generational change: Sociolinguistics often has a focus on change over time. as opposed to much of corpus linguistics which instead focuses on synchronic language use or use within a particular period. Sociolinguistics often focuses on a shorter period of time than historical linguistics. One of the main reasons for this is that the varieties that many sociolinguists are interested in do not have long historical records. Additionally, much of sociolinguistics focuses on phonetic variation, and audio and audio-visual records of language varieties do not go far back into history. Finally, much of our older historical records of language use do not have the kind of detailed metadata required to carefully study communities. The ' Apparent Time Construct' (cf.

(2) Style shifting and non-standard language: Sociolinguists are interested in 'style shifting': the change in language behaviour when language users find themselves in different social situations. Of particular relevance are those situations that speakers find themselves in most typically in their daily lives where they are assumed to use 'vernacular' speech. Other kinds of corpus linguistics are interested in variation between many kinds of register and genre, and often in the differences between spoken and written modes. There is a motivating reason for the focus on the vernacular in sociolinguistics. The idea in sociolinguistics is that vernacular speech will show the most systematic variation. Sociolinguists will often compare the vowel sounds in various stages of a sociolinguistic interview, but taking that part when an interviewee is speaking about something emotional or exciting, as being the most 'real' kind of style. Speakers 'style shift' when they move from one style to another, and are more influenced by prescriptive rules and what they judge to be prestigious in some registers. To this end, many corpora used in sociolinguistics are made up entirely of the vernacular free speech portion of a sociolinguistic interview (similar considerations are relevant in documentary linguists, cf. Chapter 10). This is also because longer stretches of language use occur in this portion of interviews, meaning researchers have a better context to study their targets of interest.

Sociolinguistics also has a long history of working with speakers of non-prestige dialects (especiallyof English). This means that sociolinguists see, understand, and sometimes feel the consequences of racism, xenophobia, sexism, and difficulties stemming from socio-economic disparities. Some sociolinguists, then, make it a part of their research to make more people aware of these perceptions and their consequences and fight against stigmatisations (cf.

(3) Socio-phonetic variation: Sociolinguistics has a long tradition of looking at phonetic variation whereas much of other kinds of corpus linguistics is concerned with lexical, morphological, or syntactic topics. The latter of these are

Corpora in sociolinguistics

Corpora in sociolinguistics 166 more readily accessible in a broad range of available corpus data, including written text corpora. Unless a spoken text corpus has been phonetically annotated (cf. 4.2.2 and 7.2.1), corpus linguists are often relegated to researching topics that can be represented by strings of characters, which are easily read by a computer. However, much of sociolinguistics has focused on phonetic variables, especially vowels, and on non-standard varieties of languages, neither are well represented in mainstream corpora which often include mainly written text in the standard variety of a language. And even where transcribed spoken texts have been included in a corpus it can be difficult to assess the degree of standardisation (cf.

The focus on vowels in sociolinguistics is motivated by their specific characteristics: vowels are continuous and lack hard breaks between one another. Speakers may thus produce a vowel a bit differently each time they pronounce it, and listeners will mostly still understand it as the intended sound. The variation in production from each person can build up to variability within a population (or community). Vowels, then, can change quite quickly over time. If you listen to speech from an elder (or young person) of your community, you might notice some words are pronounced differently than your own. Sounds, especially vowels, can also vary quite drastically across different regions and countries, even within a single language. This makes sounds a hotbed of variability that can be measured (by formant frequency, among other measurements) which makes for interesting studies.

(4) Sociolinguistic fieldwork: Like documentary linguists (Chapter 10), many sociolinguists collect their corpus data themselves during fieldwork in speech communities, with whom they tend to become very familiar. This means different kinds of questions are asked for the data and that many explanations for patterns of language use come from understanding the communities, people, and personalities the linguist is working with. Sociolinguists often want to situate language in its social and interpersonal contexts, and so much more information is needed about specific people and their relationships to and within their communities (cf.

Variables in sociolinguistics

In sociolinguistics, a variety of language can be an accent, style, dialect, language, or a specific kind of language used for study. From decades of sociolinguistic research, we know that groups of people use a constellation of linguistic features (what sociolinguists call the variants of linguistic variables). Some people will use one variant of a linguistic variable more often, others will use another. Some of these differences are at the level of consciousness and others are below. Some variants are also strongly associated with some groups as identifying features. In sociolinguistics, variants are discussed as 'stereotypes' , 'markers' , or 'indicators' following a tradition set out by William

Stereotypes are linguistic features that many people will consciously associate with a group of language users, although they may not be accurate. For instance, people may associate African American Language (sometimes called African American English, African American Vernacular English or Black English) with copula deletion: He my brother. Or people may associate young women's speech with a creaky voice. Or people may associate Australian English with a lot of lexical shortenings like arvo (afternoon), barbie (barbeque), poli (politician), rego (registration), and tradie (tradesman). Markers and indicators are features that language users of a variety (and non-users of that variety) are not aware of but help distinguish a particular variety.

Markers are variables that language users have a subconscious awareness of, which is demonstrated through the increased or decreased usage of that variable in more informal versus formal varieties of speech. For instance, a young professor may use a variant less while lecturing and more while she is at a bar with friends without actively choosing to do so. An indicator is consistently favoured by language users of a variety no matter the social situation they are in. These notions form a continuum, and markers can readily become stereotypes as people become aware of them.

We know from previous research that for many variables, most people do not use one variant exclusively. People use mostly one variant (as with an indicator) or mostly one variant in a particular situation (as with a marker). The distribution is probabilistic. Some people have a higher probability of using one variant over another in a particular context, and that context may have to do with their interlocutor, the situation, the topic of conversation, or more. A corpus approach can be used then, in conjunction with a sociolinguistic question, to describe the distribution of the variants across such external contextual features. To be able to assess these factors properly, good metadata is needed about the language users as well as good metadata or annotations about each specific context of use.

DIALECT AND REGIONAL VARIATION

For over 100 years, researchers have been interested in how people from different regions speak, where the linguistic boundaries of these regions are, and what variants -so-called isoglosses -characterise linguistic regions. A variety associated with a particular region in this way is called a (regional) dialect. This kind of work was done with questionnaire-based surveys and short interviews in different locations, often to create atlases of dialects.

Many corpora used in sociolinguistics are comprised of sociolinguistic interviews with speakers of a particular variety. For instance, the West Virginia Corpus of English in Appalachia includes word lists, reading passages, and casual conversations from 67 speakers, who are of different ages, sexes, regions, family backgrounds, occupations, and orientations to social institutions (cf.

Corpora in sociolinguistics

Corpora in sociolinguistics 168 section, we will go through three approaches to the question of regional dialect variation. The first is an approach coming from corpus linguistics towards sociolinguistics, comparing American and British English uses of run, using established corpora

Cross-dialectal variation in large corpora

In an attempt to fathom the differences between two global varieties of English, Glynn (2014) reproduces

The most frequent meaning of run Glynn finds is 'fast pedestrian motion' just as with

Dialectal variation in corpora of sociolinguistic interviews

Regional sociolinguistic corpus research often focuses on the features that are associated with a specific dialect. Like any linguistic community, a particular regional community is not a monolith and we expect variation according to age, gender, education levels, attitudes, etc. Further, a feature that may be strongly associated with a particular community can still have predictable variation within that community.

-no notable difference between genders or age groups -no notable difference between speakers of different social classes for this variable, although in the same corpus there are social class differences in the production of -ing versus -in' in words like walking

Corpora in sociolinguistics

Corpora in sociolinguistics 170 -no notable difference between northern and southern regions of West Virginian Appalachian English

Corpus-based dialectometry

In dialectometry researchers analyse the relationships between linguistic and regional variables, such as longitude and latitude (cf.

Linguists have often described dialect regions using the results of surveys as part of dialect atlases. However, the use of corpora is also possible for dialectometry.

Corpus-based dialectometry requires dialect corpora that are representative of multiple geographic areas associated with a particular language variety. The corpora have to have enough data per locale to compare multiple features across those locales.

The steps of dialectometry are broadly as follows (cf.

(1) Establish the set of features to be investigated and compared, for instance (cf. Szmrecsanyi 2013):

-negative suffix -nae versus particle not (I cannae/cannot do it); -of-genitive versus 's-genitive (my father's home vs. the home of my father);

Exercise 9.1 Reflection

What is the difference in the approach to speaker communities between Glynn (2014) and

-is versus are or was versus were with inversed plural subjects in existential constructions (there is/are/was/were several involved)?

(2) Determine the realisations of the features for each location of interest (3) Compare the features across locations. Create some set of measurements, usually in a matrix form that allows for a calculation of the (dis)similarity between each of the locations sampled. Corpus-based dialectometry will focus on the frequencies of these features (4) Map the results and conduct follow-up analyses to confirm the goodness of the results

Corpus-based dialectometric studies have been conducted for American English

SOCIAL FACTORS OF VARIATION AND CHANGE

Some sociolinguistic variables are conditioned not by area, but by some broader social divisions. Some variants are more prestigious than others and people have different ways to show how they orient themselves to standards and norms by their use (or not) of prestige variants. But prestige is a complex notion. Sociolinguists often write about overt and covert prestige. Variants that are part of a standard or have normative valuations like being 'nicer' , 'better' , and 'correct' have overt prestige, that is, people are aware of the prestige of the variant. Some variants have covert prestige or some quality that people orient to privately or subconsciously

Ethnicity

One of the key areas of research in sociolinguistics is ethnicity. Whether we want it to or not, ethnicity carves up our social space in some real ways. In sociolinguistics of American English, a great deal of research has shown that there are clear differences

Exercise 9.2 Prestige type

In a corpus of 15th c. letters,

Corpora in sociolinguistics

Corpora in sociolinguistics 172 in speech characteristics between white Americans and African Americans. It is important to remember when studying ethnicity as a factor affecting linguistic choice, that there is nothing deterministic about ethnicity (or any other social factors) (not all African Americans speak African American English (AAE)). And there are important notions of overt, covert, and local prestige to take into account. Speakers of many non-standard varieties also speak standard varieties and choose to use features of (non-)standard varieties to signal their orientation to different communities and ideals associated with these.

Let' s take a closer look at ethnicity in sociolinguistics in more detail by reviewing a wellstudied syntactic alternation: the dative alternation (cf. 4.2.5), diving into a corpus of African American English from

Like much sociolinguistic corpus-based research, establishing a large enough corpus for the variable of interest is an issue for these authors. They combine spoken interview data from the Sociolinguistic Archive and Analysis Project (SLAAP)

The authors annotated their data by hand for factors including those listed below. Factors that came out as significant in their analysis are in bold.

-whether the recipient was realised by a noun or pronoun (prepositional dative constructions are more likely when the recipient was not realised by a pronoun: He gave the book to the man) -whether the theme was realised by a noun or pronoun (prepositional dative constructions are more likely when the theme was realised by a pronoun: He gave it to the man) -the animacy of both participants -the difference in length between the two expressions (prepositional dative constructions are more likely when the expression for the recipient is longer than that for the theme: He gave the book to the very important man) -age of the speaker (collapsed into the categories of antebellum, older contemporary, younger contemporary) -sex of the speaker -corpus variety (contemporary interviews or historical letters)

The authors then compare their AAE results with the give portion of the Standard American English (SAE) data from

From this the authors conclude that the dative alternation is probabilistically equivalent across the varieties: the same factors affect the data in a similar way. This indicates that the dative alternation is not a sociolinguistic indicator; it is not being used to distinguish the varieties, even subconsciously.

Sex and gender

Like with age and ethnicity, gender is a complex notion and the kinds of linguistic forms associated with different genders may be different from community to community. Studies of major societies, particularly Western and English-speaking communities, have shown that when there is stable variation in a community, women are more likely to use prestige forms more often than men (cf.

Corpora in sociolinguistics

Corpora in sociolinguistics 174 correlations".

Ms is a title for women that does not specify their marital status, like Miss (unmarried) and Mrs (married) do. In this way, it is equivalent to Mr. The introduction of Ms was supposed to eliminate linguistic discrimination by having equivalent female and male terms. However, when societal discrimination exists, linguistic discrimination will continue to exist, although it may change in how it is deployed. Holmes' research shows that there are various attitudes towards the use of the title Ms in New Zealand. Some regard the term as signalling a feminist identity (which may in itself have positive or negative connotations). Others still imbue the term with having something to do with marital status, feeling that it is used by and/or for women who are separated, divorced, widowed, or partnered (in de-facto/common law relationships), and hence fall out of the two traditionally 'normal' and valued categories of being either married or not yet married.

In a study of Australian student usage of Ms,

Holmes sees parallels in the attitudes of university-aged New Zealand women, finding that some women construct a conservative female identity where marital status is an important aspect of this femininity. Other women may see Ms, or any title, as old-fashioned and prefer to use first names without titles.

Interaction of constraints

Like internal factors (cf. 84.1), external factors such as gender and class can interact. Through much sociolinguistic research, it is also clear that many processes of language change come about through women leading change in their communities.

Exercise 9.3 Women in corpora

Just like in the Wellington Corpus of Spoken New Zealand English, in many available English corpora, men are mentioned and discussed much more than women. Why could this be?

As an activity, compare multiple English corpora, such as the COCA or COHA, or look at multiple genres within one corpus. Search for basic terms like 'man' , 'woman' , 'male' , 'female' , pronouns like 'he/him' and 'she/her' and titles like 'Mr' , 'Ms' , 'Miss' , and 'Mrs' .

What is the ratio of the use of male words versus female words? What genres show the strongest differences and why might that be? Until 1994 South African society was governed by a regime of apartheid, a system of legally sanctioned and practised racial discrimination and segregation . People were labelled as part of different 'races' and were segregated from birth, through childhood, education, work, were not allowed to marry and were eventually buried in separate cemeteries. 'Races' included 'Black' people, mostly speakers of Bantu languages, 'Coloured' people of multiple ancestries including people of Khoesan cultures, 'Indian' people who had ancestry from the country of India, and 'White' people who would either be first language English speakers (L1) or second language English speakers (L2) who spoke L1 Afrikaans, another Germanic language closely related to modern Dutch. This complex, discriminatory situation led to five distinct types of English in South Africa. After apartheid collapsed in the 90s, there was a regime shift in South Africa and now the political and much of the economic power is held by Black South Africans (although not all are economically advantaged). An elite group has formed, in part through access to expensive private school education. Private school education means Black students now have exposure to a variety of English that was previously associated with English-speaking Whites.

White South African English (WSAE) is a prestige dialect but is no longer associated with only white South Africans. It is an L1 English variety that many young, middleclass Black South Africans are now acquiring, especially young middle-class Black women. This is now replacing the L2 English variety that was previously spoken by many Black South Africans, Black South African English (BSAE). This L2 variety has a strong influence of Bantu L1 that's spoken in multilingual South Africa.

Among other features, BSAE lacks a schwa [ə] (a central vowel) which WSAE does have. The lack of schwa is a stereotype (in the sociolinguistic sense). It is used purposefully in some advertising campaigns orienting to BSAE, with slogans like "it' s obvyas" with obvyas showing the choice of a full vowel [a] instead of

The primary comparisons were between the female versus male and private-schooled versus non-private-schooled young Black speakers. Conditional inference tree analyses on F1 and F2 of the schwa vowel for different environments (word initial, final and medial) showed that female private-schooled young people use more centralised variants and are most different from their male non-private-schooled counterparts who use more peripheral variants. The relationship between the female non-privateschooled speakers and the male private-schooled speakers is more complex, with some tests showing significant differentiation amongst the groups due to class and others due to gender. Overall, this is a sign that the women are leading this change.

Depictions and attitudes from the media also strengthen the idea that this dialect shift is tied up with both gender and class. When this change is discussed or portrayed in the media, typically women are used as examples of the vowel centralisation. The prestige of WSAE is connected to upward mobility, aspiration, and a sign that speakers of it, particularly female speakers, have education and advantages that were not available to them during the apartheid period. However, there is also some resistance to this change. There is a local prestige of BSAE, with males' dialect variation showing a strong connection to BSAE that has local prestige and stronger connections to African languages that are used by many of the multilingual speakers in the community.

VARIATION AND LANGUAGE CHANGE

Variation and change are explicitly connected in sociolinguistics. Before a change can take place in a community, variation has to exist. Someone in the community will be the first to produce a new variant, thus adding a further variant to a variable, some other people may also start using that variant, and the variation can spread and eventually lead to change in the variety of languages (or not). There are some cases where we can study variables and their changing variants over time and see whether their probability of use has changed (or not). There are some amazing corpora available that have data from different time periods, for example, COHA for American English, which covers texts from between the 1810s to the 2010s (spoken ones as published on TV or in movies from the 1930s). In other circumstances, researchers can use different corpora of the same variety to examine what variants have been used over different periods. These approaches are classified as real time studies. For sociolinguistic studies to be carried out, the corpora also need a fair bit of information about the language users (which is problematic in COHA). These kinds of corpora do exist, but they are rare. An alternative approach, and one that is more commonly used due to the ease of resourcing data, is an apparent time study.

An apparent time study uses data from one time period within a variety of languages, but that includes data from language users of different ages. If older language users are doing something different than younger language users, it is taken to indicate that there has been a change in the linguistic community. Such differences could indicate that older people took up a change that younger people did not. But

Corpora for real time studies

New Zealand English, including interviews of settlers in the 1930s and 1940s describing where they and their parents come from -Origins of New Zealand English (ONZE) -

How do you know how many ages you should look at to determine what kinds of changes (or not) are taking place in a community? Looking at more than two generations shows better that there is an increased frequency of a variant. Looking at just two generations may mean that you are positing a generational change where one does not actually exist. Some variation is stable across time, and may not be a change in progress. Age can be assessed as a continuous variable, or binned, meaning people born within, say, ten years are put together as a group. A continuous variable may be too detailed for some analyses, where we do not expect differences between people born in 1978 and 1982. Estimations of an effect over a continuous variable of age may also be affected if there are only a few people over very different ages (for example, ten 20-year olds, two 25-year olds, and thirty 70-year olds,). If a researcher wants to convincingly show a generational change, they need to show multiple age groups to make sure the change in frequency of a variant carries over from generation to generation.

In some communities, age may also be more sensibly looked at as a cohort rather than as a number

Let's take a look at a study that compares two kinds of age-related changes.

Fruehwald examines a set of variables in this dataset (vowel changes and whether or not speakers use um or uh for filled pauses). He uses a series of GAMs (cf.

Other outcome variables support both generational change and lifespan instability. For instance, the vowel /ey/ as in make and same raises and fronts (assessed by normalised F2-normalised F1), especially for women born after 1950. Earlier generations show no change during the lifespan, but for women in the 1960 and 1980 birth Exercise 9.4 Emic grouping If you were to conduct a sociolinguistic study in your community, how would you emically group language users according to age? What might be some considerations for emic groups of gender, class, and other external factors?

Corpora in sociolinguistics

Corpora in sociolinguistics 180 cohorts, there are lifespan changes moving in the same direction as the community (that is: an increase in raising and fronting as the year of the interview becomes later). Men show generational changes, but not lifespan ones. Fruehwald explains: "a woman born in 1940 would have the same /ey/ whether they were interviewed in 1990 or 2000, but a woman born in 1960 would have a higher and fronter /ey/ in 2000 than in 1990".

Fruehwald takes these careful results not only as support for the Apparent Time model of language change but also an indication that age is a complex variable that is best studied by taking into account the language users' year of birth and the year of interview to assess changes.

What is apparent across these studies is that variables like age, gender, class, and ethnicity are complicated and often interact. Although much of our knowledge of sociolinguistics comes from English-speaking communities, particularly those in the United Kingdom and the United States of America, there is a lot of good sociolinguistic research being done in other communities. In all kinds of communities, sociolinguistic work is best done with careful ethnographic research and with emic considerations of groups of people. Sensible age cohorts are different across cultures, women have different roles and access to (kinds of) power across communities, and non-traditional groupings (such as clan) may play a role in sociolinguistic variation.

CONCLUSION

Corpus linguistics is a central approach in sociolinguistics that is interested in the use of language as dependent on a range of social factors. These are generally captured in corpus linguistics as part of the external contextual features. We have seen how essentially corpus-linguistic investigations can be levelled to address sociolinguistic questions. A major remaining challenge is the lack of sufficiently rich corpora from diverse languages that contain the relevant primary data as well as metadata.

FURTHER READING

Meyerhoff (2015a) is a general introduction to the field of sociolinguistics, and it includes extensive discussion of basic quantitative research, including corpus-based work.

Specific studies on non-English sociolinguistics

Corpora in sociolinguistics 181

General references on sociolinguistics-documentation

NOTES 10.1 LANGUAGE DOCUMENTATION: CAPTURING THE DIVERSITY OF HUMAN LANGUAGES

A major concern in modern linguistics is the study of the many diverse human languages in the world, and linguists know very little about a substantial number of these. Diversity in human languages is huge: linguists estimate that there are approximately 6,500 languages used today. Each language can have distinct varieties associated with particular areas or regions (regional dialects), or a social group (social dialects), or some other extra-linguistic parameter, in the same way that English has its varieties. The task for linguists to grasp the diversity of human languages is immense.

Many languages have not been studied before at all, and often we have no descriptive or analytic work available, like grammars or dictionaries, and also, there are no raw or primary data, that is, no documentation of how the language is used. Language documentation is the area of linguistics that aims at recording the observable use of language in a given society as much as possible, and doing so in as many societies and associated languages around the world as possible. The goal of language documentation is to create a lasting record of languages' use, which crucially includes a corpus of transcribed and translated records gathered during fieldwork (cf.

Modern language documentation began in the late 1980s -beginning 1990s, at least partly as a reaction to the dramatic decrease in the diversity of human languages.

10

Corpus linguistics and language documentation KEY WORDS

Corpus versus Documentation

Documentations as Convenience Samples

DOI: 10.4324/9780429269035-10

Corpus linguistics 183

Quite suddenly linguists became aware of drastic rates of prospective language loss around the world, sparked by a seminal presentation by Eastern German linguist Johannes Bechert in 1987

Researchers expect that close to 6,000 of the 6,500 world's languages will disappear in the next 80 years. The urgency to support the ongoing use of these languages and to ensure there are good records before they are lost forever is tremendous. Documentary linguists want to capture examples of many kinds of language use in context so that if a language dies out, there is a record of how people used it. This explains in part why documentarians' work differs from that of classical descriptive and typological linguists in its primary focus on data collection rather than analysis and comparison, and creating a corpus is part of a documentation project. There is, however, more to the enterprise of language documentation as we will see.

Defining language documentation

Language documentation to a large degree deals with methods of linguistic fieldwork: documentary linguists go out and spend extensive periods of time in communities that use one or more languages that are the target of the specific documentation project. But this alone does not make them any different from a descriptive linguist who would typically also undertake fieldwork in order to capture information (vocabulary, phonological, and grammatical rules) that would end up in a published dictionary or grammar. The difference lies in the overall ends of fieldwork: while a descriptive linguist aims at getting all the data they need for their specific academic work, "[t]he aim of [a] language documentation […] is to provide a comprehensive record of the linguistic practices characteristic of a given speech community"

Language documentation in practice

Given the goals outlined above, language documentation involves the collection of audio or video recordings of numerous communicative events as they occur in their typical environment in an attempt to capture them in all their detail. Given that video recordings offer many advantages and are relatively easily done these days, video has become the gold standard of recording format: video recordings of entire communicative events give us a good sense of how a language is used over longer stretches of communication and how its use interacts with the physical environment, other participants, and bystanders (think of the use of demonstrative adverbs like here, there, and yonder). They also allow us to capture gestures, for instance, how someone points to a place indicated by a particular demonstrative adverb or how someone engages with an interlocutor with facial and manual gestures. So, a typical record in language documentation could be a video-recorded conversation, for example, about building a canoe, where we see people around a half-hollow tree trunk point at different spots and comment on what needs to be done, and possibly explaining to the researcher what is going on. Video recordings also allow us to document sign languages; see Chapter 4.3 for some details on their corpus-based investigation.

Language documentation shares with corpus linguistics the basic goal of representativeness. Yet, language documentarians often work under circumstances that are not purely research-oriented, and communities are -and should be -involved in steering the direction of a project and what it should cover. In essence then, these records are largely

Exercise 10.1 Reflect on the advantages of video as the main recording format

(2) Name some purposes of video recordings of different event types other than linguistic analysis. What user groups could benefit? What other kinds of material could arise from these?

(3) What circumstances can you think of that might suggest communicative events should not be recorded on video?

Corpus linguistics 185 convenience samples (cf. 2.3) of language use: documentary linguists record what they come across or what is being suggested to them during a field session. They are never in full control for ethical reasons, and also, they may not know (as community-outsiders) or be fully aware (even as community members) of all the communicative events relevant. This bears some consequences for corpus building in language documentation because it means that our corpora are mostly haphazard and opportunistic.

10.1.3 What are "linguistic practices"?

Himmelmann' s (1998:166) use of the term linguistic practices refers not only to verbal behaviour, that is the use of language as immediately observable and, thus, directly recordable. It also includes a second component of metalinguistic knowledge which comprises everything people know about the language and are conscious of. For instance, speakers of many varieties of English are often aware of subject-verb agreement, that is they possess conscious knowledge that a verb in the present tense with the third person singular subject ends in -s. They may also be aware of varieties of English where no ending occurs in third person singular verbs and may hold negative views about this. All this belongs in the area of metalinguistic knowledge. It is different from what we have discussed under the label of linguistic knowledge (cf.

How can metalinguistic knowledge be recorded during language documentation and how are they relevant to corpus building? First of all, it may come up in naturally occurring, recorded conversations: in many communities, people talk about the use of certain forms, in particular if they feel that one or the other variant is of lower prestige, like the lack of subject agreement in some English varieties. Second, capturing metalinguistic knowledge can also take the form of recording discussions of linguistic structures between the researcher and one or more users of a given language. Third, writing in a native language may provide valuable clues as to metalinguistic knowledge, for instance, with regard to how a stream of speech is broken down into segments like words (see

Exercise 10. The kinds of texts and interactions that are recorded and transcribed as part of a language documentation project may not be the kinds of texts one would record if planning a corpus. We discussed in Chapter 3.1 how the size and composition of a corpus reflect in various degrees its representativeness and saturation. However, the practical limitations on corpus building outlined in Chapter 6 are particularly relevant in documentation projects. Here, a corpus, especially a small one, can be specific to one genre or even one person. Researchers must simply be upfront about what makes up the corpus and be aware that not all corpora are appropriate for grand generalisations about a language. Practical considerations are also relevant when it comes to the processing and annotation of data collected in a documentation project. At the same time, however, given that documentations target languages that are not known to a wider scientific community, a greater minimum of annotation is key for documentation corpora, as will be discussed further in 10.3 (cf. Chapter 7 on annotations for requirements on annotations and their added value).

In Good for a genre-specific corpus, and a starting point for some research questions.

Elicited sentences? Not ideal as the sole basis of a text corpus, but could be used for phonetic measurements. Paradigms and word lists? These are the result of linguistic analysis and as such not appropriate for a corpus, but are good to be included in the apparatus once texts are collected. After assessing what is present in the collection, then you can plan for what you would like to add and focus on that in your corpus building enterprise. As a rule of thumb, something is better than nothing. This truism is always worth repeating given that much of linguistic work on diverse languages is based on data that is not accessible to others. Also note that limited variation bears advantages in allowing for investigations of small sets of variable characteristics, for example, specific variation across registers as outlined for Vera'a in 3.1.6 (see also Mosel 2014 on this point).

(3) What metadata and annotation files do you find? Can you access the data? Try to access an annotated text and find the respective word for 'woman' . How do you go about doing this? (Note you have to register for free and sign a code of conduct before you can access the archived material.)

Multiple purposes of language documentation

While language documentation lends itself to many different purposes, the two primary ones are for a community to have a record of how their language is used at a particular point in time, and for researchers to increase the knowledge of how human languages work. Other user groups are other academic disciplines, like ethnographers, musicologists, social scientists, and so forth, as well as journalists or other kinds of writers, or government agencies who conduct language planning and devise education policies. Crucially, the open-endedness of language documentations also makes them amenable for future purposes that no one is thinking of yet. As mentioned above, video recordings are particularly well-designed to serve a variety of purposes since they give a broad impression of communicative events, including paralinguistic behaviour like gestures and facial expression, the physical surroundings, as well as other aspects of social behaviour in a given culture, for instance, how different people dress, what levels of distance they keep between each other, etc. They reflect much better than word lists, dictionaries, or written texts how the language works in long stretches. For language communities, language documentation gives a broad sense of how their language is used. As such it can prove a valuable resource for current or future language maintenance and educational purposes (see Mosel 2012 for an example).

Corpus linguists are interested in how linguistic data is conditioned by context. To achieve this, we need annotations and metadata to turn collections of data into corpora that will form the basis for corpus-linguistic investigations of language use, and what this tells us about the structure of a specific language's grammar, lexicon, etc., as well as the conventions of the language use and that of the community members' thereof.

FROM COLLECTION TO CORPUS: CORPUS BUILDING FROM LANGUAGE DOCUMENTATION

The building of a corpus within a language documentation project is not generally different from any other corpus building project, as discussed in Chapter 6. Yet, the building of an LD-based corpus faces particular challenges through the typically severer limitations of resources and the fact that potential academic users of the corpus have typically no prior knowledge. The first aspect has already been addressed above.

Making an LD corpus accessible to a broader scientific community is a key consideration. Table

Corpus linguistics 189

In Chapters 6 and 7 we have discussed various layers of annotation and how they add value to a corpus. The necessary processing steps of raw data for LD corpora consists not only in time-aligned transcriptions -given that LD corpora target primarily spoken language use -but also in the translation of the transcribed text into a language widely known by anticipated user groups. In this way the corpus text is searchable and users can grasp the meaning of specific passages. What is crucial for languagedocumentation-based corpora is that they remain closely linked to the raw recording data. Additional important layers of annotation are translation, morphological glosses where software such as ELAN can be useful (cf. Chapters 6 and 7). Moreover, for LD corpora it is much more important that they are interlinked with a lexical database and a sketch grammar of the language (cf.

Corpora versus language documentations

An important difference between a corpus and language documentation is that the latter is relatively stable, that is to say the primary data and related metadata are not further manipulated. All that may change in the course of documentation and analysis, and hence, a growing understanding of the data at hand are the annotations that make up the core of the corpus. For a corpus then, it is perfectly normal to have multiple versions reflecting different stages of understanding, as well as for different purposes. This also means that one will often need to do transformations, exclusions, and further annotations to get the information needed for a particular question or research goal. Possibly a somewhat extreme but quite illustrative example is the creation of corpora within the previously mentioned MultiCAST collection

RESEARCH QUESTIONS APPROPRIATE FOR SMALL CORPORA

As discussed in 3.1.1, corpus size is important because we know that in a large sample, we have a better chance of finding what we are looking for, and a better chance of seeing typical patterns of usage. A small sample is more likely to be affected by chance and we may see spurious results. Small samples, unless carefully balanced, will be much more affected by the genre of the source content. A corpus of Pear stories

Function words

Very few words occur with enough frequency in a small corpus to make a robust study of them. However, function words (grammatical words) do occur often and regularly and are thus often put on a stop list (cf. 5.3). In a small corpus, particularly of an under-researched language, function words have an advantage because they are so frequent, and it may be interesting to determine the full range of their contexts. As we have described in previous chapters, one of the main focuses of corpus linguistic research is variation. If there is an element of variation in the function words, this can become a fruitful research path.

Below is a list of the nine most frequent words from the 2020 Matukar Panau corpus (150,740 words). In this corpus, there are 14,021 different words (types). In a list of the ten most frequent words of a large English corpus, all of the words will be function words. In the Matukar Panau list, we see function words and a content word (tamat, 'man'). The language features of Matukar Panau also affects the most frequent words. It does not have determiners or obligatory person pronouns, and a lot of the grammar of the language is done with morphology on the verb or nouns rather than independent words as in English. This means that we see many different inflected verbs in the language, none of which end up being very frequent. What we do see in this list of grammatical words is that the most frequent and fourth-most frequent words are related. Main is primarily a proximal demonstrative, but can also be a relativiser or clause boundary marker. Mainangan is the focused variant of the proximal demonstrative. Together, there are over 13,800 tokens of main and mainangan which would be the basis of a respectable study!

Exercise 10.3 Collection versus corpus

Look at collections available at the Pacific and Regional Archive for Digital Sources at

(1) Choose five collections and name them, include a citation for each collection.

(2) For each describe the material present that would make up a corpus. What is the format of the data? How much is available (in time or words or another appropriate measure)?

(3) What else is present in the collection and who is/are the target user(s) of that material?

(4) How consistent is the material across the five collections?

(5) From one collection, select annotated data whose annotations can serve as a small corpus. Is it possible to determine word frequencies? Genre-specific word frequencies? Keep track of your selection and search procedures.

(6) What layers of annotations can you find in annotation files in different collections? What linguistic questions could you address based on these annotations?

Grammatical marking

As with function words, grammatical marking can be a fruitful area of study even in a small corpus because it tends to be obligatory and frequent, although this obviously depends on the language of study. If there is a presence or absence of grammatical marking due to certain context features, this can be appropriate for a corpus study, particularly as part of the language description processes. For instance, is object marking optional? Does it occur with some persons or numbers more often than others? A related question is the variable realisation of objects as either pronoun or zero, and in 8.4 we have presented such a corpus-based study for Vera' a in some detail. Grammatical marking can also be studied in terms of co-occurrence. What kinds of verbs co-occur most often with imperfective versus perfective aspects and how do the aspects change the meanings of verbs?

Exercise 10.4 Cross-linguistic frequent words

(1) Search the web for "word frequency lists". There are many freely available in a variety of languages and genres, many more so than corpora for the same languages. Many lists are used for computer linguistic applications. Identify three real use cases of word frequency lists from your web research.

(2) Small Corpora Skew: look at the ten most frequent words of some small language or genre-specific corpora. Are the words function words or content words? What are the content words? Does the genre of the small corpus affect the content words that occur? Name several advantages and disadvantages of using a small, genre-specific corpus, and list possible research questions that could be answered with a small genre-specific corpus.

(3) Language effects of corpora: look at the ten most frequent words in some isolating versus agglutinating languages. How does the language type affect which words are included in the most frequent lists? While grammatical and functional information can be found often even in a small corpus, it is not the only thing linguists want to study. Particular adjectives, nouns, verbs, or adpositions may not show up often enough, but classes of these words may still be large.

In the language documentation process, word analysis like parsing and glossing helps the researcher understand the structure of the language. If that information is recorded in a machine searchable way, like through FLEX or other programs, then that material can become an annotated corpus. Something to be aware of, however, is that during fieldwork on an under-described language, one may change analyses. If the annotations are not changed throughout the corpus, that can cause issues later on.

A researcher should then balance the efforts and rewards of making changes throughout an entire corpus; keeping some glosses underspecified, as described above, is a relevant technique here.

Constructions (syntactic variants)

Constructions bigger than the word level include kinds of clause combining, word order, order of constituents, constructions with particular arguments, and constructions with particular functions or meanings like possessives, comitatives, existentials, and so on. Like classes of words, particular constructions are often more frequent than particular words, giving linguistics enough data for research. Constructions, however, can be difficult to search for unless they have a particular feature or string that can be searched for, or unless additional coding or annotation has already gone into the corpus, for example, in the form of GRAID annotations mentioned in 10.3.1 that enable searches for different types of clause constructions including the distinction between intransitive, (mono-) transitive, and ditransitive clause constructions. In particular questions concerning the latter constructions can often not be addressed based on verb searches alone because in many languages relevant verbs are not restricted to ditransitive constructions (recall also the

Zeros

Refer back to Table

The study of subject and object realisation by some overt form versus zero is a well-studied research area that includes major and minority languages. In languages like English and German, both subject and object tend to be overt: if they are not expressed as a full NP, a pronoun will often be used to fill the relevant syntactic position. In languages like Japanese and Mandarin, but also Spanish or Polish, where an NP is used, subject and object positions will more typically be left unfilled, that is zero (cf. Chapter 11). Contrasting entire languages in this way is, however, simplifying it quite a bit. For one thing, even in these relatively wellstudied languages matters are more intricate: for instance, subjects in English are much more frequently zero than objects

Other studies that could include zeros are those of copula absence, like

Phonetic information

Even in a small corpus, there are many phonemes. There are various forced aligners freely available that can automatically segment an audio file into phonemes if there is an available matching transcription. Forced aligners use a dictionary (word list) of the language, an acoustic model of the language and their own algorithms to match and segment the audio file to a transcript. Some forced aligners can build an acoustic model of the language during the forced alignment procedure, so an existing model is not necessary, which is a major benefit to under-documented and minority languages. Once segmentation has been checked, various phonetic scripts,

Corpus linguistics 195 also freely available, can be used or adapted to collect measurements. Measuring vowels is particularly useful, as we know from sociolinguistic research that a great deal of social variation is expressed through vowels. A recent project force aligning seven hours of Matukar Panau data resulting in close to 50,000 monophthongs and hundreds of thousands of vowel measurements

What we can't study

Small corpora can be the basis for the study of many things, but some topics are very difficult to investigate without a large corpus. A small corpus, unless designed to contain particular data, will be unhelpful in investigating the behaviour of particular infrequent words or collocations. Any rara (rare phenomena) are unlikely to be found in a small corpus, or if found, will be infrequent. A handful of examples of a particular token is not enough to give a confident sense of the full range of its behaviour, even if they can give a general sense of meaning.

Additionally, many measures of frequency and predictability that require bigram/ n-gram information will be skewed heavily by the data available in a small corpus.

Many studies have shown that frequency and predictability affect language processing, production, and representation

Advantages of small corpora

Although we cannot do everything with a small corpus, there are advantages to a small, single researcher or small team-built corpus. If you build a corpus out of language documentation data, you probably have a very good idea of what is in the corpus and the context for that information, much more so than with a multimillion-word corpus. Large corpora will often contain a fair number of errors, missing metadata, and incorrectly coded information. Because the corpus is large, this does not necessarily have a large impact on overall patterns. However, with a small corpus, there is probably a lot less of this "junk" to throw out. Small corpora from language documentation probably contain a great deal of spontaneous language data. This data is often considered the best kind of language data available to understand how people really use language because it is less considered and belaboured than written text. A small spoken or signed corpus, therefore, can still be a good representation of how people use their language.

CONCLUSION

The take away message from this chapter is that the corpus linguist who works within language documentation has fairly little control over the kind and quantity of corpus data they can include in a corpus. When working with corpora based on language documentations, corpus linguists need to work with what they have, and this may often require flexibility. It also means that the research we can pursue based on these corpora may be limited. At the same time, it is worth noting that corpus-based work on lesser-documented languages is of particular value given how little we know about language use in many languages.

FURTHER READING

On the distinction between descriptive linguistics and language documentation, the seminal text is Himmelmann (1998).

Exercise 10.5 Areas of study

Traditional typology has been based on abstract features of languages understood as abstract systems, for example, what case marking languages possess or which word order. In some work each language as a whole is treated as representative of one feature value, for example, a specific number of cases. A finer-grained approach is multivariate typology where features are differentiated according to construction types

• Universal Dependencies (UD) (cf. 7.3.1) provide a system of consistent, crosslinguistic annotation of grammar (parts of speech, morphological features, and syntactic dependencies). Over 90 languages have some UD annotation and there are various repositories where specific language data can be viewed or downloaded

• Some books and documents have been very widely translated and have been used as parallel translational corpora in typological research comparing the use of different linguistic expressions for the same content: The Bible, Le Petit Prince, Harry Potter, and Declaration of Human Rights, among others.

• Content-controlled stimuli-based corpora like collections of Pear Film renarrations

We are involved in recent corpus-based typological projects aimed more at spontaneous spoken and signed language for investigating issues of language user choice during discourse production. These corpora were introduced in Chapter 7 in relation to their specific annotations, and we will take them up again in this chapter.

• Multi-CAST -spoken, monologue narrative corpora annotated according to cross-linguistically standardised conventions for investigating reference and discourse

It is worthwhile to place the following disclaimer right at the beginning of this chapter: while we consider corpus-based approaches in typology highly relevant, this area is only emerging as a subdiscipline of typological linguistics. This means that we cannot introduce you here to a set of fully fledged corpus studies of typological distributions in the way that we did, for example, in Chapter 9. Rather our purpose here is to set out the ways in which corpus studies have been and will be relevant to

UNIVERSALS AND DIVERSITY IN LANGUAGE USE

In corpus linguistics, corpora serve as the empirical basis for the systematic study of language use. The main concern of CBT is to systematically study language use across diverse languages. A key concern here is what is known as usage-based approaches which seek to explain attested grammatical structures across languages in terms of the communicative function of language in use and relevant constraints on language processing. These two facets of language are what functionalist traditions have considered to be the universal basis shared by diverse languages. This suggests that many aspects of language use should be universal, but there is also the possibility that language use, related communicative functions, and underlying patterns of processing are different across linguistic communities. CBT is expected to tap into these questions.

What is universal in language use?

Corpus linguistic studies have been brought to bear on universals of use for a long time. A classic finding is

Another set of universals is connected to the production of spoken language: speech is generally divided into units between pauses (pause units), and it is produced with variable speed (speech rate) across a connected set of pause units. Recent work

Corpus-based typology

by Frank Seifart and associates finds that the allocation of pausing and speech rate alternations follow the same regularities across languages. Reporting findings from nine spoken language corpora,

A final example of apparently universal patterns of spoken-language processing comes from information management and is also related to the processing of nominal expressions and their referents. But in this case, matters are more controversial, with recent research questioning a long-standing perceived view grounded in seminal work of information management by John Du

The preference only becomes visible once larger stretches of connected discourse are investigated, as found in corpora. And indeed, Du

Building on his initial investigation of a small corpus of spoken Pear stories from Sakapultek, Du

Corpus-based typology

Over recent years, this view has been challenged in work by various authors, including the second author of this book in close collaboration with Geoffrey Haig (and Nils Schiborr in recent years). This research was a major driver to develop the multilingual corpus Multi-CAST (cf.

Collating aggregated corpus findings from a total of 19 corpora from 16 diverse languages, including five from Multi-CAST, they find that discourse does not follow the 'ergative' pattern postulated by Du Bois; instead, S-arguments pattern in between A-and P-arguments when it comes to the rates of lexical forms

(1) Human referents are of greater concern to human language users and tend to be topical, being verbalised frequently across sentences (2) Topical referents in this sense tend to receive reduced forms of expression (pronoun, zero) rather than full lexical NPs because referents are given (3) Humans are the huge majority among A-argument referents because they tend to fulfil more agent-like semantic roles, contrasting sharply with P in this regard, whereas S is overall least specified for semantic roles.

This then explains the low rate of new and lexical A-arguments, which is thus not due to an underlying constraint in information management but follows from these more general discourse properties. The S-role occupies an intermediate position because it is more open to human and non-human referents and more open to a variety of semantic roles. That newness does not seem to pose a massive challenge to reference processing is suggested by a later study by

Summing up this section, corpus linguistic studies can reveal regularities of language use that are likely to be universal. All these universals on language use are statistical universals of language use 1 : They reflect tendencies in language use, and hence, require approaches like corpus linguistics to be discoverable. Although some of these regularities had been suggested a long time ago, corpus linguistic approaches are capable of discovering regularities that have not been dealt with in classic typological research.

Universal constraints on diverse patterns of language use

A somewhat different line of corpus-based research addresses questions that have been addressed over several decades in linguistic typology. A prominent example is word order typology, which we shall focus on here. Since the 1960s, word order has been a major concern, and languages have been classified according to the order of verb (V), subject (S) and object (O) on clause level, the order of head noun (N) and adjectival modifiers (A) in the NP, or whether languages have prepositions or postpositions (i.e. the order in an adpositional phrase). As with any grammar-based typology, word order typology in the classic sense has been undertaken by classifying each

Corpus-based typology language as belonging to exactly one type, for example, English as an SVO language, including the possibility that there is no dominant word order (i.e. no type can be determined). In addition to these mono-dimensional classifications, typologists have found a range of correlations between word order types across structural domains, for example, that OV languages are more likely to have Adjective-Noun order in NPs and have postpositions in adpositional phrases. This invokes the general principle that languages tend to show head-dependent alignment across these structural levels (so-called 'harmony' in word order) so that on each level, the head either precedes or follows the dependent. This type of harmony is widely regarded as preferable for language processing since it allows language users to recognise the syntactic relations between phrases easily and quickly. Furthermore, typologists have formulated a set of implicational universals that essentially capture unidirectional correlations between types, for example, Universal #25: If the pronominal object follows the verb, so does the nominal (i.e. full NP; DB & SS) object.

(cf.

Universal #25': For every language, if the percentage of pronominal objects on the right of the verb is greater than 75%, so is the percentage of nominal objects on the right of the verb.

This reformulated universal captures the fact that in all UD corpora investigated by the authors there is considerable variation, yet the relative tendencies are such that

Corpus-based typology post-verbal position is either open to both forms or restricted to one whereas preverbal position is open to both. What is further significant about this reformulation of the universal is that it yields a generalisation about language use that also generalises across languages. These findings can then be related back to grammar-based typologies, in order to estimate how accurate is the latter despite the mentioned problems. For example,

Another line of corpus-based research on word order is not so much concerned with the proportions of specific structures and their subtypes, but rather takes on the questions of how variable word order is in each given language, and how languages compare in this regard? We mentioned in passing above that English shows overall quite a strict word order, and so do languages like Japanese or many Oceanic languages, including Vera'a. Other languages, like Russian or many Australian languages, are well known to show great variability in word order. Variability as such can be measured in corpora as entropy (cf. 5.7).

The answer is, largely yes, as

As indicated above, high entropy in word order variation appears to correlate with whether a language possesses rich morphology or not. This invokes the idea of a trade-off: if the word order is highly variable, it is less informative about the content of the sentence. Morphology can thus be seen as 'stepping in' where word order fails to provide the clue (and vice versa).

Corpus-based typology can be represented variably in corpora, and this means that case marking needs to be investigated as a variable of language use as well. It is therefore necessary to investigate to what extent the two syntactic functions are formally distinguishable in actual usage. As with word order,

In summary, the findings presented constitute an observation of stark diversity across languages. But at the same time, they hint at underlying principles that also constrain variation, and they do so in a grounded fashion since they demonstrate actual language users' productions in usage contexts. As such, they point much more directly to considerations of processing constraints, similar to findings from psycholinguistic experiments on comprehension. Needless to say, corpus linguistic studies of this sort cannot explain why languages opt for one or the other type of subject and object encoding, and the explanation for this lies in deep and intricate histories of language evolution with many stages of development, each a story worth telling in itself. In the following section, however, we will take up a number of differences across languages that are observable in language users' behaviour and can be related to either correlating linguistic structures, as well as underlying cultural or other factors.

How does language use differ across languages and cultures?

An additional strain of corpus-based research in linguistic typology focuses on diversity in language use. The usage patterns observed here are not immediately related to universal constraints on processing and human communication, but instead, point to culturally entrenched differences in the habits of language usage.

Referential density

The example we mention here is the use of zero forms of reference across languages: it is well known that languages differ greatly as to the possibility to not use an overt form of reference in discourse. Given that the choice of lexical forms is often more clearly related to certain discourse factors that hold across languages (cf. 11.2.1 above), the question practically boils down to whether languages are generally more likely to use zero (called "pro-drop" languages in some frameworks) or pronouns. Languages like Italian and Mandarin are basically of the former and languages like

Corpus-based typology

English or German of the latter type. But similar to word order typology discussed in 11.2.2 above, the problem with such typologies is that it is not straightforward to classify language systems according to this parameter given the pervasive variation in language use. 2 Bickel (2003) takes a radically different, corpus-based approach to tackle this question: he examines corpora of 30 Pear stories (between 29 and 134 clauses in length (56.8 on average)) from three languages spoken in the same area in the Nepalese Himalayas: Belhare (Kiranti, Sino-Tibetan), Maithili (Indo-Aryan), and Nepali (Indo-Aryan). In doing so, he determines per text (and thus per speaker) what he calls its referential density (RD). The RD of a text is determined by counting all possible argument positions (S, A, P, obliques; cf. 11.2.1 and 11.2.2 above) and among these all positions are filled by an overt form (pronoun, lexical NP) rather than being left zero (where a referent is clearly identifiable from preceding context although no overt form appears); then the number of overt argument positions is divided by the number of all argument positions to yield the RD. The mean RD values per individual language corpus are: Belhare -0.41, Nepali -0.47, Maithili -0.62

(1) What is the referential density in each text of the first corpus you have downloaded? Confine yourself to argument functions, excluding adjuncts. What are the relevant query expressions you use? Document these.

(2) Determine the RD of the entire corpus and differences between the texts therein. Describe these in terms of the basic statistical Exercise concepts we have introduced in Chapter 8.

(3) Do the same for the second (and all other) corpora you have chosen and compared the corpora.

Corpus-based typology language community (being all from the same geographic area) and can therefore not account for observed cross-linguistic differences. Instead, Bickel identifies significant correlations between RD values and the syntax of clause combining in the three languages: put simply, some dependent clauses in these languages require case marking on its syntactically most prominent argument, and these are regularly realised overtly for this reason. According to

What makes these findings different from what was discussed in 11.2.2, is that here observed diversity is not directly limited by universal considerations of language processing, efficiency, or the like. The main predictor of RD levels is a language-specific correlate. As such, this work is directed towards explaining language diversity by reference to other diverse structures, rather than accounting for the constraints on diversity by way of universal regularities. Although Bickel's study of these three communities is designed specifically to control for some factors, other correlates are possible, whether these are situated in linguistic structures or social and cultural parameters of communities. In a further study of RD,

Social cognition and SCOPIC

The theoretical principle behind social cognition is that people know the social facts (e.g. kinship, status, ownership) that place them and others within an interconnected social context and of psychological facts about their own feelings, attentions, desires, and their estimations of these for others

Taking human reference as an example in a sub-section of SCOPIC, the data show that there are three main semantic categories of lexical reference that are used widely by most languages in our sample

(11.   -2018-10-31-8:20-8:23 6   (11.6) Literal Translation: That's-right (it's) that-one-him-there, because (the) shirt colour (is the same for) all-of-them-there.

Auslan: MDP, SocCog-asf01-DP_B_c12b -05:39-05:46 7

In our study of human reference

In sum, SCOPIC allows for comparison between languages and between aspects of internal and external context. Allowance for an additional layer of comparisonbetween different layers of annotation -allows for an integrated and informative perspective on social cognition aspects of language.

ISSUES IN CORPUS DEVELOPMENT AND CROSS-CORPUS TYPOLOGICAL RESEARCH DESIGN

In this section, we briefly describe a number of issues relating to the specific requirements on corpus design for various research agendas in CBT. We also point to desiderata and envisaged developments at the end of the section.

Different types of multilingual corpora

CBT generally draws on multilingual corpora or at least corpora that are in some way relatable to one another. There are essentially three approaches in corpus development that have been followed to date, distinguished by the parameter of cross-corpus comparability:

(1) Parallel text corpora: texts that are translational equivalents, for example, translations of The Bible text, like the Gospel of Mark

For other research questions, control of content is less of an issue: for instance, the relatively low lexicality of A-arguments should be observable in any text (but see below). Likewise, the allocation of pauses or final lengthening is not dependent on content since the regularity applies to any nouns compared to verbs, and any word form in final versus non-final position, regardless of text content. The same is true of the variable placement of subject and object phrases or variability in case marking, as investigated in UDs. Original text corpora are thus an option where the phenomenon of interest can be considered ubiquitous enough to be represented sufficiently in the corpus (cf. Seifart In Press). This is obviously the case for the phenomena mentioned here, that is, pausing, new reference, etc., compared to human reference which may not be salient in certain texts.

Corpus property biases in CBT research

As is generally true for any empirical research, including corpus linguistics, research results can turn out to be artefacts of the data used. This is essentially what

Corpus-based typology angle and behaviour of characters in relevant contexts. These considerations are likely to explain why the Sakapultek corpus is among the very few corpora that show the postulated discourse-ergative pattern. Hence, corpus-based typologists need to carefully evaluate the specific properties of the corpora they use vis-à-vis the phenomena they are researching. . This is essentially true for all research based on UDs which contain primarily written published texts. This is significant, in particular, where relevant research is intended to reveal constraints on language processing: one would have to keep in mind that the findings may apply strictly to standardised written text production (which is often influenced strongly by traditions of formalised literacy education). Also, it needs to be kept in mind that published texts (like the one you are reading right now) usually go through multiple stages of editing, and often multiple writers are involved. This is not to say that UD-based research is invalidated by these considerations. But we should generally aim for using spontaneous data in research on processing since the more generally cross-linguistically relevant regularities will primarily come up in spoken discourse. That the differences can be severe is generally clear from cross-register studies of nominal expressions of reference, where written texts have many more such structures, and these also show much higher complexity than those in spoken language texts. Hence, considerations of dependency lengths, a notorious question in UD-based work, may potentially be much less relevant in spoken language corpora simply because rearrangement of generally shorter and simpler phrases will have little effect.

Corpus design versus bootstrapping for specific research questions

Finally, requirements on corpus design notwithstanding, we should point out that CBT researchers are generally encouraged to make the most of the corpus data they have. This is particularly true for corpora drawing to a large extent on documentary corpora where limitations on data collection are highly relevant (cf. Chapter 10). For instance, stimulus-derived texts can be of much less value for a community than recordings of texts from the relevant traditional 'orature' , and documentary linguists for ethical and research-practical reasons are encouraged to comply with a community's desiderata. There may often be possibilities to bootstrap one's data in such a way that it be useful for a particular research question. Regarding, for instance, referential density research, one cannot compare uncontrolled texts across the board, as explained above. Yet, in the absence of controlled texts, one can still aim at finding overall comparable contexts to

Corpus-based typology

Corpus-based typology 215 compare levels of RD. An example is the chains of same-subject anaphors (to the extent that identifying a category 'subject' is possible in the languages under investigation), that is, where a single referent is the subject of a series of clauses so that each anaphor has an antecedent in the preceding clause in the same function. This is a context that can be assumed to trigger either the use of some form of pronoun or zero across languages, regardless of the overall content of the texts involved, and hence it will make sense to compare rates of pronoun versus zero within this 'envelop of variation' (Torres Cacoullos & Travis 2019 on comparisons along this type of context) (cf. Schnell & Schiborr to appear for a case study based on Multi-CAST).

CONCLUSION

Corpus-based typology makes explicit the main theoretical goals of corpus linguistics in across-linguistic a cross-linguistic perspective where we are generally interested in the different properties of all human languages and their global distribution. We examine not only intra-language and context-dependent variation but also how that variation scales up to the inter-language level. Corpus linguistics takes real samples that are used to generalise about language, and corpus-based typology helps us to confirm (or confront the idea) that these assumptions are applicable for a more diverse sample. In doing this research, we see the need for corpora of more diverse languages, especially under-studied ones that require documentation, in order to test hypotheses about language structure and use. Also, we need to develop many more corpora of spoken-language texts which are particularly relevant to CBT research tapping into questions of language processing.

The findings from corpus-based typology also feed back into ideas about corpus building, composition, and annotation: more diverse languages require different considerations of register, representativeness, and potentially, require adaptations of annotation and querying strategies. It is still an emerging field and will help shape the more general perspective on corpus linguistics as a field in the 21st century.

FURTHER READING

Schnell and Schiborr (to appear) provide a succinct overview of the current work on corpusbased typology.

NOTES

1. These quantify structural tokens in usage, where statistical universal in traditional typology quantify structural types as part of individual language systems. 2. Classification of a language as "pro-drop" in relevant frameworks involves more intricate diagnostics than how frequent zeroes are in discourse, but these diagnostics have their problems as well.

Note: Bold page numbers refer to tables; italic page numbers refer to figures and page numbers followed by "n" denote endnotes.

age-graded variation 164-165, 169, 173, 177-180 AIRBUS-ATC corpus 34 ANNIS 106 annotation scheme 111-125; discourse and reference annotation