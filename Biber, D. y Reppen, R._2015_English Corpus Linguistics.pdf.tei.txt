. Phenomena that can be researched with three text archives / Web 1.4. Frequency of very infrequent words in BNC, COCA, and three text archives / Web 1.5. Phenomena that can be researched with two "hybrid" corpora 1.6. Number of collocates in different corpora 1.7. Similarity of lexis in web-based GloWbE and genres in COCA and BNC 2.1. Quantitative analysis of papers published in 2012 2.2. Top 10 n-grams from Alice's Adventures in Wonderland 2.3. C-gram tree view for and the 3.1. The frequencies of several n-grams in the untagged Brown corpus 3.2.

Introduction Douglas Biber and Randi Reppen

Corpus linguistics is a research approach that facilitates empirical investigations of language variation and use, resulting in research findings that have much greater generalizability and validity than would otherwise be feasible. Studies carried out under the umbrella of corpus linguistics share certain research goals and distinctive analytical characteristics:

-they are empirical, analyzing the actual patterns of use in natural texts; -they are based on analysis of a large and principled collection of natural texts, known as a 'corpus'; the corpus is evaluated for the extent to which it represents a target domain of language use; -they make extensive use of computers for analysis, employing both automatic and interactive techniques; -they depend on both quantitative and qualitative analytical techniques.

(see

At the same time, nearly all scholars working in this area would agree that corpus linguistics is more than merely a methodological approach, because the analytical innovations of this approach have enabled researchers to ask fundamentally different kinds of research questions, sometimes resulting in radically different perspectives on language variation and use from those taken in previous research. Corpus linguistic research offers strong support for the view that language variation is systematic and can be described using empirical, quantitative methods. Variation often involves complex patterns of use that involve interactions among several different linguistic parameters but, in the end, corpus analysis consistently demonstrates that these patterns are systematic. In addition, corpus analyses have documented the existence of linguistic constructs that are not recognized by current linguistic theories. Research of this typereferred to as a "corpus-driven" approach -identifies strong tendencies for words and grammatical constructions to pattern together in particular ways, while other theoretically possible combinations rarely occur.

A novice student of linguistics could be excused for believing that corpus linguistics evolved in the past few decades, as a reaction against the dominant practice of intuition-based linguistics in the 1960s and 1970s. Introductory linguistics textbooks tend to present linguistic analysis (especially syntactic analysis) as it has been practiced over the past fifty years, employing the analyst's intuitions rather than being based on empirical analysis of natural texts. Against that background, it would be easy for a student to imagine that corpus linguistics developed only in the 1980s and 1990s, responding to the need to base linguistic descriptions on empirical analyses of actual language use. This view is far from accurate. In fact, it can be argued that intuitionbased linguistics developed as a reaction to corpus-based linguistics. That is, the standard practice in linguistics up until the 1950s was to base language descriptions on analyses of collections of natural texts: pre-computer corpora. Dictionaries have long been based on empirical analysis of word use in natural sentences. For example, Samuel Johnson's Dictionary of the English Language, published in 1755, was based on c. 150,000 natural sentences recorded on slips of paper, to illustrate the natural usage of words. The Oxford English Dictionary, published in 1928, was based on c. 5,000,000 citations from natural texts (totaling around 50 million words), compiled by over 2,000 volunteers over a seventy-year period (see the discussion in

Goals of the handbook

Basically, any research question or application relating to language variation and/or use can be approached from a corpus-linguistic perspective. Our goals in the Cambridge Handbook of English Corpus Linguistics (CHECL) are to survey the breadth of these research questions and applications in relation to the linguistic study of English. As such, the handbook includes chapters dealing with a wide range of linguistic issues, including lexical variation, grammatical variation, historical change, the linguistic description of dialects and registers, and applications to language teaching and translation. In each case, chapters assess what we have learned from corpus-based investigations to date, and provide detailed case studies that illustrate how corpus analyses can be employed for empirical descriptions, documenting surprising patterns of language use that were often unanticipated previously.

The goals of the CHECL are to complement, but not duplicate, the coverage of existing textbooks and handbooks on corpus linguistics. There are many excellent textbooks in print, providing thorough introductions to the methods of corpus linguistics, surveys of available corpora, and general reviews of previous research. The CHECL differs from these textbooks with respect to both the target audience and goals: the handbook is written for practicing scholars and advanced students in the field, offering a critical discussion of the "state of the art," rather than an introductory overview of the field in general. As a result, the handbook includes relatively little discussion of topics that have been fully covered in existing textbooks, such as surveys of existing corpora, or methodological discussions of corpus construction and analysis. Instead, the CHECL focuses on a critical discussion of the linguistic findings that have resulted from corpusbased investigations: what have we learned about language variation and use from corpus-based research?

The most innovative aspects of the CHECL are its emphasis on critical discussion, its explicit evaluation of the state of the art in each research area, and the inclusion of an empirical case study in each chapter. Although each chapter includes a broad summary of previous research, the primary focus is on a more detailed description of the most important corpus-based studies in this area, with discussion of what those studies found and why they are especially important. Each chapter also includes critical discussion of the corpus-based methods that are typically employed for research in this area, as well as an explicit summary of the state of the art: what do we know as a result of corpus research in this area that we did not know previously? Finally, each chapter includes an empirical case study illustrating the corpus analysis methods and the types of research findings that are typical in this area of research.

Organization of the handbook

As noted above, any research question relating to language variation and use can be approached from a corpus-linguistic perspective. In our previous work, we have identified two major objectives of such research:

(1) To describe linguistic characteristics, such as vocabulary, lexical collocations, phraseological sequences, or grammatical features. These studies often attempt to account for variation in the use of related linguistic features (e.g. the choice between simple past tense versus present perfect aspect) or to document the discourse functions of a linguistic feature.

These studies provide relatively comprehensive linguistic descriptions of a single variety or of the patterns of variation among a set of varieties.

We have structured the main body of CHECL around these two domains of inquiry: chapters dealing with "Corpus analysis of linguistic characteristics" in Part II and chapters dealing with "Corpus analysis of varieties" in Part III.

Part II is organized as a progression of the linguistic levels, beginning with corpus-based analyses of prosodic characteristics, moving on to chapters dealing with lexical characteristics (keywords, collocations, and phraseology), followed by chapters on grammatical features (descriptive grammar, grammatical variation, grammatical change, and the intersection of grammar and lexis), and finally concluding with chapters on the corpus-based study of discourse functions and pragmatics.

Part III, then, is organized in terms of the range of varieties that have been studied from a corpus perspective. This part begins with chapters on the corpus-based description of spoken English, written academic English, and patterns of variation (synchronic and diachronic) among a wider range of spoken and written registers. Those chapters are then followed by chapters on the use of corpus analysis to document the linguistic characteristics of other types of varieties: literary styles, regional dialects, world Englishes, English as a lingua franca, and learner English.

Preceding these two central sections, the CHECL has a shorter section dealing with methodological issues. As noted above, methodological issues relating to corpus design and analysis have been dealt with at length in previous textbooks. In addition, each of the chapters in CHECL includes discussion of the specific methodological considerations relating to their area of inquiry. However, beyond those treatments, there is need for a more general discussion of the current state of the art concerning corpus design and analysis. The three chapters included in Part I provide this discussion, dealing with current issues relating to corpus design and composition, tools and methods for the linguistic analysis of corpora, and quantitative research designs and statistical methods used to describe the patterns of use across corpora.

Finally, the CHECL concludes with a major section on applications of corpus-based research. Corpus linguistics has had a major influence on such applications over the past two decades, so that it is now almost impossible to find a research journal in applied linguistics, language teaching, translation studies, or lexicography that does not regularly publish articles utilizing corpus research findings. Part IV of the handbook surveys these major areas of application, including classroom applications, the development of corpus-based pedagogical materials, vocabulary studies, and corpus applications in lexicography and translation.

Internal organization of chapters

To help ensure the coherence of the CHECL, we have asked all authors to follow the same general organization in their chapter. While this has not always been possible, most chapters employ the same general organization. In addition to ensuring a coherent treatment across chapters, our primary goal is to provide a more sophisticated level of critical discussion than in most previous books. To achieve this goal, each chapter is composed of two major parts: a critical discussion of previous research, and presentation of an empirical case study.

Regarding the first section (the discussion of previous research), each chapter attempts to include the following:

• a general but concise survey of previous published research, briefly identifying the research topics covered by each study • a more detailed discussion of the most important studies in this area: identifying the research questions; describing their methods; summarizing the major findings; and discussing why the study is especially important

• a critical discussion of the methods that are typically employed for research in this area, illustrated with more detailed discussions of studies that model strong research practices as well as studies that are problematic • a summary of the state of the art for research in this area: what do we know as a result of corpus research in this area that we did not know previously? What are the major research gaps that still need to be addressed?

Regarding the second section (the empirical case study), each chapter addresses the following:

• a clear identification of the research question(s)

• motivation of the research question: why is the study important?

• a relatively detailed and critical description of methods: what are the strengths and weaknesses of the approach? Does it directly address the research questions? etc. • a summary of the major research findings: what do we know as a result of this study that we did not know previously?

Our overall goal in requiring this strict organization across chapters is to achieve a handbook that will be of high interest to both students (with clear identification of the important research issues and discussion of strong and weak research practices) and advanced researchers (who can engage in the critical evaluations of each subfield).

critically with respect to specific linguistic research studies, to discuss the extent to which specific empirical research methods are well suited to the research questions of interest.

In sum, our goals in the CHECL go beyond a simple catalog of existing corpora and research tools, and go beyond simply itemizing the range of previous publications in this area. Rather, we hope to summarize and evaluate what we have learned about language use and variation from previous corpus-based research, to identify and discuss the most important of those previous studies and research findings, and to discuss the methodologies that work best for such research.

Part I

Methodological considerations 1 Introduction

Many introductions to English corpora attempt to provide a comprehensive list of the "most important" corpora currently available. While there are some advantages to such an approach, these lists are invariably outdated even before they are published, and hopelessly outdated after five to years.

In this introduction, I take a different approach. Rather than attempting to create a complete and exhaustive list, I focus on a handful of corpora (and related resources, such as text archives and the "Web as Corpus") that are representative of general classes of corpora. We will discuss the relative advantages and disadvantages of these general classes of resources, which will undoubtedly contain much better exemplars in years to come.

The types of corpora (and corpus-related resources) that we consider are the following: 1   1. Small 1-5-million-word, first-generation corpora like the Brown Corpus (and others in the Brown "family," such as the LOB, Frown, and FLOB) 2. Moderately sized, second-generation, genre-balanced corpora, such as the 100-million-word British National Corpus 3. Larger, more up-to-date (but still genre-balanced) corpora, such as the 450-million-word Corpus of Contemporary American English (COCA) 2 4. Large text archives, such as Lexis-Nexis 5. Extremely large text archives, such as Google Books 3 6. The Web as corpus, seen here through the lens of Google-based searches Finally, we will consider very large "hybrid" corpora, which take data from text archives or the Web, but which then deliver this data through powerful architectures and interfaces. These include:

7. The web-based corpora available through Sketch Engine 8. An advanced interface to Google Books, available through googlebooks.byu.edu.

As we discuss these different types of corpora, we will first (in Sections 2-5) see how well they can provide data for a wide range of linguistic phenomena -lexical, morphological, syntactic, and semantic. As we do so, we will consider how the quantity and quality of the data are affected by the corpus size, as well as the corpus architecture and interface. Second, in Section 6 we will consider the issue of variation within English, by looking primarily at genre coverage and balance in the corpora. We will also briefly consider other types of variation, such as variation in time (i.e. historical corpora) and space (i.e. corpora that provide data on dialectal variation), as well as variation at the level of individual speakers and writers. In the concluding section, we will take an (admittedly risky) "flight of fancy" and imagine what type of corpora might be available in five, ten, or twenty years.

2 Providing data on a wide range of linguistic phenomena

A typical textbook on linguistics will contain chapters on phonology, lexis, morphology, syntax, and semantics, as well as variation by speaker, by time (language change), and in space (dialects). As a result, it is probably not unreasonable to expect modern corpora to provide useful data on these types of phenomena, as shown in Table

3 Corpus size

We will examine these two questions empirically, by looking in turn at each of the ten phenomena presented in Table

Lexical

Even for some moderately frequent words, a one-million-word corpus like Brown does not provide enough data for useful analyses. For example, 83 of the 1,000 most frequent adjectives in COCA occur five times or less in Brown, including such common words as fun, offensive, medium, tender, teenage, coastal, scary, organizational, terrific, sexy, cute, innovative, risky, shiny, viable, hazardous, conceptual, and affordable (all of which occur 5,000 times or more in COCA). Of the top 2,000 adjectives in COCA, 425 occur five times or less in Brown, and this rises to 2,053 of the top 5,000 and 5,106 of the top (he elbowed his way through the crowd) Semantics 9. Collocates (generally) as a guide to meaning and usage (e.g. with click (n), nibble (v), or serenely) 10. Semantic prosody, e.g. the types of words preceding the verb budge or nouns following the verb cause.

10,000 (all of which occur 120 times or more in COCA). In addition, a Brown-based frequency list (for all words in the corpus) would be quite sparse. For example, only 3,956 lemmas occur 20 times or more in Brown, but this rises to more than 43,000 lemmas in the BNC and 100,000 lemmas in COCA. (Note that this is not due to norming, but rather it is the number of word types.)

Morphology

Morphologists are interested in morpheme ordering in English (see

Syntax

High-frequency syntactic constructions are perhaps the one type of phenomenon where Brown provides sufficient data.

Phraseology

Specific words and phrases:

Semantics

Collocates can provide useful insight into meaning and usage, following Firth's insight that "you shall know a word by the company it keeps"

Accuracy of annotation in small and large corpora

As we have seen, large corpora have certain advantages in terms of providing data on a wide range of phenomena. But it is also true that there are some challenges associated with large corpora. This is particularly true in terms of the accuracy of annotation -both at the word level (e.g. accurate part of speech tagging) and the document level (e.g. accurate metadata for all of the texts in the corpus). And this is especially true when the corpus is created by a small team and with limited resources. Consider first the issue of accuracy in document-level metadata. The Brown Corpus is composed of just 500 texts, and it is very easy to achieve 100 percent accuracy in terms of metadata. COCA, on the other hand, currently has more than 180,000 texts and the 400-million-word COHA historical corpus has more than 100,000 texts.

Consider also word-level annotation, such as part-of-speech tagging. Suppose that we want to study the use of for as a conjunction (, for had we known that . . .). As

And yet because of the sheer number of tokens, I would argue, in this particular case we can still have confidence in the data. Consider Figures 1.1 and 1.2 which show nicely the decrease in for as a conjunction from the 1810s to the 2000s (COHA) 7 and then in the 1990s to the 2000s (COCA). 8  In nearly every decade in COHA since the 1890s, for as a conjunction is less frequent than the preceding decade. And in COCA, it has decreased in every five-year period since 1990, and the decrease is still ongoing (as of 2012). So in this particular case, where

Text archives and the Web 9

Based on our analysis in the preceding section, it might appear that "bigger is always better." Of course, this is not the case. We have already discussed some of the challenges inherent in the creation of large corpora, in terms of accurate metadata and word-level annotation. In this section, we will consider several types of resources that dwarf traditional corpora in terms of their size, but which have limited use in researching many of the phenomena presented above in Table

In this section, we will consider three examples of text archives -Lexis-Nexis (representing a wide range of similar text archives, such as ProQuest or EBSCO archives, other newspaper archives, or archives like Literature Online or Project Gutenberg), the Web (via Google), and Google Books. Table

Lexical

There is no way to create frequency listing from text archives, at least via the standard interfaces for these resources. Nevertheless, with all three types of resources, it is certainly possible to see the frequency of an exact word or phrase, and of course the number of tokens will typically be much larger than with a 100-or 500-million-word corpus. For example, the adjectives in Table

For some lexically oriented searches, there is really no alternative to an extremely large text archives, because of their sheer size. As can be seen, even COCA provides only relatively meager data for the words shown in Table

Nevertheless, there are a number of problems with the figures from text archives, shown in Table

Corpora: an introduction

Another challenge with text archives is working with the often limited interface. For example, consider the output from Google in Figure

Morphology

Via the standard web interfaces, it is typically not possible to search by substrings. It is however, possible to compare competing word forms, such as HAVE + proven / proved. In Lexis-Nexis, this is straightforward. In Google (Web), one must remember that the frequency of strings can be wildly inaccurate (see note 11), so the comparison of these two numbers can also be very inaccurate. Finally, in Google Books it is possible to compare alternate forms, as in Figure

Syntax

Syntactically oriented queries present a real challenge for the often simple interfaces of text archives. Take for example the high-frequency be passive or the less frequent case of verbal subcategorization [to V / V-ing]. Text archives typically do not allow searching by part of speech (or even by lemma), so we would need to search for hundreds or thousands of matching strings one by one, e.g. start to see, started to see, started to notice, etc. One option would be to write a script to serially carry out many searches and then store the results for each search. But such queries are certainly not possible for most users, natively via the interface.

Phraseology

In cases like true feelings or naked eye, again one could write a script to parse through hundreds of "snippet" entries (as in Figure

Semantics

In order to extract the collocates using the native interface for these text archives, one would (again) have to write a program to parse through the simple "snippet" output and save each snippet, and then post-process these data to extract collocates. However, even this would probably not be possible, since most text archives severely limit the number of "snippets" for a given search (e.g. 1,000 in Lexis-Nexis, Google (Web), and Google Books). With only 1,000 tokens per word or phrase, it is impossible to create a robust dataset to extract collocates.

Summary

Text archives are initially quite appealing, because of their sheer size. For certain types of lexically oriented queries (e.g. very low-frequency words or neologisms), they may be the only option, and they may also be sufficient for comparisons of alternating word forms (e.g. have + proven/proved, or he snuck/sneaked). But for virtually all other types of searches, the simplistic interface simply cannot generate the desired data, without significant post-processing.

5 Hybrid "corpora": text archives + full-featured architecture and interface

We saw in Section 3 that size is crucial: small 2-4-million-word corpora are at times limited in terms of the range of data that they can provide. But as we have seen in Section 4, size is not everything -most text archives have such a simplistic interface that they also are very limited in the range of queries that they offer. As we will see in this section, the best solution may be to take the texts from a text archive or the Web (containing billions of words of data), and then combine this with a robust corpus architecture.

As examples of this "hybrid" approach, in this section we will consider two sets of corpora. First, we will look at the corpora from Sketch Engine (www.sketchengine.co.uk). All of the corpora in Sketch Engine that are publicly accessible and that are more than a billion words in size are based on web pages, and there are currently three corpora of English that contain more than a billion words of text. Second, we will consider the different "corpora" that are available from googlebooks.byu.edu, which are based on the n-grams from books.google.com/ngrams/, and which range in size from 45 to 155 billion words.

As Table

Lexical

Both corpora allow users to search for a particular word or phrase, and to see the frequency of the word in the different sections of the corpus. For example,

Morphology

With both corpora, it is possible to generate word lists, including words that contain particular substrings. For example, the common words ending in *ism in the Sketch Engine enTenTen08 corpus (about 3 billion words, from web pages) are terrorism (126,534 tokens), mechanism (95,034), criticism

Since we can easily search for strings in these corpora (see Section 5.1 above), we can also easily compare word forms, e.g. he sneaked/snuck. Figure

Syntax

The Sketch Engine corpora are tagged with TreeTagger and they are searched via Corpus Query Language (CQL), a widely used corpus architecture and search engine. This allows us to find constructions like the [END up V-ing] construction (e.g. you'll end up paying too much). 12  Google Books (BYU) is a bit more problematic, in terms of syntactic searches. The version of the Google Books n-grams that it uses does not include part of speech or lemma. As a result, in a search like "

Phraseology

In just a couple of seconds, Sketch Engine can provide users with concordance lines for words, phrases, or even syntactic strings, which can be re-sorted, thinned, and so on. Google Books (BYU) cannot generate these concordance lines, because it is based just on n-grams. The actual text is in the Google Books "snippets" (e.g. Figure

Semantics

As we saw above in Section 3.5, collocates are extremely sensitive to corpus size. Table

It is interesting, however, that for some words at least, there appears to be a "diminishing return" with corpus size. Although the number of collocates between the BNC and COCA (4-5 times as large as the BNC) is striking, in a corpus like enTenTen12 from Sketch Engine (which is 25 times as large as COCA), for some words (e.g. nibble or serenely) there is not nearly as significant a yield in collocates. We will discuss some possible explanations for this in the following section, as we discuss the composition of the corpora.  a This is the genre of COCA in which the word is the most frequent, which ends of being important as we talk about genre balance in Section 6. b The Sketch Engine enTenTen12 corpus -currently 11,192,000,000 words in size c Sketch Engine groups collocates by grammatical relation, so it separates for example direct object (nibble the cheese) from object of preposition (nibble on the cheese). We have done our best to group the collocates from different relations and calculate their total frequency, but 90 is an approximate number. d Collocates in Google Books (BYU) work differently than the other BYU corpora, like COCA or COHA, since Google Books is based on n-grams. As a result, these numbers are an approximate. Remember also the issue with the 40 token threshold, explained in note 14.

6 Accounting for and describing variation: genre, historical, dialect, and demographic

The importance of genre variation

Hundreds of studies over the past decade or two have shown the crucial importance of genre in describing language. Perhaps the best example of this is

We will here provide just a few pieces of data from COCA -a robust, wellbalanced corpus -to show the importance of genre. First, consider Figure

Figures

The important differences between genres extend to meaning as well. For example, Figure

Even more than with newspapers, it is very easy to create extremely large corpora that are based solely on web pages. It is no surprise that virtually all of the corpora over 100 million words in size in Sketch Engine, for example, are based exclusively on web pages. But the question is -how representative are web pages of the full range of variation in the language?

Consider Table

If we compare certain morphological and syntactic phenomena in the web only corpora to more balanced corpora, the situation becomes even more confusing. For example, the normalized frequency of -al adjectives 18 is 2,244 per million words in GloWbE-US, 19 which places it between COCA magazines and newspapers (see Figure

In summary, virtually all corpora with more than 1 billion words are composed of just web pages. But these large web page-based corpora do not represent particularly well the full range of variation that we see in genre-balanced corpora like the 100-million-word BNC, the 440-millionword Bank of English, or the 450-million-word (and growing) Corpus of Contemporary American English -which is currently the largest publicly available, genre-balanced corpus of English. 18 -al adjectives that are at least ten letters long, e.g. environmental or educational. 19 The 400 million words from the United States in the 2-billion-word GloWbE corpus.

Other types of variation

Besides genre-based variation, other important types of variation are change over time, variation between dialects, and variation at the level of the individual speaker.

In terms of historical variation, I have suggested at some length in other studies that perhaps the only historical corpus of English that is currently available, which can account for a full range of lexical, morphological, phraseological, syntactic, and semantic variation over the past 200 years (e.g. items 1-10 of Table

In terms of dialectal variation, the International Corpus of English

Even at this level of abstraction, some of what we have considered will still be outdated almost as soon as this chapter published, and much of this will be hopelessly outdated within five to ten years. This is due in part to dramatic changes that I believe are on the verge of taking place, particularly in terms of data from social media. For example, Twitter already provides real-time "fire hose" access to every single tweet

Imagine the situation five, ten, or twenty years from now, when researchers will be able to download billions of words of data every day from Facebook or other social media sites. For each status update or post that comes through, they will have accompanying metadata that show the gender, general age range, and approximate geographical location of the author. Assume further that because of advances in technology, they are able to efficiently process hundreds of billions of words of data at a rate that is hundreds or thousands of times as fast as today. One can therefore imagine a scenario -in the not-too-distant future -in which a researcher can examine the use of a particular word, or phrase, or syntactic construction -virtually in real time, and with incredible detail (gender, age, and location).

For example, researchers could examine two competing syntactic constructions (e.g. +/to with help: help Mary clean the room, help Mary to clean the room), and see which of the two is more common in the US or the UK, between men and women, between different age groups, as a function of the embedded verb, or in data from this year compared to data from last year. Even the largest "structured" corpora from the present time (e.g. Sketch Engine corpora, GloWbE, COCA, or the BNC) cannot provide this degree of granularity. And this one example from the domain of syntax can be multiplied endlessly for other variations in syntax, or in lexis, morphology, phraseology, or meaning. At this point, I suspect that many of us will look back with nostalgia on the "quaint" 100-or 500-million-word corpora that we currently have available, and wonder how we were able do so much with so little.

While this is an admittedly hypothetical scenario, what is probably beyond dispute is that the corpora that will be available to us in a decade or two will be truly revolutionary, at least from our current vantage point. The only question, then, is whether we will take advantage of the new resources that are certain to come our way.

2

Computational tools and methods for corpus compilation and analysis

Paul Rayson 1 Introduction

The growing interest in corpus linguistics methods in the 1970s and 1980s was largely enabled by the increased power of computers and the use of computational methods to store and process language samples. Before this, even simple methods for studying language such as extracting a list of all the different words in a text and their immediate contexts was incredibly time consuming and costly in terms of human effort. Only concordances of books of special importance such as the Qur'an, the Bible, and the works of Shakespeare were made before the twentieth century and required either a large number of scholars or monks or a significant investment in time by a single individual, in some cases more than ten years of their lives. In these days of web search engines and vast quantities of text that is available at our finger tips, the end user would be mildly annoyed if a concordance from a 1-billion-word corpus took more than five seconds to be displayed.

Other text-rich disciplines can trace their origins back to the same computing revolution. Digital humanities scholars cite the work of Roberto Busa working with IBM in 1949, who produced his Index Thomisticus, a computer-generated concordance to the writings of Thomas Aquinas. Similarly, lexicographers in the nineteenth century used millions of handwritten cards or quotation slips, but the field was revolutionized in the 1980s with the creation of machine-readable corpora such as COBUILD and the use of computers for searching and finding patterns in the data. This chapter presents an introductory survey of computational tools and methods for corpus construction and analysis. The corpus research process involves three main stages: corpus compilation, annotation, and retrieval (see

Retrieval tools and methods enable the actual linguistic investigations based on corpora: i.e. frequency analysis, concordances, collocations, keywords and n-grams. These tools are introduced in Section 2.3, together with a brief timeline tracing the historical development of retrieval tools and methods and the current focus on web-based interfaces for megacorpora. Corpus tools and methods are now being applied very widely to historical data, learner language, and online varieties (Usenet, Emails, Blogs, and Microblogs), so I also consider the effect of non-standard or "dirty data" on corpus tools and methods, e.g. where spelling variation affects their robustness. Although the focus in this chapter and the handbook is on tools and methods for English corpus linguistics, I highlight issues of support for other languages and corpora and tools that support multiple languages where they are relevant.

Corpus linguistics as a discipline has matured in parallel with the development of more powerful computers and software tools. In Section 2.4, I will reflect on the question of whether corpus linguistics is now tooldriven, i.e. whether researchers can only ask the research questions that are supported by the existing tools and methods, and whether other important questions are not tackled due to a lack of tool support. I highlight some limitations of the existing tools and methods, which include for example limited support of manual categorization of concordance lines and categorization of key words. The empirical study presented in Section 3 will investigate the relative strengths and weakness of tools and methods for studying n-grams, also called lexical bundles

Finally, the chapter will conclude in Section 4 with a peek into the future, taking some current tools, describing what research gaps need to be addressed and what tools and methods might look like in the future.

Improvements in speed and usability of corpus tools are important as well as interoperability between the tools. In addition, the sheer scale of mega-corpora such as those derived from online varieties of language suggests that better support for the visualisation of results would be beneficial.

Survey of tools and methods

Corpus linguistic research differs from most research in theoretical linguistics in that the language sample analyzed, and the methods used for that analysis, are central concerns. As a result, most research articles in corpus linguistics include discussion of corpus compilation, annotation, and/or the computational methods used to retrieve linguistic data. To illustrate this, I have undertaken a small quantitative analysis of recent papers published in the field and how often they discuss each of the three considerations. The source data for this analysis are the academic papers published in four leading corpus linguistics journals:

• International Journal of Corpus Linguistics published by John Benjamins

Table

Table

Many similar computational methods and tools would be seen if areas such as content analysis, Computer Assisted Qualitative Data Analysis (CAQDAS), digital humanities, and text mining had been considered. However, in this chapter, the scope needs to be limited carefully to computational methods and tools employed for corpus linguistics research. The following subsections will focus in turn on tools and methods related to the three key phases of corpus linguistics methodology that have already been highlighted, i.e. compilation, annotation, and retrieval. After that I will reflect on the current state of the art in corpus tools and methods.

Compilation

Unless the corpus linguist is planning to use an existing off-the-shelf corpus, the first thing they need to do is to compile one of their own. Unfortunately, considering the plethora of textbooks in the field, it is the practical aspects of this process that are dealt with least out of the three key phases of corpus-linguistics methodology.

Creating a machine-readable corpus can be a very costly and timeconsuming exercise. The accuracy of any transcription and scanning is a primary consideration. In the next few paragraphs I will focus in turn on spoken, written, and web-based language sampling and examine compilation issues specific to each type.

For spoken corpora, hardware and software recorders can be used for data collection. It is clearly important to obtain as high-quality recording as possible and digital recorders are available quite cheaply. Next, transcription-editing software is used to create a word-level transcript alongside the audio data. Systems such as Voicewalker was used for the Santa Barbara corpus and SoundScriber was used for compiling the Michigan Corpus of Academic Spoken English (MICASE). Praat can be employed for phonetic analysis. Unfortunately, speech recognition software is not yet accurate enough to automatically create text from sound recordings unless they are of broadcast quality. Even then, significant manual checking is required to prepare the high-quality, error-free transcriptions required for linguistic analysis. Some online sources of spoken data from broadcasters do include subtitles that may be extracted. Spoken corpora are often multimodal, incorporating a video stream as well, e.g. SCOTS and SACODEYL, so this entails the recording, editing, and processing of video data. Ideally the transcription that is produced by these different methods would be aligned with the audio and video streams using software such as EXMARaLDA and the NITE XML Toolkit.

The considerations for written corpora are quite different. If the source material is available in hardcopy form, e.g. a printed book or magazine, then a scanner is required in order to turn the printed version into a digital image and then OCR software creates a machine-readable version of the text contained in the image. A significant investment of time may be needed to manually check the OCR output and correct mistakes made by the software. Where the printed material is not of good clarity or the image has degraded over time, perhaps from a large newspaper sheet printed from a microfilm archive or photocopied from an original source, then OCR software may struggle to correctly block out multiple columns and recognize characters. In these cases, it may be better to resort to conversion by keyboarding of the original. This also applies to historical material or where the original is handwritten, e.g. children's school projects or diaries. The approach taken by the Early English Books Online (EEBO) Text Creation Partnership (TCP) is to have an original book manually keyboarded by two different individuals. Then these two versions are compared and a third editor manually intervenes when differences arise. Such processes are vital in order to ensure that the machine-readable text is as accurate as possible. Depending on the type of corpus and the age of the sources, it may be possible to find corpus material in electronic form already and then the keyboarding or scanning stages can be avoided. Out-of-copyright texts are more readily available, otherwise publishers need to be contacted to secure access and obtain copies of the data. Most corpus tools require plain text versions with optional XML encoding, so where material is sourced in another form, some format conversions will be in order. There are many tools available to assist in the conversion of Word, RTF, and PDF file formats to TXT. These vary in quality and it is obviously important for later linguistic analysis to check that the original text flow has been preserved, especially where the source has multiple columns or tabular formatting.

With the advent of the web and online data sources, it is easier to obtain electronic copies of written material. For example, the BE06 corpus

Whether the corpus contains written, spoken, or online varieties, computational tools and methods for record keeping, cataloging, and documenting the results are largely general purpose. Tools such as spreadsheets, databases, and word processors are usually sufficient here although the relevant information may be stored alongside the corpus data itself for later retrieval in headers encoded within the files. In this case, XML editing software may be required to simplify the process and check for consistency of the results.

For further reading in the area of corpus compilation,

Annotation

After a corpus has been collected, compiled, and marked-up as described in the previous section, the second stage of the typical corpus linguistics methodology is to annotate the data. This can take many forms depending on the linguistic features that are to be investigated: morphological, lexical, syntax, semantic, pragmatic, stylistic, or discoursal. Annotation can also be applied using manual (human-led) and/or automatic (machine-led) methods. Adding annotation allows the researcher to encode linguistic information present in the corpus for later retrieval or extraction using tools described in the next section. If the text is annotated or corrected by hand then this could form the basis of a training corpus for an automatic tagging system which can then learn from the human annotators in order to attempt to replicate their coding later on larger amounts of data. Part of the manually annotated dataset could also be used as a gold-standard corpus against which to compare the output of the automatic tagging system in order to evaluate its accuracy. Computational methods and tools for corpus annotation therefore take two forms. First, intelligent editors to support manual annotation and second, automatic taggers which apply a particular type of analysis to language data.

Focusing on the first kind for a moment, it would be possible of course to manually annotate texts using any standard word processor, but here it is useful to have software tools that check annotation as it is added, e.g. to ensure that typos in tags or category labels do not occur, and to allow standard mark-up formats (such as XML) to be employed consistently and correctly in the resulting corpus, e.g. as in the Dexter software.

Retrieval

Once a corpus has been compiled and annotated using the methods and tools described in the previous two subsections, it is ready for the third stage, i.e. retrieval. Retrieval methods and tools are those most commonly and prototypically associated with the corpus user's toolbox because many linguists use pre-existing corpora and so can skip the first two stages. Central amongst these methods is the concordance, which displays all examples of a particular linguistic feature retrieved from the corpus and displayed in context, usually presented as one example per line, with a short section of surrounding text to the left and right of the example itself as shown in Figure

All concordance tools provide for searching by a simple word and some tools permit searching for suffixes, multiple word phrases, regular expressions, part-of-speech tags, other annotation embedded within the corpus, or more complex contextual patterns. The idea of such a concordance arrangement predates the computer by quite a significant margin and scholars have in the past created concordances by hand for significant texts such as the Qur'an and the Bible. For example, Cowden-Clarke (1881) took sixteen years to manually produce a complete concordance of all words (apart from a small set of words considered insignificant and occurring frequently such as be, do, and have) in Shakespeare's writings. The concordance arrangement with the search item aligned centrally in the middle of each line provides the main window on to the underlying text for a corpus linguist.

Alongside the concordance method, a further four methods have emerged as central to the work of the corpus user: frequency lists, keywords, n-grams, and collocations. Frequency lists, usually of words, provide a list of all the items in the corpus and a count of how often they occur and in some cases how widely dispersed the items are across multiple sections of a corpus. Again, this is something the computer is really good at doing efficiently and accurately. Different software tools do, however, produce slightly different frequency information and word counts for the same corpus data due to the way words are defined and delimited, e.g. whether punctuation is counted, capitalization is significant, and contractions are counted as one item or two. The keywords approach is a method to compare two word frequency lists using statistical metrics in order to highlight interesting items whose frequency differs significantly between one corpus that is being analyzed and a much larger reference corpus. The keywords method can also be extended by comparing three or more word frequency lists representing distributions in a larger number of corpora. The keyness metric (usually chi-squared or log-likelihood) provides complementary information to word frequency alone and gives an indication of the aboutness of a text, or what items are worthy of further investigation. The next method in the expanding corpus toolbox is usually referred to in the computational linguistics community as n-grams. In the corpus linguistics field, it is also known as lexical bundles, recurrent combinations or clusters. This method is fairly simple, is easy for the computer to calculate, and represents the ability to count repeated phrases or continuous word sequences that occur in corpus data. N-grams of different lengths are counted separately, i.e. repeated sequences of pairs of words are counted as 2-grams, three-word sequences as 3-grams and so on. These lists can be seen as extensions of the simple word frequency list which is identical to a 1-gram list. An important variant of the n-gram approach is referred to as concgrams since they are derived from concordances and n-grams. Concgrams are repeated sequences of words that may be discontinuous and in any order, and this allows the user to find possibly interesting phraseological patterns in text which contain optional intervening items. In addition, the keyness method and the n-gram method can be combined in order to highlight key clusters, i.e. repeated sequences whose frequency differs significantly in one corpus compared to a reference corpus. I will return to consider n-grams in more detail in Section 3.

The final method in the corpus toolbox is collocation. In Firthian terms, collocation refers to the relationship between a word and its surrounding context where frequent co-occurrence with other words or structures helps to define the meaning of the word. In practical terms, collocation as a method refers to the counting of the co-occurrence of two words in a corpus depending on their relative proximity to one another, and usually includes the calculation of a statistic or metric to assign significance values to the amount or type of co-occurrence relationships. Unlike the previous four methods, where some minor operational differences that exist in tokenization for frequency lists, concordances, keywords, and n-grams could produce slightly different results in different tools, the collocation method itself is less tightly defined. Results can vary greatly depending on the parameters and metrics chosen. Many different statistics can be selected to determine the significance of the difference in the frequency of a word that occurs in close proximity to the node word against its frequency in the remainder of the corpus, e.g. simple frequency, Mutual Information, log-likelihood, Z-score, T-score, MI2 or MI3. Altering the span of the window around the node word where possible collocate words are considered can also significantly affect the results. Further typical options include whether to consider punctuation as a boundary to collocation window spans or impose minimum frequencies on collocates or node words.

The five methods described above have all been defined in relation to words contained in a corpus. They can equally well apply to tags within a corpus, if any levels of annotation have been applied. For instance, a concordance can be produced for a certain part-of-speech tag, a frequency list of lemmas, key semantic tags, and calculate collocation statistics for which semantic tags relate to a given word.

The discussion so far in this subsection has been deliberately focused on general methods rather than specific software tools, but it is useful to include a brief timeline describing the development of retrieval tools in order to put them into context alongside the methods. The historical timeline of corpus retrieval software can be divided into four generations. In the first generation that developed alongside machine-readable corpora, software tools running on large mainframe computers simply provided concordance or key-word-in-context (KWIC) displays, and separate tools were created in order to prepare frequency lists, e.g. as used by

Critical reflection

Although I have presented corpus software as distinct tools used for the three stages of compilation, annotation, and retrieval, it needs to be highlighted that the separation between these stages is not always clear cut. As mentioned, Wmatrix performs both automatic annotation and retrieval. Other tools, such as WordSmith and BNCweb, permit the user to manually categorize concordance lines and this can be viewed as a form of corpus annotation. It should therefore be clear that a specific piece of corpus software cannot always be pigeonholed into one of these three categories.

Looking back on the brief survey in the preceding three subsections, it can be seen that a wide range of computational methods and tools are available to the corpus linguist. Updated versions of corpus software are being delivered on a regular basis; however, the corpus toolkit is in need of a methodological overhaul on a number of fronts. Words of caution have been expressed over the use of the keywords technique

One notable issue is the goodness of fit of current annotation and retrieval software where the corpus data is non-standard or "noisy". Vast quantities of historical data are now being digitized, and billions of words are available on the web or in online social networks. In both these cases, automatic tagging tools have been shown to be less accurate and robust. In particular, spelling variation causes problems for POS tagging, concordancing, keywords, n-grams, and collocation techniques. Even simple frequency counting is more difficult for the computer since multiple spelling variants will disperse the counts across different surface forms. Fortunately, tools such as VARD

As described in the introduction, corpus linguistics matured following hardware and software developments in computers and text processing methods. These developments have enabled much larger corpora to be collected and analyzed. However, it could be argued that corpus linguistics is now very tool-driven

Empirical study

Following on from the critical reflection about the limitations of computational methods and tools in corpus linguistics, this section will zoom in on one of the standard methods and illustrate some of the potential problems with it for corpus linguists and some possible solutions. As described in the previous section, the computational n-grams method appears under various guises in corpus linguistics.

Let us now consider some example lists in a short empirical study to consider the usefulness of the n-gram method itself. The n-gram procedure was applied to the full text of Alice's Adventures in Wonderland (one of the most frequently downloaded texts from the Internet Archive and Project Gutenburg) 13 using Ted Pedersen's N-gram Statistics Package (NSP). 14 The text is only 26,400 words long but it produces 1,810 2-grams, 737 3-grams, 192 4-grams and 51 5-grams that occur three times or more. This illustrates the first problem with the n-gram method, since even with a small text such as this, a large number of results is generated. Table

Unsurprisingly, the top 2-grams often are dominated by high-frequency words such as the, of, in, and it. In the 3-gram list there are potentially more useful entries, depending on the research question in mind, which contain information about the main characters of the story. Higher-order clusters may be more useful for analysis as they correspond to longer phrasal or clausal-like fragments and help to disambiguate and contextualize some frequent words. The top frequencies of 3-grams and 4-grams are much lower and a total of only 51 5-grams are reported with a frequency of three or more. In terms of practicalities for analysis and categorizing these items, it would be useful to look further into concordances but that is beyond the scope of this small case study. Especially at the 2-gram level there are too many patterns

This tree view shows longer n-grams indented and arranged underneath shorter n-grams that they contain. With software support, this tree view can be expanded or collapsed in order to focus on the important details. When linking to concordance views, if the user clicks on and the they Table

Conclusion

This chapter has very briefly surveyed the three stages in the corpus research process: compilation, annotation, and retrieval. To survey this whole area in one chapter is an almost impossible task and pointers to further book-level treatments of each of these areas were provided. It would also have been possible to widen out this survey of computational tools and methods to include very similar approaches undertaken elsewhere. There are at least three groups of tools and their related disciplines which are relevant. First, tools which provide Computer Assisted Qualitative Data Analysis (CAQDAS), such as ATLAS.ti, NVivo, QDA Miner, and Wordstat, incorporate some very similar methods to those described here but are not widely used in corpus linguistics. Their application tends to be in areas other than linguistics research but where language, texts, or documents are key sources, e.g. for political text analysis or other social science research questions. Second, tools such as Linguistic Inquiry and Word Count (LIWC) are used in psychology for counting emotional and cognitive words and other psychometric properties of language. Third, another similar set of tools is employed in the field of digital humanities for text mining of language properties in order to answer traditional humanities research questions and the formation of new research questions that are more difficult to answer with small-scale manual text analysis. Software tools such as Voyant and MONK are designed to allow large quantities of text to be searched, analyzed, and visualized alongside other tools such as Geographical Information Systems (GIS) and Social Network Analysis (SNA). However, here the focus has been on the tools and methods used in the field of (English) corpus linguistics. I uncovered some limitations of the current crop of computational tools and methods and reflected on whether corpus linguistics could be said to be becoming tool-driven.

Methods and tools for corpus linguistics have developed in tandem with the increasing power of computers and so it is to the computational side that I look in order to take a peek into the future of corpus software. In order to deal with the increasing scale of mega corpora derived from the web or historical archives, significantly more processing power is needed. Cloud computing may offer a solution here where (possibly multiple) virtual machines are used to run software tasks in parallel thereby making the results quicker to retrieve. For example, the GATE system (General Architecture for Text Engineering) now runs in the cloud, and on a smaller scale, so do Wmatrix and CQPweb. In order to analyze and automatically tag a 2-billion-word Hansard dataset consisting of data from 200 years of the UK parliament, 16 we recently estimated that it would take forty-one weeks of computer time. However, using a High Performance Cluster (multiple connected computers running small batches of text) at Lancaster, we were able to complete the task in three days. 17 A similar approach was taken by

Finally, gazing into a crystal ball, it is possible to see corpus linguistics techniques spreading not just to other areas within linguistics (e.g. stylistics) but also to other disciplines, e.g. psychology, history, and the social sciences in general where large quantities of text are used in research.

(ii) a group of methods in which the word or pattern under consideration is studied by means of a detailed analysis of its context. This usually involves the inspection of concordance lines of an element and their annotation for various linguistic and/or contextual features: if one wants to determine when speakers will use the ditransitive (V NP Recipient NP Patient ) and when the prepositional dative with to (N NP Patient PP to-Recipient ), one needs to inspect the whole sentence involving these two patterns and their larger contexts to determine, for instance, the lengths of the patient and the recipient, whether the clause denotes transfer or not, etc. Such data are usually analyzed with general statistical tools, i.e. methods that are applied in the same way as they are in psychology, ecology, and so on.

Corpus linguistics needs to "catch up" with regard to both of these groups.

With regard to the former, for instance, corpus linguists have used different association measures to quantify, typically, how much two words are attracted to each other or how much a word is attracted to a grammatical pattern, but critical methodological analysis of the commonly used association measures is relatively rare. With regard to the latter, for example, with very few exceptions (such as Biber's multidimensional analysis or

In this overview, I will discuss statistical tools in corpus linguistics. Section 2 is devoted to the "first group," i.e. statistics directly involving corpus-linguistic tools; Section 3 then turns to the "second group," i.e. statistics that are usually applied to the annotation of concordances. In each section and subsection, I will first discuss some commonly used methods to provide an easier overview of common questions and methods; then I will provide some pointers to more advanced and/or currently under-utilized methods, whose exploration or wider use would benefit the field. Section 4 will conclude with more general comments.

Statistics on core corpus-linguistic methods

In this section, I will be concerned with statistical methods that apply "directly" to the methods of frequency lists, collocations, and dispersion.

Frequencies of occurrence

Frequency lists

Frequencies of occurrence are the most basic statistic one can provide for any word or pattern. They come as either token or type frequencies and typically in one of the following three forms:

-raw frequencies: give's frequency in the spoken component of the ICE-GB is 297; -normalized frequencies: give's frequency in the spoken component of the ICE-GB is ≈0.46575 ptw (per thousand words) or ≈465.75 pmw (per million words); -logged frequencies: the natural log ln of give's frequency in the spoken component of the ICE-GB is ln 297 = 5.693732 (natural logs are computed to the base of e = 2.7182818, and e 5.693732 =297).

Raw frequencies are easiest to interpret within one corpus, normalized frequencies are most useful when frequencies from differently sized corpora are compared, and logged frequencies are useful because many psycholinguistic manifestations of frequency effects operate on a log scale. For example, if words a and b occur 1,000 and 100 times in a corpus, a will be recognized faster than b, but not 1000 / 100 =10 times as fast but maybe log 1000 / log 100 =1.5 times as fast.

Most often, the frequencies that are reported are word frequencies in (parts of) corpora. However, many studies are also concerned with frequencies of morphemes, grammatical constructions, words in constructions, or n-grams/lexical bundles. Examples abound in -learner corpus research, to document potential over-/underuse by learners compared to native speakers; -language acquisition corpora, to document how children acquire patterns as they increase the number of different verbs (i.e. the type frequency) filling a slot in a particular construction; -historical linguistics, to document the in-/decrease of use of particular words or constructions over time.

In spite of the straightforwardness of the above, there are still several underutilized methods and desiderata. One is concerned with the fact that words can theoretically have identical type and token frequencies, but may still be very differently distributed. Consider shows frequency distributions of the lemma GIVE in the ICE-GB, two hypothetical ones (left and middle panels) and the actual one (from

(1) a: see

Even more interesting for frequency lists of words or n-grams is the question of what the word or n-gram to be counted is or should be. In some corpora one can make use of multi-word unit tags. For example, the British National Corpus (BNC) has annotation that shows the corpus compilers considered of course, for example, for instance, according to, irrespective of, etc. to be one lexical item each, which means one would count of course, not of and course separately. However, in unannotated corpora, the situation is more complicated. Several strategies are possible: first, one can regard spaces and/or other characters as word delimiters and retrieve words or n-grams of a particular n using these word delimiters. The identification of word delimiter characters is not completely uncontroversial -what does one do with apostrophes, hyphens, etc.? -but far from insurmountable. However, even then the choice of n is bound to be arbitrary. To find according to, in spite of, on the other hand, be that as it may, and the fact of the matter is, one would need to set n to 2, 3, 4, 5, and 6 respectively, but typically studies just set n to 4 and proceed from there.

A more interesting but unfortunately rarer approach is to let the data decide which n-grams to consider. While very useful, these approaches become quite complicated. In one of the first studies to address this problem,

(3) KðαÞ ¼ ðlen α À 1Þ Á freq α (4)

n-grams such as in spite = in spite of Then, all word sequences are sorted by K(a) and the top n elements are considered individual elements of the vocabulary. Finally, one iterates and repeats these steps with the new inventory of individual elements. Consider as an example the n-gram in spite of and its parts as well as three 4-grams it is a part of and their frequencies in the Brown Corpus in Table

Assuming that in spite is a unit is not useful given that, whenever one sees in spite, one nearly always also sees of as the next word, so the corresponding K-values are very small (see

One approach towards the same goal is Gries and Mukherjee's (2010: Section 2.2) implementation of lexical gravity G, which also leads to the notion of lexical stickiness -the degree to which words like to occur in n-grams (cf. Sinclair's 1991 idiom principle) rather than on their own (cf.

Key words

A widespread application of frequency lists is the comparison of frequency lists of two corpora, often one (larger and/or more general) reference corpus R and one (smaller and/or more specialized) target corpus T. This is useful, for instance, in applied linguistics contexts: if one wants to teach the English of engineering, it would be useful to have a list of words that are more frequent in an engineering context than they are in general English. However, one cannot use a simple frequency list of an English engineering corpus, because its most frequent words would still be the, of, in, . . . -these are frequent everywhere. One of the earliest ways to compare the frequencies of words w 1, . . ., n in R and T to determine which words are "key" to T compared to R involves Damerau's relative frequency ratio. For example, if the word Perl occurs in T and R 249 and 8 times respectively and T and R contain 6,065 and 5,596 word tokens respectively, then this can be summarized as in Table

Another approach towards identifying key words involves G

Frequencies of co-occurrence

For many linguistic questions, the frequency of occurrence of a word/ patterns P alone is not sufficient -rather, what is required is the frequency of P co-occurring with some other linguistic element S, T, . . .. Typically, when P, S, T, . . . are words, this co-occurrence is referred to as collocation (and P, S, T, . . . are collocates); when P is a construction/pattern, this co-occurrence is referred to as colligation or collostruction (and S, T, . . . are called collexemes of P). In both cases, a central concern is being able to rank collocates/collexemes S, T, . . . in terms of their direction and strength of association with P: the words strong and powerful are near synonyms, but which of them is more likely to be used with tea and how much so? Or, the words alphabetic and alphabetical seem to be very similar semantically, but can we glean how they differ by identifying the words they "like to co-occur with," such as order and literacy? More than eighty different measures have been discussed; see

Typically, association measures involve computing the frequencies one would expect to see in cells a-d if the distribution in the table followed straightforwardly from the row and column totals (see Gries 2013a: 182). (

In spite of the large number of proposed measures, the field still has much to explore. Two areas are particularly noteworthy. The first of these is only concerned with collocations and is concerned with the range of words around a word P that are included. Just as with n-grams, practitioners usually seem to make an arbitrary choice, and frequent choices are 4, 5, or 10 words to the left and to the right, yielding context windows of 8, 10, or 20 words. However,

The second area in need of additional research is concerned with the nature of the association measures per se: just about all -and all that are regularly used -have two potentially undesirable characteristics: they are -bi-directional, i.e. they assign a value to, say, the collocation of course and do not distinguish whether the association of of to course is greater/less than that of course to of; -based on token frequencies of, again, say, of and course alone and do not take into account how many different words these two words co-occur with (let alone the entropies of these type frequencies; see

There are two measures, each of which addresses one of these problems, but both need much more exploration and no single measure addresses both problems. As for the former,

(8) a: Clearly, the word of does not attract course much -many words can and do occur after of -but the word course attracts of strongly -not many other words occur frequently before course. See

As for the latter problem, lexical gravity G (see Daudaravic ˇius and Marcinkevic ˇiene ˙2004) is an interesting attempt to include type frequencies of collocations in association measures. This measure takes into consideration how many different word types make up a token frequency. Using Table

Dispersion

Another topic that is even more important but at least as understudied is the notion of dispersion, the degree to which any (co-occurrence) frequency of P is sensitive to how evenly P is distributed in a corpus. For example, if one explores which verbs "like to occur" in the imperative on the basis of the ICE-GB, then many of the most attracted verbs are what one would expect: let, see, look, go, come, and others -however, two verbs returned as highly attracted stick out: fold and process (see

Ever since some early work in the 1970s (see

Unfortunately, this problem is a very general one: any statistic in corpus linguistics is ultimately based on frequencies in parts of corpora, which means that both dispersion and the notion of corpus homogeneity should always be considered potential threats to our studies.

Given the straightforward logic underlying the notion of dispersion, the huge impact it can have, and the fact that dispersion can correlate as strongly as frequency with experimental data (see Gries 2010c), dispersion and corpus homogeneity should be at the top of the to-do list of research on corpus-linguistic statistics.

General statistics

In this section, I will now turn to statistical tools that are often applied to annotation of corpus data, i.e. to data that emerge from the descriptionlinguistic, contextual, or otherwise -of concordance data; Section 3.1 is concerned with confirmatory statistics (and mentions descriptive statistics in passing); Section 3.2 with exploratory statistics.

Confirmatory/hypothesis-testing statistics

Confirmatory statistics can be classified according to two main characteristics:

-the number of independent variables, or predictors (often, the suspected causes of some observed effect). A design can be monofactorial, which means one analyzes the relation between one predictor and one response/effect (see Section 3.1.1), or it can be multifactorial, which means one analyzes the relation between two or more predictors and one response/effect (see Section 3.1.2); -the nature of the dependent variable(s), or effect(s)/response(s), which is usually either categorical (e.g. a constructional choice: ditransitive or prepositional dative) or numeric (e.g. a reaction times in ms) and which, thus, affects the choice of statistic chosen: categorical responses usually lead to frequencies whereas numeric responses often lead to averages or correlations.   Another well-known application of chi-squared tests is

Turning to other monofactorial explorations,

The other general point is that corpus linguists need to be more aware that no linguistic phenomenon is ever monofactorial. Any monofactorial test can only be a (dangerous) shortcut, given that what is really required for confirmatory statistics is a kind of analysis that combines three characteristics (see

-they are multifactorial in the above sense: they consider multiple causes for linguistic choices (such as the choice of an of vs. an s-genitive) into consideration; -they involve interactions between the linguistic predictors so that one can determine whether a particular predictor (is the possessor of a genitive construction specific or non-specific?) has the same effect regardless of other predictors (is the possessor singular or plural?): maybe specific possessors make it more likely that speakers would produce an s-genitive, but only (or especially) when the possessor is also singular . . .; -they involve interactions between linguistic predictors on the one hand and data-type predictors on the other. Data-type predictors include, for example, L1 (is the speaker a native speaker or a learner of some variety?), REGISTER (which register/genre is a data point from?), TIME (which time period is a data point from?) etc. Including such interactions is necessary if one wants to determine whether the linguistic predictors have the same effect in each L1/variety, in each register, at each time period, etc.: maybe specific possessors make it more likely that speakers would produce an s-genitive, but only (or especially) when the speaker is a Chinese learner (as opposed to a German learner or a native speaker) of English . . .

Unfortunately, multifactorial analyses taking all this into consideration, which are usually regression models (see Gries 2013a: ch. 5), are still in the minority.

Multifactorial statistics

Perhaps the most important tool in confirmatory statistics in corpus linguistics is, or should be, the generalized linear model and its extensions, a family of regression models, which serve to model a response/ dependent variable as a function of one or more predictors. Crucially, in the GLM and its extensions, the dependent variable can be of different kinds: they can be -numeric (as when one models, say, numeric test scores as in the above discussion of

In the same way, predictors can also be numeric, ordinal, binary or categorical variables (or any interactions between such variables, see above), and the results of such regressions are predictions (either raw values for linear and Poisson regression or predicted probabilities of outcomes for logistic regressions as in Figure

Most of these applications involve binary logistic regressions, i.e. speaker choices of one of two alternatives, but multinomial regression is also slowly becoming more mainstream.

Second, such regression analyses can be fruitfully combined.

Gries and Deshors apply this approach to the use of may and can by native speakers and French and Chinese learners of English. First, their R 1 determines which factors govern native speakers' use of may and can. Second, they apply these results to the learner data and predict for each learner use of may and can which of the two modals a native speaker would have chosen. Third, they explore the cases where the learners did not do what the native speakers would have done to determine what features of the modals the learners still have (the most) difficulties with. Third, a range of other interesting statistics can help corpus linguistics tackle other statistical challenges. One example is the approach of Structural Equation Modeling, which is designed to help identify causal effects from correlational effects; see

Other examples are methods that can help corpus linguists handle the kinds of noisy/skewed data that often violate the assumptions of regression approaches but that are still quite rare in corpus linguistics; examples include classification and regression trees, conditional inference trees, or Random Forests, which, with some simplification involve the construction of flowchart-like tree structures based on successively more fine-grained binary splits of the data; see

Exploratory / hypothesis-generating statistics

Apart from the many confirmatory approaches discussed so far, there is also a large range of so-called exploratory tools, i.e. methods which usually do not test hypotheses and return p-values but that detect structure in data that the analyst must then interpret. One of the most widely known methods is of course Biber's multidimensional analysis (MDA); see

Other exploratory tools that are widespread are cluster-analytic approaches. Just like FA/PCA, cluster-analytic approaches try to identify structure in multivariate datasets, but unlike FA/PCA, they do not require the data to be numeric and they return their results in an intuitively interpretable tree-like plot called a dendrogram (see

Given their flexibility, cluster analyses can be and have been applied in very many contexts where large and potentially messy datasets were explored for possibly complex correlational structures that would remain invisible to the naked eye;

Many more exploratory statistical tools are only used occasionally at this point. Examples include (multiple) correspondence analysis (see

Discussion and concluding remarks

In spite of having discussed many techniques and desiderata, this chapter could only scratch the surface of quantitative analysis and design in corpus linguistics -most quantitative applications/tools would easily merit an article on their own. As just one example, consider studies concerning the productivity of linguistic elements:

First, in addition to the mere knowledge of what techniques are available, we also need firm guidelines on what is important in statistical analysis, what is important to report, and how methods and results should be reported (see again note 2). Other fields have had long and intense discussions about these things -corpus linguistics, unfortunately, has not. We should be prepared to be inspired by how other disciplines with similar kinds of questions and data have come to grips with these challenges; from my point of view, ecology and psychology are most relevant to us, and Wilkinson and the Task Force on Statistical Inference (1999) provide many essential tips (e.g. to always include effect sizes to distinguish significance from effect size and make analyses comparable).

Let me briefly adduce an example of what happens if even elementary rules of statistics are not followed, in this case the rule that, if one computes many significance tests on one and the same dataset, then one needs to adjust one's significance level (see

However, this analysis is quite problematic. One very minor problem is what is presumably just a typo, but since Egan does not provide any actually observed frequencies, there is no way to know whether the comparison between Channel and Means resulted in 3.4 or 34. Much more importantly, Egan seems to have adopted a critical chi-squared value of ≈5.99, the chi-squared value for p=0.05 at df=2. However, Egan did not adjust his critical chi-squared value for the fact that he runs 28 tests on a single dataset. Thus, while he reports 22 significant contrasts out of 28, an adjustment (Hommel's method) results in only 14 significant contrasts, and since it is the "significant" differences upon which his possible network of through is based, this network essentially collapses: perception senses are not significantly different from all other senses. Similar problems are common: see Gries (forthcoming) for a discussion of a similar flaw in

Part II

Corpus analysis of linguistic characteristics

Discourse intonation: a corpus-driven study of prominence on pronouns Winnie Cheng

Introduction

Not everyone agrees on what exactly is covered by the term "prosody." Prosody is considered to be all of the suprasegmental features which include changes in pitch, "loudness, timing (including pauses) and voice quality"

There is no a general agreement on what prosody is, and the same is true for intonation, a subset of prosody.

The intonation system in English has been investigated from different approaches, depending on linguistic schools and countries

A grammatical or syntactic approach to intonation views intonation as segmental (see, for example,

Another approach considers the relation among syntax, information structure, and intonation

The third approach is based on the primacy of the affective or attitudinal role of intonation (O'

The last approach covered here, discourse intonation, is derived from a discourse analysis perspective which views intonation as performing discourse functions

The term "discourse intonation" is also used to refer to the model of discourse intonation proposed by

While British approaches to intonation are concerned with tone groups or tone units and pitch contours, American approaches to intonation tend to focus on a phonemic or levels approach to intonation

The discourse intonation framework

In the prosodic transcription system developed by

A tone unit is taken to mean a stretch of speech with one tonic segment comprising at least a tonic syllable, but which may extend from the first prominent syllable to the final prominent syllable

System Choice

Prominence prominent/non-prominent syllables Tone rise-fall, fall, rise, fall-rise, level Key high, mid, low Termination high, mid, low (Adapted from

In Brazil's discourse intonation, a particular communicative value is associated with each of the five possible tones. A tone is the pitch movement that begins at the tonic syllable (i.e. the last prominent syllable in a tone unit). Any spoken discourse unfolds based on the shared knowledge between the discourse participants

fall-rise tone indicates that this part of the discourse will not enlarge the common ground assumed to exist between the participants rise tone reactivates something which is part of the common ground between the participants fall tone

shows that the area of speaker-hearer convergence is about to be enlarged rise-fall tone indicates addition to the common ground and to speaker's own knowledge at one and the same time.

There is a fifth tone, the level tone, in the tone system which is associated with "truncated" tone units and tone units which precede an encoding pause

According to

Lastly, Brazil states the speaker also chooses pitch level again at the end of the tonic segment on the tonic syllable; that is, the last prominent syllable in the tone unit which is underlined in the transcripts, and he terms this system "termination"

The local meaning of selecting high or mid termination varies according to the functional value of what is being said and can be briefly summarized based on three broad scenarios. In the case of yes/no questions

Prosodically transcribed corpora

Generally speaking, we all speak more than we write, but corpora consisting of naturally occurring spoken texts have been largely neglected in favor of those comprised of written ones. Most corpora are solely made up of written texts and those which are a mixture of written and spoken data texts are still overwhelmingly written. To date, the largest corpora of the English language, Global Web-based English (GloWbE) (1.9 billion words), Bank of English (550 million words), and Corpus of Contemporary American English (COCA) (450 million words) contain relatively small amounts of spoken English, from 0 to 20 percent. Exceptions to these are the few specialized spoken corpora that are being compiled around the world. For example, the Cambridge and Nottingham Corpus of Discourse in English (CANCODE) is a collection of 5 million words of spoken English recorded between 1995 and 2000 (see, for example,

What are some of the well-known prosodically annotated spoken corpora? One of the first prosodically transcribed corpora is the 500,000-word London-Lund Corpus of Spoken English (LLC), which has been available for use since the 1970s

A recently released prosodically annotated corpus is the SPICE-Ireland corpus that contains the annotation of tunes

In Hong Kong, almost half (900,000 words) of the 2-million-word Hong Kong Corpus of Spoken English (HKCSE) has been prosodically transcribed and is known as the HKCSE (prosodic)

The HKCSE (prosodic) is unique in that it can be searched using specially designed software which enables the user to search for tone unit boundaries, the number of words in the tone units, frequencies of each of the tones, prominence, key, and termination across the corpus or a variety of subcorpora. The subcorpora are based on gender, gender plus mother tongue, domains of interaction (i.e. conversation, academic, business, and public), and genres. This makes it possible to compare, for example, the use of the rise tone by Hong Kong Chinese women in conversation versus Hong Kong Chinese women in business meetings. The results can then be displayed in the concordance format familiar to corpus linguistics with the search feature (e.g. rise tone or low key) centered in the concordance. The iConc software also allows the user to enter combinations of words or phrases with one or more discourse intonation features in the search function. In order for the software to search the corpus, the research team devised a notation system which allowed all of the possible combinations of discourse intonation features to be retrieved automatically

Corpus-based research on prosody

In this section, examples of recent corpus-based studies of prosody are described to provide a sense of the types of current work that are underway.

In another study,

In

Corpus-based research on prominence

Two research studies examining the characteristic features of Singapore English

In the following, the focus of discussion is on HKCSE (prosodic), prosodically transcribed using Brazil's discourse intonation system, and its tailormade corpus-linguistic software called iConc

In the following, an example analyzing the use of prominence is taken from

6 Use of prominence on pronouns in HKCSE (prosodic)

The HKCSE (prosodic) was first searched for personal pronouns (I, me, you, one, he, him, she, her, it, we, us, they, and them) and possessive determiners and possessive pronouns

While the same phenomenon is seen Table

The above discussion illustrates

In

Nouns and adverbs, such as people and only, often collocate with other words, such as many, more, and most, and just and not, respectively.

Conclusion

This chapter has outlined a brief review of research studies in prosody, primarily in intonation and other prosodic features including loudness, tempo, and voice quality, with a focus on a discussion of a few recent corpus studies in prosody, including a corpus-driven study of discourse intonation

The future directions for research in the prosody of large speech corpora, as noted by

5

Keywords

Jonathan Culpeper and Jane Demmen 1 Previous research on keywords

An introductory survey

The term "keyword" has considerable currency outside corpus linguistics, but there it is usually understood in a different sense. Raymond

Early history

Some notion that relatively frequent words can characterize particular literary styles, notably authorial styles, has been around for centuries, especially in French stylistics

Toute diffe ´rente est la notion de mots-cle ´s, qui ne sont plus conside ´re ´s dans leur fre ´quence absolue, mais dans leur fre ´quence relative; ce sont les mots dont la fre ´quence s'e ´carte de la normale.

[Wholly different is the notion of mots-cle ´s (keywords), which are not considered in terms of their absolute frequency, but their relative frequency; these are the words whose frequency diverges from the normal.] Simply being relatively statistically significant is not in itself the important point of interest. That lies in the link between keywords and style, but it is not articulated by Guiraud. Although he does not use the label "keywords," this link is clearly articulated by Nils Erik

Style is concerned with frequencies of linguistic items in a given context, and thus with contextual probabilities. To measure the style of a passage, the frequencies of its linguistic items of different levels must be compared with the corresponding features in another text or corpus which is regarded as a norm and which has a definite relationship with this passage. For the stylistic analysis of one of Pope's poems, for instance, norms with varying contextual relationships include English eighteenth-century poetry, the corpus of Pope's work, all poems written in English in rhymed pentameter couplets, or, for greater contrast as well as comparison, the poetry of Wordsworth. Contextually distant norms would be, e.g., Gray's Anatomy or the London Telephone

Establishment in corpus linguistics

It is in the context of corpus linguistics that the notion of keywords and the practice of keyword analysis has been developed and popularized, notably by Mike Scott through the KeyWords facility of WordSmith Tools

The utility of this tool is obvious: a visual map of keyness enables us to see whether or not the keywords are likely to be general features of the play or concentrated at particular points.

Connected with the issue of dispersion,

Further keyword developments

In his (2004) analysis of gay and lesbian texts, Baker discusses some of the major pitfalls in interpreting keywords. He shows the risks of overgeneralizing or overstating what keyness implies, emphasizing that "keywords only focus on lexical differences, rather than semantic, grammatical, or functional differences

As a way of finding keywords which are not concentrated in only a minority of texts,

Other scholars have focused specifically on the benefits of looking at key multi-word units in addition to single words. Various terms are adopted for multi-word linguistic units, such as "lexical bundles"

Methodology

To generate a list of keywords, corpus linguistic software programs such as WordSmith Tools, AntConc, and WMatrix conduct statistical comparisons between the words in one dataset (also called the "target" corpus) and another (the comparative or "reference" corpus). This is done by first generating a "word list" of the lexical items in the dataset and the reference corpus, using the appropriate program function. The keyness tool is then run, which makes a series of frequency-based comparisons using a statistical significance test, typically

The ease and rapidity of keyness analysis afforded by the programs mentioned above is the major boon. This boon is also apparent when one considers other methods designed to reveal styles. Using data comprising three genres (conversation, monologic speech, and academic prose),

1.5.1

The reference corpus

For example,

Reference corpora are typically the same size as the target corpus, or very much larger.

Minimum frequency

The minimum frequency cut-off parameter can be used to exclude words that will be identified as unusual simply because they happen not to have occurred, or have occurred very infrequently, in either the dataset or the reference corpus. Proper nouns, for example, are often amongst these oneoff occurrences. This is not to say that such phenomena -which are referred to as "hapax legomena" -are uninteresting (see, for example, Hoover 1999: chapter 4). The problem is that in a list of keyword results, mixing frequent items with very infrequent items often means mixing generalized phenomena with phenomena that are extremely localized, making an account of the keyword list problematic (see the following subsection for a statistical technique designed to reduce this problem). It is advisable to experiment with different minimum frequency cut-off points to minimize this problem, whilst ensuring that sufficient results are generated (if the dataset is small). A further point of good practice is to provide the raw frequencies of each keyword, in addition to its keyness value (log-likelihood or chi-square) when keyword lists are given.

Statistical significance

The significance test calculates the significance of the difference in frequency between the word in the target data and in the reference corpus. Some programs offer a choice of statistical tests (e.g. WordSmith Tools offers both chi-square and log-likelihood), while others do not (Wmatrix, for example, offers only log-likelihood).

Alternative or additional statistical manipulations have been proposed. In brief, these are: Bayes Factors.

Dispersion

Uneven dispersion makes the interpretation of keywords difficult

We would concur with

The state of the art

Keywords and other key items have become established in corpus linguistics as useful methods for identifying the lexical characteristics of texts. It is recognized that the notion of exactly what qualifies as key in any study is influenced by the settings and parameters of the program used, and by the comparator texts (in the reference corpus). Keyness in corpus linguistics is but the first statistical step in the analysis of texts. As Scott emphasises, keyness is context-dependent, and keywords "are pointers, that is all" (2010: 56).

Relatively new software tools, notably Paul Rayson's web-based WMatrix

The contributors to

Other recent developments include McIntyre and Archer's (2010) use of key semantic domains to investigate mind style in a play, and the partial automation of metaphor analysis, also using key semantic domains

Methodology

Culpeper's (2009b) study built on the keyword analysis of Shakespeare's Romeo and Juliet reported in

Culpeper (2009b) focused on three characters: Romeo, Mercutio, and the Nurse, whose keywords he determined to be characterized by different functions (see

Results of key part of speech analysis

Below, we briefly introduce some of the POS and semantic category results and discussion for Romeo (based on Culpeper 2009b). Table

With the exception of the category General adjective (JJ), all the key grammatical categories in Table

Table

To reach a more definite general conclusion about what is to be gained from extending a keyness analysis to POS categories or semantic categories,

Conclusion

In addition to charting the history and development of keyword research (in Section 1), our discussions have been designed to emphasize that key lexical items should be used as a guide for what to analyze qualitatively, and not considered the end product in themselves. We have emphasized (particularly in Section 1.5) that the usefulness of key items, and the quality of analyses and conclusions based upon them, relies on careful and explicit manipulation of the keyword tools settings as well as interpretation. Finally, our case study in Section 2 aimed to demonstrate that, given the availability of new and varied techniques for investigating keyness in different kinds of linguistic structures, it is necessary to consider and test out which one(s) will most usefully target the language features the researcher wishes to uncover.

The future of work involving keyness looks bright. We can expect developments in three directions. First, there is scope for methodological improvements. As discussed in Section 1.5, statistical refinements have been suggested, some of which have yet to be integrated into mainstream programs (e.g. log ratio as a means of taking effect size into consideration in the ranking of keyword results is being incorporated into a number of programs). Second, the extension of keyness analysis to POS and semantic categories need not stop there. In principle, any computer-readable form or user-supplied tag could be interrogated. For example, styles of punctuation could be thus investigated. Third, we are only just beginning to see the deployment of keyness analyses in academia (currently, many studies have focused on literary texts). The full potential of keyness analyses across the humanities and social sciences has yet to be realized.

6

Collocation

Richard Xiao 1 Introduction

While the study of recurrent co-occurrence of words dates back to as early as the mid eighteenth century, which saw the publication of Alexander Cruden's concordance of the Bible

This chapter aims to provide a critical account of corpus-based collocation research. Following this brief introduction, Section 2 explores the state of the art in collocation research, on the basis of which Section 3 presents a cross-linguistic study of the collocational behavior and semantic prosodies of a group of near synonyms in English and Chinese. Section 4 concludes the chapter by summarizing the research.

State of the art in collocation research

This section starts with discussions of the definitional and methodological issues in collocation analysis (Sections 2.1 and 2.2), and then explores the meaning arising from collocation (Section 2.3) and collocational phenomena beyond lexical level (Section 2.4), which is followed by a discussion of the importance of collocation in language use (Section 2.5).

Definitional issues

The term "collocation" was first used by

We may use the term node to refer to an item whose collocations we are studying, and we may then define a span as the number of lexical items on each side of a node that we consider relevant to that node. Items in the environment set by the span we will call collocates.

In addition to coherence and neighborhood collocations, the term has also been used in computational linguistics to refer to a phrase that is semantically non-compositional and structurally non-modifiable and nonsubstitutable

While collocation analysis has traditionally been concerned with contiguous word associations, recent developments in corpus linguistics have also made it possible to analyze the so-called "concgrams," i.e., sequences of associated words, whether consecutive or non-consecutive, which allow constituency variation (i.e. AB, ACB) and/or positional variation (i.e. AB, BA)

Methods used in collocation analysis

While some examples of collocation can be identified intuitively, "particularly for obvious cases of collocation"

As noted earlier, the terms like "habitual" and "customary" as used by

A number of statistical formulae are commonly used in corpus linguistics to identify statistically significant collocations, e.g. mutual information (MI), t-test, z-score test, and log-likelihood test. The MI score is computed by dividing the observed frequency of the co-occurring word in the defined span for the node word by the expected frequency of the co-occurring word in that span and then taking the logarithm of the result, as shown in equation (

In the equation, N stands for the total number of words in a corpus (e.g. 98,313,429 words in the BNC via BNCweb), F (n) for the frequency count of the node (e.g. sweet occurs 3,460 times in the BNC), F (c) for the frequency of the collocate (e.g. nothings occurs 37 times in the BNC), F (n,c) for the frequency of the node and collocate co-occurring within the defined span (e.g. within 4 words to the left and 4 words to the right of the node, with S=8), or 16 in the BNC example, while log2 is a constant roughly equivalent to 0.301. Based on equation (

However, as

In the equation, x and μ respectively represent the mean of the sample and the expected mean, S 2 is the sample variance while N refers to the sample size. In the BNC, for example, the frequency counts of sweet and smell are

À

)* 3508 98313429 À Á , roughly equivalent to 1.2547 × 10 -9 . The sample variance S 2 = P(1-P), and for a very small P value, it is roughly equivalent to P, namely x in this case. Based on equation (

Conventionally a t-score of 2.576 or above is considered to be statistically significant, which means that in our example above, smell is a significant collocate of sweet. While the MI test measures the strength of collocations, the t-test measures the confidence with which we can claim that there is some association

The z-score test provides a measure of how far a sample is from the mean and in what direction. The test compares the observed frequency with the frequency expected if only chance is affecting the distribution. The z-score test is a measure which adjusts for the general frequencies of the words involved in a potential collocation and shows how much more frequent the collocation of a word with the node word is than one would expect from their general frequencies. It can be obtained using equation

In the formula, F n,c and E are respectively the observed and expected frequency counts of co-occurrence while P refers to the probability of the collocate occurring where the node does not occur. P is expressed as Fc NÀF n and E as P F n S, where F n and F c are the frequency counts of the node and collocate while N and S stand for the size of the corpus (i.e. token number) and the collocation span respectively. In the above example of sweet and nothings from the BNC, F n , F c and F n,c are 3,460, 37 and 16 respectively, while N and S remain the same. Based on equation (

It can be seen from the above that in terms of the procedures of computation, the z-score is quite similar to the t-score, whereas in terms of output, the z-score is more similar to the MI score. A higher z-score indicates a greater degree of collocability of an item with the node word. As

The solution Dunning proposes for this problem is the log-likelihood (LL) test. The LL measure does not assume the normal distribution of data. For text analysis and similar contexts, the use of LL scores leads to considerably improved statistical results. Using the LL test, textual analysis can be done effectively with much smaller amounts of text than is necessary for statistical measures which assume normal distributions. Furthermore, this measure allows comparisons to be made between the significance of the occurrences of both rare and common features

The log-likelihood test is probably the most complex of the four collocation statistics discussed in this chapter. The LL score is calculated on the basis of a contingency table, as shown in Table

Of the four association measures discussed above, the LL test produces consistently better results in collocation extraction by including both common and rare lexical items as collocates. While it is known that MI scores may unduly overvalue infrequent words, it is certainly used widely as an alternative to the LL and z-scores in corpus linguistics because of its cognitive relevance for collocations (see

Collocational meaning

Shifting from form to meaning,

In

Semantic preference and semantic prosody are two distinct yet interdependent collocational meanings.

Beyond lexical collocation

While collocation has commonly been viewed as a phenomenon of the association between individual words, whether in their orthographic or lemma forms, this does not need to be the case. Rather collocational phenomena can occur beyond word level to involve the characteristic co-occurrence between words and phrases with certain grammatical categories and syntactic contexts. Colligation is a type of this kind of higher-level abstraction, which refers to the relationship between words at grammatical level, i.e. the relations of "word and sentence classes or of similar categories" instead of "between words as such" as in the case of collocation

A specific approach that has been developed to study colligation in this latter sense, i.e. the interaction between lexical items and grammatical structures, is collostructional analysis

The importance of collocation in language use

Collocation is part of word meaning. Because of the "mutual expectancy" between two words, "You shall know a word by the company it keeps!"

While a good command of collocation is an important indicator of native-like proficiency and fluency

Second, collocation information in dictionaries, if any, has traditionally been provided in the form of illustrative examples.

Third, corpus research has provided more reliable empirical evidence than intuition that facilitates the identification of collocational behavior and semantic prosody of an extensive range of lexical items that have until recently been hidden from intuition. Such knowledge is essential in improving language descriptions in general and in detecting subtle differences between near synonyms in particular (see Sections 2.2 and 3 for further discussion). Explicit teaching of collocation and semantic prosody also has an important role to play in language education (see

On the other hand, corpus research on collocation needs to address two important gaps. The first relates to the collocation-via-significance approach. While a variety of statistical formulae are currently available to extract significant collocates, the lists of collocates extracted using different statistics differ sharply (see Section 2.2). Furthermore, existing statistical measures are based on the assumption of random distribution, which is not true in language use

Second, corpus-based collocation studies have so far focused on, or indeed have largely been confined to, the English language. There has been little work done on collocation and semantic prosody in languages other than English. Still less work has been undertaken which contrasts collocation and semantic prosody in different languages (but see Sardinha  2000; Tognini-Bonelli 2001: 131-156; Xiao and McEnery 2006; Ebeling,  Ebeling, and Hasselga º rd 2013); yet findings yielded by this kind of research can be particularly valuable in language typology, language education, contrastive linguistics, and translation studies.

As such, the case study to be presented in the section that follows will explore collocation and semantic prosody in two genetically distant languages, English and Chinese in this case, from a cross-linguistic perspective rather than in a monolingual context.

Collocation and semantic prosody of near synonyms in English and Chinese

By "near synonyms" we mean lexical pairs that have very similar cognitive or denotational meanings, but which may differ in collocational or prosodic behavior

1. Does Chinese exhibit semantic prosody and semantic preference as English does? 2. How different (or similar) are the collocational behavior and semantic prosody of lexical items with similar denotational meanings (i.e. near synonyms) in genetically distant languages such as English and Chinese?

Before these questions are answered, it is appropriate to introduce the corpora and data analysis method used in this study (Section 3.1), which is followed by a discussion of the collocation and semantic prosodies of the chosen group of near synonyms in English (Section 3.2) and a contrastive analysis of the Chinese group (Section 3.3).

Corpora and data analysis method

As intuition is usually an unreliable guide to patterns of collocation and semantic prosody, this study takes a corpus-based approach to addressing these research questions. The principal corpus data used in this study are the FLOB corpus of British English

In collocation analysis we chose to use the MI measure because it is built into the corpus tools we used, WordSmith and Xaira. Both tools allow users to set the minimum co-occurrence frequency of an item to be considered as a collocate of a given node word so that the drawback of the MI measure as noted in Section 2.2 can be partly offset. Given the size of the comparable corpora used, we set the minimum co-occurrence frequency to 3. Within a 4-4 window span, items which had a minimum co-occurrence frequency of 3 and a minimum MI score of 3.0 were accepted as the collocates of a node word. When using additional data from the BNC and PDC2000 corpora, the minimum co-occurrence frequency was set at 20. As we will see from the collocates extracted in Sections 3.2-3.3, these adjustments have allowed us to use the MI score safely.

In our analysis of semantic prosody the positive, neutral, and negative meaning categories correspond to

The CONSEQUENCE group of near synonyms in English

In English there are a number of words that mean "anything that is due to something already done," e.g. result, outcome, consequence, and aftermath. Table

In FLOB and Frown, significant collocates of consequences include (ranked by co-occurring frequency):

• Nature: important, adverse • Affected target: social, financial, economic, ethical, moral, individual, public • Action: HAVE, (there) BE, ACCEPT Of the collocates indicating the nature of consequences, important is positive while adverse is negative. Interestingly, all instances of important consequences in FLOB/Frown collocate with HAVE/there BE to denote a positive pattern meaning. This observation is confirmed in a larger corpus. Of the 68 instances of important consequences in the BNC, 54 occurrences follow HAVE and one instance follows there BE. All 54 examples are positive while the remaining cases may be either positive or neutral.

When they are modified by collocates indicating an affected target, consequences are typically negative. As such, actions associated with them normally include accept, alleviate, avoid, face, meet, minimize, offset, (be) responsible, (take) responsibility, suffer, and sustain.

(1) These officials generally attributed their problems to: [. . .] Some critics charged, though, that states were reaping the consequences of profligate spending during the growth years of 1984-1989. (Frown: H) REAP typically collocates in its literal meaning with names of crops and harvest, or metaphorically with words with a positive meaning such as benefit(s) and rewards (the three significant collocates are from the BNC). It seems that the apparently paradoxical combination of REAP and consequences in this example carries the implication that "you reap as you sow": the officials were suffering as a result of their own profligate spending.

In comparison with consequence(s), aftermath displays an even more pronounced tendency towards the negative pole of the semantic continuum. In FLOB and Frown, 14 occurrences of aftermath were found, mostly in the expression in the aftermath of. There is only one significant collocate indicating what causes the state of affairs referred to by aftermath. It is war. As the low frequency may result in unreliable quantification, we consulted the BNC, which provides 687 instances of aftermath. Significant collocates in the BNC typically include war(s), world (as in World War I) and Gulf (as in the Gulf War). Clearly these words are negative in their contexts.

Further away from the negative pole of the semantic continuum are result and outcome. Result is significantly more common than outcome (with 677 and 86 occurrences respectively in FLOB/Frown). It appears that both words are associated with a favorable affective meaning, e.g. a good result, a great result, an excellent result, a brilliant result, a successful outcome (see

• Result: better, different, early, end, final, similar, direct, empirical, likely, experimental, good, negative, desired • Outcome: likely, positive, successful It is of interest to note that negative appears on the collocation list of result. A close examination of the concordances shows that in all of the three instances negative should be interpreted in a mathematical or medical sense, which has no impact upon affective meaning. The discussion above shows that the four near synonyms can be arranged, from positive to negative, on a semantic continuum as follows: outcome/result, consequence, and aftermath.

A contrastive analysis of the Chinese group of near synonyms

Shifting to consider these words in contrast, the Chinese translation equivalent of result/outcome commonly found in a bilingual dictionary is jie ´guo ˇ"result" while the translation equivalent for consequence/aftermath is ho `uguo ˇ"consequence." In addition, there are a number of obviously positive synonyms such as che ´ngguo ˇ"achievement" and shuo `guo ˇ"great achievement," and negative synonyms including ku ˇguo ˇ"a bitter pill to swallow" and e `guo ˇ"evil consequence."

There are 240 instances of jie ´guo ˇin LCMC, which are distributed across different meaning categories as follows: positive 33, neutral 129, and negative 78. Significant collocates of jie ´guo ˇinclude:

• Modifiers: da `xua ˇn "general election," bı `ra ´n "inevitable," shı `ya `n "experiment," dia `ocha ´"investigation," ke ˇne ´ng "possible," jı ¯ngjı `"economic," ha ˇo "good" • Actions: bia ˇomı ´ng "show," za `oche ´ng "cause," ze ¯ngjia ¯"increase," cha ˇnshe ¯ng "give rise to; arise," yo ˇu "have"

There are both similarities and differences in the distribution of result and its Chinese translation equivalent jie ´guo ˇacross meaning categories. On the one hand, like its English counterparts result and outcome, jie ´guo ˇtypically does not express a negative evaluative meaning. The semantic prosody of jie ´guo ˇis dependent upon its collocates. For example, when it collocates with za `oche ´ng "cause," it indicates an unfavorable result; conversely, when it collocates with cha ˇnshe ¯ng "bring about," the result is evaluated favorably. The neutral use of jie ´guo ˇwas mainly found in academic prose. As there are inherently positive synonyms in Chinese (e.g. shuo `guo ˇand che ´ngguo ˇ), as noted above, jie ´guo ˇis less frequently used than English result to indicate a positive semantic prosody.

In relation to jie ´guo ˇ, ho `uguo ˇis typically negative, though it can be used neutrally, because in some instances there is no evidence of semantic prosody in its context. Of the 22 occurrences of ho `uguo ˇin LCMC, 19 are used negatively, with the remaining three being neutral. The only significant collocate of ho `uguo ˇin LCMC is ya ´nzho `ng "serious, grave." When the consequences are specified, they typically refer to undesirable situations such as "increasingly intensifying contradictions," "unsold goods piling up in stock," and "inflation." When the consequences are not made clear, there are usually modifiers expressing value judgments or indicating the nature of the consequences. These modifiers normally share a negative semantic preference including, for example, ya ´nzho `ng "serious, grave," bu `ka ¯nshe `xia ˇng "too ghastly to contemplate," bu `ke ˇwa ˇnhuı ´"irrecoverable," bu `lia ´ng "adverse," xia ¯ojı ´"negative," na ´nce `"dubious," and bu `ya ´nzı `yu `"selfevident." In fact, ho `uguo ˇkeeps bad company so frequently that simply using this word alone is usually sufficient to indicate some unfavorable result, as exemplified in (2):

(3) a. she ¯n ce ´ngcı `re `nshi de ho `uguo ˇbia ¯ozhı `-zhe deep level knowledge GEN consequence mark-ASP ge `tı ˇyı `ngfu `yı `ngjı ¯de ne ´nglı `(LCMC: J) individual cope-with emergency GEN ability "Deep level knowledge allows an individual to cope with emergencies." b. qı ´yı ˇnqı ˇde ho `uguo ˇjia ¯ng bu `shı `he ´pı ´ng, they cause GEN consequence will not be peace e ´r shı `za ¯ina `n (PDC2000) but be disaster "The consequences caused by any of such words and deeds will not be peace but a disaster."

In contrast to the typically positive jie ´guo ˇand the typically negative ho `uguo ˇ, shuo `guo ˇ, and che ´ngguo ˇare inherently positive whereas ku ˇguo ˇand e `guo ˇare inherently negative, regardless of genre. There are 4,572 instances of che ´ngguo ˇand 109 instances of shuo `guo ˇin LCMC and PDC2000. The typical collocates of che ´ngguo ˇinclude fe¯ngshuo`"rich and great," jia ˇng "award," zhua ˇnhua `"transform, turn into," ke ¯jı `"sci-tech," ya ´njiu `"research," qu ˇde "gain," yo ¯uxiu `"excellent," go`ngxia `n "contribution," and she ¯ngcha ˇnlı `"productivity." The significant collocates of shuo `guo ˇinclude le ´ile ´i "heaps of" and jie ´chu ¯"yield." Che ´ngguo ˇis significantly more frequent than shuo `guo ˇ, reflecting the fact that in the real world, results that can be labeled as shuo `guo ˇare considerably fewer than those labeled as che ´ngguo ˇ. Ku ˇguo ˇoccurs 32 times and e `guo ˇ42 times in the two Chinese corpora. All of these are negative, but no significant collocate was found for the two node words.

Like the synonyms of result in English, the six near synonyms of jie ´guo ˇin Chinese can be arranged on a semantic continuum, from positive to negative, as follows: shuo `guo ˇ, che ´ngguo ˇ, jie ´guo ˇ, ho `uguo ˇ, and ku ˇguo ˇ/e `guo ˇ. Our contrastive analysis of the collocational behavior and semantic prosodies of the two sets of near synonyms in English and Chinese suggests that result/ outcome in English and jie ´guo ˇin Chinese can be considered cross-linguistic near synonyms; likewise consequence/aftermath in English versus ho `uguo ˇin Chinese are cross-linguistic near synonyms. In relation to English, it appears that Chinese is more sharply divided between the clearly negative and positive ends of the continuum so that the Chinese words shuo `guo ˇand che ´ngguo ˇ(both highly positive) and ku ˇguo ˇand e `guo ˇ(both highly negative) can hardly find their cross-linguistic near synonyms in English at lexical level. It is also important to note that unlike English, in which different forms of a lemma may have different collocates and semantic prosodies (e.g. consequence vs. consequences), Chinese does not have a rich morphology which can affect collocation and semantic prosody in this way.

Our contrastive analysis shows that semantic prosody and semantic preference are as observable in Chinese as they are in English. As the semantic prosodies of near synonyms and the semantic preferences of their collocates are different, near synonyms are normally not interchangeable in either language. It can also be seen from the case study that the semantic prosody observed in general domains may not apply to technical texts. While English and Chinese are genetically distant and distinctly unrelated, the collocational behavior and semantic prosodies of near synonyms are quite similar in the two languages. This observation echoes the findings which have so far been reported for related language pairs, e.g. English vs. Portuguese

While the corpus-based approach can only reveal but not explain such cross-linguistic similarity, at least part of the explanation, in our view, can be found in the common basis of natural language semantics -"the conceptual system that emerges from everyday human experience"

Conclusion

This chapter has sought to provide a critical account of the current debates in corpus-based collocation research. The first main section (Section 2) explores the state of the art in collocation analysis, covering definitional and methodological issues, meaning arising from collocation, collocational phenomena beyond lexical level, as well as the importance of collocation in language use. The review in this section demonstrates that corpus linguistics has enabled large-scale collocation analysis and foregrounded collocation in linguistic research while corpus-based collocation studies over the past decades have uncovered a range of interesting collocational behavior and semantic prosody which have been hidden from intuition and can only be revealed by examining a large amount of attested data simultaneously. Such findings have not only helped to achieve improved language descriptions, but they also have an important role to play in practical applications such as language teaching, translation, and natural language processing. This review section concludes with a brief discussion of two major gaps to be addressed in future research, namely development of improved statistical measures and cross-linguistic research. To demonstrate the kind of research called for, the second main section in this chapter (Section 3) presents a contrastive study of collocation and semantic prosody in English and Chinese, via a case study of a group of near synonyms denoting consequence in the two languages, which suggests that, in spite of some language-specific peculiarities, even genetically distant languages such as English and Chinese display similar collocational behavior and semantic prosody in their use of near synonyms.

Phraseology Bethany Gray and Douglas Biber 1 Introduction

There has been widespread interest over the last three decades in the use of multi-word prefabricated expressions (e.g. in a nutshell, if you see what I mean). This research argues that a good portion of the language we use every day is composed of prefabricated expressions, rather than being strictly compositional (see, e.g.,

Such multi-word sequences have been investigated under a variety of labels and definitions, including "lexical phrases," "formulas," "routines," "fixed expressions," "prefabricated patterns" (or "prefabs"), n-grams, and "lexical bundles." Regardless of label, however, these studies share a focus on how words combine into more and less fixed combinations. Most early studies were primarily theoretical in nature, comparing the various perspectives and approaches to multi-word units, proposing new frameworks for analysis, and calling for further research.

Beginning in the 1990s, most research on phraseological patterns has been empirical, utilizing corpus analysis.

With respect to the first issue, two general approaches have been employed to identify and analyze important multi-word units: corpusbased and corpus-driven (see

In addition to that distinction, there are several other important differences among corpus-based and corpus-driven studies of phraseology, including their overarching research goals, the role of register in the analysis, and the nature of the multi-word units (see Table

First, studies differ in their research goals: some focus on the use of a few important lexical expressions, while others set out to identify and describe the full set of multi-word sequences in a corpus (with a focus on characterizing the multi-word sequences, or on characterizing language variety according to the extent to which is it composed of patterned units). A related consideration is whether a study includes register comparisons: some studies compare phraseological patterns across two or more registers; others focus on phraseological patterns in a single register; while some studies analyze a general corpus and disregard the influence of register altogether. Finally, there are differences in the nature of the lexical sequences targeted for analysis, including fixed idiomatic expressions versus non-idiomatic sequences of frequent words; relatively short sequences of 2-3 words versus extended multi-word sequences; and sequences of contiguous words (e.g. in the middle of, in the rest of) versus discontinuous lexical frames in which one or more "slot" in the pattern is variable (e.g. in the * of).

In the following section, we undertake a survey of some of the most important corpus investigations of phraseology carried out to date, grouped according to the considerations introduced above. Sections 2.1 and 2.2 contrast studies based on their major methodological approaches, distinguishing between corpus-based studies of pre-selected lexical expressions versus corpus-driven studies to identify the full set of important multi-word sequences in a corpus. Section 2.3 discusses two additional factors: the role of register and discourse function in analyses of lexical phrases. Section 2.4 turns to research on discontinuous, rather than contiguous, word patterns. Then, in Section 3 we take a step back to consider the state of the art of phraseological research in corpus linguistics, considering some of the core issues still being debated within the field. Finally, in Section 4, we briefly present a case study illustrating the application of large-scale corpus analysis to investigate the types of discontinuous lexical frames found in spoken and written registers of English.

2 A survey of major approaches and research findings

Corpus-based studies of lexical phrases

Collocational research is typically restricted to relations between two words; it can be regarded as a hybrid approach that employs both corpus-based and corpus-driven methods: the researcher begins with a theoretically interesting target word (or a set of roughly synonymous target words), and then explores the corpus to identify the collocates that frequently occur in the context of the target words. Research of this type is discussed in detail in Chapters 6

In this chapter, we focus instead on phrases that might be regarded as extended collocations: lexical expressions involving three or more words. Different frameworks and studies have adopted a range of terminologies to represent such extended collocations (e.g. "lexical bundles," "n-grams," "prefabricated expressions," "formulaic sequences," etc.). For the purposes of this chapter, we refer to the general construct of phraseological patterns of three or more words as "lexical phrases." The range of specific terms, and how they are theoretically and methodologically distinct, will be discussed in the sections that follow.

There is a fairly long tradition of intuitive research on phraseology, noting the importance of prefabricated expressions in discourse (e.g.

Corpus-driven studies of lexical phrases

While there have been relatively few corpus-based studies of lexical phrases, there have been numerous corpus-driven studies. The main distinguishing characteristic of corpus-driven studies of phraseological patterns is that they do not begin with a pre-selected list of theoretically interesting words or phrases. Rather, the corpus itself is analyzed, inductively and typically automatically, to identify the lexical phrases that are especially noteworthy. The corpus analysis involves recording all multiword combinations with specified characteristics that appear in a corpus, usually tracking the frequency with which each combination occurs.

In some cases, corpus-driven analysis requires intensive reading and coding by human analysts, as in the study of idioms in academic speech by

In contrast to the Simpson and Mendis study, most corpus-driven investigations of lexical phrases have used automatic techniques to investigate the use of recurrent lexical sequences. These studies set frequency thresholds and dispersion requirements in order to identify the lexical phrases that are prevalent in the target corpus.

One of the earliest corpus-driven studies of this type was Salem's (1987) analysis of repeated lexical phrases in a corpus of French government resolutions. In the late 1990s, corpus-driven studies of recurrent lexical phrases in English registers began to appear.

Around the same time, the Longman Grammar of Spoken and Written English

Register variation and discourse functions of lexical phrases

As noted in the last section, most corpus-linguistic phraseological studies begin by identifying the set of lexical phrases that are especially prevalent in a corpus. However, they often have the ultimate goal of describing the phraseological characteristics of a register (or describing phraseological variation among multiple registers), and describing the discourse functions served by different types of lexical phrases.

For example,

Subsequent lexical bundle studies keep these same research objectives, applied to other discourse domains. For example,

The disciplines also varied in their reliance on bundles for different discourse functions: science and engineering preferred bundles with research-oriented functions, while participant-oriented bundles were proportionally more important in the social science disciplines. Text-oriented bundles, though, were important in all four disciplines.

As this review of research illustrates, there has been a particular interest in lexical phrases in academic registers, perhaps because much corpus research on lexical phrases has been motivated by applied concerns related to language teaching and learning. For example,

In a second line of applied research,

Corpus studies of discontinuous lexical frames

The research studies surveyed above have all focused on continuous sequences of words. However, researchers have also been interested in discontinuous sequences of words. One approach to these phenomena focuses on the ways in which two words collocate at a distance (e.g. PLAY and ROLE; see

Eeg-Olofsson and

More recently,

Summary

As the review of research in this section has shown, corpus-linguistic studies of extended lexical sequences have addressed the nature of patterned language from a variety of perspectives, under a range of rubrics, and with varying goals and methodologies. sample of the studies discussed in Section 2 can be characterized along these parameters.

3

State of the art and current issues

Taken together, corpus investigations over the last few decades have greatly extended our understanding of phraseological lexical sequences in English discourse. As shown by the research studies surveyed above, for example, we now know that lexical phrases serve important discourse functions relating to the expression of stance, discourse organization, and local referential framing (related to research orientations in academic writing). Previous research has also shown that lexical phrases have systematic distributions within texts, and serve as important signals to the internal discourse structure of spoken and written registers. We know that idioms are not common in natural discourse, and that instead most frequent lexical phrases have non-idiomatic meanings. There are major differences in the typical grammatical correlates of lexical phrases as well as in the typical discourse functions of lexical phrases across registers. Spoken registers generally prefer lexical sequences composed of verbs and clauses, often serving stance-related functions; written registers (especially academic written registers) generally prefer lexical phrases composed of nouns and phrases, often with referential functions. However, research practices in this domain of inquiry could be further improved through consideration of some basic methodological issues. For example, one current issue for the study of phraseology in corpus linguistics concerns the best methods to be used for the identification of the most important lexical phrases in a corpus. More specifically, at issue is the quantitative measures used to identify important lexical phrases: simple frequency and dispersion, versus measures of collocational association (like mutual information).

A related consideration involves the length of lexical phrases. Lexical bundles research has consistently demonstrated that longer bundles occur with lower frequencies than shorter bundles (e.g.

A third current issue is the analysis of phraseology in languages other than English, particularly non-European languages. English is typologically unusual in that it has an incredibly rich inventory of function words. As a result, corpus-driven studies of lexical phrases (both continuous and discontinuous) have shown that lexical patterning is ubiquitous in English, and basic to the discourse structure of both spoken and written texts. These lexical sequences and frames consist mostly of different combinations of function words. However, it is not entirely clear whether these patterns should be taken to show a universal reliance on prefabricated phrases, or whether they reflect the typological characteristics of English grammar.

Although the focus of this handbook is on corpus-based investigations of English language texts, a few of the studies reviewed here have addressed the issue of phraseology in other languages.

A final issue has received very little attention in corpus-driven studies of phraseology: the extent to which specific lists of lexical phrases are reliable (i.e. can they be replicated in analyses of another corpus), and the influence of corpus design on the identification of important lexical phrases. It is clear that corpus composition must have an influence on the identification of important lexical phrases. Even if register is controlled, the set of lexical phrases identified in a large corpus (containing more words) will probably be different than the set of phrases identified in a small corpus. But the total number of words is not the only important factor here: the number of different texts (and the average length of texts) is equally important. This is because different texts deal with distinct, specific topics, and as a result those texts use different words. Thus, a corpus with a greater number of different texts is likely to result in a greater number of different lexical phrases than a comparable corpus with fewer texts. Of course, these potential influences on the identification of lexical phrases become even more problematic if there are considerable register and/or topic variations between the corpora that are being compared. These methodological considerations are generally disregarded in corpus-driven studies of phraseology. While there has been considerable discussion of the best statistical methods to identify important phrases within a corpus, there has been almost no discussion of the replicability of phraseological findings, or the ways in which corpus design and composition influence the results of this kind of research. Thus, this is a key methodological concern that must be addressed in future research.

4 Case study on discontinuous lexical sequences in conversation and academic writing

Introduction

As noted above, corpus research on lexical phraseology has been carried out across the full continuum of corpus-based to corpus-driven research.

For example, at the corpus-based extreme,

Both the corpus-based and hybrid approaches can be contrasted with a strict corpus-driven approach to this issue, which would directly identify the thousands of possible discontinuous lexical frames in a corpus (e.g. the * of the, in the * of). Each sequence in the initial list of potential lexical frames can then be analyzed to determine its frequency, the words that can occur in the slot, and the extent to which the internal slot is variable or fixed. This fully corpus-driven approach is rather resource-intensive, yet is theoretically important because it makes it possible to account for frequent discontinuous sequences of words that are not associated with a moderately frequent lexical bundle. This situation can theoretically arise if the internal slot is so variable that there is no corresponding continuous sequence that gets identified as a lexical bundle. The goal of the case study here is to explore that methodological possibility by comparing the list of highly frequent lexical frames that result from a hybrid corpus--based study of discontinuous sequences

Corpora

The academic writing and the American English conversation subcorpora from the Longman Spoken and Written Corpus were used in the case study (see

Database construction and analysis procedures

Because of the computational resources required to process and store all potential discontinuous sequences (frames) in large corpora (c. 10 million words in total) from a strictly corpus-driven approach, we used a MySQL database to store all possible four-word sequences in the two subcorpora (specifically all four-word sequences that did not cross (a) punctuation boundaries in the written corpus, and (b) turn boundaries in the spoken corpus).

MySQL database queries were then integrated into specialized computer programs written in Perl to identify all frequently recurring lexical combinations, including continuous lexical bundles and discontinuous lexical frames. To restrict the scope of our investigation, we considered only four-word patterns, and lexical frames with only one internal variable slot. Table

For discontinuous frames, the program additionally analyzed the number of distinct fillers occurring in the variable slot, which was used to compute a type-token ratio that measured the internal fixedness of each frame, where type is the number of distinct lexical items occurring in the variable slot and token is the total raw number of occurrences of the frame. For example, a frame occurring 200 times with 25 distinct fillers would have a type-token ratio of .

Following

Distribution of discontinuous lexical frames versus continuous lexical bundles

If a corpus is analyzed for all lexical combinations, rather than only those combinations meeting minimum frequency and/or dispersion requirements, we would logically assume that there will be more continuous sequences (pattern 1234) than discontinuous sequences. That is, logically, as we introduce variable slots, multiple continuous sequences (e.g. explore this methodological possibility and explore this theoretical possibility) will combine into a single discontinuous sequence (explore this * possibility), and result in fewer distinct discontinuous sequences (frames) than continuous sequences (bundles). Figure

However, when frequency and dispersion limits are set, the opposite quantitative trend appears: there are many fewer recurrent continuous sequences than discontinuous frames. Figure

At a certain point, the trend shown in Figure

The trend shown in Figure

In contrast, the approach taken here is to directly identify and analyze the full set of discontinuous sequences, bypassing the bundles stage, and allowing for the possibility that there are common recurrent discontinuous frames that are not associated with a common lexical bundle. Our results indicate that there are numerous such sequences. To illustrate, we compare the frames identified by

Figure

The fully corpus-driven approach employed in this case study shows that some of the gaps in previous findings were simply an artifact of the corpusbased methodology at the first stage of the research. For example, both

In summary, the direct corpus-driven approach -identifying all possible discontinuous sequences, and then determining which of those are recurrent -results in a considerably more complete analysis than the previously used approach in which discontinuous sequences are identified from frequent continuous sequences (lexical bundles).

Summary and conclusion

In this chapter, we have surveyed the large body of corpus research on phraseology. Unlike many other areas of linguistics, there is a fairly clear difference between corpus-based and corpus-driven research on phraseology, and both approaches have been applied productively.

Corpus-based studies begin with lexical expressions (e.g. idioms or discontinuous frames) that researchers noticed before setting out on their investigations, and then they explore a corpus to learn more about the use of those expressions. Corpus-driven studies begin by analyzing a corpus to identify the set of important lexical phrases, and then study further the use of those phrases in discourse contexts to interpret the initial results.

In our case study, we illustrated how this distinction is not absolute: some previous studies of discontinuous lexical frames (like Biber 2009 and Ro ¨mer 2010) are intermediate along this continuum, beginning with a corpus-driven approach to identify a set of continuous lexical sequences, but carrying out the corpus-based investigation of only those sequences, to analyze the extent to which they occur as discontinuous frames. In contrast, the exploratory investigation that we present in our case study employs a corpus-driven approach to directly identify the important discontinuous frames in speech and writing. The analysis has shown that the mixed methodological approach applied in previous studies fails to capture the full set of important (i.e. highly frequent) lexical frames. Rather, many lexical frames are so variable, with no individual filler being frequent enough to be captured in any individual frequent lexical bundle. Thus, an approach that analyzes lexical bundles to determine the extent to which they are fixed or variable will fail to reveal these highly variable lexical frames. However, these frames can be identified through direct corpus-driven analysis.

Future research is required for many research questions related to the study of phraseology. These include specific questions relating to our case study (e.g. the functional correlates of the discontinuous frames identified in this study; see

• Exploration of more sophisticated quantitative methods for the identification of lexical phrases, and a better understanding of the types of phrases identified by each approach • Exploration of the influence of corpus design and composition on the identification of important lexical phrases • Assessment of the extent to which corpus analyses of phraseology are replicable, and development of new methods to achieve findings with higher reliability • Exploration of phraseological patterns in typologically different languages • Exploration of the extent to which (and ways in which) discourse can be regarded as formulaic across registers and across languages.

In summary, there have been huge advances over the last twenty years in our knowledge of the types and functions of phraseological language, resulting from numerous and diverse analyses of corpora. But there are still many basic aspects of phraseology that have yet to be investigated, making this a highly promising domain of inquiry for future research.

8

Descriptive grammar

Geoffrey Leech

This chapter, as the first of a series of four chapters dealing with grammar in this handbook, will take a rather general approach to the topic, beginning by looking back in history at the treatment of grammar from the beginning of the electronic era to the recent past. As studies of grammar have progressed and proliferated enormously through the development and exploitation of corpora, I will confine this survey to the grammar of one language -English -and will inevitably consider only a selection of publications.

The term "descriptive" in my title is, in a sense, redundant. All corpus studies of grammar inevitably make use of the evidence of grammatical usage as observed in corpora in order to arrive at some kind of description of what the corpus attests about some area(s) of grammar. In this context, "descriptive" is frequently contrasted with "prescriptive" grammar, which reflects attitudes in favor of certain usages and against others, rather than what is found to be evidenced by usage. "Descriptive" is also contrasted, often less favorably, with "theoretical." It is sometimes supposed that corpus linguists are content "merely" to "describe" what is found in a corpus, for example by describing the structures found and their frequencies, rather than to show how their findings advance understanding in terms of some theoretical framework(s) of how grammar works. I think this view is mistaken, and that description and theory are mutually dependent -see

However, accounts of grammar can be differentiated as being more theoryoriented or more description-oriented than others. Another interpretation of the term "descriptive" here is that the descriptive grammarian aims to achieve unbiased objectivity through the principle of total accountability: ideally

Historical review

The principle of total accountability was first enunciated in the early days of modern corpus linguistics -although the term "corpus linguistics" was not used at that time -by Quirk, planning the first attempt to build a representative corpus of contemporary English. This attempt was also associated with another way of understanding total accountability: as the attempt to build a comprehensive corpus-informed description of the grammar of a language -eventually embodied in the "mega-grammar" of

Quirk's Survey of English Usage project, which formed the basis of the 1972 and 1985 grammars, was in a sense continuing a much older tradition, the continental "great tradition" of

A year or two after Quirk's Survey of English Usage (SEU) project began in London, Nelson Francis and Henry Kuc ˇera at Brown University began the first electronic corpus of present-day English. They finished and released their corpus, the Brown Corpus of edited written English "for use with digital computers," in 1964, before Quirk (concentrating on detailed spoken transcription) had completed as much as a quarter of his. These two corpora inaugurated the modern age of corpus linguistics, although both suffered from limitations: the Brown Corpus was restricted to written, printed material; and the SEU corpus remained on paper until the mid 1970s, when most of the spoken part of it was computerized by Jan Svartvik and became the London-Lund Corpus (LLC). Nevertheless, they provided a rich source of data for an increasing number of grammatical studies in the 1970s and 1980s. Most such studies focused on individual areas of grammar, such as modal auxiliaries, relative clauses, the comparison of will and be going to, and the choice between contractions and full forms of verbs. Important early publications were the studies by

Such studies can be seen as a continuation of a slightly different corpus tradition (particularly associated with graduate theses in northern Europe) whereby the researcher collected his/her own corpus typically in the form of printed material, and searched it manually for instances of the grammatical phenomenon under scrutiny (e.g.

The benefits of using computer corpora for grammatical studies became more obvious when automated grammatical tagging (now usually called POS-tagging) became feasible

POS-tagging is generally thought of as the basic level of corpus annotation, as a foundation for more abstract and complex levels of annotation, by which to carry out more sophisticated and abstract grammatical corpus queries. Beyond POS-tagging, the most important level of annotation for grammar is obviously the syntactic level, which allows the investigator the means to extract tokens of particular constituent structure configurations. Automatic corpus parsing, however, has proved a more difficult nut to crack than POS-tagging. The conversion of a corpus into a database of syntactic tree structures or a treebank remains a problematic and laborious task, which is associated with error or failure rates far greater than those associated with taggers.

Nevertheless, treebanks have become available over the last twenty years: examples are the Penn treebank

This background explains why advances in corpus-based grammar research have been in some ways less impressive than advances in some other areas -particularly research on phraseology and collocation, which is less dependent on complex structure-dependent search mechanisms. One negative result of the relative lack of accurately annotated treebanks has been, as pointed out by

It should be pointed out, however, that there are other means of extracting syntactic patterns (or rather, lexical + grammatical patterns) than relying on parsed corpora. One of these is to write small-scale customized programs to identify individual grammatical features of texts, the method used by

2 Extending the range and power of grammatical description: the many contributions of corpus linguistics

We move on now to some key advantages of corpus grammar in extending the range of grammatical description.

Unexpected findings

Perhaps the most memorable contributions of corpus grammar arise when the corpus linguist discovers something new and striking. Thus

It is their combination that approximates to a constant.

Another example of a surprising corpus finding is the discovery by

Peripheral areas of grammar that corpus linguistics has opened up

Theoretically oriented grammarians often ignore areas of grammar which are not "interesting" from their theoretical viewpoint. Corpus-based grammatical research (following the principle of total accountability) cannot ignore such areas, and often finds that they are by no means uninterestingrather the opposite. I will illustrate this from two related areas: adverbials and discourse markers. Adverbs and adverbials have been virtually ignored by theoretical grammarians. Even the most comprehensive of grammars written by transformational grammarians,

Closely related to the adverb/adverbial category is the even more grammatically peripheral category of discourse markers, also termed pragmatic markers, discourse particles, and the like. Discourse markers were not recognized as a part of speech in traditional grammars, and even in the present day they are an uncertain category, straddling the border between grammar, pragmatics, and discourse analysis. The early tagging systems of the Brown and LOB corpora made no provision for discourse markers. However, the compiling of the LLC in the mid 1970s gave considerable impetus to the study of the grammar of spoken language, where the frequency and conversational role of certain discourse markers (e.g. actually, really, well, by the way, you know) cannot be ignored. The work of Karin Aijmer has been particularly important in this fieldsee

Investigating spoken English

I have already implied that the unprecedented opportunity provided by spoken corpora for the detailed study of speech phenomena was a major breakthrough for corpus-based grammar. Grammar has traditionally focused on the written language,

Among studies focusing on the differences between speech and writing, a leading place should be given to

It became obvious in the last two decades of the millennium that certain phenomena were characteristic of speech, and other phenomena that were virtually absent from written data had been seriously neglected by the grammatical tradition. They include expletives, vocatives, ellipsis phenomena, and the discourse markers mentioned above -all reflecting the interactive nature of conversation, and all part of the prevalence of nonclausal, verbless material in spoken language.

North and south London -they're different worlds -aren't they, in a way?

where the chunks marked "A," "B," and "C" can be characterized as pre-clause, clause, and post-clause, forming a pattern that has no place in the standard grammar of written sentences. The orthodox clausal structure of B, which would be normal in written communication, can be extended by non-clausal elements such as A and C, which can be added initially and finally.

Carter and McCarthy, in this landmark article, argued (following a similar line taken by

The value of statistical methodologies

The two chapters on grammatical variation and grammatical change, which follow this chapter, will give more attention to the statistical modeling of grammatical phenomena. However, in this chapter it will also be appropriate to consider how quantitative methods add value to descriptive grammar.

It is worth recalling that in the fifty years following Chomsky's Syntactic Structures (1957), probabilities and statistical methods were assumed by the leading school of linguistics, the generative school, to have no role in explaining or describing the grammar of a language (see

Relatively simple statements about frequency already have implications for descriptive grammar. For example, the decision to treat the "preterite modals" would, could, should, and might as the past-tense forms of will, can, shall, and might in contemporary English (as adopted, for instance, by

The first major demonstration of the value of corpus methods in statistical modeling is found in

Gradience and multifactorial analysis

Frequency and probability, when applied in grammar, lead to the view that not all categories and structures are of equal status, but that some are more significant or salient than others. Similarly, grammar becomes a matter of "more or less" rather than "either/or" when consideration is given to the much-discussed notion of gradience

Gradience can be recognized either between members of different categories (what Aarts 2007 calls intersective gradience) or between members of the same category (what he calls subsective gradience). The latter type of gradience fits well with the notion of prototype categories

gradience more precisely -using, for example, the "plus and minus" matrix method -and can also use frequency data to give substance to the idea that some members or subtypes of a category are more typical or cognitively central than others.

In the past theoretical linguists, relying on their own language intuition and the occasional well-picked example, have found little need to recognize gradience, which can complicate rather than clarify their grammatical models. However, the corpus linguist, analyzing and classifying real data, soon discovers that gradience is a reality. An early example of corpusbased gradience was provided by Svartvik's study of the passive

(1) A total of £130 was stolen (by . . .). [BNC

(3) An unusually low price might mean the car is stolen.

(4) An unusually low price might mean [someone] has stolen the car.

Qualitative analysis of corpus examples enables a matrix table to be built up, whereby criteria showing resemblance to the be + adjective category or to the passive category can be plotted against numbers of tokens, and degrees of similarity to and difference from the passive can be established.

It must be admitted, however, that the analysis of gradience is a laborious affair, and even corpus grammarians have been known to shy away from it.

To illustrate the case of complex prepositions, corpus analysis can demonstrate the degree of fixedness of the sequence Prep 1 + Noun + Prep 2 by a number of criteria, of which

These and similar criteria of fixedness can be related to the diachronic process of grammaticalization, a topic explored by

Corpora also allow us to investigate the set of factors which determine the choice between apparently synonymous alternatives. An example of this is the choice between the English s-genitive and the (often semantically equivalent) of-construction. Using data from the LOB Corpus,

A similar multifactorial analysis of the genitive and the of-construction has more recently been undertaken by

(5) a. Fred picked up the book.

b. Fred picked the book up.

In this publication, Gries claims persuasively that he has built into the model all possible determinants of the choice, including:

Type of variable Example

Phonetic/phonological e.g. stress pattern of the verb phrase Morphosyntactic e.g. length of the direct object Semantic e.g. focus of the verb phrase Discourse-functional e.g. distance to last mention of the direct object's referent Other e.g. oral vs. written register.

More significantly, the statistical model is used to test a hypothesis as to how the choice is determined by psychological processing requirements, in the context of a cognitive theory of language. By thus linking description to theory, Gries argues that his corpus-driven study not only describes, but explains and predicts the way the choice between option (5a) and option (5b) is made.

Conclusion

It seems that the simple goal of "describing" some aspect of English grammar, such as seemed sufficiently ambitious in the early days of corpus linguistics, no longer holds the limelight. Newer developments have combined grammatical description with some other dimension of linguistic interest. The three chapters following this one survey three of those dimensions which have attracted an increasing amount of research endeavor in the last twenty years: grammatical variation (Chapter 8), grammatical change (Chapter 9) and lexico-grammar (Chapter 10). In this conclusion, I will add a paragraph on each of these, to link them to this chapter's theme of grammatical description.

(a) Grammatical variation

Almost from its beginning, corpus research on grammar has been linked with variation. A reference corpus cannot in any sense represent the language, unless it is subdivided into text categories or subcorpora representing a broad range of registers, as in the BNC or the Bank of English. As corpus grammar provides frequency information, it can hardly be ignored that different subcorpora yield very different frequency profiles associated with their communicative functions -above all, in the contrast between speech and writing. This is illustrated by

(b) Grammatical change

Diachronic change, of course, is just another dimension of variation -one that has advanced enormously over the past twenty years, through the building up of a wide range of corpus resources for previous periods of the language. With particular relevance to this chapter, a diachronic interest in PDE has developed through the compilation of corpora enabling a precise study of changes in English over the recent past: for example, the Brown family of corpora, Bas Aarts's Diachronic Corpus of Present-day Spoken English (DCPSE) and Mark Davies's Corpus of Contemporary American English (COCA) and, with a longer time span, his Corpus of Historical American English (COHA). The rise of "brachychronic" [short-time] linguistics, to use

(c) Lexico-grammar One of the ways in which corpus linguistics has changed our view of language, I believe, is in the now widespread recognition that grammar and lexis are not separate components of language, but that they interpenetrate. The view was put forward by Michael Halliday as early as 1961, that there is a "cline" rather than a dichotomy between lexis and grammar, and the inseparability of "lexico-grammar" is now widely recognized particularly through the work of

How does this affect corpus-based grammar? It has long been held that grammatical patterns, although abstract in themselves, are realized through lexical as well as grammatical choice. Even traditional grammars contain an admixture of lexical and grammatical information: for instance, patterns of complementation with lexical verbs. But in addition, large corpora have proved game-changing in providing frequency information on the interaction of lexis and grammar, as new statistical modeling techniques have developed: pattern grammar

The three areas discussed under (a)-(c) above can be described as "leading edge," as they are leading, and will lead, to further advances in the understanding of language in the future. Thanks to them, descriptive grammar will continue to have a role in corpus linguistics.

Grammatical variation

Daniela Kolbe-Hanna and Benedikt Szmrecsanyi

A discussion of previous research in this area

In this chapter, we use a fairly liberal definition of "grammatical variation," including both genuinely variationist research -where grammatical variants are modeled as competing against each other -and text-linguistic research that explores variable text frequencies of particular grammatical constructions in corpora.

Corpus-based research on grammatical variation is a wide research area, so the review we are offering is somewhat selective. By and large, research along these lines can be categorized into five groups:

1. Variationist sociolinguistics. Researchers in this tradition are typically interested in how linguistic variation is conditioned by language-internal and language-external factors. Although early studies largely relied on the researcher's personal notes taken while listening to the audio recordings, state-of-the-art work is usually based on corpora consisting of fully transcribed sociolinguistic interviews (see

In what follows, we discuss five studies, each one exemplifying one of the categories defined above.

Variationist sociolinguistics.

(1) a. The liquor closet got broken into.

b. They broke into the liquor closet.

Register/genre/text type analysis.

Dialectology.

Knowledge, processing, cognition.

(2) a. He gave the children toys b. He gave toys to the children Bresnan et al. calculate several logistic regression models that all correctly predict more than 90 percent of the actual dative outcomes in the Switchboard collection of recorded telephone conversations and in a corpus of Wall Street Journal texts. Bresnan et al.'s models draw on a wide range of explanatory variables to account for speakers' dative choices: semantic class, accessibility of the recipient, accessibility of the theme, pronominality of the recipient, pronominality of the theme, definiteness of the recipient, definiteness of the theme, animacy of the recipient, person of the recipient, number of the recipient, number of the theme, concreteness of the theme, structural parallelism in dialogue, and length difference between theme and recipient. In addition, the study employs bootstrapping techniques and mixed-effects modeling to investigate issues such as the role of idiolectal differences and the validity of cross-corpus generalizations. Besides showing that intuitions are a poor guide to understanding the dative alternation,

Discussion of methods

Most of the research in the variationist sociolinguistic tradition is based on studies of "private" (D'Arcy 2011: 55) corpora. These kinds of corpora comprise data that were gathered specifically for a project, such as in

Traditionally the focus has been on determining the conditioning of grammatical variation, so studies such as

As far as analysis tools are concerned, Varbrul has dominated the market in Labov-type variationist sociolinguistics in particular. Varbrul is designed to calculate the stochastic influence of multiple independent variables on grammatical variation (e.g.

In any event, it has been a hallmark of variationist linguistics to study relative frequencies or usage rates of a variant vis-a-vis another variant that it competes with (e.g.

In conclusion, corpus-based research has shown that grammatical variation, like phonological variation, can be sociolinguistically conditioned. Also, we now know that we can trace back the development from variation to language change in historical corpora, as do, for instance,

It also turns out that speakers implicitly know about (probabilistic) aspects of grammatical variation. For instance, in a series of experiments Joan Bresnan

An interesting issue that remains to be resolved would be to link up the variation-as-explanandum approach and the variation-as-explanans approach. An example will be provided in our case study in Section 2, which models constraints on complementizer that deletion (variation-asexplanandum), but then goes on to utilize part of the probabilistic output of this analysis to explore how complementizer that variation engenders dialectological differences (variation-as-explanans). Wolk (

2 Case study: variation in the use of the complementizer that Our case study is an exercise in variationist analysis: we investigate grammatical variation in the use of the complementizer in that clauses, such as in

(3) We think (that) these worries are common.

While many factors have proved to be influential in variable that omission, only a few studies have included language-external factors (e.g.

On the technical plane, we employ multivariate analysis, in particular mixed-effects logistic regression as implemented in the lme4 package, to include as many factors as possible known to condition this variation, and to compare the strength of each factor with the strength of each other factor. We also account for the lack of repeatability in certain independent variables by treating them as random effects. This means that rather than calculating the strength of influence of these variables, the model adjusts the calculation according to the bias of these variables (see

Previous research on the retention or omission of that

The variation in the use of the that complementizer has been the object of an abundance of linguistic research. Research in cognitive linguistics as well as in psycholinguistics has shown that the cognitive complexity of an utterance plays an important role in a speaker's choice to use or not to use the explicit complementizer. This choice reflects speakers' effort to find a balance between explicitness and economy. While the retention of that explicitly marks the subsequent clause as an embedded clause and is thus more precise, the omission of the complementizer reduces the production effort by rendering a shorter utterance. Consequently, the omission of that is in general preferred in linguistically less complex environments, where less explicitness is needed to signal that the following linguistic material is a complement clause

Data and methods

FRED consists of roughly 2.7 million words of dialect speech (Herna ´ndez 2006; see Szmrecsanyi and Herna ´ndez 2007 for the publicly available sampler version). As the retention or omission of that is determined by many cognitive factors, spoken language is a crucial resource for examining the influence of those factors. The texts in FRED derive from interviews with speakers from England, Wales, and Scotland. The corpus files mostly consist of transcripts of oral history interviews and thus offer a style of speech that is casual and adapted to the interview format

We chose to restrict attention to the complement-taking predicates think, say, and know -the most common matrix verbs of embedded that clauses

Drawing on previous research on the choice between the omission and the retention of that (see above), we identified as independent variables those aspects of each embedded clause and its matrix clause that are likely to influence a speaker's choice between explicit and zero that.

Variables

The dependent variable in our study is binary: retention or omission of the complementizer that. The independent variables in our annotation layer are detailed in the following.

Language-external factors

As

• TEXT indicates the corpus file (e.g. SFK_018 or IOM_002) where the token occurred. • AREA codes the nine dialect areas as specified in FRED. These are Hebrides, Isle of Man, English Midlands, Northern England, Scottish Highlands, Scottish Lowlands, Southeast England, Southwest England, and Wales. • COUNTY specifies the county in which the speaker lived at the time of recording. • SPEAKER renders the current speaker's ID (as defined in the FRED manual).

Information on speakers' age is unavailable for 1,124 cases in the database, or more than 20 percent. Since the inclusion of age would thus result in substantial data loss, we did not include speakers' age in the analysis. We also did not include information on speakers' sex, since the sample in FRED is skewed: of the 5,296 utterances, only a quarter

Language-internal factors

According to

Features of the matrix clause

As previous research has shown

Further features of the verb phrase in the matrix clause that affect a speaker's choice between zero and that are the morphology of the verb and whether the verb phrase contains an auxiliary. The less complex the verb phrase is, the less likely that that will occur (see Torres

• VERBMORPH codes whether the matrix verb occurs as base form, as thirdperson singular present tense, as past (tense or participle), or as -ing form. • MATRIX_NEGATION specifies whether the matrix verb is negated.

• MATRIX_AUXILIARY states whether the matrix verb is preceded by a modal auxiliary (e.g. should, could, would, will, 'll, shall, must, can + negated forms).

A third feature of the matrix clause that has an impact on a speaker's choice of complementizer is its subject. When the matrix clause subject is I or you, the omission of that becomes more likely

If the matrix clause is I think, the retention of that is highly unlikely. This clause not only comprises all features that favor the omission of that (subject I, simple verb morphology, highly frequent verb lemma that very often controls that clauses), it also functions as a comment clause or epistemic parenthetical (see, for example,

The variables MORPHID and VERBID combine features of the matrix verb that are potentially relevant to grammatical persistence as discussed in

Features of the embedded that clause

Whether speakers choose to retain or omit a that complementizer has also proved to depend on features of the embedded clause itself. The cognitive complexity of the embedded clause is gauged by means of the following variables:

• EMB_CL_LENGTH specifies the number of words in the embedded clause (excluding the complementizer when present), since speakers use the explicit complementizer more often in longer clauses

There is evidence from non-finite clauses that speakers avoid using identical forms consecutively

Features across clauses

The scope of the following variables goes beyond clause boundaries:

• Speech perturbations: Jaeger shows an effect of disfluency on a speaker's choice of complementizer

Determinants of the choice between explicit and zero-complementizer

In order to explore the influence of the independent variables mentioned above on a speaker's choice between explicit that and its omission ("zero"), we analyzed their effects in a logistic regression analysis with mixed effects, i.e. one that takes into account both random and fixed effects for the reasons stated above (see

The dependent variable is the choice between the zero-complementizer and its explicit form. As FRED consists of spoken data only and "[i]n conversation, the omission of that is the norm, while the retention of that is exceptional"

We included four independent variables, or factors, as random effects (i.e. adjustments to the intercept), since their influence is non-repeatable.

VERB lemma, SPEAKER, TEXT, and COUNTY are non-repeatable effects, as a second study relying on randomly chosen verbs, speakers, texts, and counties would result in a different sample. VERB can be seen as a classical by-item effect, whereas SPEAKER is the classical by-subject effect. TEXT and COUNTY are directly connected to SPEAKER, because they represent a particular interview with a speaker who lived in a specific county at the time. The model adjusts the intercept for each of these non-repeatable effects, to avoid skewing the results in the direction of their deviation.

At first, we created a maximal model that included all independent variables listed in Section 2.2.1. Subsequently, the model was simplified by removing factors lacking significant explanatory power (such as MORPHID and VERBID). We started the pruning process with the least significant factors, moving to more significant ones in a stepwise fashion. Explanatory power of categorical factors with more than two levels was assessed via likelihood-ratio tests. Our final model (the "minimal adequate model") comprises the minimal amount of factors showing maximal results and the best possible fit to the data. It correctly predicts 92.4 percent of all outcomes, which is a modest but significant (p=0.01) increase over the baseline percentage at 91.0 percent, which represents the percentage of zero-complementizers in the database.

The fixed effects that turned out to be significant predictors of the choice between zero and explicit complementizers concern ten variables:

• matrix verb morphology (VERBMORPH) • the subject of the matrix clause (MATRIX_SUBJECT_TYPE)

• the presence of an auxiliary in the matrix verb phrase (MATRIX_AUXILIARY) • whether the embedded clause is controlled by I think (I_THINK) • HORROR_AEQUI • the presence of an adverbial after the end of the embedded clause (ADV_AFTEREND) • whether the subject of the embedded clause is a pronoun or not (COMPLEMENT_SUBJECT) • the logarithmically transformed length of the embedded clause (LOG (EMB_CL_LENGTH)) • the occurrence of that within 50 words before the complementizer (ALPHA_PERSISTENCE_50) • the number of speech perturbations in the immediate context of the complementizer (logarithmically transformed as LOG(EHMS_ETC_NARROW +1)).

Within VERBMORPH the use of that becomes less likely when the matrix verb is in the third-person singular present tense or in the past tense (estimates -0.73 resp. -0.35) than when it is used in its base form (the default value). Although the influence of the third-person singular presenttense form is not significant at the conventional threshold of 0.05, we consider it to be marginally significant because its p-value at 0.1 means . marginally significant (p < 0.1), * significant (p < 0.05), ** very significant (p < 0.01), *** highly significant (p < 0.001)

that there is a 90 percent chance that its effect is not due to chance. An -ing participle, however, increases the likelihood of the use of zero that (1.07).

The form of the matrix subject (MATRIX_SUBJECT_TYPE) also has a significant effect on the retention of that. When the matrix subject is I or you (-1.48 and -0.99 respectively), the retention of that is less likely than with it or the default category of any other subject. When it is the matrix subject, speakers use that more readily

Moreover, the form of the subject of the embedded clause influences a speaker's choice significantly. When it is or begins with that speakers avoid the use of the explicit complementizer, to avoid the sequence that that (horror aequi, estimate -1.04). In addition, speakers tend to omit that if the subject of the embedded clause is a pronoun (-0.53), as well as after I think (-0.70).

The following conditions increase the probability of the retention of the complementizer that: the persistence of a that-complementizer, i.e. when it has been used within 50 words before this slot (1.07), an auxiliary in the matrix verb phrase (0.72), and an adverbial at the end of the embedded clause (0.42). The longer the embedded clause is and the more speech perturbations there are between matrix and embedded clause, the more likely speakers are to choose that (LOG(EMB_CL_LENGTH): 1.08; (LOG (EHMS_ETC_NARROW + 1): 0.79).

The strongest factor increasing the likelihood of a that is noted for the matrix subject it (1.42). The strongest factor decreasing the probability of the retention of that is the use of I as matrix subject

As regards the random effects, SPEAKER and COUNTY result in the strongest adjustments (standard deviations of 0.74 and 0.57 respectively). Think favors zero-complementizers most strongly of the three matrix verbs (of 3,394 instances of think, only 152, or 4.5 percent, control an explicit that clause), so the adjustment of the intercept is negative (-0.27) for this matrix verb, while the intercept adjustment for know is 0.37 and the adjustment for say is 0.15. It is not feasible to report all intercept adjustments for each of the 300+ speakers and texts. In the extremes, FRED speaker MlnJH favors explicit complementation least (intercept adjustment: -0.87; that retained in 4.3 percent), while speaker SRLM_HM likes it most

The geographical distribution of complementizer choice according to county is illustrated in Figure

Summary of findings

Most of the factors that significantly influence a speaker's choice between zero and explicit that are concerned with cognitive complexity. The complementizer is more likely to be omitted in less complex environments, in which it is easier for the listener to infer that material following the matrix clause will be an embedded that clause. These cognitively less complex environments are typically the more frequent patterns, which makes the syntactic structure of the utterance more predictable

As I think is a very frequent comment clause that can occur nearly everywhere in a sentence (see, for example, Kaltenbo ¨ck 2008), it is disputable whether this clause actually functions as matrix in sentence-initial position. It is nearly exclusively followed by zero-that clauses in our data (in 97 percent, viz. 66 out of 2,258 occurrences). The variable I_THINK captures this distribution so that the negative influence of the matrix subject I on the use of that mostly concerns the use of I as subject of other verbs, such as say, know, said, knew, but also in clauses such as I would think or I was thinking, which have similar discourse functions as I think (van Bogaert 2010). In addition, clauses such as I don't know take on discourse functions (e.g. as "utterance launcher"; see

One factor increasing the probability of explicit that is not related to cognitive complexity of the current clauses, namely the persistence of that. Speakers are more likely to use explicit that if they did so the last time they had a choice and if that choice occurred within 50 words of the present slot. Although this factor is not related to the cognitive complexity of the current locus of variation, it is linked to a speaker's processing load in general, since that is repeated simply because it prevails in the speaker's working memory (see, for example,

Many of the independent variables accounted for in our original dataset (for example, INTERV_MATERIAL_MACL_EMBCL) have proved to be less influential factors than the ones actually included in the final, minimal model. This does not mean that they are not relevant to the choice between zero and explicit that at all, but that for the speakers in our dataset they are less decisive than other factors. Further similar studies on grammatical variation should take into account as many variables as feasible, since the interplay of determinants of variation needs to be re-examined for each dataset.

In sum, our little case study is a corpus-based exercise in variationist (socio)linguistics because it investigates linguistic choices between the use of an overt complementizer and zero, drawing on modern multivariate analysis techniques; it is concerned with knowledge, processing, and cognition thanks to the inclusion of factors such as horror aequi; and it falls within the remit of dialectology because it considers the effect that geography has on linguistic choices (see Figure

10

Grammatical change

Martin Hilpert and Christian Mair 1 Introduction

This chapter is concerned with phenomena of grammatical change in the English language, and with the question of how these phenomena can be studied in corpus-based analyses. To start out, we clarify briefly what we mean by the terms grammar, grammatical change, and corpus-based analyses. In the words of

But of course there is a far more general reason why corpus data are of particular importance for the study of grammatical change. Until quite recently in the history of linguistics, changes in grammar could only be observed indirectly, through the comparison of analogous examples from different historical periods

(1) and forgyf us ure gyltas swa swa we forgyfað urum gyltendum and forgive us our sins so as we forgive our debtors

Quite evidently, a number of grammatical changes have taken place between the times of Old English and today. For instance, the two uses of the verb forgive show that some of the verbal inflections of Old English have disappeared. Likewise, the two uses of the possessive determiner our document the loss of nominal case endings. Comparisons of older and more recent stages of language use thus allow, in a rather straightforward fashion, the identification of grammatical changes. At the same time, these comparisons do not yield answers to the questions of how, when, and why these changes happened. If a researcher is interested in these questions, it becomes necessary to undertake a corpus analysis that goes beyond the pointwise comparison of single examples. The hallmark of a corpusbased analysis, as understood in this chapter, is that a grammatical phenomenon is studied in its entirety, such that all relevant examples of a phenomenon are exhaustively retrieved from a corpus.

A survey of corpus-based studies on grammatical change

This section presents different corpus-based approaches to grammatical change that are unified by a common thread: they focus on the grammar of English verbs. Characteristic grammatical behaviors of verbs concern their ability to inflect, their co-occurrence with complements, and their role as the central element in larger syntactic constructions. This section discusses these characteristics one by one in order to showcase a spectrum of current analytical approaches and to show how processes in the verbal grammar of English illustrate the different types of change that were outlined above.

Change in complementation

Many English verbs function as complement-taking predicates, that is, they project a syntactic structure such as a that-clause, an ing-clause, or a to-infinitive, amongst several other options, as one of their arguments. Quite commonly one and the same verb takes different kinds of complement with different relative frequencies, such that one type is preferred and other ones are more marginal. Over time, these frequencies may undergo shifts as relative preferences change or new complementation patterns enter the picture. This subsection reports on studies that have analyzed this particular kind of frequency change.

(2) a. This prevented me from leaving early.

b. This prevented me leaving early.

The latter variant is almost completely absent from twentieth-century American corpora, but its relative frequency in the British corpora rises from 17 percent in the 1960s to 50 percent in the 1990s. A similar tendency can be observed with the semantically related verb stop. Conversely, a case of American innovation can be observed with the complementation patterns of begin and start

Another diachronic study of verbal complementation examines the developments of 44 complement-taking predicates, such as expect, hope, enjoy, and suggest in the recent 150 years of American English

(3) full clauses ---------------I suggest we do nothing.

that-clauses ---------------I hope that John will win. ing-clauses ---------------I enjoy knitting sweaters. to-infinitives --------------I expect to hear from John. subject-to-object raising ---I want John to be our next president. noun phrases -------------I hate broccoli.

Each of the verbs under analysis exhibits different relative preferences for these complementation patterns. The verb expect shows a high ratio of toinfinitives; enjoy frequently occurs with noun phrases and ing-clauses; and hope commonly takes that-clauses and full clause complements.

Change in the modal auxiliaries

Another domain of English grammar that is currently undergoing change is the domain of modality, specifically the modal auxiliaries. In the most general of terms, the situation is that several of the core modal auxiliaries are declining in text frequency

Leech examines the possibility that newly grammaticalizing modal forms may be responsible for the observed decline. An analysis of forms such as be going to, have to, got to, need to, and several others does not, however, lend credence to this idea. Not all of these forms increase in frequency, and those that do, notably need to and want to, are relatively low in text frequency and hence do not match the declining numbers of core modals such as will or would. So if competition does not explain the decline, what does?

In a study that is based on the Time magazine corpus

As the previous paragraphs illustrate, different kinds of corpora can yield complementary, though hopefully not contradictory, perspectives on the ongoing developments of the English modals, which illustrate the problems that are associated with interpreting observed shifts in frequency either as frequency change or as style change. In this regard, increasing the size of the corpus that is used will not automatically solve the problem. Depending on the phenomenon to be analyzed and the particular needs of the analyst, the statement that "bigger is better" need not always be true:

Change in verbal inflections

Whereas loss of inflectional categories is a phenomenon that is first and foremost a characteristic of the transition from Old English to Middle English, later historical periods do also offer examples of this type of grammatical change.

What this study illustrates is that corpus data allow very detailed analyses of how a given change proceeded. The analysis not only reveals which explanatory factors have a role to play in that change, it also assesses the relative strength of these factors and, most importantly, the time window during which a factor was most powerful. This type of analysis is furthermore relevant for the identification of given changes such as frequency change, style change, or grammatical change. If time as a variable interacts significantly with the explanatory factors that condition the use of a grammatical form, this can be taken to be a tell-tale sign of grammatical change.

Change in argument structure constructions

Like verbal complementation, argument structure is a domain of grammar that concerns the structures that are projected by verbs. The work of

The inception of a construction is studied by

Historically, the construction originated in literal descriptions of movement that included verbs of motion and path creation, as in the following examples

(5) a. The kyng took a laghtre, and wente his way. (

The subsequent development of the construction involves two types of change. First, the construction undergoes a formal change in which the presence of an oblique object expressing a path becomes obligatory.

Examples without such an oblique, which are illustrated by the examples above, become increasingly rarer with time, whereas examples like the following become the norm

(6) She started up, and fumbled her way down the dark stairs. (

Second, the construction shows a type-frequency increase in its verbs.

Israel identifies analogical extension as the driving force behind this increase. Initially, verbs that encode laborious or winding motion such as plod, totter, or worm enter the construction. The construction further branches out to include verbs of sound emission. Verbs such as crunch, crash, or buzz encode the sound that accompanies certain kinds of motion. Also verbs that describe the creation of a path enter the picture: cut, pave, and fight give rise to further analogical extensions that find their endpoint in metaphorical uses of the construction such as the following. Israel's study demonstrates that the OED, with its database of precisely dated quotations, is a highly useful resource for corpus linguists. Its wide temporal coverage and large scope of lexical types make the OED an ideal basis for studies that investigate diachronic type frequency changes in phenomena such as the way-construction. The alternation of these two constructions in Present-day English has been extensively studied (e.g.

A logistic regression analysis establishes that all of the explanatory factors have an effect in the direction that synchronic studies of dative variability have found. This indicates that this area of grammar has been relatively stable in the recent past. However, with regard to diachronic change, the analysis shows that inanimate recipients, as in The herbs gave the soup a nice flavor, have become more acceptable in the ditransitive construction in the twentieth century.

Wolk et al.'s study exemplifies how diachronic corpus studies can precisely document changes in grammatical structure and simultaneously address issues of speakers' knowledge of language. Synchronic studies of the dative alternation have yielded converging evidence between corpus studies and experimental studies: statistical models that capture under what conditions the ditransitive construction and the prepositional dative construction occur in corpus data

A case study: the life and death of -ment

This section turns to grammatical change in the area of morphology, presenting a case study of the development of the English derivational suffix -ment on the basis of data from the Oxford English Dictionary (Hilpert 2013).

Motivation: why study -ment?

The overall story of -ment is one of rise and fall: the suffix entered the English language through multiple loans from French, a productive wordformation process established itself, but its productivity began to wane soon after. Dalton-Puffer (1996: 108) adduces evidence from the Helsinki Corpus to show that the origins of -ment as a productive nominalizing suffix lie in the years between 1250 and 1350. In forms such as judgment, parliament, or payment, which were borrowed from Norman French, the initial stem was transparently verbal. At some point, enough nouns of this kind had entered the language that speakers began to use the suffix with Germanic stems. Accounts vary with regard to the subsequent decline of -ment, but it is certain that speakers of English today do not produce new coinages with the suffix on a regular basis. Studying -ment thus offers the opportunity to come to terms with the full life cycle of a word-formation process.

Hilpert's study builds on two previous analyses of -ment that have utilized the OED as a corpus, namely

It is important to note that neither absolute type frequencies nor normalized type frequencies can reliably settle the question of whether and how -ment changed in productivity. Absolute type frequencies are trivially related to corpus size, with larger corpora yielding larger type frequencies, all other things being equal. Normalized type frequencies are problematic to compare across corpora because the relationship between type frequency and corpus size is not linear, furthermore exhibiting different slopes across productive and unproductive word-formation processes

Methods

Hilpert's analysis has three parts. In a first step, a quantitative measure of productivity is computed for successive time slices in the development of -ment. This step is meant to answer the question of how the productivity of -ment changed over time. In a second step, the resulting curve of changing productivity is used to divide the development into diachronic stages. The resulting time intervals can be further investigated to answer the question of how -ment was used in different ways at different points in time. The third analytical step addresses this question with a quantitative analysis that compares formations with -ment across the diachronic stages with regard to several structural and semantic variables.

Measuring change in productivity

In order to investigate how -ment changed in productivity over time, a measure of productivity is needed that gets around the problems associated with absolute and normalized type frequencies. In pursuit of such a measure, Hilpert searched the OED quotations for all ment-types in the database, retrieving a concordance of 91,908 lines and approximately 655,000 words in total. Since each quotation in the OED is tagged with its historical date, the concordance could be binned into fifty-year increments, which form the basis for subsequent assessments of productivity. Several corpus-based measures of productivity are available, but the measure of expanding productivity

Dividing the database into stages

The second methodological step in the analysis is the division of the decreasing productivity curve into stages. For this task, Hilpert used Variability-based Neighbor Clustering

What is this periodization into five periods good for? Quite simply, it forms the basis for a comparison that investigates how formations with -ment developed structurally and semantically across the past centuries. An analyst can compare the types found in period 2 against the types found in period 3 and determine whether there are meaningful differences between the two sets. In more technical terms, the periods allow mutual comparisons through the use of multivariate quantitative techniques, as described in the following subsection.

Analyzing the stages

Each type in the database is annotated in terms of a time stamp and five variables that pertain to the form as well as the meaning of the ment-types in the database. The variables and their possible values, including corpus period, are summarized in (10) below; the following paragraphs discuss each variable in turn.

(10) time: period 1, 2, 3, 4, 5 source: borrowed vs. derived stem type: verb, adjective, noun branching: binary, left, right transitivity: transitive, intransitive meaning: activity, result, means, remainder A first distinction that is fundamental to the analysis of the suffix concerns the etymological sources of the attested types. Is a given type borrowed or natively derived? All elements in the database were classified by checking their etymologies in the OED; unclear cases were coded as borrowed. A second variable concerns the word class of the host to which the -ment suffix attaches. In the overwhelming majority of cases the host is verbal. Forms such as funniment and scholarment illustrate deviations from that tendency. Cases with ambicategorical stems (debatement, securement) were decided with recourse to the etymology sections in the OED. Types such as segment or nugament, which are morphologically opaque to presentday speakers, were analyzed into the parts of speech that they originally represented, so that all stems in the database were categorized as either adjectival, nominal, or verbal. Thirdly, the ment-types in the database vary with regard to their internal branching structure. In the simplest case, exemplified by forms such as puzzlement, the types exhibit a bipartite structure. A form such as bedevilment unites a complex stem with the suffix -ment and is thus to be seen as left-branching. Conversely, the type nonattachment illustrates the prefixation of a bipartite ment-type, resulting in a right-branching structure. Importantly, the appearance of a rightbranching type does not testify to the productivity of the suffix -ment, but rather to the productivity of the respective prefix. Right-branching types were retained in the database in order to test whether diachronically, right-branching forms account for a progressively greater share of new formations as the productivity of the suffix wanes. The fourth variable that informs the analysis classifies the ment-types as either transitive or intransitive. Transitivity describes the ability of a verb to take a direct object. A clear case of a transitive ment-type would be punishment; a clear case of an intransitive type is settlement. Problematic are types with ergative stems such as move or shatter, which were resolved using the OED entries once more: higher and historically prior entries were taken as definitive.

Even more problematic are forms with adjectival or nominal stems, for which it was determined whether they encoded a transitive or an intransitive event. By that logic, merriment is classified as intransitive, desightment as transitive. The fifth and final variable concerns the overall meanings of the ment-types in the database. In the default case, a noun ending in -ment denotes an activity, as in disagreement "the act of disagreeing." By contrast, an assortment of chocolates does not refer to the act of assorting; rather, it refers to the chocolates themselves. Dalton-Puffer (1996: 109) identifies four semantic classes of ment-types that Hilpert (2013) adopts. Besides "the act of V-ing" (disagreement), Dalton-Puffer identifies "the result of V-ing" (impairment), "the means for V-ing" (steadiment), and a remainder category (abutment). These five variables enter an analysis that also takes the passage of time into account. What the annotated database allows one to investigate is whether formations with -ment have changed over time with regard to the formal and functional variation that is captured by the five variables. The analytical technique that Hilpert uses is called Hierarchical Configural Frequency Analysis (HCFA), which is a procedure that is based on the chisquared test, but which allows the analysis of data that is annotated in terms of more than just two categorical variables (von Eye 1990). The analysis was carried out using a script for the open-source software R (HCFA

Every type in the database exhibits a certain configuration of features: for instance, the type abhorment instantiates a configuration of a borrowed transitive verbal stem, a left-branching structure, the meaning of an activity, and a diachronic origin in the third corpus period. Is this configuration a type? An HCFA tests systematically for all possible configurations whether they are observed more or less frequently than expected. While the configuration of abhorment does occur more often than expected in the third corpus period (o = 75, e = 52.4), this difference is not large enough to be statistically significant, so that the configuration of abhorment is not a type. By contrast, there are other configurations that are found significantly more often than expected in their respective corpus periods. Specifically, the statistical analysis returns ten types that are summarized in Table

Results

Type 1 (o = 11, e = 3.2), which characterizes early instantiations of -ment, is borrowed and verbal as expected. The verbs that act as stems are transitive. This type can be seen as the prototype of the early borrowings with which the word-formation process originated. The second period is characterized by two types. Both types represent borrowed forms that encode means, type 2 (o = 10, e = 0.8) with transitive verbal stems, type 3 with nominal stems (o = 3, e < 0.1). The former of these reappears in the third period (o = 22, e = 5.4), whereas the latter was too infrequent to establish itself as a longer-lasting pattern. The third period further marks the entrance of two natively derived types. Type 5 (o = 174, e = 121.9) represents the most common pattern overall: in this type the suffix combines with a complex verbal stem that encodes a transitive action. The popularity of this type continues into the fourth period (o = 150, e = 93.3). Type 6 (o = 6, e = 0.3) in the third period is to be seen as a short-lived fad, namely the use of native adjectival stems to construct forms such as funniment or dreariment. The fourth period sees the ascent of right-branching forms, which indirectly signals that the suffix -ment is waning in its productivity. Type 8 (o = 41, e = 18.9), exemplified by formations such as disembodiment, subsumes all the features of the overall prototype (types 5, 7), except for the fact that it consists of prefixed forms that merely cannibalize on the high frequency of types 5 and 7. In the fifth period, the analysis detects two types. Type 9 (o = 25, e = 3.4) is identical to type 8. Type 10 (o = 19, e = 1.7), a second right-branching type, is structurally identical, but encodes a result rather than an action, in formations such as malnourishment. On the whole, the information offered in Table

Summary and concluding remarks

In a loose sense, much classical philological work on grammatical change was corpus-based. When, for example, Otto

In the early stages of corpus-based research on grammatical change, digital language corpora and the software for data analysis were powerful tools which enabled linguists to perform traditional tasks in a much more efficient and systematic way. This is illustrated, for instance, by the problem of identifying early attestations of a grammatical innovation. In the pre-digital era, apart from consulting reference works such as the Oxford English Dictionary, the only way to find them was through educated guesswork, by consulting likely sources. Today, searches in large corpora and the even larger masses of text stored in digital archives will do the same job much more effectively, and numerous ante-datings are in fact reported regularly. As the results of corpus-based research on grammatical change accumulate and as the methods of analysis become more sophisticated, the corpus ceases to be merely a tool and becomes an active ingredient in the further development of usage-based theoretical models. This is evident, for example, in language-historical periodization, where statistical analysis of corpus data serves to generate linguistically coherent periods in a bottom-up process

One central aim for future investigations would be to focus on a question that is considerably harder than the "when" and the "how": can the analysis of corpora yield explanations for why a given process of grammatical change happened? In order to address this question, historical corpus linguists need to intensify collaborations with researchers in sociolinguistics and psycholinguistics, who have long been concerned with the social and cognitive processes that shape grammar and that ultimately also shape grammatical change. A growing recent interest displayed by historical corpus linguists in notions such as "persistence" and "priming" in discourse

Lexical grammar Susan Hunston 1 Introduction

This chapter discusses a body of research in corpus linguistics that describes and theorizes a strong connection between lexical words and the grammatical features with which they co-occur. There is no consistent terminology to describe research of this kind, but the phrase "Lexical Grammar" directs us to the combination of lexis and grammar embodied in it. This chapter examines the research in terms of: innovation in observation (seeing associations and patterning that have not been seen before); innovations in methodology (finding new ways of making those observations); and innovations in theory (using observations to confirm theories of language or to generate new theories). After a brief survey of the research context, four specific studies are discussed in some detail, two under the heading of "grammar to lexis" and two under the heading of "lexis to grammar." Then a short account is given of an empirical case study in the field of lexical grammar.

Research context

The argument that the grammar of a language and its lexicon are not separate entities is consistent with a functional rather than a formal view of language, which prioritizes observation of actual language use over a reliance on instances of idealized language drawing on a speaker's intuition

For the "lexis-to-grammar" tradition, the challenge is to generalize from what can be an unwieldy mass of data; if the unit of analysis is the individual word, then the description of language consists of at least as many statements as there are words. Earlier corpus studies often focused on the patterning of a small number of individual words (e.g.

The descriptions of lexical and grammatical patterning find explanations in a range of existing theoretical approaches to language. Valency grammar, for example, has much in common with pattern grammar

With the exception of Hoey, the lexis-to-grammar tradition sketched above is agnostic with regard to psycholinguistic theories. Other studies of lexis and grammar draw on theories of phraseology (e.g.

As might be expected, much of the research on lexis and grammar stems from applied linguistic concerns. Reference grammars and dictionaries with this focus are often designed for learners of English (e.g.

The close association between pattern/construction and meaning is exploited by using pattern/construction to investigate discourse. A key example of this is the use of patterns/constructions associated with stance. Patterns/constructions exemplified by believe/argue that, dismiss something as, a demonstration of, it is likely that, it is questionable whether are routinely used to express stance in academic discourse, but their frequency varies across disciplines.

3 Grammar-to-lexis This section will discuss in detail some key publications which have in common that they take grammatical categories as prior and populate accounts of grammar with information about lexis.

3.1

The Longman grammar of spoken and written English

The result is a rich description of English that extends the previous model substantially by the inclusion of comparative frequency information. To give just one example, verb phrases across the four registers are compared in terms of the frequency of present tense, past tense, and modal verb (ibid.: 456). This allows a comparison between verb phrase types in each register and between the registers. In both conversation and academic prose, for example, present tense is much more frequent than past tense or modal, whereas in fiction past tense dominates and present and past occur about equally in news reportage. Modal verbs are less frequent than either of the verb tenses, but they are most frequent in conversation. A subsequent discussion (ibid.: 457-458) accounts for the differences in terms of the context of each register, pointing out, for example, that present tense plays a very different role in the each of the two registers (conversation and academic prose) in which it is the dominant tense. Turning to lexical grammar, the book then gives a brief list of verbs that are statistically associated with each tense, in the sense that over 70 percent or 80 percent of their total occurrences are in the relevant tense.

This particular quantitative information about lexis and grammar suggests a complex interaction of grammar, lexis, register, and phraseology in relation to frequency (ibid.: 459). The verbs occurring most frequently with present tense are those associated with particular functions in conversation (I bet, I doubt whether, you know, it doesn't matter), and those occurring most frequently in past tense are largely associated with fictional narrative.

In some other sections of LGSWE the information about lexis is more extensive. To take one example from many, there is a fairly lengthy section on verbs that control wh-clauses. The most frequent verbs (know, see, tell, wonder, ask, and understand) are identified, and a further 100+ verbs are listed in six semantic domains (e.g. "speech act," "cognition," "perception") (ibid.: 686). The relative frequency of the most frequent verbs in this structure is given in each of the four registers (ibid.: 689). This shows that, for example, tell occurs more frequently in conversation and fiction than in news reportage or academic prose, and that, conversely, in conversation and fiction tell is more frequent than the other verbs listed. None of the speech act verbs occurs more than twenty times per million words in academic prose except explain. This verb, conversely, occurs most frequently in academic prose and in news reportage. There is, then, a dual perspective on each word listed: which register(s) it occurs in most frequently, and how it compares to the other words in each register.

One of the strengths of LGSWE is its sense of completeness. Because it is based on a finite and comprehensive account of English grammar, there is a sense that every key aspect of English has been covered, and there are useful additional chapters about the lexical and grammatical special features of academic prose and of conversation. Other obvious key points are the unique quantitative information and the focus on register distinctions, an important theme in all of Biber's work.

It is, however, possible to see the model that is the foundation of LGSWE as a limitation as well as a structure. Lexis is examined only insofar as it fits within the chosen grammatical description. Also, the focus on very highfrequency words, or those with a high frequency within a particular category, means that relatively few individual words are featured in the book. The book's complement, or reverse image, can be found in the Pattern Grammar books discussed below.

Collostructions (Stefanowitsch and Gries 2003)

This paper proposes units termed collostructions, which are composed of constructions and the lexical items that significantly occur in them (collexemes). The term "construction" comes from Construction Grammar

Examples of constructions include very general ones such as the ditransitive construction, which is associated with the meaning of "transfer," as in "give someone something" (straightforward transfer) or "tell someone a story" (metaphorical transfer). Other examples are more specific, such as the "N waiting to happen" construction, as in an accident waiting to happen or a new industrial revolution is waiting to happen, which has a meaning of "currently obvious that something will occur" (ibid.: 220). Perhaps midway is the "into-causative" construction (e.g. talk someone into doing something), whose meaning might be glossed as: "person a talks to person b and as a result person b does something"

Central to the paper is an account of the methodology used to establish a defensible connection between a word and a construction. The authors use the Fisher exact test, whose advantages, they argue, include an avoidance of the false assumptions about word distribution that lie behind, for example, t-score. The Fisher test is used to establish "collostruction strength" by comparing the number of times a word (e.g. tell) occurs in a given construction (e.g. the ditransitive) with the total other occurrences of tell and the total other occurrences of the ditransitive, and the total number of other words and other constructions in the corpus. The collexemes can then be placed in order of collostruction strength. In some instances, the collostruction strength coincides with raw frequency. For example, accident co-occurs with waiting to happen more frequently than any other word, and it has the strongest association with that construction. On the other hand, in the "into-causative" construction ("verb someone into doing something"), the verb force occurs most frequently but the verb trick has the highest collostruction strength.

The paper presents its findings as a number of case studies, moving from a study based on a single lemma, cause, to ones based on grammatical categories such as the imperative and the past tense. The study of cause follows up the point made by

Another example is the construction "think nothing of doing something." An interpretation of concordance lines (as reported in

The final case study included in the paper is the ditransitive construction ("give someone something" or "tell someone something"). The collostruction strength analysis places frequent and expected verbs at the top of the list: give, tell, send, offer, show, cost, teach, award, allow, lend, deny, and so on. The authors make the point that this collostruction strength explains why most people intuitively identify these verbs as "basically" ditransitive, even though they are not limited to the ditransitive construction and the construction is not limited to them.

The construct of "collostruction strength" is extremely important, but the sophistication of the calculations it embodies needs to be kept in mind to avoid misinterpretation. Collostruction strength combines two calculations of relative frequency: the number of times a word occurs in a construction compared with the total instances of the word (answering the question "how important is this construction to this word?"); and the number of times a word occurs in a construction compared with the total instances of the construction (answering the question 'how important is this word to this construction?'). As Biber (2012) notes, it is important in interpreting the numbers attached to this construct to remember that the frequencies so described are relative only. In other words, a word+construction combination with a high collostruction strength in a given corpus may actually not occur particularly frequently.

It may be useful to think of collostruction strength as a measurement of prototypicality. It offers a quantitative explanation for intuitions that do not necessarily match absolute frequency information: why some verbs "feel" ditransitive even though they regularly occur in other constructions, or why a construction such as "think nothing of -ing" "feels" negative in spite of the counterexamples found in the construction. It may not, however, be the only explanation for such intuitions. In many instances of THINK nothing of, for example, the negativity associated with the construction is found in the broader phraseology rather than in the verb itself, as in . . . some loonies think nothing of making death threats to players . . . The same is true when the construction indicates "something contrary to expectation" rather than "something negative." Examples include thinks nothing of spending a couple of grand in the shops . . ., studying complex subjects later on in life . . ., getting up at five o'clock in the morning . . . In other words it can be argued that the prototypical meaning of the "think nothing of" construction does not derive from the relative frequency of individual verbs in the construction, and cannot therefore be captured by calculating this; rather, a true calculation needs to take into account the relative frequency of other indications of "unexpectedness" in a much broader context.

Lexis to grammar

In this section we look at the other side of the coin and discuss studies that begin with lexis and investigate grammatical aspects of their context. Two studies are examined in some detail below, though others would deserve inclusion if space permitted. For example, the Valency Dictionary of English

The "Pattern Grammar" project

The concept of Pattern Grammar (PG) came out of the COBUILD project, a large-scale lexicographical exercise that was unique when it began, in that the compilers relied on a very large (for its time) corpus of English to identify frequent usages and phraseologies of words. The project produced a large number of publications, including an early grammar book

Patterns were identified manually, and although semi-automatic pattern annotation is possible, it is not entirely straightforward, because a sequence of elements does not unambiguously constitute a pattern. One example is the sequence "provide + noun phrase + to + noun phrase," which may be an example of the pattern "verb + noun + to + noun," where the preposition to is dependent on the verb, or an example of "verb+noun" and "noun + to + noun," where to is dependent on the noun. An example of the first is provide useful information to the learner. An example of the second is provide clues to changes in sea level. Another example is the sequence "train + for + noun phrase," which may be an example of "verb + for + noun," if the noun phrase is dependent on the verb, as in train for the priesthood (priesthood is the end point of the activity). Where for introduces an adverbial of time, however, as in train for three weeks, there is no such dependency and the pattern relating to train is simple "verb" (i.e. this is an intransitive verb).

The two "Pattern Grammar" books present all the patterns identified and for each pattern list all the verbs

A number of publications discuss Pattern Grammar, notably

Possibly the most significant feature of the Pattern Grammar study lies in the comprehensive listings given in

As noted above, LGSWE and the PG books have complementary approaches: LGSWE views lexis through the lens of grammar; the PG books arrive at grammar through a study of lexis. It is not surprising, then, that they also have almost directly complementary strengths and weaknesses.

LGSWE is more explicit about its methodology, which is based on the annotation of a corpus with the categories used in the book. The PG books treat methodology less explicitly. LGSWE distinguishes registers; the PG books do not. LGSWE includes quantitative information; the PG books do not. On the other hand, where the two publications give similar information, for example listing verbs governing non-finite clauses, the PG books give a more exhaustive list than LGSWE does. Thus the PG books are more comprehensive in terms of lexis but LGSWE covers more topics in terms of grammar. Arguably, the PG books break more new ground than LGSWE, but do so at some cost in terms of lack of coverage.

Another area of complementarity involves patterns and constructions. Given that in many of the examples cited the only distinction is nomenclature, the question arises as to whether these are the same phenomenon with a different name. However, the essential feature of constructions is that they are taken to be mental constructs, whereas no such claim is made for patterns. One proposal, then, would be to use the term "construction" to refer to the mental construct and the term "pattern" to refer to aspects of language output. In addition, the notion of construction includes many items not considered to be patterns. Patterns are identified only when there are lexical restrictions on their use. For example, the ditransitive construction appears as the pattern "verb phrase + noun phrase + noun phrase," but the interrogative construction has no pattern equivalent because there are no restrictions on the lexis with which it occurs. In this case the construction is too general to be considered a pattern. Conversely, some constructions are considered too specific to be patterns. The "noun waiting to happen" construction and the "THINK nothing of" construction are more specific lexically than patterns are. One consequence of this specificity is that the number of constructions is potentially vast. A practical advantage of patterns is that simple principles lie behind them, and they can be listed

Lexical priming (Hoey 2004b)

This paper is an articulation of Hoey's theory of lexical priming, which has two main facets. The first is that the phenomenon of the unequal distribution of lexis accounts for much more about naturally occurring text than might be expected from reading any of the papers discussed so far. The second is a hypothesis about how language is stored in the brain and made available for use in everyday interaction, though this concept is less fully explained in this paper than in

Hoey uses a corpus of 100 million words, mainly consisting of texts from the Guardian newspaper. He tests the relative frequency of target items in contrasting contexts. For example, consequence is noted as occurring in a definite noun group in 67 percent of all occurrences, whereas result occurs in a definite noun group in 94 percent of all occurrences. The "semantic associations" of the two words are also studied: consequence is described as associating strongly with "inevitability," "negative evaluation," and "significance," while reason associates strongly with "positive evaluation," "accuracy," and "sameness/difference." Statistical corroboration for these associations is not given in this paper, but reference is made to

In comparing his two sentences, Hoey finds that many two-word combinations in Bryson's original sentence occur frequently also in the 100-million-word Guardian corpus. He also finds that the two-word combinations "interlock." For example, bus and ride co-occur in the corpus, as do ride and hour, and thirty and hour. The relative frequency (in percentage terms) of these co-occurrences is greater than equivalent frequencies in the invented sentence. Using the concept of semantic association, measures of "typicality" increase. For example, whereas thirty-hour ride is rare, hour occurs regularly in similar phrases (a half-hour drive, a four-hour flight, a two-hour trip, etc.) (ibid.: 44).

In a further extended argument, Hoey contrasts the phrase in winter with similar phrases: in the winter, during the winter, and that winter. He finds that in winter co-occurs with a meaning of "timeless truth" (as in Bryson's opening sentence, and as opposed to a "specific event") proportionally more frequently than the other phrases do. Similarly, in winter occurs in a present-tense clause proportionally more frequently than the other phrases do. In the sample sentence, in winter is "thematised," and Hoey shows that this phrase when occurring in Theme position collocates in his corpus with the verb be, and with the names of places, again proportionally more frequently than the alternative phrases.

Hoey's paper is an important statement of what makes even creative language sound "natural" and "idiomatic." He shows that establishing "typicality" involves going beyond word-word collocation, but also beyond lexis-grammar colligation into the identification of recurring sequences of meaning elements, or "textual colligation." It also goes beyond each individual observation; what makes the Bill Bryson sentence "idiomatic" is the intersection of the various typical uses it embodies. Hoey discusses this in terms of what he calls "priming prosody" (ibid.: 53). He argues that this prosody "occurs when the collocations, colligations, semantic associations and textual colligations of lexical items in an utterance chime with each other in such a way that they reinforce each other." In other work, most notably

Empirical study

A recurring theme in this chapter is the importance of phraseology to the study of lexical grammar. It has been argued that an explanation for cooccurrence of lexeme and structure may sometimes be found in the more extensive co-text. Inevitably, studies of co-text and phraseology are "messier" than those of lexeme and structure alone. The unit of investigation is not predetermined, and salient items are not easily identified automatically.

In this section I follow up this theme by reporting a study of the cooccurrence of verbs and wh-clauses (e.g. decided whether, discovered what)

The results showed that in general terms the prediction was met: thatclauses co-occur disproportionately with -ed forms and wh-clauses with base forms. Not all lemmas behave the same, though, and this drew attention to phraseology and to the meanings behind the forms. In general, thatclauses construe "facts" whereas wh-clauses construe "possibilities." For example, decided that . . . reports a decision that has been taken and now exists. On the other hand, decide whether . . . reports a decision still to be taken. This is reflected in the fact that the word form decided mostly occurs as a finite form whereas decide mostly does not, but instead occurs in sequences such as should decide whether . . ., had to decide whether . . .. This pattern is not true for all verbs, however. The lemma MENTION has a very different distribution pattern from DECIDE, with mention that being proportionately more frequent than decide that. On further scrutiny of the concordance lines, it was found that mention that is largely used to report a negative: someone did not mention or failed to mention a fact. This highlights a key difference between DECIDE + that-clause and MENTION + that-clause. In the first case, the act of deciding brings into being the decision reported in the thatclause. In the second, the fact in the that-clause exists independently of its mention. So whereas I failed to mention that . . . is unmarked and relatively frequent, I failed to decide that . . . is marked and is less frequent in relative terms. In other cases, differences in frequency distribution can be accounted for by frequently occurring semi-fixed phrases. For example figure out that occurs more frequently than might be expected if DECIDE is taken as the norm. However, the phrases it doesn't take [an expert] to figure out that and you don't have to be

All this suggests that the original observation regarding DECIDE and its complementation pattern does not reflect arbitrary behavior on the part of English verbs but is a consequence of what typically needs to be said about decisions, things that are mentioned, and so on. Another unexpected observation from the 2003 study was that when the base form of a verb occurs with a wh-clause, the word to occurs very frequently indeed before the verb. In turn, to forms the final element in phrases such as have to, need to, wanted to, told [someone] to, took a long time to, found it difficult to, make it possible to, etc. This suggested that the co-occurrence of base form and wh-clause was actually part of a more extensive phraseology consisting of "meaning of obligation or difficulty or possibility" followed by "meaning of creating a construct through thought" followed by "construed possibility." The term "semantic sequence" was coined to express a series of meanings of this kind. Whereas a "semantic sequence" is in part an expression of lexical grammar, it goes beyond notions of construction or pattern towards a much looser concept of a sequence of meanings. It suggests that it is the presence of the sequence of meanings that leads to the co-occurrence of lexis and grammar. In other words, just as collocation is a by-product of the existence of units of meaning, so patterns are a byproduct of frequently occurring semantic sequences.

In

Having said that, there are considerable difficulties in demonstrating that modal meaning occurs with a particular set of verbs, and these difficulties are apparent in

Conclusion

In this chapter, a number of different approaches to lexical grammar have been outlined, based on

The methodologies used in these sample papers incorporate a number of procedures that are highly valued by corpus linguists. These include: establishing statistical evidence for register variation

All the studies seek a balance between rigor (in numbers) and detail (in language). The potential conflict can be illustrated with the pattern/ construction "verb + someone + into + doing something." Stefanowitsch and Gries's paper lists the thirty verbs with the greatest collostruction strength in this construction.

Studies in lexical grammar are currently pulling in two directions, and any research project has to find a balance between the two. One direction is the refinement of methods to obtain increasingly delicate statistical information. The other is the broadening of the scope of studies into co-occurrences that move beyond grammar, strictly speaking, and into what Hoey calls "textual colligation" (a measure of "naturalness") or what Hunston calls "semantic sequences." Studies of this kind increase the number of variables to be taken into account in calculating relative frequency. Balancing the detail associated with the phraseology of open-class words with the rigor of statistical analysis is a challenge for research into lexical grammar. In the linguistics literature, "discourse" is often defined in two, not mutually exclusive, ways, namely, structurally, for instance, "language above the sentence or above the clause"

Most forms of traditional non-corpus-assisted discourse analysis have practiced the close-reading (that is, "qualitative analysis") of single texts or a small number of texts in the attempt to highlight both textual structures and also how meanings are conveyed. Some types, such as much work in critical discourse analysis (CDA), use few concepts from linguistics proper, tending to rely on the analyst's knowledge and experience (and prejudices) of similar texts, in a manner reminiscent of literary analysis (though with a politically driven purpose). Other traditional discourse analysis is more linguistically grounded.

In what follows we will attempt to outline ways in which corpus-assisted discourse studies (CADS) can help build upon traditional qualitative linguistic analysis, what "added value" it can bring. We contend that it can contribute in two ways. First, by combining close reading with statistical "overview" analysis, very generally of a large number of tokens of the discourse type under scrutiny, which can enable the analyst to build up a detailed picture of how work is typically performed in that type of discourse. Second, by integrating into the analysis a number of insights into how discourses function which have developed within the field of corpus linguistics.

The three most commonly employed statistical overview techniques are the following. First, frequency listing of words and clusters (that is, strings of words which "are found repeatedly together in each other's company"

The main linguistic insights arising from or developed using corpuslinguistic research include the lexical grammar notion of co-selection, the psychological but also textual theory of lexical priming, and, finally, evaluative cohesion.

The principle of co-selection or co-occurrence states that a far greater proportion of the language of most discourse types is made up, not of the accretion of individual items chosen from the mental lexicon, but of prefabricated or semi-prefabricated collections of items; "chunks" if we prefer. These include simple collocations (defined as two items which regularly co-occur in texts), such as roaring fire, proper names like the Houses of Parliament, set phrases like as a matter of fact, by all means, idioms like never a dull moment, semi-idiomatic templates, for instance, LIVE to a [ripe/grand] old age

Lexical priming

The user then reproduces this behavior in their own linguistic performance. By metaphorical extension, the lexical item itself is said to be primed to behave in these particular ways, and so lexical priming is also regarded as a textual phenomenon. Thus, for example, the item winter is said to be primed to collocate with in, that, during the, etc. As regards colligational behavior, Hoey's most complex examination is of the colligational behaviour of the item consequence. He looks at 1,809 occurrences in his corpus data (a 100-million-word corpus of Guardian newspaper texts) and discovers first of all that it displays a clear aversion to appearing as part of the object of a sentence (4% of occurrences) but no such aversion to appearing as part of a verb complement (24%). Given that, exactly as with many types of research, the relevance of such individual findings can only be evaluated by comparison with the behavior of other items, he also looks at four other abstract nouns, question, preference, aversion, and use, none of which exhibits the same absence from object position (occurring there, respectively, on 27%, 38%, 38%, and 34% of occurrences).

The principle of evaluative cohesion, very closely associated with coselection, states that, in normal circumstances, speakers and writers will attempt to maintain consistency or "harmony" of evaluation -of the evaluative polarity, good or bad -at local moments in discourse production. Evaluation is here intended as "the indication of whether the speaker thinks that something (a person, thing, action, event, situation, idea, etc.) is good or bad"

(1) The seven-year journey from that dazzling sales pitch in the Far East to the reality of 2012 will be complicated and arduous, and after Thursday we must fear it will be fraught with the rawest of hazards for ordinary citizens.

(SiBol 05)

(2) But appearances can be deceptive -these funds can be fraught with danger.

The managers buy riskier bonds to add to the mix to boost the income.

(SiBol 05)

Such evaluative harmony is normally taken for granted and only becomes apparent when, for dramatic or ironic effect, a speaker/writer chooses to upset it by combining items of opposing evaluative polarity within the same text, for example, an outbreak of honesty, the onslaught of goodwill and attention (SiBol), when both outbreak of and onslaught of very generally cooccur with negative items. The concordancer is an excellent way of locating examples of such prosodic clash. It has also proved invaluable, through its ability to collect large numbers on instances of use in context, as a means of uncovering the evaluative polarity of many items which was not previously apparent to the naked eye, such as set in, dealings, utterly, potentially, sit through, orchestrate, true feelings, and par for the course (generally negative) and flexible, persevere, provide, career, my place, make a difference, and brimming with (generally positive).

The main function of evaluative cohesion and the consistency of evaluation at local points in the discourse is to help maintain comprehensibility for the listener, since it meets rather than upsets primed expectations. A discourse needs to make sense not only ideationally but also at the evaluative level.

Both lexical priming and evaluation will be highly relevant to the case study in Section 3. In this survey we concentrate on sociopolitical CADS, that is, a branch of linguistics in which corpora are employed to help study how social and political phenomena are represented and constructed in the cultural products of a society. A pioneer in the formulation of this type of research is

A survey of previous CADS research

Comparative analysis of lexical patterns is a powerful tool to investigate how social, cultural, and political representations, such as gender or race, are constructed and reinforced by the accumulation of linguistic patterns. Scholars have used collocation analysis to study the discourse of sexual and gender difference.

Examining the collocates of gay(s) and homosexual(s), he shows how the word gay presents an element of self-definition that is not there in the term (of medical derivation) homosexual. He also argues, through a review of collocates, that homosexuality in general is presented as a behavior (and a definitely negative one) rather than an identity in the tabloid press.

Other collocational research has focused on the representation of minorities. In his seminal paper

A further influential example of corpus-assisted discourse analysis, also related to ethnicity, is the Lancaster University project on the representation of refugees, asylum seekers, and immigrants (or RASIM).

While in the case of RASIM the researchers track the evolution of discourses over a continuous period of time, another series of diachronic studies compares corpora from different points in time in order to identify change or stability. An instance of this is the SiBol set of CADS which employs comparable newspaper corpora from 1993, 2005, and 2010 (see Partington 2010a;

Comparison across discourse-types

Discourse analysis is, of course, inherently comparative; it is only possible to both uncover and evaluate the particular features of a discourse type by comparing it with others. We are not deontologically justified in making statements about the relevance of a phenomenon observed to occur in one discourse type unless, where it is possible, we compare how the phenomenon behaves elsewhere. Several corpus techniques, for example, keyword and key-cluster tools, have the specific aim of facilitating comparison. We can compare between corpora or within a corpus (for example, for different speaker roles such as questioner and responder) and we can compare a specialized corpus to a general (or "heterogeneric") one. We have discussed diachronic comparisons, but the parameters and entities to be compared can be various.

Other CADS work looks at the interaction between discourse types.

From Stubbs on, several CADS researchers have found it useful to combine linguistics with other disciplines and Bednarek's recent work on TV dialogue

Reflections on the methodologies of corpus-assisted discourse studies

According to

3 A case study: forced primings in White House briefings

By means of this case study on political discourse we wish to demonstrate a number of ways in which "added value" can be brought to discourse analysis by the integration of corpus techniques. In particular, we wish to show first how the concordancer's ability to collect examples of a similar linguistic phenomenon, as contained in repeated word strings or clusters, can lead to insights into the intentions of discourse participants, second how corpus techniques can enable the tracking of discourse features over time, and third how, contrary to charges from some quarters, corpora can shed light on what is absent from a dataset under examination and what this might signify. At the same time we will illustrate the typical CADS methodology of moving back and forth between statistical overview analysis (keywords and concordancing in this case) and close textual reading.

The overall topic is a study of the discourse type of White House press briefings during the opening period of the Arab Uprisings. It examines both the phenomenon of forced primings

The corpus used in the analysis: White House press briefings

White House press briefings are press conferences held on a regular basis, in normal times, daily. They are a particular type of institutional talk

The corpus of briefings employed here is called WH-Obama, and contains all the briefings of the Obama administration in the year from December 2010 to the end of November 2011 (c. 1,300,000 words, compiled by

Asserting the administration's message, imposing primings in briefings

From the point of view of the White House, the whole raison d'e ˆtre of briefings, the reason they were instituted in the first place, is to affirm the administration's favored view of events to the press and through them to the public. To this end, the Podium's discourse is replete with repeated phrases, often with minor variation. This was first noted in earlier research whilst both watching briefings, broadcast by C-Span public service TV, and by reading a good number of transcripts

In the first six months of the WH-Obama corpus, on the other hand, in times of severe economic crisis, job collocates 101 times in the Podium's speech with grow and growth in constructions like [our aim is to] drive / increase job creation and economic growth and, in fact, grow the economy and increase job creation is the most common long cluster in the corpus.

It is true that, as Biber et al. remark, spoken discourse is particularly characterized by an abundance of (semi-)prefabricated phrases (see Section 1): Time pressure makes it more difficult for speakers [compared to writers] to exploit the full innovative power of grammar and the lexicon: instead they rely heavily on well-worn, prefabricated word sequences, readily accessible from memory.

The cluster lists of WH-Obama contained several clusters containing WORK and concordancing this item showed that, in the same six months, the Podium uses we + WORK a total of 198 times, often accompanied by a positively evaluating intensifier: we are working avidly, we have worked assiduously / diligently / aggressively / very hard / every day. In a keyword list comparing WH-Obama with the one-million-word spoken section of the BNC Sampler (a collection of diverse discourse types) the following items all appeared among the top 200 keywords: continue (as in continue our efforts, continue to work on . . .), forward (move the economy forward, as we go forward to create an America that . . .), action, progress, effort/efforts, measures, steps, commitment, decision/decisions. The attempt is made to portray and evaluate the White House and their political affiliates generally as active to the point of workaholism. However, the impression (and positive evaluation) is not shared by at least one journalist in the room:

(1) Q: Why does the Congress and the President and Washington generally act like a college kid and wait until the last minute to get everything done? (20/12/2010)

It is sometimes possible, moreover, with the benefit of corpus techniques, to observe how White House messages evolve, how the exact nature of the primings flooding into the discourse changes over time, which provides strong evidence of deliberate attempted linguistic engineering. This temporal tracking is possible since each briefing is contained in a separate file which is named by date.

For instance, in a study of how the Arab revolts were debated in the briefings, the first step was to concordance the names of some of the countries involved, namely, Libya/Libyan(s), Syria/Syrian(s), and Egypt/ Egyptian(s), along with the names of the countries' leaders, Qaddafi, Assad, and Mubarak. In January 2011, Libya or Libyan is not mentioned in the briefings room. In February, both the Podium and press are comfortable in discussing the Libyan government, which is mentioned 32 times, but in March only 9 times, and after that never at all (except a couple of times in the context of freezing Libyan government assets). In the same February, there are 6 mentions of the Libyan regime and 6 of the Qaddafi regime. By March, however, regime is used a total of 58 times, 37 co-occurring with Qaddafi and 21 with Libyan. In the final six months of the year, we find only Qaddafi with regime and never Libyan. The evaluatively neutral Libyan government has rapidly been replaced in briefings discourse with the negative Qaddafi regime in a priming shift to create diplomatic distance between the White House and the Libyan administration. Perhaps the most interesting aspect is that Libyan government disappears from the journalists' speech almost as quickly as from the Podium's. They clearly acquiesce to the White House's message and evaluations on this issue or, if we prefer, the administration's priming flooding has been successful.

There is a similar process of diplomatic distancing regarding Syria in WH-Obama, but the process is slower and not complete. In the first six months of 2011, we find 48 occurrences of Syrian government and only 3 of Syrian regime. In the second six months, there are 34 references to Syrian regime but it is still called government 18 times, all by the Podium. The Podium's language towards the Syrian leader is also gentler than that used about Qaddafi. Throughout the year he continues to be called "President Assad," whilst Qaddafi moves from "Colonel" or "Muammar Qaddafi" to predominantly just "Qaddafi." When the White House in August 2011 finally deems the Syrian leader to have lost his legitimacy, he is asked to step aside (previously simply to change course or cease the violence) and there is no talk of remove/removal from power, as for Qaddafi.

There is also an evolution in the administration's evaluative messages regarding Egypt, but once again a different one. The administration in general and the Podium in particular are clearly wrongfooted and embarrassed by events. The item Mubarak was concordanced month by month (this is possible since, we might recall, each briefing is contained in a separate file which is named by date). Although occasionally simply "Mubarak" for the press, the Podium refers throughout the year to "President Mubarak." We then passed from the concordance to close reading of the co-text around occurrences of Mubarak, a very common process in corpus-assisted discourse studies. He is initially praised as "a close and important partner with our country" (27/01/2011) and the President even praises the Egyptian army just before news breaks of its failure to protect protestors (02/02/2011). The Podium cannot bring himself to condemn the President: As the violence grows, much of it reportedly committed by supporters of the President, the Podium is asked the straight question:

(3) Q: Do you think Mubarak is a dictator?

Realizing this phrasing might afford the Podium some room for footing evasion (perhaps "it's not important what I think"), the journalist switches the target or recipientship

(4) Q: More importantly does the President think Mubarak is a dictator?

But they are still not obliged with a straight answer:

(5) The administration believes that President Mubarak has a chance to show the world exactly who he is by beginning this transition which is so desperately needed in his country and for his people now. (02/02/2011)

Instead the Podium's repeated message is that of urging (maximum) restraint/nonviolence, sometimes on all sides. One journalist at least becomes frustrated at this priming flooding:

(6) Q: "Deeply concerned," "urging restraint" -to this point, from my knowledge, no US official has come out and condemned the violence. Is it time to condemn the violence?

This seems indeed to shame the Podium into slightly stronger language:

(7) MR GIBBS: Let's be clear Mike. Urging restraint and then seeing violence is obviously very counter to what we believe should be had. And we would strongly condemn the use of violence on either side during this situation, absolutely. (28/01/2011) But note on either side. And condemn the violence is not the same as directly condemning the perpetrators of the violence. At this point, we concordanced month-by-month the items violence and side(s) and the co-text of the resulting occurrences were read. No mention is forthcoming, regarding Libya, about the violence committed by opponents of the regime, nor reference to condemning violence on both/all/either side(s), as was the case with Egypt. In fact a concordance of restraint and another of violen* in an 8-word span of on either/both/all sides yielded altogether 18 results, all of them contained in the Podium's turns. The countries where, according to the White House Podium, both sides in a conflict -that is, the government/ regime and its opponents -need to refrain from violence and exercise restraint are principally Bahrain (7 occurrences) and Yemen (

Institutions and forced priming

Our knowledge, use, and expectations of language are, of course, determined by our exposure to language in context but, as we see in briefings, not all exposure is the result of random personal experience. The above episodes constitute what we have called forced priming. Frequently repeated phraseologiesgetting the job done, each country is different, and so on -result in evaluative messages being deliberately flooded into the discourse for a particular purpose. Institutions and enterprises spend considerable investment in encouraging priming through planned repetition, a process Fairclough has called the "technologisation" of discourse (1996: 71-83), and for this reason it can be illuminating to employ concordancing and key-item comparison to examine frequency data in institutional discourse.

In an age of mass communication and near instant reproduction of multimedia material, there is increased care and attention paid by institutions to how their desired messages are conveyed. Those who have the information gatekeeping role, including the Podiums in the White House, as well as government special advisers

Tracking appearance and disappearance of items: governments and regimes in White House briefings

There is a general methodological point which emerges from these investigations. It has been claimed by non-corpus-assisted discourse analysts that "the corpus-based analysis tends to focus on what has been explicitly written, rather than what could have been written but was not"

For example, we were able to identify the absence of any mention of Libya or Qaddafi in the briefings before February 2011; it just was not on the press's map.

We were able to track changes in the denomination of the various Arab country administrations and in the honorifics or dishonorifics applied to the leaders, for instance that Libyan government rapidly disappearsbecomes absent -whilst Qadaffi regime, previously absent, becomes the normal appellation.

In terms of quantifying relative absence versus presence we can contrast the fact that the Colonel of Colonel Qaddafi quickly disappears -becomes absent -whilst the honorific President continues over the period to be applied to Mubarak. The concordance of all/both sides allowed us to identify the countries where both government and opposition were urged to show restraint and those where only the government was being blamed for the violence.

One general observation is also highly pertinent here. In the first part of this study outlining forced priming keyword and key-cluster analyses were conducted contrasting WH-Obama with both the BNC and WH-Bush. Of course the entire raison d'e ˆtre of keywording, a vital tool in the corpus linguistic kit, is to ascertain and quantify the relative presence in and absence from a target corpus of lexical items -that is what "keyness" means -usually as a first step in investigating what that relative presence/absence may infer.

It is hard to see how, without the corpus techniques or some extremely time-consuming substitute for them, any firm, objective statements on these matters could be made. Before debating "what is implied, inferred, insinuated or latently hinted at"

Conclusion

The most obvious advantage of integrating corpus resources into discourse analysis is the potential it offers for analyzing large numbers of tokens of any particular discourse type, which enables the analyst to study typical discourse structures, typical ways of saying things, and typical messages, alongside the local structures, meanings, and messages available to traditional close reading. It also provides a way of locating potentially interesting linguistic features -for instance, sites of unusual evaluation -in a large body of texts, which the analyst can then home in upon. Additionally, it facilitates comparison among discourse types, highlighting the relative frequency and the possible different roles of the linguistic features they display, for instance, differences in collocational patterning or "profile" of the "same" lexical item or set of items.

There remains one final methodological-theoretical consideration. As in all research, there is much in corpus linguistics that is subjective, including the choice of research question and of the procedures and software to employ, not to mention the interpretation of the output data. However, there is one phase at least, namely the statistical analyses performed by the machine, where the analyst cannot either consciously or unconsciously predetermine the output and, when it arrives, s/he must deal with whatever it contains, including, and especially, things previously unexpected. These latter may include "known unknowns"; for instance,

Pragmatics Brian Clancy and Anne O'Keeffe 1 Introduction

Corpus pragmatics is a methodological framework that allows for the interpretation of spoken or written meaning, with an emphasis on providing empirical evidence for this interpretation (see O'

Corpus pragmatics is distinct from other fields in corpus linguistics. However, in common with other fields, corpus pragmatics investigates the co-textual patterns of a linguistic item or items, which encompasses lexico-grammatical features such as collocation or semantic prosody. However, where corpus pragmatics' "added value" lies is in its insistence that these patterns be considered in light of the context -the situational, interpersonal, and cultural knowledge that interactional participants share. Through an iterative process, corpus pragmatics therefore moves beyond important but surface observations of lexico-grammatical patterns to allow a more nuanced interpretation of these patterns taking into consideration who uses them, where they were used, for what purposes, and how this use has changed over time. In this way, corpus pragmatics has retained in part its original interpretative nature but has endeavored to supply this interpretation with objective supporting evidence.

We contend that the studies critically examined here exemplify many of the strengths of corpus pragmatics. We examine some of the current concerns of the field in key concept areas such as speech acts, pragmatic markers, and pragmatics and power. Although the majority of the research concentrates on pragmatic features of spoken language, we also include studies that highlight the importance of corpus pragmatics to the written context.

The state of the art in corpus pragmatics

The blend of corpus linguistics and pragmatics, though a relatively recent development, is a mutually beneficial one. Therefore, the area is ripe with research opportunities. One of the latest (and most fruitful) synergies of pragmatics and corpus linguistics is the area of historical corpus pragmatics which is primarily concerned with the diachronic study of speech acts (see, for example,

There is also a substantial body of research building up within corpus pragmatics around the area of pragmatic markers. Much of the seminal work in this area has been led by

Corpus pragmatics is also to the forefront in exploring the link between language, power, and ideology.

Corpus pragmatics has also advocated the synergy of corpus linguistics and conversation analysis in order to investigate the organizational level of pragmatics, that which explores turn-taking phenomena such as pauses, overlaps, interruptions, or backchannels

Finally, in relation to deixis, personal pronouns feature prominently in corpus frequency lists, especially spoken ones. Personal pronouns are strongly associated with deictic reference: a system of reference that facilitates contextual orientation. The use of personal pronouns to negotiate identity has received some attention in corpus pragmatics.

With the state of the art in corpus-pragmatic research established, we now turn to a more fine-grained discussion of exemplar studies in the areas outlined above.

3 A critical discussion of previous research at the forefront of corpus pragmatics

Speech acts

The study of speech acts outside the field of corpus pragmatics has predominantly been based on elicited data generated from discourse completion tasks (DCTs) or role plays (O'

For example, in a study of DCTs and corpus data,

Pragmatic markers

As outlined in Section 2 above, pragmatic markers have received a large amount of attention. The study we have chosen here illustrates the complementary use of large and small corpora to investigate the pragmatic markers I would say and I'd say.

Farr and O'Keeffe recommend that the use of would as a hedge is investigated at the level of register in order to more fully appreciate its use. Therefore, its occurrence in two small corpora -a 55,000-word corpus of radio phone-in data and a 52,000-word corpus of post-observation teacher trainee interaction -was examined. They discovered, through an exploration of colligational and collocational patterns, that would is used in these institutional domains to redress asymmetry, to mitigate face-threatening acts or to "transpose" the focus of the talk to a hypothetical "safe band"

Language, power, and ideology

Critical discourse analysis (CDA) has successfully utilized corpus linguistics as a complementary methodology. The purpose of CDA is to show how language in use is often constructed and shaped by various social forces (see

The organization of discourse

Corpus pragmatics has also successfully combined the methodological field of conversation analysis (CA) with that of corpus linguistics in order to provide a much more fine-grained analysis of spoken language than would be possible if each were used in isolation. This synergy of methodologies allows linguistic items to be examined at both a structural (syntactic) and interpersonal (pragmatic) level and enables us to understand how "words, utterances and text combine in the co-construction of meaning"

Deixis

The final corpus-pragmatic work that we examine here is Ru ¨hlemann's (2007) unique study of the conversational subcorpus of the BNC. This study is significant because it analyzes frequent conversational features that previously had not been systematically researched using corpus linguistics. Furthermore, the study positions deixis as one of the cornerstones of the analysis. Ru ¨hlemann argues that conversation is characterized by a much greater wealth of shared context than most written language situations. In order to quantitatively and qualitatively prove this, Ru ¨hlemann examines, amongst other features, person, place, and time deixis -sharedcontext phenomena that are manifest in spoken corpora in general. One of the most obvious and frequent manifestations of person deixis is personal pronouns. Regarding the distribution of these pronouns,

In addition to exploring verbal shared context, Ru ¨hlemann also uses corpus techniques to examine non-verbal pragmatic items. In modern spoken corpora in general, a wealth of paralinguistic information is tagged, such as coughing or door slamming, much of which is of little importance; however, some of these features, such as laughter, are of significance to corpus pragmatics. Ru ¨hlemann uses frequency counts to demonstrate the importance of laughter to conversation, for example, if "between-speech laughter" is considered as a linguistic item in and of itself, it would be placed in 29th position on the BNC conversational subcorpus frequency list. A closer inspection of the contexts in which laughter occurs demonstrates that it fulfills core pragmatic functions. According to Ru ¨hlemann, it functions as a backchannel, and, as such, is an indicator of engaged listenership akin to

Although these studies illustrate the state of the art in corpus pragmatics and showcase the field's methodological and analytical rigor, corpus pragmatics is, however, not without its thorns. As already mentioned, corpus linguistics has been criticized in relation to its suitability for the study of speech acts. Moreover, if corpus pragmatics is concerned with the interpretation of meaning in context, another disadvantage associated with the relationship between corpus linguistics and pragmatics is that many larger corpora are impoverished both textually and contextually (Ru ¨hlemann 2010).

Case study: a corpus-pragmatic analysis of vocative function

This corpus-based investigation of vocative use focuses on two small corpora in an Irish English context. The results presented here are a combination of those from

The first of the two corpora utilized is a 55,000-word corpus of a daily Irish radio program Liveline which is broadcast on the national broadcaster RTE ánd has a listenership of approximately 10 percent of the Irish population. The second corpus, the 12,500-word SettCorp, represents the conversations of a six-member (father, mother, two boys, and two girls) middle-class Irish family. Interaction in radio phone-in takes place between people who very often do not know one another, and although the speaker relationship is hierarchical (the media persona has the power), a "pseudo-intimacy" (O'Keeffe 2006) is maintained in order that a greater level of disclosure might be achieved. In contrast, family discourse is characterized by an unequal intimacy (Blum Kulka 1997) -there exists in the family an in-built hierarchy where the parents have more conversational power than the children. Therefore, this case study is concerned with comparing and contrasting the use of vocatives among intimates in family discourse and those who simulate intimacy in radio phone-in. The goal of the study is to contrast how vocatives function within the two corpora, one in an intimate family context, and the other in a pseudo-intimate institutional (radio phone-in) context, in order to better understand how vocatives contribute to the creation and maintenance of intimacy and whether this is replicated in a pseudo-intimate context.

Vocatives, terms of address

Research question and methodology

This study sets out to answer the following question: what are the similarities and differences in pragmatic function between family discourse and radio phone-in, that is, between their use in real intimate relationships and pseudo-intimate relationships? This examination of the function of vocatives is important for a number of reasons. First, it vividly illustrates, through the application of a corpus-based, bottom-up methodology, the close interrelationship between pragmatic function and context. In doing so, it showcases the usefulness of small corpora for pragmatic research, particularly with regard to how their investigation can deepen our understanding of the descriptive framework for spoken genres. One of the criticisms of small corpus research is that a small corpus does not allow for generalization. However, the encouraging aspect of this research is that the findings from a number of small corpora in similar contexts can be used to generalize if a number of features emerge as constant. For example, small corpora in institutional contexts, such as those used by

In terms of the methodology utilized, in the case of both corpora, the data were read manually and every vocative classified. Hence, this methodology, if transferred to a larger dataset, needs to employ a sampling strategy so as to arrive at a manageable amount of vocatives. This in itself poses a challenge as vocatives are not normally tagged. In these studies, the vocatives in the datasets were categorized according to vocative type (for example, endearments, kin titles, etc.) and function (relational, summons, etc.) and, although not discussed here, position (initial, medial, or final). Concordance lines were then generated using the categories as the search items so that the function and position of the vocative is placed in relief. Figure

Findings

Table

Figure

McCarthy and O'Keeffe (2003) also noted the high frequency of vocatives in the context of mitigation in CANCODE casual conversation data, saying that they are neither syntactically nor semantically necessary and they function solely as pragmatic downtoners of challenges, adversative comments, and disagreements. However, adversarial situations are relatively uncommon in the Liveline radio phone-in data. The interaction is usually between the radio host and the caller. However, there are a few instances where two adversaries give their opposing view on a conflictual situation and in these contexts, we can find some examples of vocatives used when mitigating the force of a challenge, etc., as in extract 3:

Extract 3 [Two callers, Colm and Ma ´irtı ´n, are in a heated dispute] <$3> Oh Colm come on . . . pull the other one.

The other difference of note in the two datasets is in relation to the use of vocatives in summons. Again this is very context specific. It would suggest that families frequently use vocatives to summon other family members. However, we note that

Identified However, the fact that the discourse takes place in this intimate context, coupled with fixed and pre-established speaker relationships and the "politeness license" (Blum-Kulka 1997; Clancy 2005) granted to families, serves to render the relational function almost redundant. Given the exogenously defined roles and task-focus of radio phone-in the low occurrence of vocatives in this context is possibly not surprising.

Conclusion

All in all, this brief look at two small datasets shows us the usefulness of having data from different contexts which can be used for the empirical analysis of a pragmatic item. Reflecting on the process, we can see that the corpus software aided our analysis but much of it had to be done manually. This is manageable with small datasets. We can also see that by isolating family-only data from an Irish context, we have set up at least one further research question, namely, whether there are cross-cultural dimensions to the use of vocatives (do they function differently in different families in other cultures?). The antecedent work in

Although, relatively speaking, corpus pragmatics is in its early stages, clearly there is a already a healthy picture in terms of the application of corpus linguistics to the study of pragmatics. As corpora become more sophisticated in areas such as their pragmatic tagging, it is predicted that they cannot be ignored as research tools by those researching pragmatics. Indeed, we speculate that in years to come, much, if not all, pragmatics research will involve corpus linguistics. However, in the meantime, corpus pragmatics can do more to show the real worth of methodology to the wider field of pragmatics. We need to better articulate our methodology and its rationale and make corpora more user-friendly for those researchers unfamiliar with them. It needs to be explained that pragmatic research which truly focuses on language in use has to be corpus-based because there is no convenient way of making speakers say what you want them to say where language is unpredictable, messy, and extended over many turns. While the study of pragmatic items can be challenging in a corpus, it is eminently possible. It requires an iterative approach, whereby the research goals need to be refocused with reference to the data and where the research question is continually refined by going deeper and deeper into the data. It sometimes requires the researcher to manually read and code speech acts or speech events such as pragmatic markers but there are many rewards for this (see, for example,

14

Historical pragmatics

Irma Taavitsainen

Introduction

Historical pragmatics studies communicative language use in historical texts by examining utterances in context. It is an innovative and active field of study, as can be verified from the amount of research and the number of published and forthcoming publications in the field. Most of them rely on corpus linguistic methodology, but a few, mainly on the literary side of studies, focus on individual texts or passages and their interpretations. Indeed, it is no exaggeration to say that corpus linguistics using large computer-readable language data has established itself as the main methodology in historical pragmatics. But what is the difference, what distinguishes these historical pragmatic studies from mainline corpus-linguistic studies? It is a difficult question, and my aim in this chapter is to discuss it and review the state of historical pragmatic research using corpus-linguistic methods. I shall survey the applications of corpus-linguistic methods in historical pragmatics by a selection of articles that illuminate recent trends within the field, demonstrate the range, and indicate future avenues for research. In the first phase of corpus studies, lexical items served as the point of departure, but corpuslinguistic assessments at present extend to pragmatic units like speech acts, and discourse studies are included in historical pragmatics. Since the early days, the field has developed and matured, research questions have become more ambitious, and methodologies more refined and sophisticated. In general, the repertoire of corpus-linguistic studies is fairly broad from corpus-based but mainly qualitative studies to advanced statistical methods and computer programs specially designed for the research question under investigation.

The field of historical pragmatics was launched some twenty years ago and described initially as a field in which "[t]he research efforts that are potentially relevant . . . are scattered over various branches of pragmatics and historical linguistics"

Developments within pragmatics as reflected in historical pragmatics

Pragmatics and discourse are newer areas of corpus linguistic study than morphology, syntax, or semantics. Essential features of pragmatic studies are harder to catch with corpus methodology than morpho-syntactic features, and therefore corpus linguistics came into pragmatics later, in the 1990s

It has become the dominant view in European pragmatics. Jacob Mey's definition fits this approach (2001: 6): "Pragmatics studies the use of language in human communication as determined by the conditions of society." This view is also advocated in the Handbook of Pragmatics Online, which sees pragmatics as a functional perspective to language and "the cognitive, social, and cultural science of language and communication"

The second, or Anglo-American, view has also been called the "component view." It considers pragmatics in the same way as phonology, morphology, syntax, and semantics, as a level of language analysis but not overarching them. This view is present in the Handbook of Pragmatics (Horn and Ward 2005), and historical pragmatics is defined accordingly by

Often it is only the emphasis in research questions and research planning that distinguishes pragmatics from sociolinguistics. For example, historical sociolinguistic studies are interested in establishing correlations between the speaker's or writer's gender, age, or social class and innovative language use, whereas a pragmatic study would highlight situational uses of the novel form and momentary shifts between older and newer variants in discourse.

The approaches can also be combined as has been done in a recent study by

3 Two decades of historical pragmatics

Research questions

Research questions in the field have developed and become more elaborate and more diversified. In order to make this development more conspicuous, I shall compare the state of the art when historical pragmatics was launched in 1995 with the inaugural volume called Historical Pragmatics: Pragmatic Developments in the History of English (Jucker 1995)

Corpus linguistic applications

A whole range of new research paradigms have been opened up with the increasing sophistication of corpus-linguistic tools. Technical developments have brought along a rich array of corpus-linguistic applications, and corpus compilers have created a good selection of databases for public use. Researchers have realized that a combination of quantitative and qualitative studies will yield the most reliable results. The application of frequency counts to pragmatic research questions was innovative in the mid 1990s and opened up novel ways of doing research with historical texts, but more advanced statistical methods are employed now with the help of present software programs that rely on elaborate computational techniques. One of the novel software applications, the Keyword analysis, uses significance tests to distinguish words that are significantly more frequent or significantly less frequent than in a reference corpus; calculations are carried out automatically by the program and it is possible to gain valuable insights into the material that cannot be achieved with qualitative study. It is easy for the end user to apply the method to their data, but the researcher's own input shows in the selection of the target corpus and an optimal reference corpus and the interpretation of the machine-produced key word lists, which is not simple at all (see below).

As in all corpus-linguistic studies, research can be conducted with the "top-down" method that takes a linguistic feature or grammatical category as its point of departure; this is the deductive method. The above-mentioned articles on HC serve as examples of such studies. Alternatively, studies can adopt the "bottom-up" method that relies on what the material yields. It is common to combine the two in historical pragmatics and to begin with a list of items to be searched with the top-down method and complement the study by checking whether additional items with the same or related meanings can be encountered in the texts. The demand for this practice rises from the nature of historical data, as it is not self-evident that historical manifestations of the examined feature are the same as in Present-day English. The lists in modern grammar books do not yield all historically relevant items, or there may be no prior studies. This is one of the pitfalls that a pragmatician has to avoid, and the material itself is the best guide to be consulted.

Contextualizing language use

Contextualizing language use is one of the characteristics of pragmatics as situational constraints determine which of the available variants is chosen (variability) and how the same expression can have different meanings in different situations (negotiability; see below). In historical pragmatics, contextual mappings with illustrative examples are used to complement the corpus-linguistic assessments. Sociohistorical background facts are needed to situate the investigated language phenomena, and background study of texts is necessary even prior to the study itself so that the research questions can be formulated in an optimal way. The KWIC (keyword in context) concordances show the narrow linguistic co-text and provide perhaps the easiest and most useful way of getting acquainted with the material. Word lists provide another preliminary way of exploring the data (see above). Textual context comes next: the locus of the assessed feature may be important for the results and therefore whole texts are needed especially for discourse studies. Genre context already moves on a more abstract level as genres are generalizations made on the basis of individual texts, and placing a text in its genre context reveals some of its meaning. Cultural context is even broader than the genre repertoire as it includes the world view with the position of man and his relation to the surrounding world and often helps to interpret and even explain the observations about language use (see Section 6 below).

4 Focus shift and broadening data for empirical studies Historical pragmatics has its roots in philology, and it is against this background that we can most clearly see what new corpus linguistics has brought to historical pragmatics and to historical studies in general. Early philological studies were based on hand-picked examples mostly from literary works of the past, and thus they highlighted rare and peculiar, perhaps idiosyncratic uses. With corpus linguistics the basis has broadened and the focus has shifted to common features and everyday practices.

Historical corpora

The availability of historical corpora and other electronic resources has multiplied from one pioneer corpus, HC, in 1991 to almost anything ever printed readily available as research data. The number of corpora for linguistic studies has multiplied making historical studies on more demanding questions possible. A boom of second-generation corpora followed HC, many of them compiled by members of the Helsinki team. The Corpus of Early English Correspondence (CEEC) project was the first and the work is still going on with a whole corpus family in the pipeline. Early English Medical Writing 1375-1800 is another further development of HC and consists of three corpora. The first is mainly based on editions, the second mainly on Early English Books Online (EEBO), and the third mainly on Eighteenth Century Collections Online (ECCO). The innovative aspects include a picture gallery and links to EEBO documents (subject to subscription) so that the researcher can have direct access to the originals (see

Other electronic databases

In addition to the specialized corpora, large databases of literary and biblical texts are available in the Chadwyck-Healey collections

Developing corpora for corpus-linguistic applications

Besides corpus compilation projects, corpus linguists have profited greatly from recent advances in automatic normalization of spelling variants that make possible the application of advanced linguistic methods to historical data. The Variant Detector program, VARD 2 (by Baron, see www.comp. lancs.ac.uk/~barona/vard2/) has been developed for Early Modern English to improve the reliability of data sources. Corpus development has already taken the normalized versions on board. Early Modern English Medical Texts (EMEMT) is the first corpus that in addition to the authentic texts includes normalized versions of corpus text to be used in corpus-linguistic applications of keywords, clusters, and n-grams, but researchers go back to the originals for citing examples (see

Historical pragmatic studies with corpus-linguistic methodology

In this section I shall outline some of the most important subfields of historical pragmatics where corpus-linguistic methods have yielded novel insights into central research questions. Researchers are well provided for with rich data resources and exciting new software programs.

Processes of language change

Research in the area of language change has been active since the 1980s, at first from the morphosyntactic and semantic point of view, but pragmatic motivations and the interface beween semantics and pragmatics have received increasing attention since the 1990s (e.g.

In a more recent article "Interjection-based delocutive verbs in the history of English" Brinton (2015) assesses a reverse change by which a grammatical word (e.g. a second-person pronoun used as a verb to thou) or an interjection becomes a lexical word (to boo). The point of departure is a novel set of research questions about delocutive verbs, with reference to a locutionary act of uttering x. The tokens are rare but types quite numerous, and the low frequency makes it impossible to establish a sequence of semantic development. The core of the category is verbs based on interjections expressing emotive states. Brinton points out the long diachrony of such verbs, and traces the development of interjection-based delocutives in several corpora from Middle English to the Early Modern and the Late Modern English periods from dictionaries and traditional corpora to electronic resources and literary databases. She noticed a significant increase in these items in Early Modern and Late Modern English periods. The linguistic cotext and surrounding discourse context are considered, and the findings related to larger patterns of various processes of change like lexicalization and degrammaticalization. In particular, Brinton wants to find out to what extent these verbs have undergone lexicalization (rather than conversion), and whether interjection-based delocutives have undergone degrammaticalization involving grammatical "upgrading" -a shift from more minor to more major part of speech. She considers various possibilities and concludes in favor of neologisms and states that the verbs arise through conversion or by back formation from the gerund as they first appear in the -ing form.

Studies on styles of stance

The second set of case studies represents a different point of departure and method that relies on a large repertoire of linguistic features that work together to express styles of stance, i.e. speaker's or writer's epistemic or attitudinal comments on propositional information. The linguistic features to be studied are chosen on the bases of previous studies, also representing the top-down methodology, but instead of form-to-function studies, it is related to the multidimensional method that reveals continuous scales of variation

LGSWE provides the basis for the selection of linguistic features, and it also gives the point of comparison as the synchronic patterns of expressing stance, in various registers of Present-day English (conversation, fiction, news reports, and academic writing) are established in it. The aim of Biber's article "Historical patterns of grammatical marking of stance: A cross-register comparison" (

The results indicate a general shift in the cultural norms over the three centuries: speakers and writers are more willing to express stance in recent periods. The article concludes with suggestions for future research.

The same topic, styles of stance, and the same method were developed in a new direction and applied to the more specific research task of stance marking with EMEMT data

Historical speech act studies

The language practices of common people have attracted increasing attention, for example, in historical speech act studies, where greetings and farewells, thanks and apologies, requests, and other everyday practices are highlighted. Speech act studies represent function-to-form mapping, which is more difficult to deal with than the form-to-functions direction of fit with corpus-linguistic methods. Some steps towards diachronic speech act analysis were taken in the inaugural issue of the Journal of Historical Pragmatics where Bertuccelli Papi (2000) posed the question "Is a diachronic speech act theory possible?" It was followed by tentative positive answers in qualitative studies. Corpora were used to locate relevant examples, but the identification of speech acts proved problematic. Insults are particularly difficult as they depend on the perlocutionary effect and cannot be directly searched in electronic corpora

In principle, three methods can be used. The first relies on Illoctionary Force Indicating Devices (IFIDs), and many of the present-day IFIDs also work for historical texts too, e.g. sorry and thank you, but there is no one-toone fit between the present and the past, and there may be other expressions typical of the period that could go unnoticed. Such was the case, for example, in eighteenth-century thanking as I am obliged and similar phrases are very much in accordance with the politeness ideals of the period

We have come a long way forward, and scholars are actively testing new possibilities, even automatic retrieval of speech act manifestations, but they present problems. One such study is

Discourse studies on ideology

Corpus-linguistic applications are newcomers in the field of discourse studies in general as discourse studies have traditionally relied on qualitative assessments. The development has been rapid and sophistication has increased greatly in recent years.

6 Negotiating pragmatic meanings: a case study of general nouns, vagueness, and specificity

Negotiability is one of the defining features of pragmatic approaches to language use

General nouns indicating vagueness were also included in the study. In EMEMT they occurred in all kinds of writing, but most commonly in the remedy book tradition. In EMEMT they were rare at first, but increased greatly in the last decades.

Generic references mark a shift in the locus of scientific knowledge in the early modern period, and an interesting development emerged. The discourse community and its members' role in creating new knowledge became enhanced. Earlier vague references gain new functions and implicit meanings: they become specific in the sense that all members of the discourse community knew who the general nouns referred to. The following passage deals with a conflict. The author has a clear role in controlling the text and refers to the parties of the dispute known to all with general nouns: THO I have been much solicited, to shew my Opinion, about the Debate betwixt the two Physicians, concerning . . . and violently oppos'd by a certain Club of Physicians; . . . And whether or not by the vain Fears of Friends and By-standers, a Faithful and Expert Physician may be blunder'd, and a good Method disgrac'd? And whether dallying and triffling with a Fever, tho less exceptionable, be not more dangerous, and often of more fatal consequence, than Plentiful Purging? . . . These I take to be the most material Points in this Debate, which seems to be handled with a little more Heat and Humour, than is consistent either with the Import of the Matter, or Dignity of the Members of so Judicious a Society, who would be expected to treat all their Matters, and seek to advance the Improvement of Medicine, in Candor, Amity The new data sources have brought historical pragmatics to a new phase as one branch is heading to multimodal assessments with digital images of manuscript and book pages (see

English linguistics has undergone a change with corpus-linguistic methods, but for historical pragmatics, the change is less dramatic as corpuslinguistic methods have been used from the beginning. Sophistication has increased greatly from the early years and the methods have developed from frequency counts and assessments of distributional patterns to tailor-made research algorithms and refined investigations revealing ideological underpinnings. New software tools allow researchers to probe into more subtle aspects of meaning-making processes and it is possible to gain deeper insights into past communication of earlier historical periods. In some areas, like historical discourse pragmatics, progress has been considerable, but it has also been noticed that all branches of historical pragmatics do not lend themselves easily to corpus studies. Researchers have become aware of the problems and they are trying out new solutions. The field offers plenty of challenging and rewarding research opportunities for the future.

CORPORA (For

Corpus analysis of varieties

Spoken discourse

Shelley Staples 1 Introduction

Spoken corpora have long been of interest to researchers but also more challenging to compile than written corpora. It should be noted that early "corpora" (those developed before the 1980s when corpora became computerized) were more often based on spoken rather than written language, but were quite small and focused primarily on the study of phonetic features

Due to particularly the first two limitations, spoken corpora are less numerous than written corpora and also have tended to focus on more limited domains. There are a number of available spoken corpora that contain face-to-face conversation, for example, the London-Lund Corpus (LLC), Cambridge and Nottingham Corpus of Discourse in English (CANCODE), the British National Corpus (BNC), the Lancaster/IBM Spoken English Corpus (SEC), and the Santa Barbara Corpus of Spoken American English (SBCSAE).

While these corpora also contain other spoken registers, face to face conversation forms the bulk of the texts in the spoken sections. However, a growing number of spoken corpora focus on other more specialized registers of speech. From the corpora that are publicly available, two useful examples are COCA and MICASE. Although COCA simply calls its spoken subcorpus "speech," it is important to note that it consists primarily of transcripts of news programs and talk shows, not face-to-face interaction. MICASE includes examples from various spoken registers found in an academic setting (e.g. lectures, study groups, presentations). Other examples include the Corpus of Professional Spoken American English (press conferences; faculty meetings and committee meetings related to national tests) and COLT (Bergen Corpus of London Teenage Language). Other specialized corpora tend to be unavailable to the public. These include T2KSWAL, which contains a variety of registers found in academic settings (e.g. classroom teaching, study groups, and office hours), the Nottingham Health Communication Corpus (NHCC), which consists of interactions between nurses, pharmacists, NHS Direct health advisers, a hospital chaplain, and patients, and the Language in the Workplace Project (LWP) corpus, which contains workplace interactions in a variety of settings (e.g. government departments, meetings, and factory settings). Other more specialized corpora include

A number of spoken corpora also focus on different varieties of English. The International Corpus of English in particular represents ten varieties of spoken English (e.g. Great Britain, South Africa, India). The BNC is probably the most well-known corpus focused on a national variety. The Wellington Corpus (New Zealand) and Limerick Corpus of Irish English are two other national corpora with spoken English represented.

Finally, a growing number of corpora focus on the language of learners. LINDSEI (Louvain International Database of Spoken English Interlanguage) contains interviews from L2 English learners of eleven different language backgrounds (e.g. Spanish, Chinese, Polish). One limitation of this and most other learner corpora is that most of the interviews are not rated for proficiency level.

In addition to the challenges in creating spoken corpora, another important consideration is that many corpora are aging. The LLC was gathered in the 1980s, and the BNC between 1980 to 1993. Most corpora (spoken and written) are sampled corpora (meaning that they are sampled from a specific period of time). One monitor corpus that allows us to see changes in spoken corpora and also provides more current spoken data is COCA. However, as mentioned above, one limitation of this corpus is that it is composed of transcripts from news programs and talk shows and thus the speech is likely to be more scripted or more carefully produced than informal registers of spoken English.

The following sections highlight key advancements within corpus linguistics on the study of speech, starting with characteristics that differentiate speech from writing (Section 2), and then moving to characteristics of particular spoken registers (Section 3), and specific individual features associated with speech (Section 4). New directions and challenges for spoken corpus research is the focus of Section 5, including research on fluency, prosody, and non-verbal behavior in spoken corpora, dialect studies, and discourse-level investigations. After a summary of the advancements and future directions for spoken corpora (Section 6), the seventh and final section will focus on a case study that brings together some of themes and innovations highlighted in the previous sections. The case study investigates stance features in nurse-patient interactions, a lesserstudied discourse domain, and also highlights differences within the interactions and across speaker groups (nurses and patients).

Distinctive features of speech in comparison with writing

The earliest studies investigating spoken corpora used corpora of both speech and writing to identify key linguistic features associated with different modes of communication. While characteristics differentiating speech and writing were discussed by many scholars in the 1980s (see, e.g.,

Xiao (

Finally,

Taken together, these studies show the overwhelming reliance of spoken discourse on clausal features as well as personal pronouns. By comparing speech to writing through MD analysis, it is possible to determine key characteristics of the speech, which can be used for more detailed investigation across spoken registers.

Distinctive features across various spoken registers

A number of more recent studies have focused on differences in the linguistic features used across spoken registers. One such study is

Other studies have focused on variation across TV dialogue, movie language, and face-to-face conversation

These studies reveal important differences in patterns of use across spoken registers. Using MD analysis allows researchers to identify differences in the use of a combination of linguistic variables for particular functions. A number of studies have investigated individual features in spoken discourse more closely, to provide an even more fine-grained analysis of the use of these features.

4 Individual features distinctive of spoken discourse

Formulaic language

Studies of lexical bundles have revealed distinctive characteristics of this type of formulaic language in speech when compared to writing. Studies show that lexical bundles are more common in speech than in writing, particularly academic writing

Other studies have focused on developing lists of frequent formulaic language for speech in order to inform language learning. The most wellknown of such lists is probably the Academic Formulas List

One recent innovative study focused solely on speech is Lin (2013), which investigates the use of prominence (sentence stress) in relation to formulaic language. Lin (2013) finds that while most formulaic language follows the patterns expected for prominence in general (at the end of an intonation unit), a subset of formulaic language is unstressed in final position, suggesting that the phrase in question functions more similarly to function words than to content words. Examples of formulaic language that was unstressed included if you like and in other words. As will be discussed in Section 6 below, examinations of prosody in spoken corpora are infrequent, although a growing number of studies include this important aspect of spoken discourse.

Stance features

The Longman Grammar

Discourse markers

One feature examined in many corpus-based studies of speech is the use of discourse markers, most likely due to their long association with spoken as opposed to written discourse (see, e.g.,

Vague language

A final area that has seen increasing activity recently is the investigation of vague language in spoken discourse, which, like discourse markers, has been identified as a distinctive feature of speech (see

5 New directions and challenges

Fluency and prosody studies

Due to the current labor-intensive process of hand-coding fluency and especially prosodic features, few large corpora have been analyzed for fluency and prosody features. Notable exceptions include the London-Lund Corpus (LLC) and Lancaster/IBM Spoken English Corpus (SEC), both developed in the 1980s. The LLC is coded for intonation units, placement of prominence, and pitch movement (intonation). The SEC corpus is coded for these features as well as temporal alignment at the level of the phoneme. More recently, the Intonational Variation in English (IViE) (developed in the late 1990s) was developed to investigate dialects of British English. It includes information about pitch movement and prominence. The Hong Kong Corpus of Spoken English (HKCSE;

Cheng, Greaves, and

The automatic extraction of phonetic and phonological elements (both segmental and suprasegmental) is undoubtedly one of the major challenges facing researchers interested in using spoken corpora to investigate phonetic and prosodic patterns. A few studies offer promising developments in this area.

Another neglected feature in the collection and study of spoken corpora has, until recently, been non-verbal behavior (e.g. gestures, eye contact). One exceptional project attempting to fill this gap is the Nottingham Multi-modal Corpus (NMMC) (see

Dialect studies

Along with Inner Circle varieties of English (British, New Zealand English), a growing number of corpora focus on other national varieties of English (for example, the International Corpus of English, discussed above in Section 1, and VOICE-Vienna-Oxford International Corpus of English). However, the investigation of regional dialects within national varieties has mostly focused on an "atlas" approach, which relies on words or very short stretches of speech, similar to the model discussed earlier when describing early speech "corpora." Longer stretches of speech have been recorded as part of dialect studies but often lack widespread accessibility. Exceptions include the Survey of English Dialects (SED), which contains sociolinguistic interviews, more or less question-and-answer sessions. An interesting recent study using this corpus is the work of

Less constrained corpora have been developed more recently for the study of dialectology, including the Freiburg English Dialect Corpus (FRED). This corpus was created for the study of grammatical variation in dialects rather than phonetic/phonological variation. It consists of oral interviews with speakers of six dialects in Great Britain.

Discourse-level units

Investigation of the linguistic features used within different stretches of discourse reveals important variation within spoken discourse rather than across registers. The challenge, however, is identifying discourselevel units, particularly through automated methods. Few studies have attempted to automatically identify discourse-level units in speech.

While these approaches appear to be suitable for longer stretches of speech, using automated techniques on discourse-level units in highly interactive, dialogic spoken corpora is less feasible. Thus, studies that attempt such segmentation currently require a combination of top-down and bottom-up approaches, using models from previous literature but making modifications based on the actual corpus in question. One such study is

Summary

The previous sections have attempted to illustrate many of the advancements in the use of spoken corpora and the important findings that corpus-linguistics research on spoken corpora has revealed. The empirical identification of distinctive features of spoken language (primarily in English but in other languages as well) has revealed important differences in the linguistic characteristics of speech in comparison with writing. Notably, speech is characterized by the use of more verbs, adverbs, and other clausal structures, as well as personal pronouns when compared to writing. This finding has important implications not only for the description of spoken language but also for the expectations about the language produced by more proficient speakers. While a large number of studies have confirmed this finding, it still seems to not have been adopted in models of spoken discourse used within more applied settings, particularly assessment and pedagogical communities.

Identifying systematic variation across spoken registers has allowed us to understand in more detail the function of linguistic variables acting in concert (e.g. features of involvement) as well as providing a more finegrained analysis of the features characteristic of speech (e.g. stance features, discourse markers, and vague language), offering a more subtle understanding of their functions in particular discourse contexts. There are few large or publicly available corpora for specialized discourse contexts, however, so this is an area for further development and research. In addition, corpora focusing on dialects within national varieties are rare.

While automated methods have been developed for the identification of lexico-grammatical features, a major challenge remains the investigation of fluency, prosodic, and nonverbal features as well as the segmentation of speech into discourse-level units, particularly dialogic speech. These areas are a challenge to be met by the next generation of corpus linguists focusing on spoken corpora. The advances in automated techniques are promising, but at this point still a great deal of manual labor is required.

This case study focuses on the use of stance features across interactional phases within nurse-patient interactions and across speaker groups (nurses and patients). Similar to studies comparing the use of stance in particular registers, it illustrates the different functions of stance features based on speaker role. Unlike many studies, however, it also investigates the use of stance features within particular phases of the nurse-patient interactions, which demonstrates the variation within medical interactions.

The motivation for this study is that no previous studies have used corpus linguistic methods to investigate differences in the use of linguistic features by patients and nurses across the phases of an interaction. The use of these features elucidates the different roles of and functions performed by the two groups within various parts of a medical interaction. The investigation of the various interactional phases provides insight into variation within medical interactions.

The primary research question in this study is: how does speaker role impact the use of stance features across the phases of a medical interaction?

Methods

The corpus

The corpus used for this study is the American Nurse-Standardized Patient corpus (ANSP corpus). This corpus was collected and transcribed in 2012 and includes 50 interactions between registered nurses working at a US hospital and standardized patients (SPs). SPs are actors trained to present the same case to multiple healthcare providers and are often employed to assess nurses and doctors in training. The use of SPs means that the same topics were discussed by all nurses, which allows for clearer comparisons across the interactions. The nurses included in the study were all native speakers of English and had spent most of their lives in the US. They were predominantly female (46) and white (37). The average age of the nurses was 50 years and the average number of years working as a nurse was 21 years. The 50 interactions include just over 60,000 words and just under 8½ hours of recording time. Table

Stance features

Table

Phases of the interaction

After the interactions were recorded and transcribed, they were divided into phases (opening, exam, counsel, and closing) according to previous research

Data analysis

Rates of occurrence were computed for the stance features in each text of the corpus. The speech produced by the nurses and the speech produced by the patients were analyzed separately. The rates of occurrence for each of the variables investigated were normed per 100 words so that they could be compared across the different speaker groups and across the phases of the interactions.

Main findings

As Figure

Stance adverbs pattern quite differently depending on the phase of the interaction. In the opening, exam, and closing phases they are used most frequently by patients. However, the greatest use of stance adverbials was found in the counsel phase, by nurses. Stance complement clauses were used most in the closing phase, by patients. However, they were also used frequently by both nurses and patients in the counsel phase. These patterns are discussed in more detail below. Among the modals, prediction modals were used most frequently, particularly in the opening and closing phases. In the opening, nurses used prediction modals to establish their role in the interaction:

(Excerpt 1) N: High Elaine I'm Sue. I'm going to be your nurse today. (Excerpt 2) N: Elaine is fine. Okay. Um I'm going to be your nurse this morning. My name is Rita. Okay. In the closing and to some extent the counsel phases, the nurses used prediction modals to indicate what will happen after the encounter is over:

(Excerpt 3) N: And I'll also have a dietician come and speak to you. ( However, nurses also used certainty adverbs in the counsel phase, with greater frequency than patients. They did so in order to assure patients about the plan of care:

(Excerpt 9) N: Okay. Um so we'll definitely connect you with somebody that can get you some help with that and then maybe some you know maybe a you know some outpatient counseling you know after you leave the hospital. (Excerpt 10) N: But there's a lot of different counseling. We can always like discharge before you go home. We can always provide you with documentation that for like outside counseling if you need. And I'll make sure that I'll let our doctors know Likelihood adverbs were used by nurses very frequently in the counsel phase as well. For nurses, likelihood adverbs were used in a similar fashion to probability modals, to discuss possible solutions to problems: (Excerpt 11) N: Well, I would say maybe talk to a counselor and take it from there and if it doesn't resolve maybe then you can get something from your doctor. (Excerpt 12) N: Maybe it's time to kind of wean yourself a little bit away from chocolates.

Nurses also used likelihood adverbs to hedge about causes of patients' symptoms:

(Excerpt 13) N: So when uh you you have a low grade temperature which could kind of be from inflammation so we're not going to be real worried about that.

Another function of likelihood adverbs was their use in expressions of empathy. In the examples below, the nurse indicates an understanding of the patient's situation, but the likelihood adverb allows the nurse to emphasize that each person's experience with grief is different: Patients, on the other hand, generally used likelihood adverbs to hedge about their symptoms in the exam phase:

(Excerpt 16) N: How else are you feeling physically? P: Well um just my chest and N: So your chest is hurting. P: Maybe a little fever. I haven't slept.

In the counsel phase, likelihood adverbs were used by patients to talk about possible solutions/courses of actions, similar to nurses' use:

(Excerpt 17) P: Yeah that'd maybe be a good idea and get my my mother my brother involved or even my aunt if she wants to come in or we can just talk in a conference or something.

Patients also used style adverbs quite frequently in the closing phase. They did so to stress the focus of their visit and to revisit the issues discussed, to make sure that the nurse will follow up after the interaction is over.

(Excerpt 18) N: Is there anything else I can do for you right now? P: Um not that I can think of. I mainly just want to make sure I'm not having a heart attack. N: Right. Your first one was normal. We'll uh I'll uh let the doctor know that you're still having chest pain. We'll get another EKG. And uh see if he wants to draw some more labs on you and I'll get you some uh pain medication.

Finally, stance complement clauses were the most variable across interactional phases. Most frequent was the use of stance verbs + that-clauses by patients in the counsel phase. In fact, both nurses and patients used this construction most in the counsel phase, and stance verb + to-clauses were also very frequent in this phase for both nurses and patients. Interestingly, for both nurse and patient speech, the patient is the subject of the main clause. For the nurses, these patterns are used to give directives (especially with the verb need): Here, the focus is on the patient's desires and choices for solving problems, emphasizing a more patient-oriented interaction.

In contrast, patients used desire verbs at approximately the same rate as nurses, but to express their own stance, especially to convey their main reason for coming to the hospital: (Excerpt 25) N: And what's your goal today? P: Uh mainly just make sure my heart's okay I know I've been stressed so I just want to make sure.

Finally, nurses used effort verbs + to-clauses more frequently than patients, for the purpose of providing directives:

Conclusion

This chapter has attempted to briefly introduce important advancements and new directions in the area of spoken corpus analysis. The case study provided in Section 7 illustrated a common focus of corpus-based studies of writing and increasingly speech, namely stance devices; it also provided an example of a new direction in spoken discourse analysis in its exploration of variation within spoken interactions.

16

Corpora and written academic English

Ken Hyland

The impact of corpora in the study of written academic English over the past twenty years has been enormous, transforming how we understand, study, and teach this key area of language use. Corpora provide language data which represent a speaker's experience of language in a particular domain and so therefore offer evidence of typical patterning of academic texts. It is a method which focuses on community practices and the ways members of particular disciplines understand and talk about the world. Bringing an empirical dimension to the study of academic writing allows us not only to support intuitions, strengthen interpretations, and generally to talk about academic genres with greater confidence, but it contrasts markedly with impressionistic methods of text analysis which tend to produce partial and prescriptive findings, and with observation methods such as keystroke recording, which seek to document what writers do when they write. It also differs from methods which employ elicitation methods such as questionnaires and interviews, or introspection methods like think-aloud protocols to understand the perspectives of writers or readers on how they use texts. Perhaps most significantly, corpus approaches to academic writing provide insights into disciplinary practices which help explain the mechanisms by which knowledge is socially constructed through language. Together, this research explicitly contradicts the view that corpus linguistics takes an impoverished, decontextualized view of texts and replaces it with a detailed picture of how students and academics write in different genres and disciplines. In this chapter I discuss some of the key studies and ideas which contribute to our understanding of academic writing in English. Section 1 offers an overview of published studies, while Section 2 describes a study which illustrates how corpus research can inform our understanding of academic writing. This section discusses previous research, identifies a number of key studies, and provides an overview of the research methodologies that have been employed.

A brief survey of research

The textual data for studying academic writing include all the ways of using language in the academy. This is a range of genres which enact complex social activities like educating students, demonstrating learning, disseminating ideas, evaluating research, and constructing knowledge, and almost all have been collected and analyzed as corpora. Studies of these corpora reveal that all academic texts are, in one way or another, designed to persuade readers of something. In most cases this is the efficacy of an idea or piece of research, so that claims are encoded, warrants employed, arguments framed, and appropriate attitude to readers conveyed in ways that a potential audience will find most convincing. Thus, the ways academics represent themselves in bios, webpages, and prize applications, for example, seek to persuade readers of their competence and expertise as disciplinary insiders by drawing on attributes and experiences which relate the individual closely to what is valued in their community (e.g. Hyland 2012).

More specifically, the comparison of features in a corpus of 240 research articles and 56 textbooks (Table

The greater use of hedging, for example, underlines the need for caution in opening up arguments in the research papers compared with the authorized certainties of the textbook, while the removal of citation in textbooks shows how statements are presented as facts rather than claims grounded in the literature. The greater use of self-mention in articles points to the personal stake that writers invest in their arguments and their desire to gain credit for claims. The higher frequency of transitions, which are conjunctions and other linking signals, in the textbooks is a result of the fact that writers need to make connections far more explicit for readers with less topic knowledge. Thus, to achieve their persuasive purposes academics draw on the same repertoire of linguistic resources again and again. This is, in part, because writers try to anticipate their readers' background knowledge, processing needs, and rhetorical expectations through use of familiar rhetorical features. It is these patterns of repetition which corpus analyses seek to uncover. Corpus analyses have, for example, been productive in identifying the structural regularities of a range of genres, describing moves in grant proposals

Corpus research has also enabled researchers to make comparisons across different corpora. Thus

Perhaps comparison has been explored most extensively in the effects that culture and/or first language has on writing in English. Culture, seen as a historically transmitted and systematic network of meanings, is inextricably bound up with language and so influences writers' expectations about appropriacy, audience, ways of organizing ideas, and of structuring arguments. Corpus research has broadly supported the view that the schemata of L2 and L1 writers differ and influence how they write in English (e.g. Loi 2010;

Yet corpus studies show discipline to be a decisive factor in the construction of academic genres. Individuals use language as members of social groups and they write essays, theses, and articles by framing problems and understanding issues in ways specific to their disciplines

Finally, it is worth mentioning the support corpus studies have provided the view that academic writing is permeated by social interaction and intersubjectivity. These concepts have become central to language studies in recent years as we have come to realize that academics do not simply produce texts that talk about the world, but use language to acknowledge, construct, and negotiate social relations. Corpora have helped illuminate the range of features writers use to construct an appropriate authorial self. So, the considerable use of self-mention in research articles

Despite considerable work on genre structure, however, the ways that moves are signaled by writers and identified by readers have been far less studied. Typically, researchers have relied on changes in discourse function, or what particular stretches of a text are contributing to the overall purpose of the discourse. Often these are explicitly signaled, so that in this example from a research article abstract in biology we see a purpose statement announced by a to + infinitive clause and a method move indicated by a switch to past tense active verbs:

To study the expression of ALDHs in plants we isolated and characterized a cDNA coding for a putative mitochondrial ALDH (TobAldh2A).

More generally, it is likely that particular rhetorical features cluster within particular moves to perform the specific functions of those moves, but more work needs to be done to identify these frequently occurring signals.

Another criticism of academic corpus studies is that, until fairly recently, these have been largely text-focused so that features seem rather abstract and disembodied from real users. Studies are needed that do not just analyze text corpora but which involve the authors or the readers of the texts in the analysis by also collecting interview data. Finally, there are still many gaps as researchers have been tempted to build and analyze corpora of the most publicly prominent and easily accessible genres, typically published texts and student work. This tends, however, to skew research towards a narrow area of the academy and neglects more "occluded" genres

Some key studies

The studies selected here represent both significant contributions to a particular area of academic writing and important moments in the evolution of corpus research in academic discourse.

Genres across the disciplines (Nesi and Gardner 2012)

This is the first detailed description of the kinds of assessed writing students do in different disciplines and in different years of their studies in UK universities. Based on the 6.5-million-word British Academic Written English (BAWE) corpus, the study develops a genre classification to identify and describe thirteen major types of assignment according to their purpose, stages, genre networks, and characteristic language features. Each chapter in the book discusses a "family" of genres, each with a particular social function. These are "demonstrating knowledge and understanding" (e.g. explanations and exercises); "developing powers of informed and independent reasoning" (e.g. critiques and essays); "developing research skills" (e.g. research reports and literature surveys); "preparing for professional practice" (e.g. proposals and design specifications); and writing for oneself and others (e.g. empathy writing and narrative recounts).

The study is also a good example of how corpus techniques can be used to map patterns in a large collection of texts, identifying moves in different genres, comparing frequencies of various language features, and offering detailed description of how individual words and phrases are used. The study is especially important as it provides a detailed account of undergraduate writing and descriptions of several previously disregarded genres. More importantly, it underlines the significance of disciplinary variation, showing how some genres are found almost exclusively in certain fields and how genres change as students progress through their course of study. This information is not only useful to discourse analysts, but also to teachers and those involved in syllabus and materials design for students in higher education.

University language: a corpus-based study of spoken and written registers

The descriptions offer important characterizations of academic writing so, for example, Biber found that over 50 percent of all nouns in the written corpus had abstract/process meanings that refer to intangible concepts or processes (system, factor, difficulty). The study also confirms the variation between written and spoken texts, with textbooks containing twice as many different words as classroom teaching, despite their broadly similar instructional purposes, largely due to their use of specialized lexis. The book is also interesting for its methodological approaches which include multidimensional analysis to identify sets of linguistic features that commonly co-occur with markedly high frequencies in texts. Thus institutional writing and course management texts contain high frequencies of necessity and prediction modals, second-person pronouns, and conditional adverbial clauses which push them towards the procedural end of a continuum with more content-focused genres such as textbooks and course packs at the other.

Disciplinary discourses: social interactions in academic writing

Learner English on computer

If you look at . . . lexical bundles in university teaching and textbooks

Disciplinary identities (Hyland 2012)

This study extends corpus research into a new area: the relationship between author identity and disciplinary practice. Drawing on corpora which include academic bios, acknowledgments, undergraduate essays, academic homepages, book reviews, and prize applications, the analyses seek to show how we can understand identity as a performance of writers which is informed and reinscribed over time through their use of language in disciplinary communities. What we say and write aligns us with or separates us from other people and other positions, so the command of a disciplinary idiom can therefore be an assertion of oneself as a particular kind of person: one who has a right to be taken seriously in the academic world. By studying how language is routinely used in particular genres it is possible to see how disciplinary identities are performed and recognized as legitimate.

In most cases the analyses start by focusing on potentially productive items from interviews with writers or prior studies, while in other cases the task of identifying features is delegated to the computer, generating lists of high lexical items and keywords for further study. Items identified from either of these starting points then provide the basis for investigation through collocation and comparisons to see how particular academics and disciplinary communities used these features to express social identities. Such approaches reveal the regularity and repetition of what is socially ratified and independently variant and in so doing offer insights into the preferred practices of both individuals and collectivities.

Corpus methods in studies of academic writing

Perhaps most corpus studies of academic writing have followed what Tognini-Bonelli (2001) calls a corpus-based approach, where the researcher begins with a pre-selected list of potentially productive items and uses the corpus to examine their frequencies and the ways they behave in different contexts. This is, for example, how researchers have used corpora to study features such as self-mention

Frequency provides evidence of non-randomness, revealing what regularities, and exceptions, exist in the language use of a group of people when engaged in a particular activity. High-frequency items represent repeated, taken-for-granted choices in academic writing as, from all the different ways of saying roughly the same thing, members of individual disciplines select the same items again and again. In-group abbreviations, acronyms, shorthand names for methods and theories, preferred argument patterns, preferences for author visibility or anonymity, particular lexical bundles, and so on, all help define and identify disciplines and genres.

Frequency can therefore lead us to what is worth discussing as it often indicates what is salient for groups of language users. We find, for example, that all disciplines shape words for their own uses, as demonstrated by their clear preferences for particular meanings and collocations. Thus science and engineering students, for example, are very unlikely to come across the noun volume in the meaning of "a book or journal series" while the noun strategy has different associations across disciplines, often appearing in the multi-word unit marketing strategy in business, learning strategy in applied linguistics, and coping strategy in sociology

Keyness is another frequency approach often used in studies of academic writing. The basic idea is that a word form or cluster of words which are common in a given text are key to it, it is what the text is "about" or "what it boils down to . . . once we have steamed off the verbiage, the adornment, the blah blah blah"

Keywords are therefore useful for identifying which words best distinguish the texts of a particular author or group of authors from another. Comparing different disciplines, for example,

Keyness therefore reveals a kind of interdiscursive similarity and helps build a picture of particular disciplines and how they are distinctive from each other. It also offers a starting point for corpus-driven investigations of academic corpora by generating list of items which can be further explored in more detail using concordance analyses.

Concordances. While frequency lists provide information about the focus of a collection of texts, they don't tell us how words are actually used. This is the function of concordance analyses, which provide information about users' preferred meanings by displaying repeated co-occurrence of words, allowing us to see the characteristic associations and connections they have, and how they take on specific meanings for particular individuals and in given communities. One example of this is Hyland and Tse's (2012) study of bios and how collocation allows us to see differences in the ways that senior academics and graduate students refer to themselves in the bios accompanying research articles. So, by checking the frequency of definite, indefinite and "zero" articles in a corpus of bios and then looking at concordance lines for each, we find that professors are far more likely to use naming terms that collocate with definiteness (she is professor of, he is the author of) which serve to uniquely identify them. In the bios of students and non-professorial faculty, on the other hand, such attributive choices signal class membership rather than a unique identity (she is a PhD student, he is an editor of).

Annotation refers to adding linguistic information to a corpus. While a raw corpus is a highly useful resource, annotation provides an extra layer of information, which can be counted, sorted, and compared. Lemmatizers, for example, retrieve word lemmas, the "canonical root" of a word such as cook from cooking, cooks, cooked, but while potentially useful for lexical analyses and mapping semantic relationships they are rarely used in academic writing research. POS-tagged corpora, on the other hand, are very powerful resources and have contributed to our understanding of academic writing by allowing for detailed studies of the use of grammatical categories, such as prepositions, phrasal verbs, modals, passives, etc., although the search and retrieval possibilities depend on the sensitivity of the tagset, which can range from 50 to 250 tags.

One example of how a POS tagger has been used in academic writing is Granger and Rayson's (1998) identification of salient features of interlanguage essays. Using a reduced tagset of nine major word categories and fourteen subcategories from Claws4, the analysts compared a corpus of argumentative essays by advanced French-speaking learners of English with a corpus of similar writing by native English writers. While both groups were found to use articles, adjectives, and verbs with similar frequencies, the non-native speaker writers overused determiners, pronouns, and adverbs significantly and significantly underused conjunctions, prepositions, and nouns.

A summary of findings and gaps

Some key findings:

1. That academic texts are persuasive and structured to secure readers' agreement; 2. That there are variations in spoken and written academic genres; 3. That language groups have different ways of expressing ideas and structuring arguments; 4. That ways of producing agreement represent disciplinary specific preferences; 5. That academic persuasion depends on negotiating appropriate interpersonal relations; 6. That authors are everywhere in their texts, presenting a stance towards their topics and readers; 7. That academic texts are constructed through fixed phrases to a greater extent than we expected; 8. That academic conventions constrain both meanings and author identities, but also provide the resources for creativity and agency.

Some major research gaps which remain to be addressed:

1. We need more descriptions of the wide range of specific disciplinary genres students need to write and read. 2. We need a greater understanding of how particular genres are used within specific contexts, adding a focus on "action" to balance the focus on "language" by including research techniques such as interviews and observations in what Swales calls a "textography" (Swales 1998) 3. We need to expand corpus studies into multimodal academic genres where writing is frequently used with graphical and visual semiotic forms, such as academic websites and textbooks. 4. We need studies which focus on NNES students and how their academic writing in English is similar and distinct from each other and from NESs. 5. We need more studies to help us understand the nature of disciplinary identities and the meaning of expertise in particular fields.

An example study

As an illustration of corpus research, I want to consider a study which attempts to see what corpus research can contribute to the study of identity

Background and rationale

Identity has come to be seen as something that we actively and publicly accomplish in our interactions with each other (e.g.

Academic contexts obviously privilege certain ways of making meanings, but we can also see these writing conventions as options which allow writers to actively accomplish an identity through discourse choices. This is because it is through our use of community discourses that we claim or resist membership of social groups, defining who we are in relation to others. This suggests it might be productive to compare the writing of individuals with the general practices of their discipline to find evidence for identity construction. How do their choices help them achieve credibility as insiders and reputations as individuals?

The main investigative technique in this study was therefore comparison. Comparing the features of target writers' texts with a much larger reference corpus of work in the same discipline can help to determine what is general in the norms of a community and what represents more personal choices. We can, in other words, see that if a particular word, phrase or usage is common in a corpus of a particular writer's work, then it might be said to be a consistent preference which reveals something of that individual's routine expression of self: of a relatively unreflective performance of identity. To capture this I compiled a corpus from each of the published single-authored works of two experienced and wellknown applied linguists, Deborah Cameron and John Swales. I selected these two academics partly because of their celebrity in the field of applied linguistics and their contrasting personalities and careers, but largely because their highly distinctive rhetorical styles seemed to offer a good starting point for this kind of analysis.

Corpora and methods

My corpus of Cameron's published writing consists of 21 single-authored papers made available by the author. It represents some twenty years of publishing and comprises 125,000 words. The Swales corpus was compiled at the Michigan ELI and consists of 14 single-authored papers together with the bulk of his three monographs, representing eighteen years of output and comprising 342,000 words. These corpora were individually compared with a larger reference corpus representing a spectrum of current published work in applied linguistics and in the same genres as the target texts. It comprises 75 research articles from 20 leading international journals and 25 chapters from 12 books totaling 750,000 words.

Wordsmith Tools 5

Main findings

The high-frequency content words and keywords indicate the niche of specialization which these academics have carved out from the mass of disciplinary subject matter. They reflect the main themes of an individual's work and serve as motifs for their contribution to the field. Items such as women, language, gender, men, social, talk, discourse, and work indicate Cameron's concern with the ways language functions to structure social relations, particularly in work contexts, and in the ways gender-linked patterns of language use are made significant in social relations. The top content items from the Swales corpus are research, genre, English, academic, writing, non-native speakers of English, and the concept of discourse community which similarly encompass his key areas of contribution.

More interesting, however, are the non-content words and phrases in the keywords lists which emerge as consistent individual choices. One example from Cameron's writing is the significantly above-average use of is; which was the fifth most frequent keyword in her corpus. While one of the most common words in English, in Cameron's texts it often occurs in the pattern it is+Adj.+to infinitive (161 times). This structure not only shifts new or complex information towards the end of a sentence, to the rheme, where it is easier for readers to process, but asserts the writer's opinion and recruits the reader into it (e.g. It is important to; It is difficult to think of). This assertiveness in Cameron's authorial positioning is also realized through the frequency with which is occurs in the company of that (230 times) in "evaluative that" constructions

John Swales, on the other hand, projects a very different identity. Here is an altogether more self-effacing and conciliatory writer, projecting a cautious colleague using rhetorical choices which impart a clear personal attitude and a strong interpersonal connection to his readers, particularly through the use of self-mention and hedges. Both devices project the author as a participant in the text, indicating that the writer is prepared to debate issues and contribute half of a dialogue with readers. Frequent use of the first person is perhaps the most striking feature of Swales' discourse, with both I and my occurring in the top ten keywords. Self-reference, in fact, occurs 9.1 times per 1,000 words in the Swales corpus compared with 5.2 in the reference corpus, imparting a clear authorial presence of a thoughtful reflective colleague thinking through issues. An interesting aspect of Swales' identity is the extent self-mention is used in a self-deprecatory way, explicitly associated with modality, or at least a deliberative attitude. The most frequent main verbs related to I are think (86), believe (71), suspect (35), hope (33), tried (31), and guess (29), all of which point to some degree of tentativeness and care in handling claims and in dealing with the alternative interpretations and understandings of readers.

In Cameron's discourse then, the analyses reveal a range of features used to confidently and forcefully advocate a position, projecting a distinctive identity as a radical disciplinary expert. John Swales' choices, on the other hand, convey a clear personal attitude and a strong interpersonal, rather than intellectual, connection to readers, projecting the identity of a cautious colleague rather than a combative advocate of truth. Overall, the analyses suggest that the ways we write do not simply mimic community patterns but are a means of constructing who we are, or rather, how we would like others to see us.

Review of the study

The value of a corpus in this kind of research is that it can highlight what is common and what is individual.

In this view, identity can only be understood by close analysis of the ways writers routinely draw on the rhetorical repertoires of their communities to position themselves in recognizable ways as both individuals and members of collectivities. It might be argued, however, that using corpora in this way fails to provide sufficient context to understand identity performance as it ignores the detailed biographies of interview techniques and perhaps draws instead on assumptions about the writers which are not in their texts at all. After all, we know something of these academics and their styles and I selected two of the most rhetorically aware individuals writing in applied linguistics today. Both writers are professional discourse analysts and so are highly attentive to the effects of their choices (see

It is a methodology, however, which offers a way of exploring other unanswered questions about disciplinary constraints. Do all academic writers have a relatively consistent stylistic "signature," for example, or is this something that only develops over time? Are novice writers more tightly constrained by conventions? What changes in their repertoire with greater experience and confidence? What variations exist across disciplines and between individuals in other fields? Not least it makes sense to address the wider political operation of discourse communities and to ask, with

Conclusions

Corpus studies have made a considerable contribution to our understanding of academic discourse and revealed many of the ways that writers in different disciplines, genres, and languages represent themselves, their work and their readers in different ways. In particular, they have shown that a range of features occur and behave in dissimilar ways in different disciplinary environments and underlined the importance of community, context, and purpose in writing which has helped inform EAP course design and teaching.

It is this observation about students' target needs which helps clarify future directions for research. Quite clearly we need more descriptions of the specific disciplinary genres students need to write and read. Reports, essays, articles, critiques, presentations, case notes, lectures, and so on all differ across disciplines and knowledge of their structures and salient features can demystify them for learners. As corpus research into academic genres continues to grow, therefore, we can anticipate an ever increasing broadening of studies beyond texts to the talk and contexts which surround their production and use, beyond the verbal to the visual, and beyond tertiary to school and professional contexts. Corpus studies will, in tandem with other methods, have a continuing and important role to play in this endeavor.

It is important to mention, however, that generalizing from a corpus will always be an extrapolation -it provides the evidence for interpretations about how language works. Intuitions remain in the explanations analysts bring to the data that are collected, making a corpus approach a unique combination of empirical analysis, deduction, and human sensitivity.

Register variation

Susan Conrad 1 The importance of text categories based on situational characteristics

Long before corpus linguistics was widely known, researchers recognized that texts used in different settings and for different purposes had different distributions of linguistic features. For example,

In this chapter, I use the term register as in

The next section reviews major approaches to corpus-based studies of register, providing an overview and exemplification of different approaches. A few additional details about English for Specific Purposes studies are then added in Section 3. Section 4 summarizes the overall accomplishments and challenges of work in register variation. The chapter then presents a sample study of registers within a specific subject area -civil engineering -to exemplify several characteristics and challenges in more detail.

Corpus-based approaches in studying register variation

Although register variation can be studied with many methodologies, corpus-based research is particularly well suited. A well-designed corpus can provide representative samples of registers (see Clancy 2010 on representativeness). In addition, the quantitative analysis that is typical of corpus research facilitates comparisons of linguistic features' distributions across registers and judgments about what is common or rare in a particular register.

Corpus-based studies of register variation can be analyzed along two continua based on the type of linguistic feature that is studied and the kind of text category that is emphasized

The categories identified in Figure

Emphasis on individual linguistic features

Studies in this category are designed to investigate linguistic features, with register a variable that accounts for variation in the use of the feature. These studies are thus not designed to describe registers themselves, but they provide a great deal of information about the linguistic features in different registers.

Numerous studies have used this approach. Table

Linguistic feature emphasis

The work also demonstrates that broadly defined registers have subregisters within them that correspond to more specific situational characteristics. In some cases, the effect of the subregisters is even more important than previously identified dialect differences. For example, Herring and

Grammatical features

Single registers Conditionals in medical discourse

Comparisons of registers and subregisters

Highlighting a spoken/written distinction: synthetic and analytic negation

Lexico-grammatical features

Comparisons of registers and subregisters

The verb help + full or bare infinitives

Intonation and prosodic features

Subregisters of speech Monologic vs. dialogic discourse use of low pitch

A striking example of an individual feature approach is the Longman Grammar of Spoken and Written English

Work by McCarthy and Carter also exemplifies the individual feature approach well, especially in comparing speech and writing. For example, McCarthy (1998) brings together individual feature studies of conversation, and

The individual feature approach has also been used in investigating variation across discourse units, though these studies are less common. The studies combine a genre perspective -identifying rhetorical moves in texts -with a register perspective on features used in the different moves. For example,

Emphasis on a discourse system

Studies that take a "discourse system" emphasis are generally concerned with how a certain type of meaning or function is expressed in discourse; they examine multiple linguistic features that can convey that type of meaning. For example, Nesselhauf (2010) takes a discourse system approach to studying the expression of future time, including six linguistic realizations: will, 'll, shall, be going to, be to, and the present progressive. Occasionally, a discourse system approach is used to study a more abstract characteristic, such as grammatical complexity, which

A crucial issue for investigating a discourse system concerns how to operationalize the system. That is, how will realizations of the system be identified and which realizations will be included? Although always important, this issue is especially important for corpus-based studies, which generally seek to produce more generalizable results than many other approaches and to facilitate comparisons between different corpora. One strategy is to search for discrete features known to be part of the system -as in

One especially popular area of study has been systems of stance or evaluation (including studies of metadiscourse, hedging, and engagement). The diverse studies include evaluation in two types of newspaper reporting (broadsheets and tabloids, Bednarek 2006a), stance features in spoken and written academic registers

An exemplary study for investigating a discourse system is

Emphasis on the co-occurrence of multiple linguistic features

A third major approach to investigating register variation has been to analyze the co-occurrence of numerous linguistic features, investigating their patterning across multiple registers. The purpose of this approach is to investigate the range of variation in a set of registers. The approach is dominated by the multidimensional (MD) analysis technique, introduced by

By its nature, MD analysis is a comparative approach, and since its introduction, it has been used to make comparisons of registers, subregisters, and discourse units in several ways. First, the 1988 model of variation in English has been used in studies so that specific registers can be characterized relative to a wider range of variation (Table

Table 17.2 Examples of studies using multidimensional (MD) analysis

Design

Example studies

(1) Application of

Academic registers and sub-registers

World Englishes

MD analysis is designed for large-scope comparison of registers. Like all methodologies, it cannot provide all perspectives on texts. One disappointing aspect of its application thus far is that MD analysis has rarely been incorporated with other, more qualitative techniques in research studies. Especially for educational applications, this has left implications and pedagogical applications tentative. For example, Asencio ´n-Delaney and Collentine (2011) reveal a great deal about Spanish learners' writing development by using MD analysis, but when they find a puzzling integration of features of personal involvement with features of narrative writing, they can only speculate about why. As they put it, "This involvement may be due to task requirements or to beginner-intermediate learners' tendency to produce the L2 to talk about themselves, which is typical in the Spanish curriculum" (Asencio ´n-Delaney and Collentine 2011: 319). More qualitative data analysis -such as adding interviews with the students -could offer more specific evidence of how students understand the task requirements and what their intentions were for their writing.

Register variation and English for Specific Purposes

The summary in the previous sections broke down register studies by aspects of their designs, using examples from a range of topic areas. It is also important to note that the study of register variation is central to one area of work -English for Specific Purposes (ESP). A foundation of the field of ESP is that language varies when it is used for different purposes, audiences, disciplines, etc. -the same concept that is central to register studies generally. (Of course, a genre perspective and a variety of other approaches not covered in this chapter also contribute greatly to our understanding of ESP.)

Many of the studies mentioned in Section 2 are part of ESP. However, a few additional features deserve mention. Most ESP work is concerned with academic contexts and teaching applications to improve second language students' success. Consequently, a number of studies that take an individual feature approach have focused on the development of word lists -i.e. identifying frequent words that are useful for students to learn for a certain context. The contexts have varied from a general academic context, as with

An additional purpose in some ESP studies is to compare learners with proficient speakers or writers. Table

Summary: accomplishments and challenges in register studies

Most importantly, all approaches in corpus-based register research have revealed just how important register variation is. Situational characteristics -including purpose, setting, production circumstances, mode, etc.correspond to pervasive variation in linguistic features when studied at any level of specificity. Register studies have been especially successful in describing features that differ between registers of speech and writing (especially contrasting casual conversation and academic prose) and providing more specific descriptions of subregisters of speech and disciplines of academic prose. Variation related to the function of linguistic features in subregisters has even been found to be more important than some traditional categories in sociolinguistic studies, such as gender. Studies of new electronic registers, which pose special challenges for identifying situational characteristics and categorizing texts, are being increasingly refined (see further chapters in

Delving deeper into the accomplishments of register research, however, reveals significant challenges. Some concern methodology within corpus linguistics. First, even among sophisticated scholars, register variation is sometimes ignored or described in confusing ways.

What have we learned about register variation that should be applied to better represent the variability that exists in text categories? A thorough synthesis that answers this question would be very useful to corpus linguists.

Another challenge concerns a lack of impact in other areas of linguistics. Most sociolinguistic textbooks, for example -which cover other variation in detail -do not cover register variation (see further

Many register studies are conducted in educational contexts or stem from educational needs. Despite individual teachers developing useful register-related materials, however, the impact of register research on education has been disappointing. In many countries, including the United States, register concerns are still generally considered important only in the context of ESP. A few ESL textbooks now emphasize register differences consistently (e.g.

Not every register study needs to connect to a broader theory or provide concrete teaching applications; purely descriptive linguistic studies are also valuable. However, corpus-based register studies could have far greater impact than they currently do. Integrating corpus studies with other theoretical background or other research techniques would make register variation studies more applicable to other fields. The next section provides an example for applied educational research.

Sample study: registers in civil engineering

This sample study applies

The purpose of the study is to address a widely acknowledged problem in engineering education: the mismatch between students' writing proficiency and the demands of writing in the workplace. The problem has particular significance for civil engineering, where communication has been identified as the single most important factor in infrastructure project success

The study took place at Portland State University, a regional university in the northwestern United States. Most of the civil engineering students want to be practitioners when they graduate, and many course assignments mimic practitioner contexts -for example, writing to clients to document analyses, discuss design alternatives, and argue for preferred designs. In some cases the clients are real people the students interact with; in others, they are imagined. The study focuses on reports because they are a common register and represent the most in-depth projects students undertake. In addition, the study uses a small set of academic journal articles as a comparison register; this is a register that faculty and students usually have great familiarity with, but whose audience, purpose, and setting differ from practitioner reports.

Specifically, the study addresses these research questions:

1. Relative to a wide range of registers in English, how do the linguistic features of civil engineering student reports compare to practitioner reports and academic articles? 2. Which differences between the student reports and practitioner reports are likely to be the most problematic for engineering practice?

With the answers to these questions, student writers' greatest needs could be identified and teaching materials devised to address those needs.

Methodology

Because I wanted a broad perspective on the civil engineering registers, I chose to apply Biber's 1988 model of variation in English. This methodology makes it possible not just to compare the registers to each other, but also to assess more general faculty impressions -such as the claim that students write like they speak. A drawback of this approach is that the 1988 model is dated; text messages, e-mails, and blogs are undoubtedly common registers for today's students, but they are not included in the model. Nevertheless, the 1988 model is still the broadest perspective on registers in English available today.

The corpus for the study comprises 60 practitioner reports, 60 student reports, and 35 articles from engineering research journals (Table

The study followed typical analytical procedures for an MD study. The texts were tagged for grammatical categories (with the tagger developed by Biber), features counted, and dimension scores calculated based on the normalized counts for the 1988 registers. The registers were compared statistically with a one-way Analysis of Variance, with a post-hoc Scheffe test to determine pairwise differences.

However, the study varied from typical corpus studies in its use of interview data. Previous studies have emphasized the importance of expert informants for understanding new registers, different disciplines, and the purposes of student writing

Summary of findings

To illustrate the study findings, this section focuses on two dimensions -Dimension 1: Involved vs. Information Production and Dimension 5: Impersonal vs. Non-Impersonal Style. The linguistic features for these dimensions are listed in Table

At the same time, when the civil engineering registers are compared, the differences are noteworthy. For Involved vs. Informational Style, the student reports were statistically significantly different from the professional registers, using fewer features of informational production, while the two professional registers did not differ significantly from each other. For Impersonal vs. Non-impersonal Style, the student reports were not significantly different from the academic articles, but both used significantly more features of impersonal style than the practitioner reports did. An important aspect of MD studies (and all register studies) is the connection of the quantitative findings with description of the function of the features in the registers. In this study, with respect to Dimension 1, Involved vs. Informational Production, all of the civil engineering registers reflect an informational focus and a dense packing of information with nouns, prepositions, attributive adjectives, and other negative features of Dimension 1. Student writing, however, is slightly less dense with these features, while also using slightly more of the positive features of Dimension 1. The result is a difference in the information that is expressed: more concise and precise information in the professional writing than in the student writing, with more elaborate explanations in the student writing. Consider these examples that illustrate the typical patterns in professional and student writing:

Text sample 1 (a) Practitioner report At your request, we have completed the field investigation, instrumentation monitoring, and slope stability analysis for the Green Glen Road landslide. The purpose of this report is to transmit the results of the field exploration, instrumentation results, and landslide analysis. We have also included a discussion of landslide repair options and recommendations for design and construction of landslide mitigation using horizontal drains.

(b) Student report At the intersection of 5th and Anderson in [CityName], Oregon, a pedestrian-activated crosswalk was installed during the summer of 2009 . . .. The purpose of this project is to analyze the effectiveness of the improvements to this intersection. The analysis will provide a before and after comparison of the intersection, explore the effectiveness of the improvements, and then discuss suggested alternative solutions if necessary.

The practitioners refer to precise objects in relatively long noun phrases that incorporate adjectives, prepositions and other nouns (e.g. the field investigation, instrumentation monitoring, and slope stability analysis for the Green Glen Road landslide and recommendations for design and construction of landslide mitigation using horizontal drains). Such noun phrases are typical for the academic professional writing, too. Students use similar features, but the frequency is lower, corresponding to slightly less specific references (e.g. a pedestrian-activated crosswalk and suggested alternative solutions). Furthermore, professionals tend to coordinate noun phrases while students use more clauses; in this example, the practitioners have completed the field investigation, instrumentation monitoring, and slope stability analysis, while the students will provide, explore, and discuss. Although practitioners tend to use slightly more first-and second-person pronouns (a feature of involved production), the students tend to use other features of involved production with a much greater frequency than practitioners. This is especially true of subordinate clauses with because and wh-clauses. Often these structures occur as students describe purposes and reasoning behind procedures: In order to properly treat and remove bacteria and contaminants, we must first determine what exactly is in the water and at what concentrations.

To some extent, it appears that the students' different language choices reflect their school context. It is not surprising that their noun phrases are less technical as they are still learning engineering, or that they justify their reasons more explicitly when they know instructors are grading their understanding. However, the students' less informationally dense language is also, at times, not entirely accurate. For example, in text sample 1, the students state that the analysis will provide a comparison, explore the effectiveness, and discuss alternative solutions -but the analysis itself cannot discuss effectiveness or other solutions.

Along Dimension 5, the student reports and academic articles are similar in using a high frequency of passive structures, conjuncts, and other adverbial subordinators (the positive features in Table

Text sample 2 (a) Academic article (passive voice in italics)

When comparing the behavior of the strips and bar mats, it was observed that the barrier displacement was about the same but the panel displacement was about three times less for the bar mats than for the strips.

(b) Student reports (passive voice in italics)

Pedestrian activity was noted near the intersection of X Ave, Y Ave, and Z Ave. The width and unusual geometry of Z Ave made pedestrian crossings difficult. It was recommended that some form of pedestrian improvement was necessary to increase the safety of crossings.

(c) Practitioner reports (passive voice in italics, active voice + animate subject in bold)

We drilled four borings on July 5, 2007, using a CME-75HT, truckmounted drill rig using hollow-stem auger drilling techniques. Three of the borings (BH-1 to BH-3) were drilled within or near the footprint of the proposed power generation building and BH-4 was located near a corner of the control building (Figure

We observed pavement and curb cracks near the intersection of Front Avenue and 47th Street . . . Due to slope stability considerations, we recommend that hillside excavation and wall construction be completed during the dry season . . .

In their passive choices, student reports look very much like academic articles, where agents are unimportant and assumed to be someone in the research group. Practitioners tend to state themselves as the agent in observations, recommendations, and the beginnings of methods. In addition, student reports and academic articles also use more adverbial subordinators, creating complex sentences where practitioners tend to have simpler sentence structure. Many student sentences contain multiple subordinated ideas:

Text sample 3: Student report (subordinators in italics; other embedded structures are part of other dimensions) Designing the bridge to be an attraction for the garden as well as meeting ADA accessibility requirements is a priority since the longterm plan calls for widespread accessibility improvements to be implemented such that all may enjoy the beauty that the garden has to offer.

Many long student sentences have a stream-of-consciousness appearance, as though one idea just led to another during the drafting of the report and the initial draft was never revised thoroughly.

To illustrate the usefulness of the interviews, I cover just a few of their many contributions. In the practitioner interviews, the link between language use and successful engineering practice was a consistent theme. Their prime concerns were precise and accurate meaning, a lack of ambiguity, and ease of reading for clients. They saw these characteristics as necessary for conveying engineering content, maintaining client satisfaction, and managing firms' legal liability. Thus, the dense, specific noun phrases, the shorter sentences with fewer subordinate clauses, and active voice sentences are all tied to the practice of engineering. The active voice and first-person pronouns for observations, recommendations, and procedures were repeatedly noted as important because they overtly established the firm's responsibility, one way of preventing unintentional liability. Students' multiple ideas in sentences, absolute use of passives, and inaccurate meanings were all identified as serious problems for the practice of engineering.

For the student interviews, the single most important contribution concerned a belief that emerged when students were asked, based on their experience, to speculate about reasons for the study findings. Three-quarters of the interviewees immediately stated a belief that longer is better. In the words of some of the students: I kind of felt like I had to sound professional and smart. I mean, you want to sound really knowledgeable about things, and it seems like the easiest way to do that is to be wordy. It looks better if it's longer. I think it's that simple. Make it fancy. This belief influenced their use of features for both dimensions summarized here. More clausal elaboration, more subordination, and more passives all contributed to longer, fancier sentences. For these students, the problem does not concern revising; it concerns their understanding of writing. They do not consider language as having an impact on content and liability, or on readers' ease of finding information. In fact, in the majority of interviews, students made no connection between engineering content and writing. They identified engineering content as something found in calculations. Writing had to do with stylistic rules learned in English composition or technical writing classes; it provided a way to give an impression of being knowledgeable through wordiness.

From the MD analysis alone, the research team would probably have developed useful materials targeting students' language needs, such as how to choose between active and passive voice and how to revise for precise content in shorter sentences. With the greater understanding from the interviews, however, we have additionally addressed students' underlying misconception that writing should sound fancy and has nothing to do with accurate engineering content. The MD analysis combined with the interviews thus not only provides information for understanding the registers as linguistic entities, but also for addressing the educational problem underlying the study.

Conclusion

As discussed in Section 4, register research has shown that register variation is a central concern for understanding language use. Work needs to continue to describe its importance to other linguists and to other fields where communication skills are central. Section 5 provided a brief example to illustrate the benefits of supplementing register analysis with qualitative research techniques. The combination allows for more specific applications than register analysis alone, and gives a study greater credibility among content specialists, who would otherwise be understandably skeptical of a linguist's understanding of their field. With connections like this to other fields, more integration with theoretical perspectives, and continued descriptive linguistic work, the importance of register variation can become more widely appreciated in the future.

18

Diachronic registers Merja Kytö and Erik Smitterberg 1 Introduction

The present chapter discusses the concept of register from a diachronic perspective. The terms "register" and "genre" have been used as cover terms for categories of text that are grouped together based chiefly on text-external criteria such as functions, audience expectations, and presentational conventions (see

The present chapter is structured as follows. In Section 2, an initial survey demonstrates the importance of the register factor in historical corpus linguistics and introduces a number of central matters that arise when the concept of register is applied to diachronic material. These matters include attempting to achieve comparability and representativeness, two important but sometimes mutually exclusive goals. Furthermore, we discuss the challenges that researchers face regarding the absence of, or the dearth of texts from, some registers during part of the recorded history of a language. As regards spoken language, attention is paid to the extent to which the spoken interaction of the past can be approached via speech-related registers such as drama and court records.

After this survey, we provide a more detailed examination of a selection of studies of language variation and change. We begin by considering detailed studies of single linguistic features whose distribution changes over time in specific registers or in ways apparently conditioned partly by register variation. Attention is also paid to studies that chart the development of a large number of linguistic features as they occur in different registers. The discussion of individual studies leads to an account of two important trends that have been identified in recent research on registers, viz. colloquialization and densification.

In Section 4, we provide a more in-depth account of one study where careful consideration of the register parameter has led to new insights into language variation and change:

Initial survey

As

The register parameter can be taken into account in two ways in diachronic investigations. In one approach, several different registers are sampled for each period analyzed, and the aim of the analysis is then typically that the corpus should be representative of a language variety so that studying the corpus "can stand proxy for the study of some entire language or language variety"

Representativeness versus comparability in historical corpora

In this section, we discuss how two of the central desiderata in corpus linguistics apply to historical registers: representativeness and comparability. As we shall demonstrate, compiling representative and comparable (sub) corpora poses particular problems in historical linguistics; in addition, one of the desiderata may have to be sacrificed in order to achieve another.

A synchronic or diachronic corpus is representative to the extent that the study of that corpus can replace the study of the textual universe it represents. Depending on which of the two perspectives mentioned above is used, the textual universe may comprise an entire language variety or specific registers in that variety. There currently appears to be no generally agreed-upon way of operationalizing this variable.

However, both Biber's and Leech's approaches to representativeness may lead the linguist into difficulties when s/he is confronted with historical material. Most obviously, several important registers -including the 90 percent of language use that

The difficulties outlined above arguably make the register parameter even more important in historical corpus linguistics than in studies of Present-day English. If the aim is to represent a whole language variety, ensuring that appropriate registers are included in the corpus is one of the ways in which historical corpus linguists can enhance the representativeness of corpora. Including a wide range of registers and ensuring that they are proportionately represented in a corpus help to make such a corpus balanced, which improves representativeness

Many historical studies within corpus linguistics are also diachronic in that the researcher wishes to study language use in two or more periods to see whether any differences over time that can be interpreted as language change are attested in the material. This, however, means that another desideratum of corpus composition must be considered, viz. comparability. Two corpora (or two samples of the same corpus) are comparable if they differ "in terms of only one parameter"

Moreover, whether the aim is to capture a register or a variety, the fact that registers change over time will affect corpus compilation.

Moreover, even if a register has not changed dramatically in itself, its place in the sampling universe may have done so: other registers may have taken over some of its functions, or the register may have increased or decreased in importance for other reasons. The private letter in British English is a case in point. While the register has clearly existed since the Middle English period, sociopolitical and technological change has meant that its place in the typology has varied extensively during this time. Before the introduction of the Penny Post in 1840, the expense of postagea minimum of 4d., paid by the recipient of the letter -kept down the number of letters that were sent; in other words, several topics that would have been discussed in the form of a private letter after 1840 were either not communicated at all or communicated within the scope of another register (e.g. conversation the next time the interactants met). Conversely, in 2013, the availability of alternative channels of communication such as e-mail and Facebook messaging has drastically decreased the communicative role played by letter writing. Even registers with a great deal of diachronic stability, such as religious writing, are subject to change in this regard.

Registers may also differ in how homogeneous they are. Some registers are characterized by considerable linguistic homogeneity, something which may have developed over time; see, for instance, Go ¨rlach's (

Register heterogeneity becomes important when registers are sampled for diachronic corpora. If the corpus compiler or user has reason to suspect that a given register is linguistically heterogeneous, measures need to be taken to make period samples of the corpus comparable in this regard. If this aspect is not controlled for, a linguistic difference between two period samples may be interpreted as language change when in reality it is due to register-internal variation. There are different ways to control for this factor. One is simply to sample a larger number of texts, which will make it statistically more likely that the full range of internal variation is present in each period sample. Another possible solution is to stratify the register into those component subregisters that are assumed to cause the variation. If the relative importance of different subregisters has varied in diachrony, the question arises whether or not such fluctuations should be taken into account in the compilation and exploitation of corpora. For instance, it is likely that monographs occupied a more prominent place compared with journal articles in the Natural Science register in the 1800s than in the late twentieth century. If the goal is to represent Natural Science as a register at different points in time, this distinction would need to be taken into account so that different proportions of monographs and articles are sampled for the two centuries; but if the aim is to make the period samples comparable, such differences would not be reflected in sampling.

Register representation across time

There are several extralinguistic factors that influence the availability of registers for research through the history of English. If the period coverage of a study is considerable and a great deal of societal or politico-cultural change has affected language users during that time, it is likely that registers will have gained new features and conventions, developed into other registers, been replaced by new registers, or fallen into oblivion; such shifts affect the comparability of period samples. Registers may also disappear at a certain point in the history only to re-emerge later on; for instance, legal texts in English, which are represented in the Old English period (c. 850-1150), reappear towards the end of the Middle English period, after a gap of several centuries during which Latin and French were used instead

There may also be variety-specific differences in register representation. For instance, the investigation of differences between language use in a mother country and its early transplanted colonies is a fascinating topic for research. However, circumstances of life in the colonies tended to promote utilitarian registers such as record keeping and letter writing, leaving less room for literary tradition and registers such as fiction and drama

The question of literacy constitutes a serious problem hampering the textual coverage in historical corpora: the further we go back in history, the fewer individuals could read or write. This is one of the factors contributing to the underrepresentation of texts by female authors and speakers from low socio-economic groups. Registers displaying writing habits of those with little or no formal education are valuable sources for the study of dialectal variation and language change; for instance, spelling variants produced by untutored writers can display features of early pronunciation. While spelling variation is a problem in advanced corpus linguistic analyses using historical material (e.g. keyword analysis), texts are increasingly being normalized by the application of semi-automatic techniques (e.g. VARD 2 = Variant Detector 2; see www.comp.lancs.ac.uk/~barona/vard2/;

A related issue concerns the form in which texts from various registers are available for inclusion in corpora: as manuscripts or in the form of text editions. Using fresh manuscript material for corpus compilation is a timeconsuming enterprise: in-depth philological and computational work is often required to transfer the manuscript readings into searchable computer files. However, if text editions are used, the editorial choices made must be taken into account when the suitability of an edition for linguistic research is assessed, as "the edited text may have been altered in various ways for reasons such as facilitating the text for a particular audience whose main concern is not the language but the content of the text or other characteristics"

Speech-related registers: bad data?

One fundamental problem in the study of language change of past periods is that the material has been preserved in writing. While the study of changes unique to the written language has received a great deal of recent scholarly interest (see, for instance, Biber and Gray 2011), it remains true that a great deal of linguistic change has taken place in speech, and notably speech used in dialogue situations

Even when the ultimate aim is to say something about the spoken language of the past, written texts thus play an important role in register comparison. According to

Examination of specific studies

In this section, we will discuss a number of studies that represent prominent aspects of diachronic research from a register perspective. While some of the studies selected study variation among several registers, others focus on the language of a single register. In our discussion, the main division is that between studies that focus on a single linguistic feature and studies that consider the occurrence of a large number of features in the same texts. While the single-feature approach is, in principle, feasible based on the manual use of non-electronic material, the multifeature perspective requires access to electronically stored texts and to software such as search programs.

Single-feature approaches

Impressive research on individual linguistic features was carried out in historical English linguistics even before the advent of electronic corpora. Some notable studies based on non-electronic material compared the incidence of linguistic features in several registers; for instance, Ryde ´n and Brorstro ¨m (1987) compare comedies and letters in their analysis of the variation between BE and HAVE as perfect auxiliaries. Other studies based on manually collected material focused on the distribution of the relevant feature in a single register; indeed, sometimes the language of a single author was examined.

The extension of the corpus-linguistic paradigm to past stages of the English language has increased the attention given to sampling issues in the above regard. Kyto ¨and

In

Multi-feature approaches

The studies exemplified so far have all focused on what can be called single linguistic features. An alternative approach to register variation is to consider the occurrence of a large number of linguistic features as they cooccur in texts (see also Chapter 17). Such an approach requires access to computerized material, as time limitations make it nearly impossible to retrieve several different linguistic features from the same printed or handwritten documents. The computerized texts are typically also annotated to facilitate the retrieval of grammatical categories. As was first shown in factor analyses of Present-day English such as

Extending the scope of multidimensional analyses to address historical register variation was a natural next step. In one such analysis,

From a register perspective, it is clear that multi-dimensional techniques have a great deal to offer historical corpus linguistics. One desideratum for future research on historical registers would be not only to carry out new factor analyses, but also to start out from period-specific lists of linguistic features. One of the most important findings revealed by multi-dimensional historical register analysis is the existence of longterm trends in usage. As mentioned above, popular and specialist registers have followed different paths in this regard, leading to increased register differentiation in diachrony. The next section will be devoted to two of these trends and their significance for historical register analysis.

Register drift

Scholars have recently become interested in identifying types of linguistic change that span large periods of time. This section briefly discusses two such trends in English written registers over the past few centuries: colloquialization and densification.

During roughly the same time span, a trend towards densification has been noted in several registers. Densification can be defined as an increase in information density; that is, more information content is expressed using a given number of words

Thou vs. you across three registers in Early Modern English

As the language use of past periods can be expected to pattern along the register axis as it has been shown to do today, it is difficult to ignore the role played by registers in a corpus-based study of language change. Our linguistic feature selected to illustrate the influence of the register factor is the rivalry of the second-person singular pronouns thou and you in the Early Modern period when you forms expanded at the expense of thou forms. Regarding data collection, speech-related texts offer a particularly rewarding area. As mentioned in Section 2.3, the juxtaposition of several written registers with a relation to the spoken language can give us insights into the nature of past speech.

In her study based on A Corpus of English Dialogues 1560-1760 (CED),

Looking at the dimensions of Walker's study, the texts examined totaled 400,000 words (trials: 100,000 words; depositions: 150,000 words; drama comedy: 150,000 words). Altogether close to 10,000 instances of thou and you forms were included in the study. As only singular uses of you were included in the analyses (to establish the tertium comparationis), plural uses had to be screened from the data manually; subjective, objective, and possessive determiner/pronoun uses of both forms were included in the study. Like many other studies,

On the basis of these results, Walker's task was then to show how the change proceeded across the 200-year period (stratified into five 40-year subperiods) in the light of the register and other factors, extralinguistic and linguistic. One of her hypotheses based on previous literature was that the extralinguistic factors would influence the pronoun selection to a greater extent than the linguistic factors (the pronoun forms and their functions, closed-class vs. lexical verbs, modal vs. primary verbs, and public vs. private verbs). Differences between the registers were also expected as well as the decline of thou. All these hypotheses were verified in the study. As regards differences between registers, trials displayed "a marked decline after 1600"

Walker's study is a good example of a diachronic corpus-based investigation where the author needs to consider the special nature of his or her data and carefully assess the reliability of the data sources used. A desideratum for future research would be to incorporate all factors considered by Walker into a multifactorial analysis such as logistic regression.

Concluding remarks

This chapter has highlighted the growing recognition of the crucial role played by the register parameter in historical corpus linguistics. These advances have of course been made in large part by building on important pre-computerized work on language history. Research has shown that register is one of the many extralinguistic categories which lie behind the linguistic variation that is a prerequisite for language change. Moreover, careful studies of variation in the history of English based on pre-computerized text collections demonstrated the importance of taking the register parameter into account; for instance,

However, as we have also tried to show, applying the register concept to historical stages of languages is not without complications. Not all languages are equally well represented in different registers throughout their history. Even though English, which has been our main focus in this account, does relatively well in this regard, there are conspicuous gaps in register coverage (see, for instance, the comparison of German and English with regard to early legal texts in Section 2.2). Moreover, potentially conflicting desiderata such as comparability and representativeness make it necessary for scholars to consider carefully the make-up of their corpora and the extent to which results based on a selection of registers can be generalized to the language as a whole.

Future advances in historical corpus linguistics are likely to have theoretical as well as practical effects on how scholars use registers. Challenges involved in applying the register concept across time have recently been analyzed critically in several studies. For instance,

Corpora

Literary style and literary texts

Introduction

According to

Corpus stylistics is the study of literary texts that employs corpuslinguistic methods to support the analysis of textual meanings and the interpretation of texts. As such, corpus-stylistic research makes it possible to focus on individual texts and even text extracts -as the places where the aesthetic effects of language are best analyzed

To delimit the object of study for corpus stylistics it might be more useful to refer to "meanings in literary texts" than "literary style." The term "style" is used in a range of different ways. To talk about "literary style" seems to imply a clearly discernible variety that can be defined as "literary language" -in contrast to non-literary language. Typically, literary use of language is seen as creative. However, creativity is also found in "ordinary" language and literariness is best seen as a matter of degree

The present chapter begins by situating corpus stylistics within the context of corpus linguistics (Section 1) and computational stylistics (Section 2). The relationship between corpus stylistics and literary stylistics will mainly be highlighted through the discussion of examples

Literary texts in corpora: register and style

Literary texts in corpora tend to be analyzed from a "register" perspective so that features of literary texts are compared to features of other varieties of the language.

Focusing on novels,

A register rather than a style approach to literary texts reflects the aims of corpus linguistics to find generalizations -based on large collections of texts -about the way in which language is used in a range of contexts. Such generalizations are captured in dictionaries, grammars, and textbooks on the use of language. If the data contain examples that occur just once, or patterns that occur repeatedly only because they are all from the same text, these cases will usually be discarded in the search for general patterns. While the purpose of the analysis of texts may vary between corpus linguistics and studies interested in style, the methods, however, can still be similar.

Literary computing and computational stylistics

The application of quantitative, computational, or computer-assisted methods to literary texts has a long tradition. It can be situated within the much wider field of the digital humanities that is concerned with methods of computing to preserve, process, and make accessible a range of media and artifacts. Corpus approaches to literary texts are specifically related to work in the area of literary computing or computational stylistics. In his outline of computational stylistics,

Early applications of computer methods in the study of literature include the compilation of concordances. In reviews of historical developments in corpus linguistics, reference is often made to the fact that concordances are not an invention of corpus linguistics, but have been used in the study of literature even before computers existed, for instance, to compile concordances of the Bible or of works of Shakespeare. While in corpus linguistics concordancing has become a mainstream method, in literary criticism it does not seem to play a major role. I will return to methodological issues below.

From a literary point of view, the existence of the journal titles like Literary and Linguistic Computing or Computers and the Humanities may be regarded as a reflection of the specialist nature of literary computing. "

The computer-assisted study of textual features often takes the form of computational stylistics "in which all the most common words . . . of a large set of texts are subjected to appropriate kinds of statistical analysis"

Stylistic studies that are concerned with the variation of a set of features across texts are similar to studies in corpus linguistics that investigate register variation with the help of statistical methods (see

It is a truth not generally acknowledged that, in most discussions of works of English fiction, we proceed as if a third, two-fifths, a half of our material were not really there.

Beyond the immediate interest into patterns in Jane Austen's work,

He draws attention to the fact that the distinction between literary and non-literary language cannot be a clear-cut one

Approaches to corpus stylistics

The previous sections have argued that corpus stylistics relates to both corpus linguistics and computational stylistics through its quantitative methods. At the same time it is set apart from these fields through its intrinsic explanatory purpose that makes it possible to focus on specific meanings in texts. In this sense, corpus stylistics requires engagement with concepts that address properties and interpretations of literary texts. In the following I want to look at four studies that exemplify principles relevant to corpus stylistics. These approaches extend or develop categories for the analysis of literary texts and/or show how corpus methods are relevant to the study of textual meanings.

In the course of their study,

Another book-length contribution is

Coming from the corpus-linguistic end of the spectrum,

With his study of Conrad's Heart of Darkness,

Methods in corpus stylistics

Corpus-stylistic methods often draw on the standard functionalities offered by concordance packages to retrieve frequencies, study words in the form of concordances, generate collocations (e.g.

Importantly, different methods are suited to different types of texts or different analytical aims.

If corpus methods are not sufficiently tailored to the research question, their usefulness is limited. Amador-

Corpus studies of literary texts often aim to demonstrate the "usefulness" of a particular methodology.

Overall, corpus-stylistic methods are characterized through the tension between qualitative and quantitative techniques. This tension is determined by the text(s) under analysis. Studies that employ corpus-linguistic methods to demonstrate the working of a method make selective links to literary critical arguments. This allows them to focus on the quantitative over the qualitative. While making a programmatic contribution, from the point of view of literary stylistics they only tell part of the story. On the other hand, studies that begin with research questions situated in literary stylistics may less readily be able to draw on automatic procedures, as is shown by

The state of the art

Because of the range of questions that are generally reflected by definitions of style and approaches to literary language, corpus research in this area can take a variety of forms. Importantly, the study of literary texts seems to be best approached through a combination of methods that makes it possible to find links between literary and linguistic concerns. The term "corpus stylistics" can be used to emphasize an intrinsic explanatory goal of stylistics that is concerned with the meaning of individual texts. Even if the goal is to focus on specific meanings in texts, these texts still need to be seen against more general patterns of the language. Computational stylistics in particular highlights the role that frequent words play in creating subliminal patterns in texts. This focus is closely related to key concerns in corpus linguistics showing that frequent patterns are not necessarily those that language users are aware of. Such frequent patterns also reflect the relationship between linguistic features of registers and the situational contexts of language production.

Corpus approaches to literary language contribute to showing that the relationship between literary and non-literary language is not a clear-cut one. This relationship is addressed by questions about what linguistic features are best regarded as register, genre or style features, but also by testing models originally designed for the analysis of literary texts on a larger corpus. In this sense, research contributes to finding a description of the language that accounts for both literary and non-literary languagenot by means of different sets of categories but along a continuum.

With the focus on textual meanings, limitations of the application of corpus methods are highlighted. Effects that readers perceive may not clearly be linked to countable features. Hence, it is important to combine corpus methods with other approaches to the effects of texts; these can, for instance, include psycholinguistic approaches to gain a better understanding of how meanings are actually created in the reader's mind

If corpus stylistics aims to pay attention to a literary text not only as a sample of language but also as a work of art, the relevance of this research for the discipline of literary studies has to be made clear.

An example: studying patterns of characterization in Dickens

This section draws on

The main corpus method to address the overarching research question of the study is the analysis of clusters. This approach results from a combination of corpus-linguistic and literary arguments. Habitual phrases or specific character idiolects have been identified as important means of characterization in Dickens, hence clusters appear to be a useful starting point. At the same time, corpus linguistic studies show that very frequent clusters (more commonly referred to as "lexical bundles") are associated with discourse functions and so become important textual building blocks. From both perspectives the underlying assumption is that repeated occurrences of sequences of words reflect their functional relevance in a specific text or a register more generally. The concept of "local textual functions" allows a combination of both corpus-linguistic and literary perspectives in the analysis of clusters. Local textual functions describe the meanings of linguistic items in texts. They are local in the sense that they do not claim to capture general functions, but they account for specific (groups of) items and/or specific (groups of) texts.

The more specific corpus tools and methods that are employed comprise relatively basic techniques: the retrieval of clusters, key comparisons, concordance searches, and the identification of (significant) collocates. The major steps of the study are:

1. The retrieval of five-word clusters in a 4.5-million-word Dickens corpus and their key comparison with a nineteenth-century reference corpus. 2. The identification of groups of clusters initially on the basis of formal features (e.g. clusters that contain body-part nouns are grouped together as "body-part clusters," or clusters that include first-or second-person pronouns are collected in a group referred to as "speech clusters"). 3. The different groups of clusters are analyzed more qualitatively in order to describe their functions in the creation of fictional worlds. This functional analysis also takes account of distributions across Dickens's texts and the nineteenth-century reference corpus and hones in on detailed textual examples discussed mainly from an intrinsically explanatory point of view. Especially in step 3, the analysis requires engagement with approaches in literary stylistics and Dickens studies. Methodologically, the working of the corpus-stylistic circle here means I tried to find links between the patterns that emerged from the corpus and the discussion of related examples or relevant theories in the literature on Dickens.

The study identified five groups of clusters that are associated with groups of meanings in the fictional world: in addition to clusters that refer to time and place, local textual functions specifically describe the creation of characters through their speech and body language, but also through the narrator's comments on their behavior and actions. Other patterns refer to ways of talking about characters that may or may not include names. The results indicate that local textual functions are best described along a cline of highlighting and contextualizing functions: some patterns strikingly emphasize character information, while others present the information more subtly and integrated into the wider picture of the fictional world. Added to the comparisons with fiction written by other nineteenth-century authors, this functional continuum indicates a relationship between Dickens-specific techniques of characterization and more widely used patterns.

The approach is initially limited to the focus on five-word clusters, i.e. it does not systematically take into account three-or four-word clusters or even non-contiguous sequences, which would all have added to the functional variety and can be studied in future work. Also from a computationalstylistic point of view quantitative information is assessed only in a basic way. However, at the same time, this narrow corpus-methodological focus makes it possible to systematically complement the quantitative findings with a detailed qualitative analysis. The critical engagement with approaches in literary stylistics as well as Dickens studies is a strength of the approach. Links are made, for instance, with cognitive poetics, approaches to body language in literature, or impoliteness in spoken language. Instead of providing a range of methods and linguistic examples to demonstrate the usefulness of corpus stylistics more generally, the study creates a coherent argument for a theoretical approach to characterization in Dickens. Crucial for this theoretical argument is that characterization is seen as a process in the reader's mind where information provided in the text interacts with knowledge about people in the real world

The text-driven approach complements and develops approaches in literary criticism. It shows that habitual phrases associated with characters that have been extensively discussed by critics are part of a bigger picture. They belong to a range of patterns and textual functions for the presentation of character information. The text-driven approach also helps to show relationships between seemingly opposing critical arguments, which is shown through the detailed discussion of

Beyond Dickens, the study extends the stylistician's toolkit. In contrast to discourse presentation, body language in literature is still an underexplored area to which this study contributes by suggesting lexically driven categories of body language presentation.

Conclusions

This chapter has shown that corpus approaches to the study of literary style can take various forms. The variety of approaches is due to the fact that literary texts can be treated both as examples of language that are part of a register, as well as individual works of art to which the reader responds in a literary way. The more corpus approaches are interested in the literary quality of texts and intrinsic analytical goals, the more these approaches have to become interdisciplinary. Computer-assisted methods as such do not result in interpretations and the provision of data and tools alone does not convince the literary critic that the corpus linguist has something to say. In spite of the challenges that cross-disciplinary research poses, maybe now is a particularly good time for corpus stylistics? Literary stylistics has witnessed a cognitive turn that puts more emphasis on the position of the reader in the creation of meaning. In the reading process patterns in the text determine which area of background knowledge or previous experience are relevant to the creation of meaning. Hence there are obvious points of contact for cognitive-stylistic and corpus-linguistic approaches. At the same time, it seems in literary criticism close reading has started to receive more attention again. Additionally, the growing number of digitized texts is likely to increase the interest in methods of studying electronic versions of literary texts. Even more fundamentally, however, the corpus-linguistic study of language has great potential not only to show differences between literary and non-literary language but to shift the focus to the similarities between the two.

20

Dialect variation

Jack Grieve

Introduction

Relatively little research on dialect variation has been based on corpora of naturally occurring language. Instead, dialect variation has been studied based primarily on language elicited through questionnaires and interviews. Eliciting dialect data has several advantages, including allowing for dialectologists to select individual informants, control the communicative situation in which language is collected, elicit rare forms directly, and make high-quality audio recordings. Although far less common, a corpus-based approach to data collection also has several advantages, including allowing for dialectologists to collect large amounts of data from a large number of informants, observe dialect variation across a range of communicative situations, and analyze quantitative linguistic variation in large samples of natural language. Although both approaches allow for dialect variation to be observed, they provide different perspectives on language variation and change. The corpusbased approach to dialectology has therefore produced a number of new findings, many of which challenge traditional assumptions about the nature of dialect variation. Most important, this research has shown that dialect variation involves a wider range of linguistic variables and exists across a wider range of language varieties than has previously been assumed.

The goal of this chapter is to introduce this emerging approach to dialectology. The first part of this chapter reviews the growing body of research that analyzes dialect variation in corpora, including research on variation across nations, regions, genders, ages, and classes, in both speech and writing, and from both a synchronic and diachronic perspective, with a focus on dialect variation in the English language. Although collections of language data elicited through interviews and questionnaires are now commonly referred to as corpora in sociolinguistics and dialectology (e.g. see

2 A review of corpus-based dialect studies

National dialect variation

The earliest corpus-based dialect studies were concerned with national variation. The first modern corpus, the Brown Corpus

In addition to these American and British corpora, the Kolhapur Corpus of Indian English

Apart from these Brown-style corpora, the International Corpus of English (ICE;

In addition to the Brown and ICE corpora, the much larger British National Corpus (BNC; Burnard 1995) and the Longman Corpus of Written and Spoken English (LCWSE;

Regional dialect variation

As opposed to national variation, there has been a limited amount of corpus-based research on regional dialect variation. The earliest collection of regional dialect speech was the Helsinki Dialect

Corpora of naturally occurring speech have only recently been used for regional dialect studies. The spontaneous spoken section of the BNC contains some regional information, which, although it has been criticized for reliability

One of the most well-known and extensively studied regional dialect corpora is the Freiburg English Dialect Corpus (FRED;

Although most corpus-based research of regional linguistic variation has focused on speech and on Great Britain, recent research on regional variation in written American English has been based on the 26-millionword Corpus of Written American Regional Dialects (WARD; Grieve 2011;

There have also been a limited number of corpora with regional data compiled for other European languages, although they have not yet been the subject of regional dialect studies. Most notably, the 10-million-word corpus of spoken Dutch, Corpus Gesproken Nederlandse (CGN)

Historical dialect variation

In addition to national variation, one of the more successful applications of the corpus-based approach to dialectology is in the field of historical sociolinguistics. Because historical writings are the only source of direct empirical data about language from before the twentieth century, historical sociolinguistics has naturally adopted a corpus-based approach to data collection, showing that complex patterns of historical dialect variation can be observed in written sources.

In the earliest systematic study of historical social dialect variation,

Perhaps the most notable historical dialect corpus is the Corpus of Early English Correspondence (CEEC;

In addition to the CEEC, the diachronic component of the Helsinki Corpus (Kyto ¨1996), which covers Old, Middle, and Early Modern English, and the ARCHER Corpus

Historical dialect atlases have also been based on corpora of written language. In particular, both The Linguistic Atlas of Older Scots (1380-1500)

Social dialect variation

Although corpus-based studies of national and historical dialect variation are common, corpus-based studies of synchronic social dialect variation, involving extralinguistic variables at such as gender, age, class, and ethnicity, which are at the core of variationist sociolinguistics

The corpus that has probably been the subject of the greatest number of studies of social dialect variation is the BNC, which is coded for a variety of demographic information, including age, gender, education level, and class. For example,

As well as the BNC, other major national corpora have been the basis of social dialect studies. For example,

In addition to dialect studies that are based on general corpora, there are a growing number of dialect studies that are based on corpora built specifically for social analysis. One of the most well studied of these corpora is the Corpus of London Teenage Language (COLT;

The relationship between class and linguistic variation was also analyzed in

In addition to spoken corpora, written corpora have also been used to analyze social dialect variation, especially computer-mediated communication. For example,

Similar corpora have also been analyzed in author-profiling research in forensic linguistics and natural language processing, where the social background of authors, especially their gender and age, is predicted based on the values of linguistic variables, including the relative frequency of parts-of-speech and function words (e.g.

Summary

Although dialect studies based on corpora of naturally occurring language are far less common than studies based on elicited language, corpus-based studies have made many important contributions to the field in a relatively short time. Two general sets of findings stand out as being particularly important. First, corpus-based studies have shown that dialect variation exists across a wide range of different varieties of language, including forms of written and standard language, where dialect patterns had never been sought or even believed to exist. Corpus-based studies have therefore shown that dialect variation is far more common than had previously been assumed.

Second, corpus-based studies have shown that dialect variation can involve a much wider range of linguistic variables than is generally analyzed in dialectology and sociolinguistics. Traditional dialect studies have tended to focus on alternation variables, which are measured as the frequency of individual linguistic forms known as variants (e.g. segments, words, grammatical constructions) relative to the frequency of all synonymous linguistic forms in a sample of discourse

In addition to looking at new types of linguistic variables, corpus-based dialect studies have tended to focus on quantitative grammatical variation to a far greater extent than traditional dialect studies. In part, grammatical variation has been underresearched in traditional dialect studies because it is difficult to define legitimate grammatical alternation variables (see

3 Dialect variation and change in not contraction in American letters to the editor

Research goals

In addition to reviewing previous corpus-based dialect studies, this chapter presents an analysis of dialect variation and change in not contraction in a corpus of American letters to the editor. In particular, the goal of this analysis is to compare not contraction across years, genders, and regions in the WARD corpus, which was introduced earlier in this chapter. In previous studies (e.g. Grieve 2012; Grieve et al. 2011), regional variation has been identified in this corpus, including regional variation in not contraction

Corpus

The WARD corpus (see Grieve 2011) was compiled by downloading letters to the editor published between 2000 and 2010 in major regional newspapers from across the United States. The letters were then sorted based on their author's place of residence, as listed in the bylines of the letters. City subcorpora were then created for the 206 cities whose residents contributed at least 30,000 words of text. In total, the WARD corpus contains 26,573,826 words, spread across 159,181 letters, written by 130,659 authors -which is a far larger sample than would be possible if traditional methods for data collection had been applied. Each letter is also annotated for its date of publication, facilitating the analysis of temporal variation in this corpus. The analysis of gender, however, is more complicated, as direct information about the gender of the authors of letters is not normally made available by newspapers. In order to analyze gender variation in this corpus, the gender of the author of each letter was predicted based on their first name, as listed in the byline of the letter. To this end, a list of the most common male and female forenames was obtained from the US Census Bureau, including the percentage of the male and female population with those names. The two lists were then cross-referenced and the unique male and female names were extracted. Based on a manual analysis of the remaining ambiguous names, it was clear that many of these names (e.g. Adam, James, Mary, Patricia) were hardly ever used by the other sex. A conservative cut-off percentage was therefore set and names that were predominantly male or female were also extracted. The other 195 ambiguous names (e.g. Pat, Shelby) were excluded from both lists. In total, this process identified 1,002 predominantly male names, and 3,965 predominately female names. The letters for each city were then sorted by gender based on these names. Letters totaling approximately 15 million words were identified as having been written by men and letters totaling 8 million words were identified as having been written by women. Letters totaling approximately 4 million words could not be identified due to ambiguous names, rare names, or joint authorship.

Not contraction

Four forms of not contraction were analyzed for this study: BE not contraction, HAVE not contraction, DO not contraction, and MODAL not contraction. Each of these variables were measured as the percentage of contracted not in a given corpus. This percentage was calculated by dividing the number of occurrences of contracted not following one of these four verb types by the number of occurrences of contracted not following one of these four verb types plus the number of occurrences of full not that could have been contracted following one of these four verbs types, and by then multiplying this value by 100. For example, if a corpus contains 80 tokens of the words do/does/did followed by the full form of the word not and 20 tokens of these verbs followed by the contracted form of the word not, then the DO not contraction rate in that corpus is 20 percent.

Temporal variation

To analyze change in not contraction over time, the values of the four not contraction variables in letters from 2002 to 2008 are plotted in Figure

Gender variation

To analyze gender variation in not contraction, the values of the four not contraction variables were tested for significant differences across male and female writers over the 206 cities using a non-parametric Wilcoxon signed-rank test. This analysis was restricted only to the letters for which the gender of the author could be determined. The results are presented in Table

Regional variation

To analyze regional variation in not contraction, the values of the four not contraction variables were mapped across the 206 city subcorpora. For example, DO not contraction is mapped in Figure

The local autocorrelation maps for all four not contraction variables are presented in Figure

In addition to analyzing the maps for the four alternation variables individually using a local spatial autocorrelation analysis, the smoothed maps for the four variables were also combined to produce a single map representing the general pattern of not contraction in the corpus by using a k-means cluster analysis to split the locations into two groups: the region where not contraction is relatively common and the region where not contraction is relatively uncommon. These two clusters are mapped in Figure

To verify that not contraction does in fact vary systematically across these two regions identified by the cluster analysis, the four alternation variables were tested for significant differences across the city subcorpora included in these two regions using a non-parametric Wilcoxon rank sum test. The results are presented in Table

Discussion

This case study analyzed variation in not contraction across year of publication, gender and region in a corpus of American letters to the editor. The analysis found that not contraction became more common in letters to the editor from 2002 to 2008 (Figure

In addition to these basic findings, because not contraction is generally associated with more informal language, these results suggest that letters to the editor are becoming less formal over time and that they are less formal in the western than in the eastern United States. This result is supported by several other analyses of the WARD corpus (e.g.

Conclusion

This chapter has reviewed the growing field of corpus-based dialect studies, where social and regional linguistic variation is analyzed in large collections of naturally occurring language. The corpus-based approach to dialectology contrasts with the standard approach, which is based on analyzing language elicited through interviews and questionnaires. As demonstrated by the studies reviewed in this chapter, the corpus-based approach to dialectology is a growing field of inquiry that allows for new types of research questions to be pursued and new types of dialect variation to be identified. In particular, a corpus-based approach is especially conducive to the analysis of quantitative grammatical variation, because it allows for large samples of natural language to be collected for analysis, and for dialect variation to be observed and compared across a variety of communicative situations. Because of these advantages, corpus-based dialect studies have greatly expanded our knowledge of dialect variation, showing that social and regional linguistic variation are far more complex and pervasive than has previously been assumed. Nevertheless, there are disadvantages to the corpus-based approach as well. Most notably, it is difficult to obtain high-quality recordings of spoken language and to collect detailed data about the social background of informants when analyzing natural language. To a large extent, these are reasons why the corpus-based approach is not more popular in dialectology and sociolinguistics today. It is, however, only a matter of time until dialectologists will be able to download millions of high-quality audio and video posts online, along with rich social data about the posts and their audiences, and automatically transcribe and acoustically and grammatically analyze this language in order to build immense dialect corpora of spoken and written language. When this level of technology is reached, corpus-based dialect studies will become the norm.

World Englishes Marianne Hundt 1 Introduction

English corpus linguistics was kick-started by the compilation of the Brown corpus of written American English (AmE) in 1961. A parallel British English (BrE) version was soon to follow. In the 1980s, the Brown-type compilation model started spreading to other parts of the English-speaking world (India, Australia, and New Zealand). 1 While Brown-type corpora are a useful resource, and their sampling frame is even extended to cover previous stages of World Englishes, 2 they are limited with respect to regional spread and, more importantly, only provide evidence on printed written language use. English corpus linguistics truly went global when, in the late 1980s, Sidney Greenbaum launched an international project that aimed at providing standard one-million-word samples of World Englishes on a hitherto unprecedented scale, the International Corpus of English or ICE

The focus in this chapter is on World Englishes that are used as first or second language varieties. 3 While some scholars have compiled their own corpora of world Englishes (e.g. by tapping into archives found on the World Wide Web), 4 the focus in this chapter is on research based on ICE, as these 1 For an overview of research based on some of these corpora, see

are the most widely available corpora of World Englishes, and they are corpora in the more narrow corpus-linguistic sense, i.e. principled, representative collections of texts (see

7 For a list of available corpora and those under construction, see

in different Englishes. The chapter concludes with a short evaluation of the existing resources and an outlook on future developments.

Previous ICE-based research 11

ICE corpora have been used for the description of single varieties (e.g.

ICE as a resource for the study of World Englishes

Any study that uses data from several ICE components relies on the comparability of these corpora. Thus, corpus comparability needs to be addressed in a critical evaluation of ICE for the study of World Englishes. It was one of the key design features that the initiator of the project wanted to achieve:

The ICE project views as the basis for international comparisons the provision of parallel corpora that sample English used in the participating countries. For valid comparative studies the components of ICE need to follow the same design, to date from the same period, and to be processed and analysed in similar ways.

occasionally stretch over a considerable time period, which introduces additional diachronic variation within individual ICE components. The sampling for ICE-Fiji, for instance, started back in 2005, included individual texts published as early as 1990

While it is sometimes necessary to be aware of the potential diachronic bias introduced by the data, background information on ICE corpora is at times difficult to obtain. The majority of ICE corpora were released without detailed bibliographical background information on individual texts included in the corpus or biographical information for the spontaneous spoken conversations, notable exceptions being ICE-NZ and ICE-IRE. ICE-NZ includes texts (both written and spoken) from 1990 to 1998

Another problem for comparability has to be attributed to the interpretation of text types from one cultural environment to another (see e.g.

(1) Plato would suggest aristocracy.

And Freud would . . . Ehehehe . . . As for me . . . Er . . .

Argh.

Maths is so much easier. P.S. I didn't realize how hard it is to write something that has to do with Philosophy until now. Too many thoughts.

(ICE-PHI, W1A-001)

While an individual text is unlikely to affect the results of a study, a more systematic bias in interpreting text categories differently in a regional variety of English will have an impact, e.g. on variables that are sensitive to "formality." I will return to this issue below. Similarly, a closer look at some spontaneous conversations in ICE shows that informants at times engage in interview-like behavior (note that the contributions of the fieldworker have been marked as extra-corpus material), throwing some doubt on the "naturalness" of such "private" conversations:

The ICE corpus was conceived before e-mail communication became one of the most common forms of written long-distance communication. It is therefore not surprising that the original corpus design included letters (both social and business) as a text category to be sampled for the written part of the corpus. Nowadays, e-mail and other means of electronic written communication have largely replaced letter writing, especially in the private domain. It is therefore not surprising that a few ICE teams have gone against the original design (which stipulated the inclusion of e-mail as a separate, additional text type) and have (also) sampled e-mails. ICE-CAN, for instance, includes the whole range from handwritten to typed letters, but also e-mails, whereas neither ICE-NZ nor ICE-IRE includes any e-mails. With other ICE components sampling only e-mails (see e.g.

Thus, formality needs to be considered in the interpretation of findings from ICE corpora. It is a factor that plays a role at several levels. First, previous research on individual varieties (e.g.

Finally, ICE corpora have been used alongside other resources in the description of World Englishes. Especially for the study of lexicogrammatical variation, ICE provides interesting sources for hypothesis building that can then be verified against larger datasets, usually from less stratified material. Examples of such studies are

Some findings and research questions

The potential problems with cross-corpus comparability outlined in Section 2.1 do not mean that ICE does not allow for meaningful comparative research. On the contrary, ICE components (and parts thereof) have been used to investigate various linguistic features. A recurrent research question concerns ongoing change and whether a particular variety is more advanced or more conservative with respect to a particular change.

AmE is leading the change towards a greater use of quasi-or semi-modals like going to, want to and is also more advanced in the decline of core modals (see e.g.

Other studies focus on the relative closeness or distance between ENL and ESL varieties, looking both at how global features are used in local varieties and at evidence of structural nativization: one of the reasons that New Englishes are less advanced in the move away from core modals is that would, for instance, shows an extended (i.e. nativized) use (see

(3) First, I would be explaining about the gender inequality, which often leads to the high incidence of poverty amongst women, which is what I would be discussing about in the second part of this essay.

(ICE-FJ, W1A-016)

Nativization is an important indicator of how far a "new" English variety has come in its development along the stages suggested in

In the collection of the spoken ICE data, representative sampling did not include variables such as speaker age or gender, so there is no straightforward way in which the spontaneous spoken data in ICE could be used for apparent-time studies that allow linguists to trace ongoing change. On the assumption that written usage is generally more conservative than spoken language, a few studies have used ICE to extrapolate ongoing change from differences found in the two subsections of the corpora (e.g. van der Auwera et al. 2012 on the use of need to).

Finally, a recent trend in corpus-based research of World Englishes is the detailed statistical modeling of variation, often including ENL, ESL, and EFL varieties.

Case study: the present perfect

The present perfect (PP) is of interest because it is an example of stable regional variation in written BrE and AmE (see e.g.

For past-time reference, Present-day English (PDE) has a choice between the PP (I have seen her) and the simple past tense (PT) (I saw her). The textbook account of the PP in standard ENL varieties is that it refers to past events that have current relevance. Elsness' (1997) long-term, corpus-based study of BrE and AmE shows that the PP increases over time but starts decreasing again from the second half of the eighteenth century, a development led by AmE. In the twentieth century, there is relatively stable variation in the use of the PP, with higher levels found in BrE than in AmE (see e.g.

As far as functions of the PP are concerned, standard PDE differs from languages such as German or French, where the perfect has grammaticalized into a form used for reference to events that are clearly in the past. However, both historical and regional varieties of English also provide evidence of the occasional narrative use of the PP in clear past-tense contexts (see e.g. Elsness 1997: 292 for historical varieties and

Recently, a number of studies have made use of ICE to investigate the use of the PP across both ENL and ESL varieties. There are studies that look at the text frequency per million words of the PP (e.g.

Seoane and Sua ´rez-Go ´mez (2013) use a similar approach but a slightly different set of ICE corpora (Hong Kong, Singapore, India, Philippines, and GB as a benchmark corpus) as well as a slightly different methodology of data retrieval and definition of the variable. Like Davydova, their focus is on spoken data, but while Davydova uses both face-to-face conversations and telephone calls, Seoane and Sua ´rez-Go ´mez limit their analysis to private conversations. (The rationale for using spontaneous speech in both cases is that this is the least monitored kind of data and that, according to

In addition to the standard variants, i.e. the PP with auxiliary have, ESL ICE components also reveal traces of nativization, for instance the pattern without an auxiliary (

Examples (

Data and methodology

The case study aims to broaden the scope of previous research by including varieties of English that have not been subjected to comparative research, partly because the respective ICE components have only recently been made available or are still under construction. The ENL varieties included are BrE, AmE, CanE, NZE, and AusE; ESL varieties selected are Fiji English (FijE), PhilE, IndE, Sri Lankan English (SLE), and Ghanaian English (GhE). In addition to providing evidence on the use of PPs in some new ICE corpora, another aim is to illustrate how different approaches to data retrieval may influence the results. The analyses will be limited to the newspaper section of ICE, not only for obvious time constraints on a small-scale study and limitations on the availability of spoken data,

In addition, a verb-based approach will be used for an analysis that looks at more strictly variable contexts (i.e. includes only SPs that can be replaced by a PP), making use of nine high-frequency lexical verbs

As far as the definition of the variable is concerned, the focus is on standard variants of both the PP and the SP. Occasionally, a perfect with auxiliary be rather than have is attested even in edited, printed texts from an ESL context:

(9) The game was long been seen as a hobby . . .. (ICE-GH, W2C-004) Such non-standard variants are not included in the counts (see Hundt forthcoming for an in-depth study of such patterns).

In interpreting the overall frequency of SPs in ESL varieties one has to be aware of the possibility that there is zero past-tense marking on verbs. The following example comes from ICE-FJ -it is a serendipitous find from a manual post-edit of co-occurrences with the adverb yesterday. Note that zero past-tense marking (brave) is used alongside regular past tensemarking (stood) in this example:

(10) Hundreds of students of a Suva prominent school brave yesterday's heat and stood in long queues to wait for their turn to pay their fees. (ICE-FJ, W2C-012)

While I did not systematically search for zero past-tense marking, the phenomenon seems to be rare in the newspaper data, so occurrences are not included in the counts. Similarly, PPs with a base form of the participle are not included in the present case study, partly because PPs were retrieved by searching for the standard past participle and partly because these nativized patterns, again, appeared to be typical of spoken rather than written usage. By narrowing down the envelope of variation in this way we will not have missed a large number of relevant hits: Sua ´rez-Go ´mez and Seoane (2013: 167) found only 1.1 percent zero-marked SPs and 0.6 percent PPs with a base form in their written Asian English material.

While zero past-tense marking might lead to underreporting of SPs in automatically retrieved data, lack of back-shifting to past perfects in reported speech will lead to overreporting of SPs:

(11) He said his wife could have been saved if there was someone who knew how to apply CPR. (ICE-FJ, W2C-014)

Lack of back-shifting also occurred with PPs (and not only in the ESL varieties); these instances were not included in the counts because they are not part of the variable context investigated here, i.e. they are not typical PP contexts but variants of the past perfect:

(12) The Burnaby Lawyer noted that Bourassa has come to B.C. before -the most recent visit was in April, 1988. (ICE-CAN, W2C-010) (13) While acknowledging that the Board had not lived up to its role, he emphasised that since his takeover two years ago, things have turned for the better. (ICE-IND, W2C-019)

Nativized patterns were also excluded from the co-occurrence data with temporal adverbs. In IndE, for instance, yet can be used in the sense of "still," as the following examples show: Finally, instances where the adverb did not modify the VP but another temporal adverb were also manually excluded from the concordances:

(16) The government just recently moved to dismantle the allocation of the imports of sugar under the so-called minimum access volume scheme under which a limited group corner the bulk of the importation. (ICE-PHI, W2C-006)

Findings

The automatically retrieved data is presented in two different ways. Figure

A somewhat different picture emerges if the frequency of PPs is measured against corpus size rather than as a proportion of PPs vs. SPs (see Figure

Figure

With active-only VPs, AusE and NZE show more similar usage of PPs, as do AmE and CanE; BrE has the highest proportion of PPs amongst the ENL varieties (see Figure

(17) Laced with the victorious Fiji Barbarians players who just returned from Auckland the side has a full set of arsenal to do the damage in Vanua Levu. (ICE-FJ, W2C-018) (18) he did not push the players hard in the first run considering the fact that they just came back from the festive break (ICE-FJ, W2C-020)

A systematic search for co-occurrence of the PP with a clear past-tense adverb (i.e. yesterday) did not yield a single incidence in any of the press sections of the ten corpora surveyed for this case study. Likewise, a qualitative analysis of the opening paragraphs of articles in ICE-AUS, ICE-NZ, ICE-FJ, and ICE-PHI did not provide any evidence of the typical framing function that

Discussion

The different methods used to retrieve PPs from ICE and the different measures employed to compare the results make it difficult to assess them. The data presented above have shown that the envelope of variation that is studied will result in a different picture of the relation among ENL and ESL varieties: it makes a difference, for instance, whether the overall text frequency of PPs is compared or whether the variable is defined more narrowly, e.g. as an alternation between PP and SP in perfect contexts. We also saw that the results are slightly different if passive VPs are included in the counts or not.

Qualitative analyses of the corpus data show that variable use of PPs and SPs is at times difficult to categorize. In the following example, a PP is used in a clear past time context, but the choice of the PP itself suggests that the past action has current relevance: A follow-up search showed that this is not a tense choice regularly attested in any of the ICE corpora. Previous web-based data

The results presented in the previous section used a fairly conservative definition and compared PPs and SPs only. Qualitative analyses of corpus data, however, reveal that the envelope of variation cannot only be broadened to include the nativized patterns mentioned in Section 3.1, but the present progressive, as well, as the following examples show:

(21) "Over the past five years, the number of newborns affected is steadily increasing which corresponds with the increase in females detected with the disease over the past five years," she said These variants have not been discussed in the context of variable use of the PP so far because they are extensions of the progressive to traditional PP contexts. They are not limited to ESL varieties but also occasionally attested from ENL contexts (see

Conclusion and outlook

The ICE is an excellent resource for the study of standard(izing) varieties of English around the world. Due to the history of the project, certain limitations apply with respect to the diachronic bias inherent in individual components and across regional varieties. Another limitation concerns the use of spoken material, which is so far only available in orthographic transcription. For some points of fine-grained grammatical analysis (e.g. final consonant cluster reduction in past-tense VPs), availability of the original sound files would be desirable. In an ideal world, the sound files would be aligned with the transcription allowing researchers to target the particular grammatical structure retrieved from the corpus (this design feature is currently available for ICE-NIG, only, but seems to have been envisaged in the original plan for the ICE corpora, as the sound samples at the project website (

New answers to familiar questions: English as a lingua franca

Anna Mauranen, Ray Carey, and Elina Ranta

English as a lingua franca (ELF) is a comparatively new domain of scholarly inquiry, which has really taken off as a research field and begun to flourish only since the middle of the first decade of this millennium. The research is overwhelmingly qualitative, as perhaps befits a field that is very much in an exploratory state. Corpus work is therefore still rare; the databases that have been collected have mostly been small, and are perhaps best counted into the very generic category of "corpus" that in traditional philology was used to describe the language data investigated for a study. Most investigations have adopted a qualitative orientation, with Conversation Analysis and various pragmatic and discourse analyses as the principal methods; most of those using large amounts of data have been surveys mainly based on questionnaires (notably Jenkins 2007; Wang 2012), apart from Jenkins's investigation into ELF accommodation in ELF phonology

Exploration into language universals on ELF data seems particularly fruitful as ELF is an extremely rich manifestation of language contact. In a typical lingua franca situation, a multitude of different L1s come into contact with English simultaneously and, in turn, these L1-based lects are in contact with each other, making ELF what

Despite the somewhat bleak overall picture of the amount of corpus work completed hitherto on ELF, the first one-million-word spoken corpus, The Corpus of English as a Lingua Franca in Academic Settings (ELFA, www.helsinki.fi/elfa) was completed in 2008, very soon followed by The Vienna-Oxford International Corpus of English (VOICE, www.univie.ac.at/voice) of the same size. Also a third spoken corpus, the Asian Corpus of English (ACE) led by the Hong Kong Institute of Education, has now been compiled (

The corpus research carried out to date, although still scarce, has already been able to show features of ELF that are of a fundamental kind.

A basic question facing an ELF corpus is how different ELF is from English as a native language (ENL). As even a short fragment of ELF talk heard or seen in transcription is usually enough to tell it is not ENL, intuitions about the actual differences apart from perhaps accent are unreliable. Qualitative studies based on small samples may be deep but fall prey to the bias that intuition suffers from: is this a good reflection of the wider picture? From a corpus perspective, comparing the overall distributions of expressions, the answer is that ELF is not spectacularly different from ENL: word lists of individual words and n-grams show a notable overall similarity in comparable genres

The prototypical ELF user is neither a native speaker nor a learner. Nevertheless, their English is in many ways similar to both. As we might expect, second-language varieties of English, such as World Englishes, learner language, and ELF share features that are likely to reflect the general processes of multilingual speakers using their non-first languages. When we look at these kinds of language use as situated in their social contexts, the differences become more pronounced. The social parameters of being a learner in classroom settings in particular creates rather specific settings for language use. The negotiation of norms characteristic of ELF interaction

The accumulating knowledge from a large number of small-scale studies has produced a list of linguistic features that have established themselves as the set of "known" ELF features, essentially those listed in

ELF corpus studies

ELF corpus work employs essentially similar tools to any corpus linguistic enterprise, with an emphasis on extracting the big picture with quantitative methods in combination with close reading of the relevant items in their contexts. Corpus tagging involves the same pros and cons as with other speech data and non-standard data. Where ELF is special is in certain principles of corpus compilation. In contrast to a learner corpus (see Chapter 23 this volume), an ELF corpus seeks to include speech in a natural, often complex mix, rather than selecting for given L1 backgrounds and comparable proficiency levels. Unlike World English corpora (see Chapter 21 this volume), an ELF corpus does not seek to capture a local or regional variety of English, which would then lend itself to comparisons across others of the same kind. The resulting ELF corpora do not therefore have equal amounts of given "similects"

A corpus of this kind allows us to seek answers to the question of how the situational constraints of lingua franca use shape the language. What commonalities emerge from these mixtures, and what new preference patterns can we see? Lexical, grammatical, and phraseological patterning can be either novel or show new frequency distributions. In both cases the commonalities and new preferences attested in ELF corpora show English taking shape in one of its major and fast-expanding uses in non-local environments.

Methodological issues

The earliest book-length studies based on ELF corpora -

When ELF research shifts from ideological arguments to empirical description of language in use, these pedagogical orientations can be seen to influence the corpus methodology. This is evident in the two monographs cited above, as both are based on small corpora with a bias toward experienced language professionals and language teachers in training as sources of linguistic data. In the case of

In the case of

In an earlier publication,

The purpose of making these observations is twofold. First, both studies perform distributional comparisons between their data and much larger native-speaker corpora. As already mentioned, Dewey compares his 61,000 words to the 900,000-word demographic component of the BNC Baby

In contrast, the one-million-word corpora of ELFA and VOICE have been meticulously compiled for balance and representativeness (see

Lexical simplification

One of the common assumptions about ELF is that it must be a "simplified" English. While processes of simplification can indeed be observed in ELF talk, the question of lexical simplification is especially salient.

Looking more closely at these word lists making up 50 percent of the corpus data, Mauranen has compared ELFA's 44 word types with the 58 found in MICASE. She reports that 36 of these word types appear on both lists and in similar rank order, constituting 82 percent of the most common ELFA word types and 62 percent of those in the MICASE list (ibid.: 93). These figures indicate broad overlap between the most frequent items in the ELF and ENL corpora, most of which are textual organizers such as conjunctions and prepositions as opposed to contentoriented words; neither list contained a single adjective (ibid.: 94-96). While the difference in coverage of word types between the two corpora may constitute evidence of lexical simplification in ELF, it also points toward the conformity of ELF to general trends in language evolution, with the majority of these most common words being closed-class, grammatical items which are most resistant to change (see

In a similar vein, lexical simplification is also associated with "overuse" of general nouns and verbs as claimed by learner language research (see e.g.

Grammatical differences

A focus of

However, the more robust ELFA corpus data in fact show an overwhelming predominance of which over who in academic ELF interaction. The pronoun who is distributed evenly between ELFA and MICASE, with 13 and 14 occurrences per 10,000 words, respectively, and identical positions of 104 on their respective frequency-ranked word lists

Finally, the phenomenon of present tense third-person singular zero in place of third-person singular -s has been an area of interest in ELF research.

Again the POS-tagged VOICE corpus clarifies the situation. By providing a manually checked, dual POS tag which encodes both form and function (VOICE Project 2013), the XML corpus can be searched for all cases of an "innovative" form, in Cogo and Dewey's terms. This meticulously annotated VOICE dataset should put to rest the exaggerated claims of word-level variation in ELF, as the corpus findings are unequivocal. Of the 5,335 words in VOICE which have a VVZ function tag (i.e. third-person present singular verbs, excluding all forms of HAVE and BE), only 5.8 percent (n=310) vary from a conventional English form. The rates of variation with highfrequency HAVE and BE are even lower. Only 26 instances of third-person singular has are in a non-standard form, all of which are third-person plural (e.g. somebody have to judge). As for third-person singular is, a mere 19 cases in all of VOICE are non-standard, all of which are also in third-person plural form (e.g. language which are less spoken). When all verbs functioning in a third-person singular present tense role are taken together (n=22,428), only 1.6% of these (n=355) have an "innovative" form. In other words, 98.4% of all third-person singular present tense verb tokens in VOICE conform to standard English usage.

Multi-word units

Phraseological sequences, under a variety of names, have been held to constitute the ultimate hurdle for the non-native speaker. It has become a generally accepted fact that L2 users get these wrong even at high proficiency levels (e.g.

However, if we look at ELF data, and compare the most frequent trigrams to equivalent ENL data (comparing ELFA to the MICASE corpus of academic speaking), we see striking similarities

Apart from the most frequent items, the frequency distributions of multi-word items -just like those of individual words -diverge in ELF relative to ENL. For instance, in terms of ranks 37th in ELFA, but 8th in MICASE. Also, trigrams like would like to (no. 14), I would like (no. 22), and I would say (no. 44) on the ELFA rank order list do not appear among the most frequent 100 trigrams in MICASE. This suggests that new preference patterns arise in ELF use, as observed in distributions. Moreover, fixed ENL patterns also suffer breaches, and new patterns develop from there. For example, in the common pattern (let me say) a few words about (x), which is immutable in MICASE data, ELFA shows not only more variability, but also a new preference: (let me say) some words about (x) is the most frequent variant

It is these incipient patterns that occur across independent events and speaker L1s that provide perhaps the most intriguing evidence of the linguistic processes that are going on as ELF is taking shape.

ELF corpus research now

As already observed at the outset, the use of English as a lingua franca is a new research field, with few actual corpus-linguistic studies so far. Corpora have nevertheless already shown their powerful potential: they have helped gain a big picture of the prominent linguistic processes in ELF, and revealed new facts about second-language use (SLU). In this last respect it complements the study of second-language varieties of English

The main contributions to linguistic description relate to the overall picture: while small-scale studies, even if taken together, have not been able to sort out the main drift from the contingent detail, corpus work has provided a sense of the degree of similarity between ENL and ELF, robust features in ELF, and new, divergent developments in frequency patterns and phraseological preferences. Corpus studies have also uncovered ongoing processes of lexical simplification, as well as morphological regularization and productivity, also showing that divergences from ENL are directional, not random. Similarly, corpora have helped settle pragmatic questions like whether there is more or less vagueness in L2 than in L1: there is somewhat more (e.g.

Corpus evidence has also illuminated ELF processing issues: phraseological data indicate that L2 processing is not so different from L1 processing as to allow merely bottom-up processing, leading to inevitable errors, but also top-down processing of longer sequences, just like L1. The L1-L2 difference is thus not categorical. At the same time, the distinctly greater incidence of "dysfluency" phenomena, such as hesitations and repeats, provides strong evidence that L2 is more taxing on the working memory.

Methodologically, ELF corpus work has emphasized the importance of running inter-corpus comparisons in both directions, and shown discrepancies between seemingly similar L1 corpus samples (MICASE and T2K-SWAL), which yielded different register features in comparison to ELFA

A number of major gaps remain to be addressed in this new field; how do our largely European findings compare to ELF in other continents, secondlanguage varieties, learner language, and to other lingua francas? How diffuse or differentiated are genre, register, and mode in ELF? This is an issue that has not been addressed in ELF research yet, and while it is beyond the hitherto dominant small-scale studies, it is possible to take this on board with the corpora in existence so far. Methodologically, the vital demand is for robust analytical programs that are adept at handling approximations of conventional forms.

In keeping with the theme of seeking meaningful patterns in ELF above the level of individual words, in Section 2 we report a large-scale study of verb syntax in the ELFA corpus.

An empirical exploration into syntactic universals of spoken ELF

Due to the aforementioned lack of large ELF corpora until very recently, methodologically sound analysis and comparisons between ELF and ENL have been difficult to carry out. This applies especially to the level of syntax in ELF (as indicated by the studies discussed above) which, on the whole, has been the least researched area of ELF so far. However, with the advent of the one-million-word spoken corpora of ELFA and VOICE, such analyses have finally become possible. This section presents an overview of a recent study and findings on four syntactic features of spoken ELF carried out on a subset of the ELFA corpus. The features looked into are the inverted word order in indirect questions (i.e. "embedded inversions"), the extended use of the progressive, the use of would in hypothetical if-clauses, and the preference for singular agreement in existential there constructions. A subset of the ELFA corpus was used to gain a maximal diversity of L1 backgrounds of the speakers. As the ELFA recordings were carried out in Finnish university settings, the proportion of L1 Finnish speakers in the data is inevitably somewhat higher compared to that of other L1s (although overall relatively low, as it was kept in check all through the compilation process). But for the purposes of the study it was considered important to further limit the amount of speech by Finnish speakers to avoid false conclusions based on a possible L1 Finnish effect on the results. Thus, in principle, speech events were discarded where the proportion of English produced by L1 Finnish speakers was over 50 percent. The ensuing subset of ELFA has 0.76 million words based on speech by 482 speakers from 50 different L1 backgrounds.

In the study,

In SLA studies the emphasis has been on the differences between L1 and L2 output with the quest for explanations why L2 speakers fail to achieve specific standard language forms. The explanations have often been found, for example, in the interference from the speakers' respective L1s or compensatory communication strategies employed by L2 speakers, and comparisons have mainly been made to standard grammars. However, ELF research looks at L2 use from the same perspective as any other natural language use, setting L1 and L2 speakers on a par. This means departure from the SLA "deficit" perspective and also renders similarities in the L1 and L2 production interesting objects of study.

Thus, Ranta (2013) looks into the above-mentioned four non-standard verb-syntactic features of spoken ELF with the question in mind whether the features are truly "ELF-specific" or if they can also be detected in comparable spoken L1 data, and if so -whether the uses are similar or different between the two speaker groups. This, on the other hand, leads to the question whether some of the observed features could actually be universal features of spoken English grammar (rather than mere L2 errors). The initial selection of the features for closer observation was purely data-driven, as the attempt was to find features in the ELF data that diverged from the standard use but that caught the researcher's eye as recurring phenomena with no link to any particular L1 background. The four features were then compared to those found in spoken L1 data.

The corpora employed in the study were the ELFA corpus for primary data, and the 1.8-million-word MICASE corpus for reference data for its close match in content and construct to ELFA, but collected in native-speaker settings. ELFA includes a handful of English native speakers and MICASE, on the other hand, some non-native English speakers, but in order to render comparisons feasible, the speaker status of all those producing non-standard forms of each feature was checked and instances produced by English native speakers in ELFA and, on the other hand, instances produced by non-native speakers in MICASE were excluded from the analysis. Both corpora derive from academic contexts, which were considered especially fit for purpose as academia uses English de facto as its international lingua franca with many non-native speakers using English as their daily working language. Moreover, the genre relies heavily on linguistic means for discussing abstract points, (co-)constructing arguments, defending one's views, and elaborating on ideas with not much help from the physical context. Academic speakers can, thus, be regarded as "expert users" of ELF.

The emphasis of the study was on qualitative methods, i.e. finding qualitative similarities or differences in the linguistic contexts for the non-standard features in both corpora as in the present study "universalness" was essentially understood as a similar qualitative tendency in the features, not a quantitative proportion of features that only look the same (but might actually be due to different kinds of linguistic conditioning). Quantitative frequencies and statistical significance of the differences found were computed to check whether there was a match in the proportional patterns of different qualities for each feature -which was interpreted as a sign of a universal tendency. However, for instance an identical occurrence rate was not considered either a sufficient or necessary condition for "universalness" of a feature. But if the proportional tendencies conflicted or the differences proved statistically significant, the universal hypothesis was dropped. The linguistic factors looked into for each of the four non-standard structures mentioned above partly arose from earlier research or from reference to standard grammars, and partly from observations on the databases themselves.

The results indicate that qualitative similarities are, indeed, to be found in the non-standard uses of the four structures studied. The affinity is the clearest in the case of embedded inversions, where the non-standard patterning is virtually identical in both L1 and L2 production. The nonstandard indirect word order occurs both in wh-type questions (e.g. I wonder when are they coming) as well as in yes/no-type embedded questions (e.g. I wonder are they coming) in both ELFA and MICASE. The matrix verbs (i.e. the verbs introducing these questions, such as WONDER in the above example) that are most likely to trigger the indirect word order in whquestions are WONDER, ASK, and TELL in both databases, and for yes/no questions ASK, WONDER, and KNOW. The top three interrogative words beginning a wh-embedded inversion are the same (in the same rank order) for both corpora: what (ELFA: 66% of all WH-embedded inversions, MICASE: 59%), how (ELFA: 15%, MICASE: 22%), and why (ELFA: 7%, MICASE: 10%), and for both speaker groups it is the cliticized what's that is especially closely associated with embedded inversions in the WH-type (what + BE is the most common wh-word + predicate combination in these embedded inversions, and in ELFA 22.6% of these are cliticized, in MICASE 29%). In yes/no-questions the top two auxiliaries appearing in the embedded inversions (in place of the standard if/whether) are BE and DO in equal proportions for both ELFA (72%/27%) and MICASE (70%/26%). Further, a vast majority of the matrix clauses introducing both kinds of embedded inversions are declarative clauses (almost 90% in each corpus), which seems to indicate that it is the ("interrogative-like") matrix verb (not e.g. an interrogative clause) preceding the indirect question that has the strongest effect on the occurrence of the non-standard formulation for both speaker groups.

Also the extended use of the progressive is to be found in both academic spoken corpora studied, with no clear indication of ELF speakers radically "overusing" the construction in non-standard ways compared to L1 speakers. (In ELFA, 91 percent of all progressives fell into conventional categories for the use of the progressive, for MICASE the figure was 97%.) The categories where non-standard use is to be found are almost the same for both speaker groups: stative verbs, general truths/habits, and punctual events -with the exception of "habits" not figuring in L1 data. There seems to be a slight quantitative difference, too, as L1 speakers extend the progressive most readily to stative verbs, followed by instances of general validity and even punctual events, whereas for ELF speakers most of the non-standard use falls into the category of "general truths/habits," followed by stative verbs and punctual events. However, many analogical examples of non-standard use can be detected in both databases, and the analysis also suggests exploitation of the progressive for its saliency in speech for both L1 and L2 speakers.

In the case of non-standard use of would in hypothetical if-clauses, both hypothetical conditionals with reference to present/future events (e.g. I would leave immediately if she would come) and those denoting past events (e.g. I would have left immediately if she would have come) were studied. In both cases a non-standard would construction is inserted in the if-clause in place of the standard past tense or past perfect tense respectively. Non-standard past conditionals appeared to be a common feature in both databases (in ELFA 55% of all past conditionals, in MICASE 15%) and for both corpora it seemed that the non-standard formulation was more likely if the if-clause preceded the main clause (in ELFA, 89% of the non-standard if-clauses came before the main clause, in MICASE 73%). For present/future conditionals, on the other hand, the quantitative and qualitative differences proved greater than similarities: non-standard present/future conditionals seem to be mainly an L2 feature (occurring more in connection with irregular verbs) and no common linguistic denominators for its appearance could be found in the L1 and ELF data.

Finally, in the results for the preference for singular agreement in existential there-constructions even with plural notional subjects (e.g. There's people in the street) the most striking finding was that this nonconcord is overall more frequent in L1 production than in ELF production (in MICASE 34% of all instances displayed non-concord, in ELFA 19%). An explaining factor seems to be that native speakers employ there's as an unanalyzed and grammaticalized chunk introducing both plural and singular subjects far more frequently than non-native speakers (over 98% of the non-concord instances were introduced by there's in MICASE). However, also for non-native speakers the non-concord formulation is most often introduced by the cliticized there's (60.5% of the non-concord instances in ELFA). Also the distance between the copula BE and the head noun of the notional subject appears to increase non-concord for both speaker groups, which seems to point to similar constraints of speech production as an explaining factor behind the phenomenon for both L1 and L2 speakers.

Overall, the results -together with support from previous research literature -suggest that the non-standard features studied (with the exception of non-standard present/future conditionals) display similar enough qualitative tendencies in the use and linguistic conditioning for both native and ELF speaker production to merit consideration as "just normal" features of spoken English grammar and thus akin to "vernacular universals." Quantitatively, the non-standard use is more pronounced among ELF speakers, which is only to be expected as grammatical patterns are likely to be less deeply entrenched in L2 users' repertoire than in that of L1 speakers (see

Thus, closely comparing ELF data (ELFA) with comparable L1 data (MICASE) -and not, for example, with standard language reference grammars -has provided new insights into spoken L2 grammar and brought forth similar tendencies in L1 and L2 speech that have thus far gone unnoticed. The ELF user perspective on L2 data has proved methodologically useful in seeing familiar phenomena in a new light and showing how English used as a lingua franca, despite its indisputable own peculiarities, is in many respects as natural a language as English used as a native language (as also shown by

Learner corpus data

There are many different types of performance data and only some of them qualify as learner corpus data. Unlike the more experimental data types often used in SLA, where learners are forced to produce a particular form (as in fill-in-the-blanks exercises or read-aloud tasks), the focus in learner corpus data is on message conveyance and the possibility for learners to use their own wording. In principle, like any other corpora, learner corpora need to be authentic, i.e. "gathered from the genuine communications of people going about their normal business"

Learner corpora can be of different types, including general or specific, written or spoken, synchronic or longitudinal, mono-L1 or multi-L1 data, which can be produced by learners of different origins and different proficiency levels. A survey of the learner corpora currently available (see www.uclouvain.be/en-cecl-lcworld.html), however, reveals that some types of learner corpora are more common than others. Thus, while in principle learner corpus data can be collected from learners at all proficiency levels, most corpora to date represent the more advanced stages. This initially stemmed from a wish to fill a double-sided gap, i.e. a general neglect of the more advanced proficiency levels by both SLA researchers and designers of teaching resources, but it would now be desirable to revisit the other stages on the basis of corpus data. Another feature is that the number of written corpora by far outnumbers that of spoken corpora. This imbalance results from the difficulty of collecting and transcribing oral data produced by learners. To some extent, this focus on writing can be seen as a positive shift from SLA studies that generally prioritize L2 oral production and indeed, as will be shown below, LCR studies have greatly contributed to the analysis of learner writing. However, this balance needs to be redressed and projects such as the Role Play Learner Corpus and the Louvain International Database of Spoken English Interlanguage are particularly welcome. To take full advantage of these spoken learner corpora, which are usually released as transcriptions, it would also be advisable to have access to the audio files, so as to allow the investigation of learner pronunciation and prosody.

The majority of learner corpus studies are based on raw data, i.e. data devoid of any linguistic annotation. This is changing, however, and an increasing number of studies make use of annotated data, usually in the form of part-of-speech (POS) tagged or error-tagged data. Annotation of learner data comes with potential problems. Having been developed on the basis of native corpus data, POS-taggers may not perform as well when applied to learner texts. Studies have shown the success rate to be sensitive to errors, especially spelling errors, although for higher-proficiency-level texts which contain relatively few formal errors, the accuracy rate remains quite high

Linguistic phenomena

Learner corpus research has tackled aspects of learner language that had been neglected until then. As against SLA studies which have traditionally prioritized morphology and grammar, LCR is characterized by a strong focus on lexis, lexico-grammar, and a range of discourse phenomena. This has been made possible by corpus software tools such as AntConc

General research orientations

Unlike non-corpus-based SLA studies which are typically hypothesistesting, LCR studies tend to be exploratory or descriptive. This general research orientation is consistent with the very nature of learner corpora which are usually collected as generic resources to be used to answer a wide range of research questions not identified at the time of collection. However, some learner corpus researchers have adopted a more explanatory research design, which uses learner corpora to revisit important SLA findings. For instance,

Another important orientation of LCR resides in its strong links with teaching, which were in evidence from the start. Several studies demonstrate how learner corpora can be used to develop pedagogical tools and methods which target more accurately the needs of the learner.

Representative studies

(1)

( This grammatical study on the placement of the adverb in learner English relies on two learner corpora, one containing essays produced by French learners only (Chambe ´ry Corpus) and the other one including essays produced by learners from different mother-tongue backgrounds (ICLE). These corpora were compared with two corpora of essays written by native speakers, viz. the Louvain Corpus of Native English Essays (LOCNESS) and the Essay Bank. All four corpora were POS-tagged so as to permit the automatic extraction of adverbs. The main objective of the study is to find out whether the learners' L1 may have an influence on the use of the Verb-Adverb-Object order (e.g. to see clearly the contrast), which is normally not allowed in English. The large proportion of this structure among French, Italian, and Spanish learners might be explained by syntactic transfer from the L1, since French, Italian, and Spanish all allow this structure. However, the finding that learners with other L1s also produce Verb-Adverb-Object sequences suggests that transfer is not the only explanation. Besides the information it provides about adverb placement in learner English, this article is important because it clearly demonstrates that problems seemingly due to L1 transfer could in fact be shared by other learner populations and thus be attributed to other factors. This should serve as a warning against studies that hastily conclude that transfer is at work without considering further evidence such as data from other learner populations or data from the learners' L1.

(3) Flowerdew, L. 1998. Integrating "expert" and "interlanguage" computer corpora findings on causality: Discoveries for teachers and students. English for Specific Purposes 17(4): 329-345.

The objective of this study is to investigate the rhetorical function of causality in scientific text on the basis of an expert corpus (taken from the MicroConcord Academic Corpus Collection) and a learner corpus (taken from the Hong Kong University of Science and Technology Learner Corpus). The careful examination of concordances of 52 devices expressing reason-result, means-result, or grounds-conclusion reveals a number of features that are distinctive for the learners (as compared to the expert writers). These differences include the overuse of logical connectors as markers of local coherence, their predominantly sentence-initial position, the reliance on a small set of devices, the use of idiosyncratic phrases (e.g. it is because), the absence of certain grammatical patternings (like reduced relative clauses with causative verbs), and the lack of mitigating markers such as modal verbs or adverbs in the direct environment of the causal devices. The article is especially interesting for its discourse-oriented perspective, starting from a rhetorical function rather than from one or two isolated items, as well as for its focus on scientific prose and its plea for more corpus-based English for Academic/Specific Purposes textbooks. It is also a good illustration of how useful and enlightening it is to consider the functionality of items in context (qualitative approach) in addition to their overall frequency (quantitative approach).

(4) Granger, S. and

The objective of this study is to establish whether it is possible to identify distinctive stylistic characteristics of learner writing fully automatically on the basis of POS-tagged corpora. The frequencies of POS categoriesboth major categories such as pronouns and subcategories like personal or indefinite pronouns -were compared in two similar-sized corpora, a corpus of native novice writing, LOCNESS, and the French component of ICLE. The comparison generated a number of distinctive POS configurations which highlight the speech-like nature of learner writing. The learners tend to underuse the categories typical of academic writing (e.g. nouns and prepositions) and overuse those typical of speech (e.g. indefinite determiners and pronouns, first-and second-person pronouns). The study is a good example of a fully corpus-driven analysis which allows generalizations to emerge bottom-up from the learner data. It demonstrates the interest of using POS-tagged data, an approach that is still more the exception than the rule in LCR. The study paves the way for Biber-inspired multidimensional approaches to the analysis of learner language (e.g. Asencio ´n-Delaney and Collentine 2011), typology-driven studies

(5) Thewissen, J. 2013. Capturing L2 accuracy developmental patterns: Insights from an error-tagged EFL learner corpus. Modern Language Journal 97(S1): 77-101.

This study makes use of data from ICLE to trace second language developmental trajectories in terms of accuracy. It is based on data sampled at the same point in time from learners at different proficiency levels. The data were submitted to two independent processes: they were rated by testing experts according to the Common European Framework of Reference for Languages (Council of Europe 2001) and fully annotated for errors on the basis of the Louvain error-tagging system

(6)

Methodological issues for learner corpus research

While the methods generally applied in corpus linguistics can be applied in LCR too, there are a number of methods that have been specifically designed to deal with learner corpus data. They include contrastive interlanguage analysis, the integrated contrastive model, and computer-aided error analysis. New directions can (and should) also be envisaged to complement these three methods.

Contrastive interlanguage analysis

Many learner corpus studies rely (explicitly or implicitly) on a method called contrastive interlanguage analysis (CIA) (see

The first type of comparison makes it possible to highlight features that are distinctive for learner language. This includes errors (which were the focus of pre-corpus interlanguage studies), but also cases of under-or overuse, i.e. the use of significantly fewer or more instances of a particular item as compared to the reference corpus. Particularly important in this type of comparison is the use of corpora that are as comparable as possible in terms of

The second type of comparison involved in CIA is between (varieties of) interlanguages. Most commonly, this comparison is made between several learner populations with different L1s, which helps identify the possible source of certain non-standard features. Features that are limited to one L1-group (or several groups with L1s from the same language family) are likely to be due to transfer from the mother tongue (interlingual features). On the other hand, features that are shared by a large number of L1-groups are more probably linked to inherent difficulties in acquiring the target language (developmental features). This type of comparison is crucial to avoid attributing to transfer features that are common to learners from different L1s (see

Integrated contrastive model

While, as noted above, comparisons between different L1 populations help make more reliable claims about transfer, learner corpus researchers have sought to develop even more rigorous methods to identify transfer, given its central place in SLA. One such method is the integrated contrastive model (see

The methods described up to now do not specifically require that the learner corpora be annotated -even though annotation such as POS-tagging or parsing may enhance the possibilities of analysis (see Section 1.1). There is one method, however, that requires a specific type of annotation, namely computer-aided error analysis

Future directions

The methods used in LCR have gradually become more sophisticated since the first learner corpus studies conducted over twenty years ago. Yet, a number of directions should be further pursued before LCR can be said to meet the methodological requirements that are expected of corpus research and empirical research in general. A case in point is the use of statistics in LCR. As opposed to earlier LCR studies that did not include any statistics, most current studies now follow the general trend in corpus linguistics by providing some sort of statistical analysis. Most of the time, however, it merely consists in testing the statistical significance of the results (e.g. the frequency of a word in a native and learner corpus). Often this is done through the use of the well-known chi-square test -a test which, incidentally, may not even be adequate to compare word frequencies between corpora (see

Advances and challenges

Since its emergence in the late 1980s LCR has established itself as a vibrant research strand at the crossroads between corpus linguistics, second language acquisition, and foreign language teaching. The advances in data collection, methodology, linguistic analysis, and applications are impressive but each of these areas still has a number of challenges to overcome before the field can truly come into its own.

Data

One of the main contributions of LCR, if not the main contribution, is the amount and variety of learner data it has made available to the community of researchers interested in L2 acquisition for theoretical or applied purposes. The empirical basis on which researchers can now rely, especially for writing, is more solid than in previous data collections which, in the eyes of SLA specialists themselves, suffered from a lack of representativeness. At first limited to English, the coverage in terms of L2s now includes a large number of different languages. On the downside, however, is the fact that very few learner corpora contain truly longitudinal data, with the same learners followed for an extended period of time. This dearth of longitudinal data, which is also deplored by mainstream SLA researchers

Methodology

Contrastive interlanguage analysis (CIA) and computer-aided error analysis (CEA) have been used successfully to analyze a wide range of linguistic phenomena and have contributed to a number of important debates in language acquisition. CIA studies raised the issue of the norm (native vs. non-native; novice vs. expert) and pointed to the benefit of relying on an explicit corpus-based norm rather than the implicit and intuitive norm that underlies many SLA studies. CEA, on the other hand, provided the opportunity to ponder on the notion of error and introduce a higher degree of standardization at each level of the error analysis process: from error identification to error interpretation through error annotation and counting methods. Another particularly positive development is the integrated contrastive model which establishes a close link between learner corpus studies and contrastive studies, thereby paving the way for more rigorous investigations of transfer. One of the major methodological weaknesses of LCR to date is the exclusive use of aggregate data. While there are undeniable benefits to be gained from pooling data from a large number of learners, the reliability of the results is not guaranteed if possible differences between individual learners are disregarded. This methodological weakness can be addressed by the use of statistical techniques like the analysis of variance (ANOVA), which compares the between-group variation to the within-group variation. The combination of learner corpus data and experimental data is another area in need of further exploration.

Linguistic analysis

Learner corpus research has put in evidence an aspect of interlanguage which had hitherto been intractable, i.e. frequency of use. It has amply demonstrated that interlanguages are characterized by patterns of underand overuse which are as distinctive as, if not more than, downright errors. The shift of focus from morphosyntax to lexis and discourse has proved to be particularly fruitful for the analysis of advanced interlanguage. A number of features related to lexical expansion and genre diversification have been identified and found to be systematic across different L1 populations

Applications

Potential applications of LCR are extremely varied: they include materials and syllabus design, language testing, lexicography, data-driven learning, as well as a number of natural language processing (NLP) applications. One of the earliest applications is the integration of error warnings into monolingual learners' dictionaries

2 Empirical study: two-word discourse markers in native and non-native speech Some of the aspects discussed above will now be illustrated by means of a study of two-word discourse markers (DMs) in native and non-native speech. Through this study, we were interested in finding out how learners of English from different mother-tongue backgrounds use DMs, and how their use compares to that of native speakers (quantitatively and qualitatively), but we also wanted to demonstrate that when doing learner corpus research one should consider individual data in addition to pooled data. The role of DMs in efficient communication has often been underlined, both in native speech (e.g.

Two corpora lie at the basis of our study, namely LINDSEI, which is made up of informal interviews with higher intermediate to advanced foreign learners of English

Considering the corpora as aggregates reveals a general underuse of DMs among learners: you know, sort of, I mean and and then are significantly more frequent in LOCNEC than in LINDSEI, while the frequency of and so is not significantly different between the two corpora; in fact is the only exception, being significantly overused by the learners (see Table

.1).

There is however a great deal of variation between the subcorpora, depending on the learners' L1. For instance, sort of (Figure

An ANOVA test reveals the presence of interesting clusters of L1 populations for each of the six DMs, which demonstrates the relevance of the L1 variable. It should be emphasized, however, that the variation is not necessarily a direct reflection of the L1 influence. The overuse of in fact among the French-speaking learners, for example, is very probably a consequence of the frequent use of the equivalent French DM en fait, but the high frequency of sort of among the Swedish learners may simply be due to these learners' high proficiency in speaking skills.

At the last level of analysis, that of the individual interviews, we also found marked variation, in the form of speakers' idiolectal preferences for certain DMs. Interestingly, this variability also appears in the native corpus, where it is actually the most marked of all (sub)corpora. While some native speakers have a strong preference for sort of, for instance, others clearly prefer you know. The same is true of the learners, who may have strong preferences for certain DMs. The main difference between the two groups, however, is that the learners' preferences tend to be exclusive: they show a preference for one or two DMs to the exclusion of the others, which they do not (or at least hardly ever) use; the native speakers, by contrast, may display certain preferences but usually still use the whole range of DMs (except for and so and in fact, which are less common in LOCNEC). This corpus-internal variability should be taken into account when doing LCR. More generally, one should bear in mind that the native norm is not unique, nor is the learner behavior.

It may be tempting, in corpus linguistics in general and in LCR in particular, to limit the analysis to a quantitative approach. While quantitative results provide interesting insights into certain aspects of interlanguage, they may also hide some qualitative trends that are worthy of interest. In the case of two-word DMs, we wanted to go beyond the simple equation between high frequency of DMs and fluency (as established, e.g., in

While both the quantitative and qualitative analyses should be expanded to provide a full picture of the use of two-word DMs by foreign learners of English, this study shows the potential of LCR to bring to light linguistic features typical of certain (groups of) learners. The exploitation of a native corpus, used in combination with the learner corpora, makes it possible to see how the learner data are situated in relation to a certain reference norm (without being limited by it), whereas the inclusion of the L1 variable gives a glimpse of the possible influence of the mother tongue. This "classic" application of the CIA model is furthermore refined by also adopting a more individual approach, which considers the speakers individually and underlines the idiolectal variation that can be found within corpora. Like many other learner corpus-based studies, however, this one does not examine the wide range of variables that are available in learner corpora like LINDSEI and that may have an effect on the learners' use of DMs (such as the time spent in an English-speaking country or the knowledge of other languages), nor does it consider the general context in which the learners acquire English (e.g. input-rich vs. input-poor environment). It also fails to fully exploit the spoken corpus at hand, since we did not use the audio files, even though these would have been useful, for example, to disambiguate between the DM and non-DM uses of the six bigrams under study. In addition, since we only worked on the basis of the (transcribed) utterances produced by the interviewees, without looking at the interviewers' turns, we could not adopt a more pragmatic perspective, which would have consisted in investigating how interaction is created between speakers by means of DMs, nor a sociolinguistic perspective, which could, for instance, have studied whether the interviewer's profile (e.g. male or female, native or non-native speaker of English) might have an impact or not on the presence of DMs in the learner's language. Finally, this study is mainly descriptive and does not seek to establish links with two fields which can be seen as close

Part IV

Other applications of corpus analysis Vocabulary Ron Martinez and Norbert Schmitt

In both L1 and L2 pedagogy, the question of which lexis should be taught and in which order of priority has long been asked

Introduction

The size of the adult native-speaker lexicon has been estimated at tens of thousands (e.g.

What corpus linguistics has contributed, in essence, is making the identification of those most common lexical items much easier and more data-informed than would have been possible without such a tool. With massive amounts of computerized texts -now more easily obtained than ever before -at a keystroke one can generate a frequency list in a fraction of the time it would have taken to achieve the same task by hand. Indeed, it was by hand that the early work in frequency lists was carried out; moreover, it will be suggested in this chapter that while there can be no doubt that computerized corpora have made an invaluable contribution to our understanding of the frequency-usefulness relationship, some of the earliest work in list-making may hold some important lessons.

2 "Old" wordlists 2.1 The General Service List

Much has changed since Thorndike's manual tabulation of 5 million words from children's schoolbooks. Nonetheless, on a qualitative level, the corpus research and concomitant issues taken on by Thorndike and colleagues over a century ago remain largely the same. Much like today, the researchers had to make decisions about what corpus size was needed (or adequate), and how and why they would choose the texts that comprised the corpus. One question that was asked, however, that was often not asked as much in the wake of computerized corpus linguistics: Is it enough to simply provide a list of words? Or, as put by Michael West in his report on the early Thorndike work, "Are we to count 'Apply for a job' and 'Apply a cup to the lips' as one word or two? . . . We shall certainly teach 'large' ('a large box'). Shall we teach 'at large'?"

Recognizing the importance of such questions, Thorndike teamed up with colleague Irving Lorge to enhance the existing list. The researchers went back to the original

To help make the list more user-friendly, West applied the Lorge and Thorndike semantic frequency data to a 2,000-word subset of words (judged as especially pedagogically relevant due to features related to usefulness, difficulty, and style), and further enhanced it by dividing the individual senses "more coarsely"

As can be seen in Figure

2.2

The Academic Word List

Another list that benefitted from the use of a computer was Avril Coxhead's Academic Word List

Much like Thorndike and those that followed him, the unit of counting was not word forms but "base" forms that included any inflected and/or derived forms, or what

In the next section, we will look at "new" versions of the lists so far discussed, to later evaluate how far we have actually advanced as a field.

3 "New" word lists 3.1 The New General Service List

With those issues in mind,

As can be seen in Table

Without a doubt, the new GSL benefits from a number of improvements upon the old, including accounting for dispersion and not frequency alone, and being informed by far larger corpora than were available in the West's day.

The New Academic Vocabulary List (Gardner and Davies 2013)

As discussed in Section 2.2, the Academic Word List represented an important advancement in corpus-informed vocabulary research in academic English; however, not unlike the GSL, some potential issues with the list have been pointed out by researchers since its initial publication. One such issue -again, like the GSL -is the AWL's inclusion of word families.

Another shortcoming Gardner and Davies find with the original AWL is its exclusion of the GSL, when in fact many high-frequency "general" words are also important in academic genres. Consider the following extract from a business academic journal (from

With these points in mind especially, Gardner and Davies conceived of a new list, one that would include lemmas and not word families, and not necessarily exclude general high-frequency words if they were found in academic English corpora. The corpora, in turn, would be much larger than the AWL's 3.5 million. Hence, gathering texts from a wide swath of academic disciplines, Gardner and Davies extracted a "core" academic list from a corpus of over 120 million words. Taking into account important data related to each lemma's range (its frequency across academic disciplines) and dispersion, the researchers arrived at a new Academic Vocabulary List (AVL) of just over 3,000 words (the full list can be explored at www.wordandphrase.info/academic). Taking the top 570 word families (and not lemmas) from the AVL, one can see that it compares favourably to the AWL in terms of its coverage of academic text (Table

As

4 Discussion of "old" versus "new" So, how exactly have word lists improved? At least three important aspects can be mentioned. The first one is related to corpus size.

Abstract

Within the literature of marketing and management, researchers have explored different models that examine the relationships between market orientation, entrepreneurship, and performance. In this paper, we offer a new model that includes curvilinearity in the moderating effect of entrepreneurship on the relationship between market orientation and performance. Clearly, the new GSL and new AVL are based on corpora many times the sizes of their respective predecessors, not to mention better sampling methods. A second aspect is to do with subjective decisions regarding what should be included and excluded. The original GSL excluded important lexical items solely on the basis of a priori assumptions regarding what was pedagogically most useful; the new GSL takes greater care to ensure replicability. In the case of the AWL, there was a presumption made that it should exist "on top of" the GSL, but the AVL shows us that there is some important overlap between general and academic English. Finally, probably the most important development in the new lists has been the decision to include lemmas rather than word families. There is no doubt that listing word-family headwords can belie an important underlying semantic complexity. We believe, however, that a note of caution may be in order before concluding that the lemma should be what all lists should consist of. For one, the lemmatization process employed in the new GSL and AVL research involved automated part-of-speech (POS) tagging, which has error rates often hovering around 4 percent

Indeed, a similar issue can be found in the new AVL. As an example, the lemma result is presented with result as a noun (72,083), as a verb (20,138), and derived adjectival forms (resulting/resultant). However, in the academic portion of COCA, result occurs in as a result (i.e. "therefore"/"because of") 11,407 times -over 15 percent of the noun total. Perhaps even more compelling, the bigram result in (i.e. "cause") occurs in that same academic subcorpus 16,446 times -or over 80 percent of the verb total. At the same time, there may be issue with some items that were not included in the AVL.

In other words, while the newer lists should be lauded for their more careful compilation and choice of lemma over word family for its superior discrimination of different senses of meaning, perhaps a way forward is to explore the lexicon beyond single orthographic words, to aim instead for the lexeme over the lemma. Collins Dictionary

5 Lists that go beyond "words" Indeed, there have already been a number of attempts at developing lists of multi-word items.

-that's one of the -and this is a -and this is the -is one of the -was one of the -one of the things -and one of the -one of the most -those of you who -of the things that The fact that these expressions recur in the corpus is no doubt important, and potentially of great pedagogic value. Although in and of themselves these bundles may not appear to have much meaning, that is not the point; as Biber et al. point out, lexical bundles should be thought of as "descriptive facts that require explanation" (2004: 400). On the other hand, it could also be said that such a list is probably of not much obvious use to the average classroom language teacher or student, and therefore is perhaps of limited pedagogic value in practical terms.

A more recent list of academic expressions is the Academic Formulas List (Simpson-Vlach and Ellis 2010). Much like

The authors first extracted n-grams

Therefore, in order to determine which quantitative information (e.g. frequency, n-gram length, MI score, or combination) would help them best inform their ultimate metric, Simpson-Vlach and Ellis recruited twenty native-speaker judges (with language testing and teaching experience) to rate a stratified random sample of the formulas on the basis of the following criteria (2004: 496): A. whether or not they thought the phrase constituted "a formulaic expression, or fixed phrase, or chunk" [. . .]; B. whether or not they thought the phrase has "a cohesive meaning or functions, as a phrase" [. . .]; C. whether or not they thought the phrase was "worth teaching, as a bona fide phrase or expression" [. . .].

The researchers were then able to correlate the qualitative judgment data with the quantitative statistics and, through multiple regression, arrive at a metric could be applied to all quantitatively derived formulas and predict which ones would be worth teaching (or "formula teaching worth" -FTW), which ended up mostly being MI, with some influence from frequency (β 0.56 MI + β 0.31 frequency). Therefore, the items in the Academic Formulas List (AFL) are in theory prioritized by this FTW metric (Table

As the authors point out, such strict adherence to pure statistical selection criteria virtually eliminates possible "claims of subjectivity" (p. 490); however, as the criteria (A, B, C above) did not actually guide the selection, many items in the AFL -particularly those with lower FTW ratings, might be seen as only marginally having "cohesive meaning" as a "bona fide phrase." In the end it is unclear the extent to which many expressions in the AFL offer a more practical, pedagogical tool than the lexical bundles in the

Perhaps we should turn once again to the original GSL. Although clearly out of date now and fraught with a number of issues, including the corpus on which it was based, and subjective decisions regarding what should be included or not, there may be a baby in that bathwater. While the subjectivity can be seen as problematic, at the same time there was some value, we believe, in the (laborious) qualitative analysis that went into the work. That meticulous counting method resulted in what was probably a more accurate representation of the nature of the lexis in the corpus from which the 1953 GSL was derived, with counts that reflected separate lexemes, including multi-word expressions. Moreover, in our view, one thing the West GSL did well was present information in a way that made sense to classroom practitioners, teasing out semantics and including contextualizing example sentences. In the section that follows, we present our own contribution to vocabulary list research, one which we hope has benefited from the successes and lessons to be gained from other list work, both old and new.

6 The PHRASE List

Revisiting issues of frequency and semantics

Our main objective was to create a list which would have pedagogic utility, mirroring purposes similar to the GSL and AWL lists, but for multi-word expressions, to be ultimately juxtaposed and even integrated with such lists. Indeed, the proposal itself is not really a new one: Some items larger than a word behave like high frequency words. That is, they occur frequently as multiword units (good morning, never mind), and their meaning is often not clear from the meaning of the parts (at once, set out). If the frequency of such items is high enough to get them into a general service list in direct competition with single words, then perhaps they should be included.

Using the corpus data

The next step was to decide on the corpus source of the language data for the list. After careful consideration, the full 100-million-word BNC was deemed the best choice from among the publicly available large corpora for a number of reasons, including its size, diversity, and reputation. Of course, a corpus of the size of the BNC cannot be easily analyzed without the use of some kind of specialized software to be able to observe patterns using all the data contained in it. WordSmith Tools (version 5.0) was chosen, among other reasons, due to its compatibility with the latest BNC XML edition (used in our study) and ability to generate both word frequency lists and lists on recurring strings of words (or "n-grams").

WordSmith Tools was then used to upload all the texts (over 4,000) and construct what is called an "index" of all the words in the corpus. An index analysis collects vital information about each word in the corpus (e.g. dispersion, collocation, and so on), and is necessary if one wishes to run an analysis of recurrent word strings.

Once the index was complete, the list was further analyzed and restructured in a process of lemmatization. This process allowed us to arrive at the crucial frequency band cut-off points with the 5,000-word frequency level, mentioned earlier, already established as a target range (Table

With the frequency cut-off bands now established, we began the actual extraction process by using WordSmith Tools to interrogate the original indexed list for any and all n-grams (or bundles) between two and four words long repeated in the corpus at least five times. This search rendered a list of over 4.2 million n-grams. It is interesting to contrast this figure with the single-word index list. As our frequency cut-off exercise indicated that we only needed to search for items recurring at least 787 times in the corpus, our candidate pool was limited to 14,500 n-grams -which, as can be seen in Figure

The time-consuming qualitative stage of analysis then began, involving a line-by-line data deletion phase (Figure

An example is the phrasal expression at first. At a glance, it may seem clear that at first is an adverbial expression ("initially"), but with each potential phrasal expression identified an additional concordance of that item was run, and then it would become clear that at first also has non-phrasal expression manifestations, as in love at first sight. However, since an item like at first has a frequency of over 5,000 in the corpus, line-by-line searching was not a viable option. Therefore, a random sampling method was employed instead.

What the random sampling entailed was simply generating a concordance of the potential phrasal expression in question using the entire BNC corpus. Once generated, the concordance was saved and then a special command -"delete to N" -was used to reduce the concordance lines to a random sample of just 100. Each line was then scrutinized and deleted if necessary until the percentage of lines reflecting the desired sense of the multi-word item was arrived at. In the case of at first, out of 100 randomly selected concordance lines, 84 exemplars of at first in its phrasal adverbial sense remained -or 84 percent of the original total.

In order to validate this percentage, a second random sample was generated to check consistency. This method produced stable results, and in cases of minor discrepancies the lower of the two percentages was used (e.g. the two random concordances for at first yielded 84 and 85 percent, so the 84 percent figure was used). In the rare cases in which the figures did not match so closely, additional random samples were generated until a reliable percentage figure could be derived. Finally, the frequency figure for each multi-word item was calculated by multiplying the total frequency figure by the percentage figure as explained above. For at first, this calculation was 5,090 (raw frequency) × .84 (% of desired sense) = 4,275 (adjusted final frequency). The lines in the actual WordSmith word list were then edited to reflect the adjustment.

Also, frequency figures sometimes increased from their original levels. Since the current BNC-derived word lists are lemmatized and organized into word families, it was decided the same construct should remain in the multi-word item list. The expression take place, for example, in its uninflected form had a frequency count of just 3,248. However, the form can also be lemmatized: take place → takes place, taking place, taken place, took place In the case of take place, after conflating all of the inflected forms, the count increased from 3,248 to 10,556.

On other occasions, a subtractive method could be employed in order to arrive at a more accurate frequency figure. For example, opposed to essentially has two manifestations: (be) opposed to sth, and as opposed to. The n-gram list is not much help on its own since the program was asked to identify all recurring 2-to-4-word strings, and therefore opposed to is subsumed in as opposed to. In order to focus on just opposed to, it was possible to simply subtract the number of occurrences of the string as opposed to

Finally, expressions were sometimes encountered that contained variable components. For example, in the BNC, the first exemplar of shake one's head is actually shook his head

In all, 505 phrasal expressions were identified that occurred at least 787 times in the BNC -matching the single-word frequency range of the top 5,000 words in that corpus -and which also met the semantic criteria.

Presenting the corpus data

Following the analysis presented in Section 6.2, the first version of the PHRASE List was produced. However, the list eventually underwent a number of changes as a result of further analyses and consideration. The first version (Figure

For example, colleagues and peer reviewers commented that while certain phrases were readily recognizable as lexical items (e.g. might as well, in the first place, take for granted) with clear, discrete form-meaning mappings, some other phrases eluded immediate interpretation (e.g. or so, all but, yet to) not unlike the expressions listed in the

The frequency column remained the same, but in Figure

As seen in other lists reviewed in this chapter, we also saw the value of distinguishing genre and modality (written/spoken) information, and wanted to do the same with the PHRASE List. However, the BNC is  composed of hundreds of different subcorpora, and there is no easy way to isolate, say, just general spoken conversation and investigate the frequency of a given phrase in those files. Furthermore, even the individual files in the BNC that are tagged as representing "spoken" English, for example, are not what one would immediately think of with respect to that modality of communication, with many BNC files actually containing data of memorized and/or written language that has been read aloud. This problem of genre mislabeling in the BNC has actually long been recognized by users of that corpus

However, as presented, these new frequency data pertaining to genre were ultimately found to be more of a hindrance than a help, unfortunately. Every person who had the opportunity to look at the new version of the list found the new numbers confusing, and understandably so. First of all, the original data columns containing frequency information are still in the list, so the addition of three new sets of numbers is somewhat daunting. Second, the new sets of frequency information actually are uninterpretable in practical terms. As an example, the phrase such as is shown to have 130 attested examples in the spoken general corpora analyzed. This led to the development of a new, non-numerical system (also used in

As seen in Figure

Conclusion

It has been our aim in this chapter to review what we believe have been important lessons learned (or that should be learned) over various attempts to use linguistic corpora to identify and prioritize vocabulary for English language teaching and learning, so that current and future related research can remain mindful of them. Although it is clear that, with the help of computers, the trail blazed by Thorndike and colleagues a century ago when they painstakingly labored for years through a dense timberland of millions of printed words has since been turned into a veritable superhighway, the lexical forest still needs to be occasionally traversed unhurriedly and observantly in order to be properly appreciated. As evidenced by the enduring influence of Michael West's (1953) General Service List, vocabulary lists driven by pure quantitative data are more likely to find their way into practical applications when they are complemented by qualitative judgments in a user-friendly presentation. At the same time, the new GSL and AVL teach us that we must be careful with subjective judgments, as those lists show how careful sampling and methodology can lead to more reliable lists of the most important vocabulary. However, the new GSL and AVL also remind us of the importance of considering semantic as well as frequency data to avoid potentially presenting a skewed picture of the lexicon. We believe that our list has benefited from the legacy of successes and caveats that each corpusinformed vocabulary list provides. Nonetheless, we must also recognize that in developing and releasing our own list, we become a part of that legacy. We do not expect that our research as presented here should dictate the design of future similar studies, but we hope to have contributed to the ever-evolving understanding of how corpora can enhance the study of vocabulary. As West himself said so many years ago:

it is undesirable that there should ever be any one prescriptive list, for that would tend to hamper the liberty of teachers and writers, and do more harm than good. What is needed is a standard form from which infinite divergences may be made, as well as a set of criteria, so that those who diverge may do so with reasoned intention.

Lexicography and phraseology

Magali Paquot

Introduction

Corpus linguistics has contributed to lexicography in a number of ways. It has provided the methods and tools for lexicographers to better assess the relative importance of different words and their different uses. It has led to the development of innovative approaches to the lexicographical treatment of meaning, grammar, and pragmatics, and extended the entire scope of lexicographic research

The principle of idiom is that a language user has available to him or her a large number of semi-preconstructed phrases that constitute single choices, even though they might appear to be analysable into segments.

Sinclair's pioneering corpus work was first put into practice lexicographically in the Collins COBUILD English Language Dictionary (CCELD), a monolingual dictionary for learners of English published in 1987. The concern for word combinations was not new in pedagogical lexicography: phraseology had long been recognized as an essential component of native-like fluency and idiomatic language use

Since the CCELD's publication in 1987, the use of corpus data has spread rapidly to English pedagogical lexicography. Dictionaries for other languages, specialized dictionaries, and bilingual dictionaries are now also following suit. The aim of this chapter is to assess the impact of corpus data on the description of phraseology in various types of English dictionaries.

2 In search of phraseology: from dictionary making to the study of dictionaries The third column shows that suggest is commonly used in the past participle form followed by the preposition by and lists the nouns that are typically introduced by the preposition. The fourth column provides a list of adverbs that typically follow the verb suggest. Other features of the Sketch Engine that are particularly useful for the lexicographic description of phraseology include:

1. A thesaurus which provides a list of "nearest neighbors" for a word, i.e.

words that share collocates with the search word and may therefore be potential synonyms (or possibly antonyms). For example, the ten nearest neighbors for the noun argument are claim, idea, view, theory, interpretation, explanation, account, concept, principle and reason. 2. The Sketch-Diff option compares word sketches for two words and identifies the collocates that they have in common and those that are unique to each word.

See

Lexicographers can also make use of admirable online corpus-based resources such as the Database of Analysed Texts of English (DANTE) and the Pattern Dictionary of English Verbs (PDEV). DANTE is a lexical database that provides a fine-grained description of the meanings, grammatical and collocational behavior, and text type characteristics of over 42,000 English words. It was created for lexicographers and computational linguists, using a custom-built corpus of 1.7 billion words uploaded in the Sketch Engine. The PDEV is an ongoing corpus-driven project in which a procedure called Corpus Pattern Analysis (CPA) is applied to identify the various patterns in which a verb is used and then discover how exactly meanings arise from each of the patterns. The completed project will contain around 5,800 verb entries

The systematic exploitation of corpus data in the process of dictionary making, together with the advent of electronic dictionaries, has resulted in the reshaping of lexical entries. This is especially true of electronic learners' dictionaries where phraseological information may surface in various elements of the microstructure:

1. The full-sentence definition format in which words are defined in context "to represent the match between phraseology and meaning"

14 to the point dealing only with the important subject or idea, and not including any unnecessary discussions: Her comment were brief and to the point. 15 make a point of doing something to do something deliberately, even when it involves making a special effort: He made a point of spending Saturdays with his children. I always make a point of being early. (LDOCE5) 4. Collocation boxes where salient collocates as identified by a statistical analysis of corpus data are organized by part of speech. LDOCE5 is the only dictionary that provides collocation boxes and phrase banks for almost each word, while MEDAL2 deserves special mention for offering collocation boxes at the level of a word sense rather than for the word in general.

Some of these features are typical of just one dictionary: the full sentence definition format, for example, is a hallmark of the Collins COBUILD series

Two studies by

1. There is a lack of consistency in the collocations recorded in the three learners' dictionaries. Only 5 percent of all the collocates listed in the learners' dictionaries appear in the three dictionaries and 24 percent appear in two of the three dictionaries. Put differently, 71 percent of the collocates appear in just one of the three dictionaries (see also

4. There is very little agreement in the collocates recorded in the three collocation dictionaries: only 3 percent of the total number of collocates listed are found in all three dictionaries, and 82 percent appear in only one of the three dictionaries. 5. The Oxford Collocations Dictionary for Students of English is the only one of the three collocation dictionaries which is corpus-based. Not surprisingly then, it was found to contain the largest number of collocates which were the same or similar to those revealed by the corpus analysis

One year earlier than Walker, Moon (2008b) adopted a similar methodological framework to evaluate the coverage of collocations in monolingual dictionaries for native speakers of English, monolingual learners' dictionaries and bilingual French-English dictionaries. After a general description of the collocational behavior of the three English words river, rivet, and riven, as observed in the 450-million-word Bank of English, the study examined how it is represented in the different types of dictionaries. Moon's analysis is particularly enlightening in that it offers a diachronic perspective to current lexicographic practice and places emphasis on "the function of phraseological information in relation to the needs and interests of the target users" (2008b: 333). The analysis of the Collins English Dictionary (2003) and the New Oxford Dictionary of English (1998) showed that dictionaries for native speakers scarcely represent the phraseological patterns of river, rivet, and riven as identified in the Bank of English. This lack of phraseological information most probably stems from the fact that, in a monolingual dictionary for native speakers, information presented has essentially been for decoding: "a primary role of a native-speaker dictionary is to list and explain the lexical items of a language"

The evidence of current research clearly shows that learners' dictionaries have played a pioneering role in the description of phraseology and that other kinds of dictionaries have lagged behind. Today, however, the most exciting developments are to be found in bilingual lexicographic research. The lack of large corpora for languages other than English is one of the greatest impediments to the successful treatment of bilingual phraseology

In the second part of the study, they show that data of high linguistic quality can also be obtained from a Web-derived corpus of French (frWaC, 1 billion words). For example, they used the frWaC to extract a list of the sixty most frequent noun collocates in a span of 1 to 3 words to the right of two translation equivalents of the verb charge, namely inculper and accuser. Potential translation equivalents for 12 out of 16 collocational pairs found in the ukWaC were found in the resulting list (e.g. charge + burglary ĩnculper/accuser + vol, charge + connection ~inculper/accuser + complicite ´, charge + conspiracy ~inculper + conspiration). They were all validated by an English to French professional translator with French as a native language. The corpus also proved particularly useful for identifying preferred collocational pairs and lexicogrammatical patterns in the target language as well as larger but perhaps less lexicalized phrases such as "faire payer + NOUN."

Apart from collocations, a wide range of less salient word combinations remain largely disregarded in current lexicographic practice. Corpus-based approaches to phraseology, however, have uncovered the essential functions played in language by n-grams or lexical bundles, i.e. "recurrent expressions, regardless of their idiomaticity, and regardless of their structural status"

In the second part of the study, Granger and Lefer (2012) used the English part of the Label France translation corpus to identify frequent translation equivalents of two lexical bundles, i.e. de plus en plus (de) and sur le plan (de), and compare corpus-derived translation equivalents with those found in three French-English bilingual dictionaries: RC, HO, and the Larousse French-English Dictionary (LA). They found that bilingual dictionaries offer two main translations for de plus en plus: more and more and "comparative + comparative" (e.g. hotter and hotter). However, the most frequent equivalent in the translation corpus is increasingly, which is only mentioned in the LA. The translation corpus also revealed a translation equivalent which is conspicuous by its absence from the three dictionary entries, "ever + comparative." Granger and Lefer's study thus also provides compelling evidence that parallel corpora can be used to improve the number and accuracy of translation equivalents.

Summary and critical standpoint

The treatment of phraseological units differs significantly across dictionaries both in terms of coverage and access. Co-occurrence analysis lay at the core of the pioneering COBUILD project and collocations now feature prominently in (at least) British pedagogical lexicography. By contrast, a whole range of recurrent phrases with essential discourse functions have yet to find the place they deserve in learners' dictionaries, dictionaries for native speakers, and bilingual dictionaries alike. As regards access, techniques range from highlighting a restricted number of word sequences in examples to providing lists of salient collocates in collocation boxes.

There are many different types of English corpora (see Chapter 1 this volume) but the most widely used corpus in lexicography is the large monolingual reference corpus. Today, lexicographers at Oxford, for example, have at their disposal a corpus of over 2 billion words that represent a range of material from different subject areas (e.g. business, computing, law), regions of the world (e.g. Australian English, Canadian English as well as new varieties such as Hong Kong English), and types of writing (e.g. academic papers, newspapers, novels, blogs).

While the large monolingual reference corpus is an extraordinary source of lexicographic data, other types of corpora certainly deserve a more prominent place on the lexicographer's computer: specialized corpora, parallel corpora, and learner corpora. As regards the use of learner corpora, they certainly have a major role to play in the prevention of phraseological errors. Learner corpus research has revealed the huge impact of the first language on the learner phrasicon (see

In the words of

3 Towards a genre-based approach to the lexicographical treatment of phraseology in electronic monolingual learners' dictionaries

Corpus-based studies have highlighted the crucial role of recurrent word combinations such as prime example, final point, noted above, worth noting, as follows, as a result, the evidence suggests that, it is possible to, or in the case of in academic texts (e.g.

i.e. "words that are reasonably frequent in a wide range of academic texts but relatively uncommon in other kinds of texts and which, as such, might be used to refer to those activities that characterize academic work, organize scientific discourse and build the rhetoric of academic texts, and so be granted the status of academic vocabulary"

In terms of quantity and access route, the treatment of collocations varies considerably across the five learners' dictionaries. In OALD8 and CALD3, there is no collocation box for verbs of evidence: a limited number of collocations and phraseological units are highlighted in bold in example sentences. As shown in Table

In the electronic age, dictionary lookup is often described as an information retrieval activity

Recall rate of relevant collocations

¼

Relevant collocations found in dictionary Relevant collocations as found in corpus

Precision is the proportion of collocations listed in a specific dictionary that are relevant:

Precision rate of relevant collocations

To investigate the usefulness for academic writing of the collocation boxes available in CCAD6, MEDAL2, and LDOCE5, I assessed the recall and precision rates of the ten most typical academic collocations of each verb of evidence as found in the Corpus of Academic Journal Articles (CAJA), i.e. a 90-million-word corpus of research articles published in peer-reviewed journals

Using the Sketch Engine, I extracted Word Sketches for the verbs argue, demonstrate, illustrate, imply, indicate, prove, reveal, show, suggest, and support. To operationalize the concept of "relevant collocations," collocates were ordered by decreasing frequency to identify the most frequent "general" academic collocations rather than by statistical score as the latter option retrieved too many discipline-specific collocations (e.g. prove + theorem, plaintiff + prove). The analysis was restricted to the ten most frequent collocates in subject and object positions as these two syntactic relations are clearly identifiable in CCAD6, MEDAL2, and LDOCE5, and thus comparable between the Word Sketches and the three dictionaries.

Recall and precision rates were computed for each verb in CCAD6, MEDAL2, and LDOCE5. Recall rates range from 10 percent for the verb prove in LDOCE5 to 65 percent for the verb illustrate in the same dictionary, with a mean of 29.76 percent. In the case of the verb support, for example, only 7 collocates out of the 20 academic collocates as found in the CAJA are listed in LDOCE5. As shown in Table

MEDAL2 does not provide many collocation boxes for verbs of evidence but when it does, recall is often relatively good, as the dictionary innovates by offering collocation boxes at the level of the word sense, rather than for the word in general. For example, the collocation box under Sense 4 of the verb support ("to show that an idea, statement, theory etc. is true or correct") lists eight abstract nouns that are frequently used as objects of the verb in academic texts: argument, claim, conclusion, contention, hypothesis, idea, theory, and view. Among those nouns, six are typical academic collocations as found in CAJA (see Table

Precision rates range from 6.8 percent for the verb prove in LDOCE5 to 75 percent for the verb support in MEDAL2 (Table

The results of a precision and recall analysis of the collocations included in a dictionary are crucially dependent on the definition of "relevant collocations" put forward and may even vary according to (the quality of) the corpus data used to identify the relevant collocations. Recall and precision nevertheless prove particularly instructive tools for measuring how well a dictionary answers specific users' needs.

Precision is most probably also an appropriate measure to quantify what has been variously called "information stress" or "information overload" in the literature. As put by

Conclusion

The use of corpus data has considerably improved the coverage of phraseology in electronic dictionaries, but its lexicographical treatment has "still not found an adequate balance between the parameters of quantity and quality" (Go ¨tz-Votteler and Herbst 2009: 57). In fact, much remains to be done. In terms of quantity, for example, the use of corpus-derived collocation boxes needs to be systematized. Today, they are often restricted to a limited set of highly frequent nouns or verbs. When available, collocation boxes are devoted to a small class of morpho-syntactic relationships such as "adjective + noun" or "verb + noun." Word Sketches provide different lists of collocates for the different patterns of a word (e.g. argue + case, point vs. argue + for + importance, existence, view or suggest + Ving: using, adding, considering vs. suggest + as+ cause, explanation, factor) and these combinations should also make their way into dictionaries. Ideally, phrase banks should also feature more prominently in electronic dictionaries to address the current paucity of lexical bundles, especially when they are cohesive markers that fulfill a range of functions (see

In terms of quality, a wider range of multi-word expressions certainly deserves to be granted headword status (see

The field of lexicography has been very much part and parcel of the corpus revolution and very few would argue today against the statement that, unlike many contemporary revolutions, it has been a real success story. The part played by corpora has become increasingly important and "no serious compiler would undertake a large dictionary project nowadays without one (and preferably several) at hand"

26

Classroom applications of corpus analysis Thomas Cobb and Alex Boulton 1 Introduction

Corpus linguistics is almost by definition applied linguistics, as was tacitly acknowledged when the American Association of Applied Corpus Linguistics (AAACL) dropped its third A in 2008. Its methodologies can be applied far beyond the discipline itself (see

Upstream use

Early instantiations of the first approach predate modern electronic corpora, with famous examples including Thorndike and Lorge's Teacher's Wordbook of 30,000 Words (1944) or West's General Service List (1953) for English, and Gougenheim and colleagues' Dictionnaire fondamental de la langue franc ¸aise (1958) for French. Work on frequency lists continues to this day derived from ever larger, electronic corpora, such as the British National Corpus (BNC: Oxford, 1995) and the Corpus of Contemporary American English (COCA:

Corpus research has not only informed syllabus and testing but has also been the driving force behind many other tools in language description, one of the most influential being the COBUILD project at Birmingham University (see

But it is possible to go further still and make direct use of corpus material with learners.

Teacher use

This brings us to the second major use of corpora in the language classroom, when teachers consult corpus data directly rather than relying on decision-makers upstream. First, corpus tools can be applied to individual texts, in helping decide whether a text is appropriate and what elements to focus on. Free software such as VocabProfile online (www.lexutor.ca/vp) or AntWordProfiler offline (www.antlab.sci.waseda.ac.jp/) allows a teacher to input a text which is then returned with the lexis color-coded according to the frequency of each word in the BNC or COCA corpus. Such information can help with decisions about which items to teach in a given text, for example, ignoring or glossing over less frequent items while using the highly visible multiple occurrences of others as an aid to teaching in context

From the teacher's perspective, corpora can help in deciding what to teach. Often the corpora used for this purpose are not large modern corpora like the BNC or COCA but rather smallish corpora like the Brown (Kuc ˇera

Native and non-native teachers can also turn to corpora when they have a language question, as intuition is notoriously unreliable in many cases (even textbook rules are at times quite inadequate descriptions of actual language use; e.g.

Learner use

Here we come to the third and final major use of corpora by language learners themselves. Corpus-based learning tasks and activities can be designed along a wide spectrum from "hard" to "soft" (see

Clearly in its most open-ended form, such activity can be quite demanding on the learner, who is likely to need intensive training or, perhaps preferably, scaffolding during extensive practice over a period of time in order to reap the full benefits of corpus consultation. We therefore need sound theoretical reasons to introduce work of this type, to be clear we are not doing so for contrived reasons

All of these would appear to be desirable elements in current applied linguistic thinking. The question of course is whether corpus work really lives up to expectations, with benefits sufficient to justify the investment. For this, we need to look at research to date, which is the purpose of the rest of this chapter. The following section takes an overview of the research field as a whole, then focuses in on a number of studies we have conducted. The subsequent section takes the form of a preliminary metaanalysis in order to assess more broadly the benefits derived (or costs incurred) from the direct use of corpora by learners.

Empirical research in Lcorpus use

Getting learners to explore language is nothing new: they are frequently asked to compare example sentences on the blackboard, or identify features of written or spoken texts

Most of the early academic publications emanating from all this activity were descriptive and argumentative in nature; the first empirical evaluation comes from

Of these 116 publications, 76 were published in 36 different journals, 53 of them ranked on the 2011 European Reference Index for the Humanities (ERIH) lists; 35 were book chapters, some from major publishers, often resulting from thematic conferences (11 include the word proceedings in the title); the remainder are "fugitive" literature in the form of unpublished PhDs and working papers. Though they spread from 1989 to 2012, the increasing interest can be seen in that nearly half the papers were published in the last five years. Virtually all the publications are in English; though this might be due in part to search bias, we have only found five in French, which suggests that publications in other languages are likely to be comparatively rare too. About half of the total were conducted within the European Union, and half of the rest in Asia; most were in a foreign language environment, but about a third comprised mixed L1 classes in a second language context. English was the target language in 95 cases, though some feature learners of French (eight studies) or another European language, and in one case Chinese.

Over 100 of the studies are from higher education settings, though only about half seem to feature students majoring in languages (such basic meta-data are often frustratingly missing). There are at present only nine studies in secondary education, and a handful of other contexts such as language schools. Unsurprisingly, perhaps, many of the participants have quite substantial language proficiency: advanced or upper-intermediate in just over half, but lower levels in at least fifty studies. The language objectives generally tend towards the level of vocabulary or lexico-grammar (including clusters and collocations, i.e. word usage in context), but there are attempts to use corpora in learning grammar and syntax, and even occasionally in phonetics or semantics. A recent development is an increase in studies at the level of text, including discourse and critical analysis, genres, sensitivity to text type or sociolinguistic variation. Some go further still, using corpora in courses on literature or cultural studies with non-native students who thus combine linguistic and non-linguistic uses of corpora.

The Web is used as a corpus in ten studies, whether through a generalpurpose search engine (e.g. Google) or a dedicated concordancer (e.g. www.webcorp.org.uk). Large corpora such as the BNC or COCA feature in about a third of all studies, but about half use locally built corpora, especially where the students have specific disciplinary or language needs such as writing research articles. These are sometimes created by the learners themselves, and can comprise as few as 2,000 words. It is worth noting that only 26 studies use corpora that are available free online, which means that many students would not be able to continue their explorations after the end of their courses. Mostly these corpora are explored on computer, only 24 using exclusively or in part printed activities derived from a corpus. WordSmith Tools is used in 18 studies despite its relatively advanced features and interface; AntConc and LexTutor are also popular, and a small number use purpose-built concordancing software.

The study duration varies from just a few minutes in some experimental contexts to a semester or more in five cases; the majority involve part of a course that lasts several hours over a few weeks. There is an average of 40 participants (including control or comparison groups), ranging from case studies with just one participant to quite large-scale studies with 100 or more. This gives rise to considerable methodological heterogeneity, with statistical analysis of quantitative results in 49 studies, raw figures and percentages in 41 more, and the remaining 26 favoring a purely qualitative approach.

This factual description of the work to date can do little more than scratch the surface. The rest of this section presents a small selection of our own empirical studies featuring a variety of research designs and objectives. They provide a flavor of research in this area and prepare the reader for a synthesis of some of the more general outcomes in the section that follows.

2.1 Learning with corpora

A target set of 240 word families was chosen as a 12-week test of a corpus-based approach to word learning. In a within-groups design, 11 learners met 20 new words per week via game-like computer activities that used either concordances or short definitions as an information source, on alternate weeks. A post-test of the 240 new words showed that 75.9 percent of the words met through concordances were retained, but only 63.9 percent of those met via definitions, an advantage for concordancing of more than one standard deviation.

Following this indication that corpus work could help these learners expand their lexicons, a scaled-up version of the project was prepared using two levels of learner, both experimental and control groups, two outcome measures corresponding to experimental and control conditions, and a learning target of 200 new word families per week for twelve weeks (or 2,400 words, roughly the number these learners would need to have a chance of reading for content in English). Experimental subjects used concordances to work with their new words exclusively, inferring meanings from multiple concordance lines and only using a dictionary to confirm their inferences, while controls used the same software but with a bilingual dictionary as the information source.

Weekly and pre-post tests recorded word knowledge on both definitional and novel-text gap-fill measures. It was hypothesized that learning words via concordances would facilitate the gap-fill task. The results showed that both experimental and control groups made significant and substantial pre-post gains on the definitional measures (4 to 8 percent), but only concordancers made significant gains on the novel-text/gap-fill measure. This was true for both lower (13 percent gain) and upper intermediate concordancers (16 percent gain), gains of just under and just over one standard deviation, respectively. Further, a delayed post-test showed that even definitional knowledge was quick to decay for definitional learners, but the opposite was true for concordance learners (reported from different perspectives in

Types of learning, types of learner

In the first study in this series

A subsequent question was whether such learners could cope with online corpus work. This allows greater learner responsibility and less programmatic input, but also greater room for problems. In this longerterm study

In both these studies, the learners were generally receptive to working with corpora, but it was noted that there were quite substantial individual differences, suggesting that corpus work might not be equally appropriate for all learners. In the next study

The final study was inspired by

The questions at the end of this discussion of some reasonably encouraging studies of learning from corpora are: how typical are these research studies? How typical are the results? Do enough of the larger cull of studies have the design criteria and data to support any sort of generalization about outcomes, and if so, what is the generalization? To answer these questions we assemble as much of the learner concordancing research as possible into a preliminary meta-analysis of findings.

A meta-analysis of corpus results

This chapter has so far surveyed various uses of corpora for language teaching/learning purposes. This type of "literature review" is common in the introductory sections of research articles, and the effects of corpus use have been the object of several extensive narrative syntheses (e.g.

Rather than providing new experimental data, this part of the chapter provides a preliminary meta-analysis of research in the field so far. For present purposes, the research questions are kept as simple as possible:

• Is corpus use effective for L2 learners -i.e. does it have a demonstrable effect? • Is corpus use efficient for L2 learners -i.e. compared to other forms of learning?

While this may appear reductionist to an extent, it does respond to a clear desire on the part of researchers and practitioners to have simple answers to complex questions, and allows us to make some kind of sense of a highly heterogeneous collection of studies as objectively as possible.

Methodology

The procedures and criteria of meta-analysis in second language acquisition (SLA) are now well established, and the present consideration of the empirical work on integrating corpora in language teaching and learning will follow those of

The data considered here are drawn from the corpus of 116 individual studies described in the previous section. These date from 1989 to 2012, and include journal papers and book chapters, but also PhDs and conference proceedings (published as text and not just slides or oral presentations). Some meta-analyses avoid such "fugitive literature"

For this preliminary meta-analysis we retained only studies that focused on some kind of broadly defined "outcome" in terms of learning or of performance, in order to include, for example, using concordances as an aid to translation or in retrieving lexical items, which are not strictly speaking learning outcomes. In other words, this meta-analysis investigates whether corpus use can have an effect over a wide range of variables, including vocabulary and grammar learning, error correction, lexical retrieval, and translation success.

Further exclusion criteria are needed for the purposes of a meta-analysis of this type; in particular, only experimental or quasi-experimental studies with a pre/post-test or a treatment/control group design, or both, can provide appropriate comparative data. It should also be noted that few studies assign students randomly to treatment groups, though the intact groups they use may themselves be randomly assigned; and the distinction between control and comparison groups is blurred.

It is precisely this type of quantitative reporting that is likely to be consistent over many studies, thus lending itself to comparison and synthesis. However, application of the exclusion criteria unfortunately means that many valuable qualitative studies cannot be represented -especially regarding such un-or under-operationalized variables like awareness, noticing, and autonomy which, as already mentioned, are difficult or impossible to quantify

The pre/post-test and experimental/control studies were kept separate for the purposes of analysis, for the reasons outlined below. However, no other variables will be considered at this stage of the meta-analysis, such as participant meta-data (e.g. age, L1, L2, level of proficiency), instructional design (e.g. duration, hands-on or mediated interaction with various corpus types) or experiment design (e.g. immediate or delayed post-test). Many of these outcome types and conditions could be coded and investigated separately as moderating variables in a fuller meta-analysis, but that is beyond the scope of the present chapter. To conclude: while our metaanalysis will depart from the standard model on several points, the basic idea of the meta-analysis model is preserved.

Furthermore, this model is particularly suited to help us understand the state of research in this area, even in its nascent state. That is because studies are particularly vulnerable to the problems inherent in the significance-testing type of research, where the credibility of experiments depends so much on their n-sizes (see

Results

The 21 studies are summarized in Tables 26.1 and 26.2. These separate within-subject studies (comparing pre-and post-tests) and between-subjects studies (i.e. comparing treatment and control groups), as the different designs tend to produce rather different results. The former show whether the treatment is effective (whether or not there is a difference before and after), while the latter show whether the treatment is efficient (whether or not there is a difference compared to the comparison group). Since almost any form of instruction is likely to lead to some effect (the main conclusion from Hattie's 2009 meta-analysis of meta-analyses), it is to be expected that the results of a within-groups analysis will be markedly higher than a between-groups analysis. This is indeed precisely what

The answers to our two main research questions are drawn from the information in Tables 26.1 and 26.2, which show the authors and year of publication in the first column, followed by the essential research focus in simplified form, and then the basic data necessary to calculate the effect size (number of participants, means, standard deviations and pooled standard deviations) for the 21 studies. At the bottom is the combined effect size along with its standard deviation, and the 95 percent confidence intervals.

The mean gain effect size as shown in Table

These effect sizes of 1.69 and 1.04 compare favorably with

Discussion

The overall effect sizes reported here of 1.68 (within subjects) and 1.04 (between subjects) is respectable in educational terms, suggesting not only that corpora can be effective but that they can be efficient compared to other treatments. In other words, the answers to both our research questions (Is corpus use effective for L2 learners -i.e. does it have a demonstrable effect? Is corpus use efficient for L2 learners -i.e. compared to other forms of learning?) are clearly Yes and Yes, based on the studies available to date. Given the broad sweep of focus in the various primary studies, it seems that corpora can be of benefit to L2 users for a range of purposes: learning and use of language anywhere on the lexico-grammatical continuum (including collocation and idiom) for both receptive and productive purposes, as well as in more extensive reading and writing tasks or in translation. It seems particularly appropriate in the usual problem areas that feature prominently in these studies (i.e. where conventional transmission-based teaching has been found ineffective). It can be useful in both controlled, paper-based work and in more autonomous, hands-on concordancing, and can be suited to both general and specific purposes. The evidence suggests that corpus work is now ready to expand beyond the university ESP class, where it has largely been used to date, into mainstream second and foreign language learning -where, of course, its effects can continue to be investigated and the conditions of its success elaborated. Yet, inevitably, a note of caution must be added. Attaching a single figure to a meta-analysis helps to make sense of a body of research with limited risk of bias or subjectivity, provides a convenient yardstick by which to gauge individual studies past and future, and may be politically expedient for attracting interest to the area (see

First, in the meta-analysis presented here, we have attempted only a preliminary study, and further work would be required to come to more reliable conclusions. In particular, it is essential to note the variation within the studies, which by no means all produce the same results: the details are as important as the major findings

Finally, and perhaps most importantly, our aim here is to suggest avenues for future work. This includes areas that are underrepresented at the present time. First, in terms of research focus, we would hope the future would bring more discourse-level studies with a focus on text and associated features of genre, stance, etc., to complement the current dominance of studies on lexis and specific grammar points. It will be interesting to see what multimodal or multimedia corpora can bring to the table, and their impact on speaking and listening skills. The ways corpora are used and integrated are also in need of further study: how do controlled, teacher-led corpus tasks compare with the type of more serendipitous, independent hands-on corpus work traditionally associated with Johns' data-driven learning? And how do these relate to learner profiles (such as motivations, styles, or levels of proficiency), i.e. are there some learners for whom corpus work is more or less suitable? Perhaps most strikingly in need of study are the longer-term or secondary effects of regular concordance work on language awareness and sensitivity, autonomy, motivation, noticing, and other cognitive and metacognitive skills, and so on; their virtual absence in the studies covered here is no doubt due in large measure to the difficulty of assessing such features over time.

Second, in terms of study design, we would hope for more longitudinal studies with delayed post-tests to balance the short-term focus on very specific target items often found in the work reviewed here. We would strongly encourage the authors of studies to publish their results whatever the outcomes, as experience suggests that many conference presentations in particular are subject to the "file-drawer" problem where they elicit undesired or non-significant results -of all the studies included here, only

Conclusion

Corpora have found many uses in the field of language teaching and learning in the hands of decision-makers, teachers, and learners. Published research covers classroom applications for a wide variety of learner profiles and for extremely different uses, from highly controlled to entirely autonomous work, from paper-based materials to hands-on concordancing, from reference resource to learning tool. This variety underlines the highly flexible role of corpora -there is no single "right" way to use them. From a research perspective, this may lead to a perceived fragmentation of the field, which a thorough meta-analysis may go some way to resolving.

The meta-analysis as a research form is by definition exploratory rather than confirmatory, starting from questions (to be explored) rather than hypotheses (to be confirmed or denied). Of course, few researchers, metaanalysts or otherwise, would deny hoping that their questions would be answered in a certain way, and take steps to ensure objectivity. In the survey presented here, we were gratified to uncover a measure of confirmation from research to date that corpora have been not only effective in language teaching and learning, but also efficient, insofar as they produce fairly regular advantages of a standard deviation or more over other methods of achieving the same goals. Our meta-analysis is only exploratory; further work will be needed to exploit current research fully, especially in exploring the mediator variables that are likely to be worth investigating.

The synthesis presented in this chapter has shown that there is more research in the area than sometimes claimed, but of highly varying rigor both for qualitative and especially quantitative studies. Further, the questions addressed, though varied, tend towards the short-term and experimental with a focus on specific language items; more longitudinal, ecological, open-ended studies are needed, especially addressing the alleged benefits of corpus work in promoting learning to learn and, consequently, in producing "better learners."

A final word. Traditional corpus consultation is in some ways a relatively marginal activity, to be found in few classrooms around the world. However, it is in many ways analogous with internet searches and use of other technologies for querying the vast stores of data available, which has arguably become the dominant learning mode in our culture. Learners regularly Google up internet-as-corpus data to help with collocations, grammar choices, and many other matters, particularly in their writing (see

27

Corpus versus non-corpus-informed pedagogical materials: grammar as the focus Fanny Meunier and Randi Reppen

Introduction

In 2000, TESOL Quarterly published an article by Susan Conrad titled "Will corpus linguistics revolutionize grammar teaching in the 21st century?" Conrad argued that three changes prompted by corpus-based studies of grammar had "the potential to revolutionize the teaching of grammar" (2000: 549): first, monolithic descriptions of English grammar would be replaced by register-specific descriptions; second, the teaching of grammar would become more integrated with the teaching of vocabulary; and third, the emphasis would shift from structural accuracy to the appropriate conditions of use for alternative grammatical constructions. The article also ended with a number of thought provoking questions, viz. whether or not corpus-based research had reached the right audiences; how research applications were presented; how and how much corpus research had been incorporated into materials; and finally, how teachers reacted to the use of corpus research.

The present chapter aims to check whether the changes predicted by Conrad have actually taken place and how exactly they have materialized in pedagogical materials. Section 1 presents some of the key issues in the writing of corpus-informed materials. In Section 2, we briefly present eight grammar textbooks (four corpus-informed and four non-corpus-informed); these textbooks are analyzed with a view to finding out the similarities and differences between these two types of materials and to answering the research questions presented in the introduction. We carry out a more indepth analysis of two of the four research questions listed above, namely how corpus-based research applications are presented, and how (and how much) corpus-based research has been incorporated into materials. As numerous corpus studies have investigated the passive, we have selected that topic as a candidate for the comparison of corpus-informed versus non-corpus-informed pedagogical materials. Some suggestions for the future are presented in the concluding section.

1 Creating corpus-based/corpus-informed materials: some key issues

Terminology

On his "Bookmarks for Corpus-based Linguists" page,

• the inclusion of results, conclusions, discoveries from research carried out on a variety of corpora (e.g. native or learner corpora, spoken or written, from different genres, produced by expert or novice writers/ speakers); • the selection of what exactly should be included (e.g. structures, vocabulary, contexts of use, collocational and colligational patterns, frequency); • the decisions linked to the presentation of the corpus information (e.g. text, graphs, concordances, data-driven approach, other); • and, when the materials focus on skills, the selection of suitable texts (oral or written) as a prompt for instruction.

Authenticity

Numerous studies have stressed the need to include authentic (usebased) lexico-syntactic features of language in language-teaching materials. The importance of specifying contextual and register or genre specificities has also been put forward as a key factor in the acquisition of communicative competence, both receptively and productively (e.g.

When it comes to instructed second language acquisition, however, the use of authentic vs. simplified/didacticized materials is still hotly debated, with some arguing that authenticity is key to language teaching (Ro ¨mer 2005 suggests that texts included in textbooks should mirror the frequencies and uses of present progressives in native-speaker corpora), others presenting the pros of simplified/didactized materials (e.g.

In favor of the use of fully authentic texts as input texts is the fact that linguistic authenticity is de facto guaranteed (on the condition, however, that the texts be truly representative of the particular genre that is being tackled); in favor of the use of simplified/didactized materials as input texts is the fact that learning can be better scaffolded according to learners' levels and also the fact that contrived texts/dialogues can incorporate natural discourse features. Throughout this debate the fact that learners should aim at a good level of linguistic authenticity in their communicative competence is much more consensual.

Although the debate on authenticity will no doubt continue, no publisher, teacher, or learner would claim that linguistic inauthenticity is a learning goal. As an attempt to consider how corpus research can be incorporated into materials to reflect authenticity we propose a number of ways in which corpus research can be used to inform materials. These factors will be influenced by several considerations including: the communicative or linguistic skill(s) being taught (e.g. speaking, reading, vocabulary, grammar), the proficiency level of the students and the course content (i.e. is this a general English course or an ESP course?). Considering these factors, we propose that corpus research can be used to inform materials development in the following ways:

• in helping select the linguistic target features (e.g. vocabulary, lexicogrammar; grammar); • the amount of space in the text devoted to the features; • in the sequencing of materials; • through the inclusion of actual corpus data (e.g. lists of vocabulary or common lexico-grammar patterns); • through the inclusion of information on register differences (e.g. conversation and academic prose); • in the selection of the texts used in examples (e.g. do the texts accurately reflect the use of the target feature?).

Accessing linguistic authenticity: the use of corpora

Representing, explaining, or describing linguistic authenticity has been made possible through the use of corpus analysis. Linguistic descriptions have shown that intuition is often unreliable when it comes to matters related to patterns of language use. Linguistic descriptions based on both large comprehensive corpora and descriptions of specialized corpora have greatly contributed to knowledge of the linguistic characteristics of language use across different situations and production circumstances. When it comes to grammar,

In the last decade there has been a significant increase in corpusinformed teaching materials.

In Sections 2.1. to 2.4., we first introduce and briefly describe four corpus-informed grammar (text)books: the Longman Student Grammar of Spoken and Written English

Review of grammar materials

In this section we first review four corpus-informed ELT grammar "books" which we consider as representative of current corpus-informed materials. We use the generic term "book" on purpose as the titles we have selected are not homogeneous in type, with some being closer to reference grammars, some others to pedagogical grammars, while the last type deals with grammar integrated with other language skills (reading, writing, etc.). This choice of books that are not all meant for the same audiences, nor have the same purposes, naturally implies that differences are to be expected in terms of granularity, precision, and amount of grammatical metalanguage used, and also in the actual structure of the books or space devoted to specific grammatical topics. These differences notwithstanding, we opted for variety rather than homogeneity of material types as this variety is more representative of the impact of corpus research on teaching materials. We decided to choose books which were aimed at upper-intermediate to advanced learners of English. In addition to the corpus-informed books, we will also review four popular noncorpus-informed grammar books at this same upper-intermediate to advanced level. These are: Understanding and Using English Grammar, 4th edition,

The Longman Student Grammar of Spoken and Written

English (LSG),

2.2 Real Grammar (RG)

2.3 English Grammar Today (EGT)

Whilst mostly informed by corpus research, the guidance to English grammar use and understanding is also informed by the authors' and their colleagues' own experience as teachers of English. Some of the entries contain (usually at the end of the entry) information about the typical errors made by learners and those errors come from the Cambridge Learner Corpus. The target audience is described as intermediate learners of English at the B1-B2 levels of the Common European Framework of Reference for Languages (CEFR).

2.4

Grammar and Beyond (G&B), level 3

2.5

Understanding and Using English Grammar (UUEG), 4th edition, international edition

2.6 Focus on Grammar (FoG), 4th edition

2.7

Grammar in Context (GiC), 5th edition

2.8 Grammar Dimensions (GD), 4th edition

3 The case study: corpus-informed vs. non-corpus-informed treatment of the passive in grammar textbooks

Overall comparison

In this section we analyze the treatment of the passive in the four corpusinformed books and four non-corpus-informed grammar books presented in Section 2. Our aim in comparing those two types of grammar books is twofold, viz. to find out the similarities and differences between these materials, and see which corpus findings have been included in corpusinformed materials. To do so, we have opted for a case study approach and have chosen to work on the passive. This topic has been extensively researched in corpus studies and, therefore, much is known about the use and also the lexical associations of the passive. We designed a checklist to help us compare the materials. The first column lists items based on knowledge that has been accumulated in the past ten years from research on the passive. The checklist for corpus-informed materials will be presented first and will then be followed by the non-corpus materials one. Intermediate conclusions will be provided after each checklist and general conclusions will be given in Section 4.

• 80-90 percent of the passives are agentless; • get-passives are rare; • the frequency of use of the passive is subject to strong register associations with the highest rate of passives found in academic/scientific writing and the lowest in informal conversation; • there are strong associations between active-passive constructions and lexical choices with some verbs displaying strong passive attraction or repulsion.

In the same article

• the information on the dominance of the agentless passive, whilst mentioned, is usually backgrounded; • the get-passive tends to be presented as very frequent and interchangeable with the be-passive; • register preferences are either totally absent or given very cursory treatment; • lexical aspects are nearly always presented negatively as lists of verbs that cannot passivize (and the examples are sometimes surprising as they include structures rarely found in learner language, such as A nice house is had by them, I'm fitted by my shoes, or Tact is lacked by your mother, which are found in

We have decided to check the issues listed above in the eight grammar books that we have selected to see if we find the same patterns as Granger. General tables will first be presented, with a view to highlighting general trends in terms of overall structure and contents. Basically, this will help us answer the following question: do "corpus-informed" and more traditional grammar books present different types of descriptions of one and the same grammatical feature?

We will then provide more details on exactly which type of information is presented in the corpus-informed books, but also how is it presented. In 2008, Meunier and Gouverneur stated that publishers seem to acknowledge the importance of corpora in ELT but fail to give precise information on how exactly the corpus is used. A more qualitative analysis (Section 3.2.) will help us answer those questions.

Although not part of the checklist, it is worth pointing that all the books covered offer sections on how to form the passive (typical structure, various tenses, etc.). They also include a discussion on the main reasons for using a passive structure (e.g. agent unknown or not interesting). The number of pages devoted to the passive varies from one book to another but, as explained in Section 2, as the books are not fully comparable in types, we will not comment on that aspect here. a This feature has been added as it will be further exploited in the qualitative analysis (Y = yes, N = no, N/A = non-applicable)

What the checklist reveals is that some corpus-based information is rather coherent across the various books (get-passives are rare and are more commonly found in speech; agentless passives are more frequent than passives with by-agent, etc.). When lexical preferences are mentioned, however, there are differences in the degree to which these are covered. For example, the number of verbs mentioned as frequent in the passive varies greatly (from 4 to 46).

Another difference (which is due to the inherent variety of the books selected) is the integration, or lack thereof, of the grammatical topic with(in) skills. The integration of learner corpus data (and use of error correction exercises) is another case in point. Apart from G&B, which presents error correction exercises as one of the key features of the approach adopted, most books either avoid that aspect completely (LSG), or only refer to errors in passing.

We will now turn to Table

Granger's (2013) conclusion that corpus-based studies of the passive have had relatively little impact on pedagogical grammars is thus confirmed for the non-corpus-informed books that we have selected in our study (which, apart from one book, were different from those in Granger's study). Non-corpus-informed pedagogical grammars fail to include important information on the passive.

Granger's results are, however, disconfirmed for the corpus-informed materials as we obtained a clear Yes for almost 70 percent of the cells on the checklist. There nonetheless remains room for improvement as 11 percent of the cells received a negative evaluation.

Non-corpus-informed materials slightly outperform corpus-informed materials on two fronts: the contextualization of the examples (in 3 cases out of 4, versus 2 out of 4 for corpus-informed books) and the integration of grammar within skills (in 3 cases out of 4, versus 2 out of 4 in corpus-informed books). This said, the new generation of corpusinformed grammar books also works toward integrating grammar in a more holistic and communicative skills-based approach.

A rather surprising result for us was the fact that none of the non-corpusinformed books dealt with errors. The fact that information from learner corpora was absent was to be expected, but much less so was the total absence of focus on errors.

A more qualitative analysis: zooming in on lexical information and exercises

In this section, we will carry out a more in-depth and qualitative analysis of one of the features that distinguish corpus-informed from non-corpusinformed ones, i.e. the inclusion of lexical information. Analysis will also be provided on the types of exercises presented in the textbooks and some of the accompanying workbooks. Due to limitations of space, not all  aspects will be addressed for all the books but we will zoom in on a number of focal illustrations.

Lexical information

Vocabulary is an important cornerstone of language learning and proficiency. During the last decade we have become more aware of the intimate relationship between vocabulary and grammar. The passive is no exception to this. Lexical information is one area where the corpus-informed books have a clear advantage over the non-corpus-informed books.

Corpus-informed books can provide accurate lists of verbs that are frequent in the passive based on information found in corpora. These books can also provide information on lexical relationships including: prepositions that are frequent with the passive (e.g. be associated with, be composed of); passive verbs that are common with a non-human by-phrase (e.g. Real Grammar: 50). These all highlight the relationship between lexis and grammar and are useful to a language learner.

Exercises

Authors of corpus-informed materials stress the importance of using authentic and "real" language, thereby providing the learners with linguistic authenticity (see Section 1.2). Through the types of exercises included, it is also possible to assess the two other types of authenticity presented by Bu ¨ndgens-Kosten (2013), namely authenticity through origin (cultural authenticity), and authenticity through daily life experiences (functional authenticity). We would also like to add the notion of pedagogic task authenticity, defined by

We have analyzed the place devoted to exercises on the basis of the number of exercises (and exercise items) and the types of exercises proposed. Table

Depending on their audience and aims, some textbooks devote much more space to exercises than others (see, for instance, G&B with 21 exercises vs. the LSG 4 exercises). The various columns describing the types of exercises are not mutually exclusive. For instance, an exercise can include both focus on form aspects and discussions on contexts of use (which consequently means that the total percentages in columns 4 to 8 can exceed 100 percent if one adds up all the categories). Focus on form exercises still constitute an important proportion (minimum one-third of the exercises) with some including at least some sort of focus on form (e.g. identification a Keywords used for the search in the index: passive/passive voice/passives and . . . (verbs, forms, typical errors, etc.)

of the form) in all the exercises. Despite some differences in percentages, all the books also include exercises relating to the context of use of the passive (up to 75 percent for the LSG).

When it comes to textual coherence (understood here as exercises which do not contain isolated and unrelated sentences), we note marked differences between the books, with EGT featuring only one-third of the exercises with textual coherence and G&B offering 100 percent of exercises displaying textual coherence (even if in some exercise sentences are numbered individually, they form a text or relate to one coherent topic).

G&B is the only book which includes exercises integrating focus on form and skills (listening, writing, discussing). It is also the only one which regularly

Almost all the books include exercises that ask students to contrast the forms being presented. Most of the time those involve rewriting exercises from active to passive. Two of the exercises proposed by EGT did, however, strike us as being particularly unnatural. In exercise 4, students are presented with five sentences in the passive and are asked to rewrite the underlined sections as active voice forms using the words given in brackets as subjects of the sentence:

• e.g.: "Can you believe how much footballers are paid these days"? (they . . .) • expected answer: "Can you believe how much they pay footballers these days?"

If the exercise can help students better master the shift from one voice to another, the validity of the answer can be debated as the active form does not sound particularly better. Exercise 5 is the reverse type of exercise (i.e. students are asked to rewrite newspaper headlines presented in the active form as full passive sentences):

• e.g. "Major bank announces 200 job losses." • expected answer: "200 job losses have been announced by a major bank."

Here again, whilst we agree that newspapers usually contain more passive forms than some other text types and that many learners (who often underuse the passive) need practice in using passive sentences, we feel that the exercise presented here might be counterproductive. As was the case for exercise 4, the expected answer does not come out as being a very natural/authentic option for a newspaper headline.

As mentioned earlier, the workbook accompanying the LSG contains fewer exercises than the other books. It must be noted, however, that it is the only book where all the examples are clearly identified as coming from corpora (the text type is always listed). This book does not offer any "shifting" exercise, which does not come as a surprise as all examples are authentic and shifting would make the examples less authentic.

Apart from a few exceptions mentioned above, a vast majority of the exercises presented in the four books can be said to have pedagogic task authenticity. In terms of linguistic authenticity, some are "more authentic" than others as all the examples come from corpora. For some other books, the examples may have been slightly adapted, and for some others the origin is not mentioned.

The authenticity through origin (cultural authenticity) is more difficult to assess here and will not be discussed. As for the authenticity through daily life experiences (functional authenticity), it seems to be present only in G&B, thanks to the reading, speaking, listening, and writing activities suggested.

Conclusion

This chapter first addressed the value of using native and learner corpora in second/foreign language teaching and showed that it was both possible and desirable to adopt corpus approaches in the design and development of language teaching materials. We then briefly presented a number of corpus-and non-corpus-informed grammar books and carried out a case study on the treatment of the passive in those two types of grammar books. The comparison revealed that non-corpus-informed materials fail to include important information on the passive.

Our aim in carrying out the case study was not to come up with the conclusion that all grammar textbooks should include corpus-based information on all grammar points. Whilst corpus-based information on article usage might not add much to the treatment of articles in grammar books, we believe that some areas would really benefit from the inclusion of the results of corpus studies. These areas include, among others, the passive, the conditionals, the use of relative clauses and the treatment of aspectuality (and notably the use of the progressive). Corpus information on registers, frequency, and lexical preferences is key to a good understanding and use of grammar, and that is why they should no longer be ignored and should find their way into all types of grammar books. The results of corpus studies carried out on native and learner corpora can help textbook designers prioritize features, be it on the basis of frequency of use (native corpora) or of difficulty in acquisition (learner corpora).

Finding exactly the right amount of corpus information (frequency, registers, lexical preferences, etc.) in sufficient detail is probably an elusive goal as each user/learner has different needs. But, as shown in the case study carried out in this chapter, it should be feasible to draw up a list of core corpus findings worth including in all types of grammar books.

Translation Silvia Bernardini 1 Introduction

The empirical study of translation has traditionally been text-based, typically focusing on the comparison of single originals and their translations. In this way, linguists have looked for examples of translation shifts, or "departures from formal correspondence" in the process of going from the source language (SL) to the target language (TL;

The first part of this chapter surveys the development of corpus-based translation studies (CBTS), from the programmatic proposals in the early 1990s to recent developments and trends. Section 2.1 briefly outlines the theoretical and methodological bases of CBTS, in particular as concerns the types of corpora and the research questions specific to translation research, as opposed to other uses of corpora in translation (e.g. for translation teaching or practice) and to bordering disciplines such as contrastive linguistics. Section 2.2 digs deeper into five studies that have been especially influential and/or that embody especially sound research practices, while Section 2.3 concludes by summarizing the state of the art in CBTS and the major questions still requiring to be addressed. In the second part (Section 3), a case study is presented which aims to test whether translated texts are more or less collocational than comparable non-translated texts, using a combination of comparable, parallel, and reference corpora. The application of corpus methodologies to translation research can be traced back to Mona Baker's seminal paper in which she argues that: the most important task that awaits the application of corpus techniques in translation studies . . . is the elucidation of the nature of translated text as a mediated communicative event. In order to do this, it will be necessary to develop tools that will enable us to identify universal features of translation, that is features which typically occur in translated text rather than original utterances and which are not the result of interference from specific linguistic systems.

This body of research has provided a wealth of insights about typical features of translated texts, going beyond a particularistic approach and shedding light on tendencies common to sets of translations, even though there is still no consensus as to whether these tendencies are in fact universal, and whether it makes sense to speak of universality in the first place. Methodological doubts have been raised about issues of corpus (in)comparability

The analysis of translation shifts

Parallel corpora have not been central to CBTS so far, due to the concurrent general shift away from the ST (see introduction) and to methodological reasons. Bilingual or multilingual parallel-corpus analysis is inherently more complex than monolingual corpus analysis, requiring a descriptive framework includingcruciallya tertium comparationis, or common platform of comparison, and for this reason mostly relying on the direct observation of parallel concordances.

Translation research using parallel corpora has focused on translation shifts, or the small changes "that build up cumulatively over a whole text as a result of the choices taken by or imposed on the translator"

A more complex parallel design is used by Øveras (1998), who searches for shifts in cohesion/coherence in the English-Norwegian Parallel Corpus, a bidirectional corpus including STs in English and their Norwegian TTs and (comparable) STs in Norwegian and their English TTs. By carrying out the analysis in both translation directions, she can factor out language-specific effects. She concludes that, in both translation directions, explicitating shifts (i.e. cases in which co-textually recoverable ST material is made explicit in the TT, e.g. when ellipsis in the ST is replaced by a noun in the TT) are more common than implicitating ones (in which an explicit ST item is rendered by one that relies more on the co-text for reader interpretation, e.g. when a lexical word in the ST is translated as a proform in the TT). This work thus provides support for the explicitation hypothesis. A similar corpus setup (a bidirectional parallel corpus of French and Dutch) is used by

Less central to CBTS than monolingual comparable corpora, parallel corporasimple ones, bidirectional ones including STs and TTs in two directions, multi-target ones with one source and many targets, and so forthhave been used extensively in research carried out at the crossroads of corpus-based translation studies and contrastive linguistics. Where the latter focus predominates, the purpose is to highlight systemic differences between languages, the very aspect that CBTS attempt to factor out in their attempt to highlight translation-specific shifts that occur regardless of the languages involved. According to

The stylistic fingerprints of translators

Translator style has emerged in the last decade as one of the research objects in CBTS, investigated either by means of comparable or parallel corpora. Studies adopting the monolingual comparable design borrow insights from literary stylistics to bring to the fore "the translator's characteristic use of language, his or her individual profile of linguistic habits, compared to other translators"

A more promising approach to the analysis of translator style involves a multi-target parallel structure, i.e. an ST and two (or more) TTs, as in the case of

Summing up

Three main objectives of descriptive research have drawn the attention of CBTS researchers: first and foremost, the search for textual patterning supporting hypotheses about the existence of norms or universals of translation; second, the analysis of translation shifts; and, third, the identification of stylistic fingerprints left by translators. These issues have been investigated by means of monolingual comparable and parallel corpora, the former being seen as more innovative and powerful than the latter. After initial enthusiasm, however, it has become clear that source-language and source-text specific effects should not be ignored by design

Focusing mainly on textual patterning, norms, and universals of translation, and adopting a varied array of corpus resources including monolingual comparable and parallel ones, the five empirical studies presented in the next section have all played a central role in first establishing CBTS as a discipline with its theoretically motivated research agenda and methodology, and then buttressing its foundations and bringing it forward.

2.2 CBTS: selected studies 2.2.

In Laviosa's study, the fiction subcorpus of the ECC is searched for evidence supporting the simplification hypothesis, i.e. the idea that translated texts are simpler than comparable non-translated texts in the same language. Based on previous analysis of the newspaper subcorpus,

The translational component of the comparable corpus of narrative texts has a lower lexical density and mean sentence length than the nontranslational component.

The translational component of the comparable corpus of narrative texts contains a higher proportion of high-frequency words and its list head covers a greater percentage of text with fewer lemmas than the nontranslational component.

The first hypothesis is confirmed with respect to lexical density, significantly lower in translated texts, but not with respect to mean sentence length. Differently from the newspaper corpus, this turns out to be significantly higher, with higher variance, in translated fiction. The second hypothesis is confirmed for both observations: in the translated component, the most frequent word forms account for a significantly higher percentage of the corpus and the proportion of high-frequency to lowfrequency words is significantly higher.

On the basis of this study and of a previous analysis of newspaper language, Laviosa proposes four "core patterns of lexical use" potentially applying to translated English in general, namely that: Translated texts have a relatively lower percentage of content words versus grammatical words (i.e. their lexical density is lower); the proportion of high frequency words versus low frequency words is relatively higher in translated texts; the list head of a corpus of translated texts accounts for a larger area of the corpus (i.e. the most frequent words are repeated more often); The list head of translated texts contains fewer lemmas.

Laviosa's work from the late 1990s has been extremely influential in paving the way for the construction of translation corpora for languages other than English (e.g. the corpus of translated Finnish at the university of Savonlinna) and for the search for core patterns of translated language. Xiao (2010) is a recent example of a corpus analysis comparing translated and non-translated Mandarin Chinese in terms of the core lexical features proposed by Laviosa, and finding that they are "essentially also applicable in translated Chinese, which suggests that translated Chinese also demonstrates a tendency for simplification at lexical level"

Kenny (2001)

Kenny's study of lexical creativity (2001) takes as its starting point the observation that translators opt for conventional TL solutions when faced with creative or unusual SL expressions (Øvera º s 1998

To give an example

The approach adopted by Kenny relies on (informed) subjective evaluation and manual inspection of concordance lines. This is arguably unavoidable given the focus on atypicality and creativity, but it also follows from the adoption of a parallel perspective that prioritizes translation shifts. As such, it occupies the opposite end of the methodological spectrum from

Teich (2003)

For her study of cross-linguistic (English/German) variation in system and text,

Teich's aim is to determine whether, in the two translation directions, there is evidence of SL shining through (or interference) or, conversely, of TL normalization. The selection of features for analysistransitivity and agency, voice, grammatical metaphor, the theme system, and nominal pre-and post-modificationis made on the basis of a preliminary contrastive account of the two languages rooted in systemic functional linguistics, and of previous research contrasting the registerial features of scientific English and scientific German. The distribution of each feature is first observed in the non-translated subcorpora, and then comparisons are made at the monolingual comparable level (translated and non-translated English and German) and the parallel level (English-German translations; German-English translations).

The general picture emerging from this study is a complex one. Both SL shining through and TL normalization are found: translations "appear to be a particular kind of register that tends towards an extreme of registerial typicality concerning some features and at the same time lets the SL interfere with regard to other features"

2.2.

The authors count the number of types unique to each subcorpus and calculate the extent of the overlap between each pair of subcorpora. They find "a remarkable similarity in (a) the number of types unique to each translated corpus and (b) the number of types common to the original-English corpus and each of the translated corpora"

While this study does not offer any motivation, social, cognitive or otherwise, nor any explanation for the observed patterns, it does confirm that translated (English in this case) and non-translated language differs in objective, quantifiable ways.

Delaere et al. (2012)

The study by

On the basis of these counts, a profile-based correspondence analysis is applied to nine language varieties identified within the corpus. Six of these are text types (instructive, administrative, etc.) and three are translation-related varieties (non-translated, translated from English, translated from French). Profile-based chi-square distances are calculated for the different varieties, distances are mapped on a two-dimensional plot, and confidence ellipses are drawn around each variety: lack of overlap indicates a statistically significant distance. The interaction between text type and translation-related variety is also calculated and displayed graphically.

Ellipses for the three translation-related varieties do not overlap, i.e. they are significantly different in terms of use of (non-)standard variants. More specifically, non-translated Belgian Dutch is (slightly) less standard than Belgian Dutch translated from English and substantially less standard than Belgian Dutch translated from French. Apart from the general picture, Delaere et al.'s results indicate that not all translated texts are standardized to the same extent: translated fiction, external communication, and administrative texts confirm the general trend, while journalistic texts and non-fiction texts do not.

Despite some limitations (gaps in the corpus for certain text types, as acknowledged by the authors, but also lack of reference to STs and parallel observations), this study is an example of best practice, nicely combining a careful corpus design, a linguistically motivated choice of patterns, solid grounding in theory, and sophisticated statistical techniques complemented by intuitive graphic representations. And, crucially, it raises more questions than it answers, as good research should:

What is the role of the publishing houses? . . . Can we attribute the use of standard language in certain text types . . . to a process of editorial control? What is the influence of the status of, for example, a literary translator versus a technical translator?

Summing up: CBTS today

The body of research surveyed so far has provided us with a wealth of hypotheses about the typical features of translated language. Even though none of these features has been uncontroversially proved to be universal, several seem to be candidates for statistical universality testing. For instance, it has been shown that translated texts in languages as different as English and Chinese are more likely to be simpler, more normal, more standard, more explicit than comparable texts in the same language. It has also been pointed out that translated texts share basic linguistic traits that tell them apart from comparable non-translated texts (e.g. number of unique words, n-gram patterns).

These findings provide empirical confirmation for theoretical claims that predate the 1990s and the corpus-based approach:

Alongside typical features shared by translated texts, TTs also carry with them imprints of the SLs from which they were translated, as shown by CBTS using parallel/bidirectional corpora and reference corpora. These studies have also suggested that interference, like other typical features, is register-and language-dependent. The parallel perspective therefore cannot be bypassed.

Going back to the typical features of translated language (simple, normal, standard, explicit), it is clear that they do not form an arbitrary list, but rather point to a common unifying factor.

3 Case study: collocations in translated (and non-translated) language

Introduction and aims

This case study investigates the use of English collocations by authors and translators of financial texts. The topic seems an especially rewarding one for CBTS. Evidence from research on second language learning and translator performance

Using a corpus of Brazilian Portuguese narrative texts (eight non-translated and five translated from English),

In general, translation-driven corpora are costly to assemble, requiring ingenious design decisions to guarantee comparability and/or, in the case of parallel corpora, the collection and alignment of two versions for each text. As a consequence they tend to be small compared to monolingual corporausually measured in hundreds of thousands rather than millions of words.

To bypass the data-sparseness bottleneck experienced by previous studies of collocational patternings in translation, in this study collocations are identified in, and compared across, monolingual comparable subcorpora (English only) based on lexical association data obtained from reference corpora. In a nutshell, bigram types are first obtained from the corpora of translated and non-translated texts used for the study; they are then matched with frequency and Mutual Information data obtained from a reference corpus of English, and ranked according to these data. Lastly, rankings for the same part-of-speech pattern are compared across translated and non-translated subcorpora, to see if they differ significantly.

Taking the reference corpus to represent "the collective linguistic experience of a language community"

Corpora and method

Corpora

Two corpora were built specifically for this study. The FINREP corpus is a corpus of corporate financial reports, i.e. reports issued annually by companies providing financial information as well as commentaries about operational and financial performance. The SHARLET corpus covers a prominent subgenre within the corporate financial report, namely that of shareholders' letters. These are short texts (about one page on average), appearing in the introductory (non-audited) part of the report, normally preceding the more technical chief executive report on operations. Previous research has singled out this subgenre as especially worthy of attention because of its wide readership of both experts and lay people, its inherent promotional nature, and its role in shaping financial analysts' opinions and investor decisions

Both corpora have three components: English texts translated from Italian, their Italian STs, and comparable texts in non-translated English. English translated reports and shareholders' letters are downloaded first, selecting companies based in Italy and whose CEOs/chairpersons are of Italian origin and upbringing. Then their Italian STs are also downloaded, and comparable English texts are sought. These should be published by companies based in countries where English is a first language, and cover a range of business types and years of publication roughly comparable to those in the translated subcorpus.

Tables 28.1 and 28.2 summarize basic information about these corpora. The central columns (EN-NT and EN-TR) are the most important ones, since the main comparison in this study is monolingual comparable, contrasting translated and non-translated English. The Italian source texts (IT-NT) are only checked in case higher levels of collocativeness are found, to ensure that these are due to translation and not to unrelated variables.

As a reference corpus, the ukWaC corpus was used. This is a generalpurpose corpus of (British) English built in 2007 by web crawling

Both translation-driven and reference corpora are tagged and lemmatized using the TreeTagger and indexed with the Corpus WorkBench.

Method

For the purposes of this study collocations are defined, adopting a pattern rather than keyword method

Eight POS patterns are formed of contiguous lexical words (a Noun followed by a Noun, e.g. operating profit, a Verb followed by an Adverb, e.g. act swiftly, and so forth), while five are formed of lexical words separated by one or two function words (a Noun followed by a Conjunction or Preposition followed by a Noun, e.g. board [of] directors; a Verb followed by a Particle or Preposition or Pronoun, followed by a Determiner or Pronoun, followed by a Noun, e.g. respond [to] [the] challenges). The intervening function words are used to constrain searches but are not retained in the subsequent phases: only the association between lexical words is tested against the reference corpus. All word pairs matching the POS patterns in Table

The lists of types from the translation-driven corpora are then filtered on the basis of attestedness in ukWaC. Word pairs are ranked according to their bare frequency of co-occurrence in the latter corpus, and according to their MI score, setting a cut-off point of MI>2 with FQ≥2 to exclude hapaxes and extremely low MI values. These two separate rankings are meant to account for both very common and (less common but) strongly associated word pairs

Similar rankings are produced for all the patterns in Table

Shareholders' letters

Only one ranking comparison returned a significant difference, namely that for the Adverb-Verb pattern and the MI values. This result may be taken to suggest that the method is not ideal for very small text collections, or that different parameters and thresholds should be used in these cases.

Results for this comparison are summarized in Table

In several cases, this pattern seems to result from non-obligatory explicitating shifts (examples 1-4).

(1) <snam-05> infrastructures that can transport ever increasing volumes of gas infrastrutture per trasportare volumi crescenti di gas [increasing] (2) <finmec-09> Finmeccanica has been negatively affected to a limited extent Finmeccanica ha risentito in maniera limitata [affected] (3) <interpump-08> with the widely publicized defaulting of subprime mortgages con la nota vicenda dei mutui subprime [known, familiar] (4) <barilla-06> Our goal is to identify newly discovered benefits per dare nuovi benefici

A near-significant difference (p=.07) was also found for the Verb-Noun ranking comparison, similarly suggesting that translated texts are more collocational. Several shifts are once again explicitating ones: translators add premodifiers that are not present in the ST (unwavering commitment to render Italian "impegno," simply meaning commitment) and resort to lightverb constructions to render a logical relation expressed by a simple preposition in the ST (forming part of to render Italian "del," meaning of). Light-verb constructions are also employed to render a wide range of ST expressions, including figurative ones. For instance, take advantage is used to translate Italian dictionary equivalents like "sfruttare" and "approfittare di," but also to render two figurative verbs literally meaning hook the economic recovery and grab the opportunity. These shifts seem indicative of a normalizing tendency whereby translators opt for standard, frequent phrases offered by the TL to render a variety of less lexicalized ST expressions. Further studies on larger corpora are necessary to ascertain that these findings are in fact statistically significant and thus generalizable.

Conclusion

A method for comparing use of collocations in translated and non-translated texts was applied to two monolingual comparable corpora of texts from the same domain and in the same language (finance/English) but varying in size and genre (a largish corpus of financial reports and a tiny corpus of shareholders' letters). Relying on frequency data obtained from a large monolingual corpus, it was possible to show that translated financial reports are less collocational than comparable non-translated reports, while translated shareholders' letters seem to go in the opposite direction: they feature stronger collocations than non-translated letters, often resulting from explicitating or normalizing shifts. The latter can be observed thanks to the corpus design, which includes a parallel component.

Even though the data available for the second genre are too few to allow confident generalizations (suggesting that some tuning of the method would be required for very small corpora), the picture emerging from this study is one in which (a) both interference and normalization occur in translation, and (b) they do not occur at random. The technical collocations that make the bulk of the FINREP rankings are more subject to interference, while the less technical, often figurative language found in SHARLET is more likely to be rendered in translation with standard, even stereotyped collocations. These findings reinforce a view of the translation process as a norm-governed activity, rather than one that is subject to universal constraints.

Observations about non-technical translation are also in line with corpus studies comparing native and non-native written production