[
    {
        "text": "Users of the corpus will therefore be able to study the development over time of both individual words as well as a variety of different syntactic structures.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "Third, in the process of corpus construction we have to think about the relationship between the population and the sample in a somewhat different way to how this is done in fields where sampling can be done on a random basis.",
        "entities": [
            [
                25,
                44,
                "TERM"
            ],
            [
                25,
                31,
                "TERM"
            ],
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "The reason for this is that relative frequency is used not only to compare frequencies of a particular type in two (or more) corpora, but it is also used to present evidence about the frequency of words and phrases in a form that is easier for a reader to grasp than the absolute frequency would be.",
        "entities": [
            [
                103,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "Rates of occurrence were computed for the stance features in each text of the corpus.",
        "entities": [
            [
                78,
                84,
                "TERM"
            ],
            [
                66,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, for handwritten data, there is no solution other than to manually type it on the computer.",
        "entities": [
            [
                75,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another type of meta-information is represented by a table of contents (in the front matter) or an index (in the back matter) of a scholarly book, where the meta-information serves as a kind of navigational aid in accessing individual parts of the book, and where the information is clearly linked to the content -or organisation thereof -itself.",
        "entities": [
            [
                8,
                12,
                "TERM"
            ]
        ]
    },
    {
        "text": "This written form is what we treat as the corpus text since this is what can be searched and further annotated.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ],
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "Spatial restrictions apply to a handbook article like this one (hence the 15line snippets as opposed to displaying the concordance in its entirety) as much as to the use of concordances for classroom use (not many students would want to inspect thousands of concordance lines).",
        "entities": [
            [
                119,
                130,
                "TERM"
            ],
            [
                258,
                269,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given the recent overarching knowledge-building practices and the methodological roles of corpus linguistics, it is necessary to review how a certain body of knowledge has been created according to the common denominator of corpus linguistics.",
        "entities": [
            [
                90,
                108,
                "TERM"
            ],
            [
                224,
                242,
                "TERM"
            ],
            [
                90,
                96,
                "TERM"
            ],
            [
                224,
                230,
                "TERM"
            ]
        ]
    },
    {
        "text": "When describing decision trees in text, you can refer to the node numbers (found in our figure at the top of each section/bin of the data, followed by the number of tokens in that group) and the split numbers (the numbers at the top of the circles).",
        "entities": [
            [
                61,
                65,
                "TERM"
            ],
            [
                34,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "Yet, in order to ascertain the 'spokenness' of a text/corpus until such time, we may often want to handle contractions as single units.",
        "entities": [
            [
                54,
                60,
                "TERM"
            ],
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let's take a sample of the factors we looked at and apply them to our data to help understand the statistical methods.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, the hopefully not too high-flying goal of this paper is to become for corpus linguistics what the abovequoted papers have become for psycholinguistics: a first go-to resource that explains to corpus linguists what (generalised) linear mixed-effects/multilevel modelling ((G)LMM/MLM) has to offer and that provides them with a concrete example and some instructions on how to perform such analyses.",
        "entities": [
            [
                76,
                94,
                "TERM"
            ],
            [
                76,
                82,
                "TERM"
            ],
            [
                198,
                204,
                "TERM"
            ]
        ]
    },
    {
        "text": "Examples include translations from EU Parliament debates into the 23 languages of the European Union, or the Canadian Hansard corpus, containing Canadian Parliament debates in English and French.",
        "entities": [
            [
                126,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "Please note that, so far, what we've done has not turned the file into valid XML yet as there are still some parts missing, so we're really just 'pretending' that the file is XML.",
        "entities": [
            [
                77,
                80,
                "TERM"
            ],
            [
                175,
                178,
                "TERM"
            ]
        ]
    },
    {
        "text": "The more frequent a linguistic phenomenon, the better it can be studied on the basis of a small corpus.",
        "entities": [
            [
                96,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, some semantic aspects are part of the typologically oriented annotation systems, and we will outline these in 7.3.",
        "entities": [
            [
                71,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "Experimenting with the options should allow you to find that BNCweb also lets you list the PoS categories that collocate with the node by selecting 'collocations on POS-tags' next to 'Information'.",
        "entities": [
            [
                130,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "This corpus includes four original works in French and their translation into English, as well as four original works in English and their translation into French.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "This will then be followed by all instances where the relative frequency is higher in the first (general) corpus, and you can easily identify these 'dominant' words due to the fact that they'll have a ratio above 1.",
        "entities": [
            [
                106,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can, in other words, see that if a particular word, phrase or usage is common in a corpus of a particular writer's work, then it might be said to be a consistent preference which reveals something of that individual's routine expression of self: of a relatively unreflective performance of identity.",
        "entities": [
            [
                86,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "A text that is read on a web browser such as Google Chrome or Safari looks like this: You are not very good at parking.",
        "entities": [
            [
                2,
                6,
                "TERM"
            ]
        ]
    },
    {
        "text": "While it is relatively easy to carry out lexical studies with corpus-driven approaches (whether you rely on existing corpora or analyze your own corpus), as available tools allow you to extract lexical patterns from the texts, it is quite difficult to apply corpus-driven approaches to do a full lexico-grammatical analysis of texts.",
        "entities": [
            [
                62,
                68,
                "TERM"
            ],
            [
                145,
                151,
                "TERM"
            ],
            [
                258,
                264,
                "TERM"
            ],
            [
                62,
                75,
                "TERM"
            ],
            [
                258,
                271,
                "TERM"
            ]
        ]
    },
    {
        "text": "The easiest option is to find an archive for the corpus, such as The Oxford Text Archive or CLARIN.",
        "entities": [
            [
                49,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "Strictly speaking, a concordance does not have to list every occurrence of a word in a corpus.",
        "entities": [
            [
                87,
                93,
                "TERM"
            ],
            [
                21,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "The variables and their possible values, including corpus period, are summarized in (10) below; the following paragraphs discuss each variable in turn.",
        "entities": [
            [
                51,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "This value is very low and shows that the annotation is not reliable and should be revised.",
        "entities": [
            [
                42,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "Following the same steps outlined above, choose a sample from another register -for example, academic prose (marked as ACADEMIC on the list).",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "But in this case, a version without misspellings should also be included so that the words can be found by a concordancer.",
        "entities": [
            [
                109,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the data contain examples that occur just once, or patterns that occur repeatedly only because they are all from the same text, these cases will usually be discarded in the search for general patterns.",
        "entities": [
            [
                125,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section we analyze the treatment of the passive in the four corpusinformed books and four non-corpus-informed grammar books presented in Section 2.",
        "entities": [
            [
                102,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "He also observes that the most complex prepositions (i.e. prepositions that consist of three words and more) are over-represented in the corpus of Indian English.",
        "entities": [
            [
                137,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "Likewise, the topics men and women talk about (identified from the keywords of the corpus) also differ.",
        "entities": [
            [
                83,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you are writing your own computer scripts to build your corpus, you can integrate (or merge in) your metadata, bringing in all the metadata for each participant and all the metadata for each file for every token in the corpus.",
        "entities": [
            [
                59,
                65,
                "TERM"
            ],
            [
                222,
                228,
                "TERM"
            ],
            [
                104,
                112,
                "TERM"
            ],
            [
                134,
                142,
                "TERM"
            ],
            [
                176,
                184,
                "TERM"
            ],
            [
                209,
                214,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each provides a different type of information about a distribution of values.",
        "entities": [
            [
                26,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Granger's results are, however, disconfirmed for the corpus-informed materials as we obtained a clear Yes for almost 70 percent of the cells on the checklist. There nonetheless remains room for improvement as 11 percent of the cells received a negative evaluation.",
        "entities": [
            [
                53,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, corpus-based studies have shown that dialect variation exists across a wide range of different varieties of language, including forms of written and standard language, where dialect patterns had never been sought or even believed to exist.",
        "entities": [
            [
                7,
                19,
                "TERM"
            ],
            [
                7,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "I then present what I take to be the methodological foundations that distinguish corpus linguistics from other, superficially Preface similar methodological frameworks, and discuss the steps necessary to build concrete research projects on these foundations -formulating the research question, operationalizing the relevant constructs and deriving quantitative predictions, extracting and annotating data, evaluating the results statistically and drawing conclusions.",
        "entities": [
            [
                81,
                99,
                "TERM"
            ],
            [
                81,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "And as more text is considered, there is a greater chance (particularly in humanities texts) that new words will be encountered.",
        "entities": [
            [
                12,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "With a total frequency of 3,700, and a normalized frequency of 37.6 instances per million words, it can be regarded as a high-frequency word in the corpus.",
        "entities": [
            [
                148,
                154,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is also TEI-conformant Textual Markup to describe features occurring within a particular corpus.",
        "entities": [
            [
                95,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "A colligate can also be a syntactic structure that the node tends to occurs within or alongside -such as a sentence position, or a verb complementation pattern.",
        "entities": [
            [
                55,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "Stanford Parser, for example, is widely used for the syntactic level of analyses of the corpus.",
        "entities": [
            [
                88,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section, we will carry out a more in-depth and qualitative analysis of one of the features that distinguish corpus-informed from non-corpusinformed ones, i.e. the inclusion of lexical information.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, corpus researchers need an understanding of the issues that arise in corpus construction even if they never build any corpora of their own.",
        "entities": [
            [
                78,
                97,
                "TERM"
            ],
            [
                9,
                15,
                "TERM"
            ],
            [
                78,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the contrary, the disadvantages of one type can often be counterbalanced, at least partly, by the advantages of the other, and vice versa.",
        "entities": [
            [
                42,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "CHILDES and the CHAT format as well as widespread markup languages such as XML have made a great contribution to unification but still leave room for enormous variation, even in areas that are of great interest to many researchers such as word meaning, morphology, or syntax.",
        "entities": [
            [
                75,
                78,
                "TERM"
            ],
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given how frequently we have compared British and American English in this book, these two varieties may seem an obvious place to start, but the two cultures may be too similar, and the word happiness happens to be too infrequent in the BROWN corpus anyway.",
        "entities": [
            [
                243,
                249,
                "TERM"
            ]
        ]
    },
    {
        "text": "It will do so in a way that should not only provide you with the technical skills for such an analysis for your own research purposes, but also raise your awareness of how corpus evidence can be used in order to develop a better understanding of the forms and functions of language.",
        "entities": [
            [
                172,
                178,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, the corpus can only be used for questions based on comparisons within the Lost Generation in a broad sense, and it does not allow the user to perform comparisons along other lines of inquiry, for instance, carrying out comparisons between different genres of fiction.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "This process is guided by the ultimate use of the corpus.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, we must formulate one or more queries that will retrieve all (or a representative sample of) cases of the phenomenon under investigation.",
        "entities": [
            [
                88,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "The other type abstracts a new and usually much smaller set of variables on the basis of the existing ones.",
        "entities": [
            [
                10,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "The situation is somewhat easier if we need to distinguish between proper nouns and common nouns, as far as we can rely on the accuracy of the tagging.",
        "entities": [
            [
                143,
                150,
                "TERM"
            ]
        ]
    },
    {
        "text": "While much of that work has, of course, been successful because, for example, high token frequencies in b and c are positively correlated with high type frequencies, and high token frequencies in a are negatively correlated with clumpy distributions, it is unclear how potentially skewed the results are for cases where those correlations do not hold.",
        "entities": [
            [
                83,
                88,
                "TERM"
            ],
            [
                175,
                180,
                "TERM"
            ],
            [
                148,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is best done inside the style sheet definition, but may also happen inside the XML file itself.",
        "entities": [
            [
                84,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "In both these cases, automatic tagging tools have been shown to be less accurate and robust.",
        "entities": [
            [
                31,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus comprises selected extracts of narratives, 153 in all, for a total of around 150,000 words, taken from the demographically sampled 'casual conversations' section of the BNC, which is balanced by sex, age group, region and social class, and which totals approximately 4.5 million words.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this study would require the assembly of a corpus which tangibly represents the legal language, such as court decisions, because these writings properly match the targeted field of study, that is, the legal language.",
        "entities": [
            [
                52,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "Following on from the critical reflection about the limitations of computational methods and tools in corpus linguistics, this section will zoom in on one of the standard methods and illustrate some of the potential problems with it for corpus linguists and some possible solutions.",
        "entities": [
            [
                102,
                120,
                "TERM"
            ],
            [
                102,
                108,
                "TERM"
            ],
            [
                237,
                243,
                "TERM"
            ]
        ]
    },
    {
        "text": "Among these systems, XML systems are used frequently since they include both SGML and TEI.",
        "entities": [
            [
                21,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "The best way to do this is to save both sets of result to text files as we did earlier for our concordancing results.",
        "entities": [
            [
                58,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter has shown that corpus approaches to the study of literary style can take various forms.",
        "entities": [
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "Regarding overlap tags, you'd actually be quite right in assuming that, theoretically, these should be container elements because they mark up specific spans of text.",
        "entities": [
            [
                161,
                165,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will use G through much of the remainder of this book whenever dealing with collocations or collocation-like phenomena.",
        "entities": [
            [
                95,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, all the corpus studies illustrated in this chapter were carried out on corpora of very diverse shape and size.",
        "entities": [
            [
                17,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "Please note that the extensions for the files containing the word tokens (.tok) and frequency lists (.frq) are not extensions that are generally recognised by any programs, such as editors, but you'll be able to view them with any text editor if you use the usual file-opening mechanisms.",
        "entities": [
            [
                231,
                235,
                "TERM"
            ]
        ]
    },
    {
        "text": "These corpora certainly have their uses, but they push the definition of a linguistic corpus in the sense discussed above to their limit.",
        "entities": [
            [
                86,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "Dynamic corpora grow over time as more and more texts are included (monitor corpora are a type of dynamic corpus).",
        "entities": [
            [
                106,
                112,
                "TERM"
            ],
            [
                90,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unlike the previous four methods, where some minor operational differences that exist in tokenization for frequency lists, concordances, keywords, and n-grams could produce slightly different results in different tools, the collocation method itself is less tightly defined.",
        "entities": [
            [
                224,
                235,
                "TERM"
            ]
        ]
    },
    {
        "text": "The problems faced by such researchers are similar to those faced by corpus linguiststhey often wish to characterise a population which is far too large to encompass fully.",
        "entities": [
            [
                69,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, over the years, researchers have realised that even this type of size and stratification may not be sufficient for performing certain tasks -such as research in lexicography or collocations (see Chapter 10) -efficiently, and hence started devising ways of creating a variety of different types of corpora, representative of both spoken and written language, and of varying sizes, ranging from very small specialised corpora to some that comprise many millions of words.",
        "entities": [
            [
                66,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a matter of fact, issues related to multilingual annotation (e.g. whether it should be languagespecific or language-neutral, or, more generally, how cross-linguistic comparability can be achieved) have received relatively little attention in contrastive linguistics and translation studies (one notable exception is Neumann 2013).",
        "entities": [
            [
                52,
                62,
                "TERM"
            ],
            [
                169,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "We use lines to add the type-token ratio plot and add smoothers with lines(lowess(...)).",
        "entities": [
            [
                29,
                34,
                "TERM"
            ],
            [
                24,
                28,
                "TERM"
            ],
            [
                24,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us further limit the category to verbs first documented before the 19th century, in order to leave a clear diachronic gap between the established types and the productive types.",
        "entities": [
            [
                111,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "In principle, the former only applies to corpora for general use, though, as it's often assumed that these ought to provide an equal amount of materials from many different genres or areas of relevance that allow us to investigate a representative and realistic sample of the language and draw more or less universally applicable conclusions.",
        "entities": [
            [
                262,
                268,
                "TERM"
            ]
        ]
    },
    {
        "text": "These matters include attempting to achieve comparability and representativeness, two important but sometimes mutually exclusive goals.",
        "entities": [
            [
                62,
                80,
                "TERM"
            ],
            [
                44,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "One of the ways of selecting material for a corpus is by stratified sampling, where the hierarchical structure (or 'strata') of the population is determined in advance.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "Linguists would probably agree that the design of the ICE corpora is \"more representative\" than that of the BNC Baby, which is in turn \"more representative\" than that of the BROWN corpus and its offspring.",
        "entities": [
            [
                180,
                186,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, given its robustness, high reliability, flexibility, and potential for reusability and replicability, it is at least worth considering whether this (semi-)automated data annotation procedure could be what is next for corpus linguistic methodology.",
        "entities": [
            [
                176,
                186,
                "TERM"
            ],
            [
                223,
                229,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, a true conversion to percentage can be achieved by considering the maximum possible variation in a given corpus.",
        "entities": [
            [
                114,
                120,
                "TERM"
            ]
        ]
    },
    {
        "text": "A concordance provides a quick overview of the typical usage of a particular (set of) word forms or more complex linguistic expressions.",
        "entities": [
            [
                2,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have also described the different forms that variables in a corpus may adopt, and highlighted the fact that statistical tests must be adapted to the nature of the variables.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "The type/token ratio cannot therefore be considered as a reliable measure of linguistic development.",
        "entities": [
            [
                9,
                14,
                "TERM"
            ],
            [
                4,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, what we're really looking into here is a form of colligation, which, however, is probably a little too finegrained for most purposes.",
        "entities": [
            [
                65,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "To do justice to examples such as (5), a corpus architecture must be capable of mapping word forms and annotations to any number of tokens, in the sense of minimal units.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a result, the handbook includes relatively little discussion of topics that have been fully covered in existing textbooks, such as surveys of existing corpora, or methodological discussions of corpus construction and analysis.",
        "entities": [
            [
                196,
                215,
                "TERM"
            ],
            [
                196,
                202,
                "TERM"
            ]
        ]
    },
    {
        "text": "After the loop, we will again use exact.matches.2 to retrieve the tags from the matches, we will use gsub to retrieve the forms only (i.e., discard all annotation), and we will use substr to define the lemma of each match (by retrieving the first letter, which gives us enough information to distinguish run and walk) and using ifelse to define a lemma column).",
        "entities": [
            [
                202,
                207,
                "TERM"
            ],
            [
                347,
                352,
                "TERM"
            ],
            [
                152,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "One monitor corpus that allows us to see changes in spoken corpora and also provides more current spoken data is COCA.",
        "entities": [
            [
                4,
                18,
                "TERM"
            ],
            [
                12,
                18,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because so much text is now available in computer-readable form, many stages of dictionary creation can be automated.",
        "entities": [
            [
                16,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we recalled above, it is not always optimal to include entire texts in a corpus when these are very long.",
        "entities": [
            [
                76,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "This corpus-internal variability should be taken into account when doing LCR.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "Lexical information is one area where the corpus-informed books have a clear advantage over the non-corpus-informed books.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ],
            [
                100,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "A more common approach is to begin with a single word (or lemma) of interest, called the node, for which a concordance search has been performed; the surrounding text is then scrutinised to establish what elements occur frequently in the vicinity of the node.",
        "entities": [
            [
                89,
                93,
                "TERM"
            ],
            [
                254,
                258,
                "TERM"
            ],
            [
                58,
                63,
                "TERM"
            ],
            [
                107,
                118,
                "TERM"
            ],
            [
                162,
                166,
                "TERM"
            ]
        ]
    },
    {
        "text": "Metadata is data about data, that is, information about the texts that have been included in the corpussuch as whether they are written or spoken, information about genre or domain, bibliographic information on original publication of a written text, or demographic information about the speakers in a spoken text.",
        "entities": [
            [
                245,
                249,
                "TERM"
            ],
            [
                309,
                313,
                "TERM"
            ]
        ]
    },
    {
        "text": "First of all, keeping the 'Search Term Position' set to 'On Left' will help to mainly identify noun or NP collocates, while changing this to 'On Right' reveals other types of combinatorial options, such as combinations of determiners, possessive pronouns, intensifying adverbs, etc. with the node.",
        "entities": [
            [
                292,
                296,
                "TERM"
            ]
        ]
    },
    {
        "text": "The main distinguishing characteristic of corpus-driven studies of phraseological patterns is that they do not begin with a pre-selected list of theoretically interesting words or phrases.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ],
            [
                42,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, there are 36 types that occur only in the prose sample (for example, churchmanship, dreamership, librarianship and swordsmanship) and 12 that occur only in the newspaper sample (for example, associateship, draughtsmanship, trusteeship and sportsmanship).",
        "entities": [
            [
                61,
                67,
                "TERM"
            ],
            [
                183,
                189,
                "TERM"
            ]
        ]
    },
    {
        "text": "The second hypothesis is confirmed for both observations: in the translated component, the most frequent word forms account for a significantly higher percentage of the corpus and the proportion of high-frequency to lowfrequency words is significantly higher.",
        "entities": [
            [
                169,
                175,
                "TERM"
            ]
        ]
    },
    {
        "text": "As the term suggests, it is a ratio of two probabilities from the crosstab table comparing the probability of a particular linguistic outcome (e.g. the definite article) occurring in one context type relative to the same outcome occurring in the other context type.",
        "entities": [
            [
                195,
                199,
                "TERM"
            ],
            [
                260,
                264,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we will see throughout the chapter, creating a corpus is a challenging task and presents many difficulties.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to the corpus-informed books, we will also review four popular noncorpus-informed grammar books at this same upper-intermediate to advanced level.",
        "entities": [
            [
                19,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "Linguists analyzing this corpus would draw totally incorrect conclusions about the language in question, since this person does not represent the linguistic competence of a typical speaker.",
        "entities": [
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "Until relatively recently, corpus-based studies have tended to focus almost exclusively on the English language, and on British and American English in particular.",
        "entities": [
            [
                27,
                39,
                "TERM"
            ],
            [
                27,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "For Step 3, make sure that you are still using the COCA corpus and have selected \"chart\" in the search.",
        "entities": [
            [
                56,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "We add a numeric second-level fixed effect which specifies the token frequency for each level of LEMMA in the following R code.",
        "entities": [
            [
                63,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "As pointed out in connection with the comparison of the TTRs for mini-in the FLOB and the FROWN corpus, we would like to be able to test differences between two (or more) TTRs (and, of course, also two or more HTRs) for statistical significance.",
        "entities": [
            [
                96,
                102,
                "TERM"
            ],
            [
                220,
                244,
                "TERM"
            ]
        ]
    },
    {
        "text": "Essentially, being a concordance facility, too, some of its basic features are rather similar to the ones we've already discussed for AntConc.",
        "entities": [
            [
                21,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "You generate a frequency list when you want to know how often something -usually words -occur in a corpus.",
        "entities": [
            [
                99,
                105,
                "TERM"
            ],
            [
                15,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "This means that because w 2 is evenly distributed throughout the corpus, its frequency should not be reducedwe should continue to consider each instance as a separate occurrence.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can compare between corpora or within a corpus (for example, for different speaker roles such as questioner and responder) and we can compare a specialized corpus to a general (or \"heterogeneric\") one.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ],
            [
                159,
                165,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, if we change the composition of the corpus to make it more homogeneous, this ought to change very quickly.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is done for all of the distances between two occurrences of the word in the corpus.",
        "entities": [
            [
                81,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given especially the predominance of work on English in corpus linguistics, until rather recently many corpora came in the so-called ASCII (American Standard Code for Information Interchange) character encoding, an encoding scheme that encodes 2 7 = 128 characters as numbers and that is largely based on the Western alphabet.",
        "entities": [
            [
                56,
                74,
                "TERM"
            ],
            [
                56,
                62,
                "TERM"
            ],
            [
                202,
                210,
                "TERM"
            ],
            [
                215,
                223,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to talk about these problems, in this chapter, I use the words \"long\" and \"short\" to refer to texts which are and are not long enough for typical quantitative corpus-linguistic analysis, respectively, though the line between the two is of course fuzzy.",
        "entities": [
            [
                168,
                174,
                "TERM"
            ]
        ]
    },
    {
        "text": "My corpus of Cameron's published writing consists of 21 single-authored papers made available by the author.",
        "entities": [
            [
                3,
                9,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, at 1.9 billion words in length, the Corpus of Global Web-Based English is so lengthy that it would be impossible to determine not just the content of the corpus but the distribution of such variables as the gender of contributors, their ages, and so forth.",
        "entities": [
            [
                168,
                174,
                "TERM"
            ]
        ]
    },
    {
        "text": "Parameters are values that characterise an entire population and statistics are estimates of those parameters within a specific sample.",
        "entities": [
            [
                128,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will return to this in section 1.4, devoted to the connections between computer science and corpus linguistics.",
        "entities": [
            [
                95,
                113,
                "TERM"
            ],
            [
                95,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "At this age, his type/token ratio was 0.38.",
        "entities": [
            [
                22,
                27,
                "TERM"
            ],
            [
                17,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "Type/token ratio (TTR) expresses the proportion of types (different word forms) relative to the proportion of tokens (running words).",
        "entities": [
            [
                5,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "Anybody who wants the claims made based on a corpus to be accepted by the research community needs to show in some way that the corpus material is appropriate for the type of research done.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ],
            [
                128,
                134,
                "TERM"
            ],
            [
                167,
                171,
                "TERM"
            ]
        ]
    },
    {
        "text": "These areas are a challenge to be met by the next generation of corpus linguists focusing on spoken corpora.",
        "entities": [
            [
                64,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is also important to stress here that the concepts of source language and source text are becoming increasingly blurred.",
        "entities": [
            [
                84,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "Subsequent sections discuss other topics relevant to planning the building of a corpus, such as defining exactly what a corpus is.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ],
            [
                120,
                126,
                "TERM"
            ]
        ]
    },
    {
        "text": "GloWbE was constructed using 'web for corpus' techniques, seeded through search engines queries.",
        "entities": [
            [
                38,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "These corpora were individually compared with a larger reference corpus representing a spectrum of current published work in applied linguistics and in the same genres as the target texts.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ],
            [
                55,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "In CFA, an intersection of variables whose observed frequency is significantly higher than expected is referred to as a type and one whose observed frequency is significantly lower is referred to as an antitype (but if we do not like this terminology, we do not have to use it and can keep talking about \"more or less frequent than expected\", as we do with bivariate 𝜒 2 tests).",
        "entities": [
            [
                120,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "If one is planning to create a multi-purpose corpus, for instance, it will be important to consider the types of genres to be included in the corpus; the length not just of the corpus but of the samples to be included in it; the proportion of speech versus writing that will be included; the educational level, gender, and dialect backgrounds of speakers and writers included in the corpus; and the types of contexts from which samples will be taken.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ],
            [
                142,
                148,
                "TERM"
            ],
            [
                177,
                183,
                "TERM"
            ],
            [
                383,
                389,
                "TERM"
            ]
        ]
    },
    {
        "text": "Corpus studies do not make it possible to draw this type of conclusion.",
        "entities": [
            [
                52,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to charting the history and development of keyword research (in Section 1), our discussions have been designed to emphasize that key lexical items should be used as a guide for what to analyze qualitatively, and not considered the end product in themselves.",
        "entities": [
            [
                55,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "Consequently, much of what could potentially be annotated in a written text is likely to be of marginal interest to future users of the corpus.",
        "entities": [
            [
                136,
                142,
                "TERM"
            ],
            [
                71,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "The (orthographic) word plays a central role in corpus linguistics.",
        "entities": [
            [
                48,
                66,
                "TERM"
            ],
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "This really only makes sense if you're planning to put the result into a relational database for complex analysis and annotation, and where you'll automatically be able to look up what the numbers mean from a lookup table.",
        "entities": [
            [
                118,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "A corpus is a collection of a fairly large number of examples (or, in corpus terms, texts) that share similar contextual or situational characteristics.",
        "entities": [
            [
                2,
                8,
                "TERM"
            ],
            [
                70,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "Just like Firefox, it also breaks longer paragraphs into shorter lines, thus adding extra line breaks that do not form part of the original text.",
        "entities": [
            [
                140,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Traitement des corpus oraux en français project or TCOF from the ATILF laboratory brings together corpora collected between the 1980s and 1990s, and later enriched in the 2000s.",
        "entities": [
            [
                19,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "The presence of proper nouns in the keyword lists is very frequent because these words often specifically refer to a particular person, which is not used equally in different corpora.",
        "entities": [
            [
                36,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, the pressing academic quest is to review past achievements as well as future directions of corpus linguistics.",
        "entities": [
            [
                97,
                115,
                "TERM"
            ],
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "Various registers are also included in the corpus, such as law, philosophy, history, and fiction.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "Interpretative information is classified into two types: (i) intralinguistic information, which is linked with linguistic features and properties of a text, and (ii) extralinguistic information, which is related to information not linked with linguistic properties and features of a text.",
        "entities": [
            [
                151,
                155,
                "TERM"
            ],
            [
                283,
                287,
                "TERM"
            ]
        ]
    },
    {
        "text": "To transfer and align the data is probably the most difficult and time-consuming part of the exercise because it's easy enough to make mistakes when creating new rows and moving the data around, as well as adding the noughts to the relevant cells where a type doesn't exist in one of the corpora.",
        "entities": [
            [
                255,
                259,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this chapter, we have defined corpus linguistics as an empirical discipline, that is, based on the observation of real data.",
        "entities": [
            [
                33,
                51,
                "TERM"
            ],
            [
                33,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, a frame occurring 200 times with 25 distinct fillers would have a type-token ratio of .",
        "entities": [
            [
                84,
                89,
                "TERM"
            ],
            [
                79,
                83,
                "TERM"
            ],
            [
                79,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "Of course, you could fix this manually, but, since we've now separated the data from our ability to concordance on it, we'd have to go back into BNCweb to look at the original frequency list.",
        "entities": [
            [
                176,
                190,
                "TERM"
            ],
            [
                100,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "It would be unrealistic, therefore, to expect that different POS-tagging algorithms for the same language will produce identical results.",
        "entities": [
            [
                65,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "The statistical significance of a correlation is directly related to the number of observations (cases).",
        "entities": [
            [
                4,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "The previous sections have discussed several methodological issues that need to be considered as one plans and creates a corpus.",
        "entities": [
            [
                121,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "The data presented above have shown that the envelope of variation that is studied will result in a different picture of the relation among ENL and ESL varieties: it makes a difference, for instance, whether the overall text frequency of PPs is compared or whether the variable is defined more narrowly, e.g. as an alternation between PP and SP in perfect contexts.",
        "entities": [
            [
                220,
                224,
                "TERM"
            ]
        ]
    },
    {
        "text": "In another type, such combinations generally create a complex meaning, as in, for example, up until or down below, where the resulting meaning is a mix of the semantic properties of both elements.",
        "entities": [
            [
                11,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "One way is manual and largely qualitative: to undertake a hand-and-eye analysis of the concordance, as explained above, where the focus of analysis is to identify co-occurring elements, the collocates of the node, in the concordance lines.",
        "entities": [
            [
                208,
                212,
                "TERM"
            ],
            [
                87,
                98,
                "TERM"
            ],
            [
                221,
                232,
                "TERM"
            ]
        ]
    },
    {
        "text": "Before we start, please watch the tutorial on how to use the keyword feature in AntConc: www.youtube.com/watch?v=SludW4FHatI&list=PL iRIDpYmiC0SjJeT2FuysOkLa45HG_tIu&index=10.",
        "entities": [
            [
                61,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, these differences very obviously depend on the topics of the conversations included in the corpus.",
        "entities": [
            [
                100,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, data for a study of student performance at university might include variables like personality type, degree of motivation, score on intelligence tests, scholastic record, family background, class, ethnicity, age, and health.",
        "entities": [
            [
                108,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "Despite its limitations, bootstrapping can provide a wealth of information about the distribution of a sample.",
        "entities": [
            [
                103,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, a concordance can be produced for a certain part-of-speech tag, a frequency list of lemmas, key semantic tags, and calculate collocation statistics for which semantic tags relate to a given word.",
        "entities": [
            [
                139,
                150,
                "TERM"
            ],
            [
                80,
                94,
                "TERM"
            ],
            [
                16,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter describes the process of analyzing a completed corpus.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, a concept known as 'semantic sequences' was developed -this suggested that concordance lines can be read to identify 'what is often said', thus moving from lexis to grammar to discourse.",
        "entities": [
            [
                88,
                99,
                "TERM"
            ],
            [
                169,
                174,
                "TERM"
            ]
        ]
    },
    {
        "text": "A higher z-score indicates a greater degree of collocability of an item with the node word.",
        "entities": [
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "A plain text format (such as .txt) is often used for corpus files.",
        "entities": [
            [
                53,
                59,
                "TERM"
            ],
            [
                8,
                12,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, once we have extracted and -if necessary -manually cleaned up our data set, we are faced with a problem that does not present itself when studying lexis or grammar: the very fact that affixes do not occur independently but always as parts of words, some of which (like wordform-centeredness in the first sentence of this chapter) have been created productively on the fly for a specific purpose, while others (like ingenuity in the same sentence) are conventionalized lexical items that are listed in dictionaries, even though they are theoretically the result of attaching an affix to a known stem (like ingen-, also found in ingenious and, confusingly, its almost-antonym ingenuous).",
        "entities": [
            [
                156,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "This function is a good function to start with as it chooses what type of graph to use based on the kind(s) of variables to be plotted.",
        "entities": [
            [
                66,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another distinction that can be made regarding the types of existing corpora relates to the type of processing carried out on the linguistic data of the corpus.",
        "entities": [
            [
                153,
                159,
                "TERM"
            ],
            [
                92,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, the position of the collocate in text (whether it occurs predominantly before or after the node) is shown by the position of the collocate in the graph (left, middle or right).",
        "entities": [
            [
                100,
                104,
                "TERM"
            ],
            [
                42,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "These annotations imply a global processing of the corpus.",
        "entities": [
            [
                51,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "But in research projects that are based on a specific understanding of Sex (for example, as a purely biological, a purely social or a purely psychological category), simply accepting the (often unstated) operational definition used by the corpus creators may distort our results substantially.",
        "entities": [
            [
                239,
                245,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are various ways of processing (e.g., data analytics, concordance, collocation, keyword marking, local-word-grouping, lexical clustering, lemmatization, morphological processing, sentence processing, and named entity marking), which are applied to a corpus with appropriate technological supports.",
        "entities": [
            [
                256,
                262,
                "TERM"
            ],
            [
                73,
                84,
                "TERM"
            ],
            [
                86,
                93,
                "TERM"
            ],
            [
                60,
                71,
                "TERM"
            ],
            [
                144,
                157,
                "TERM"
            ]
        ]
    },
    {
        "text": "The nonstandard indirect word order occurs both in wh-type questions (e.g. I wonder when are they coming) as well as in yes/no-type embedded questions (e.g. I wonder are they coming) in both ELFA and MICASE.",
        "entities": [
            [
                54,
                58,
                "TERM"
            ],
            [
                127,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "What therefore seems to be even more important than recognising the c-unit as the correct unit is the fact that one should always be aware that there are certain boundaries in text that form natural borders between the units of text we may want to see as belonging together, an issue that gains in importance once we move away from looking at single words only.",
        "entities": [
            [
                176,
                180,
                "TERM"
            ],
            [
                228,
                232,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to protect the privacy of tweet authors, we only reproduce textual content without any metadata.",
        "entities": [
            [
                96,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the purposes of illustration, all occurrences of the word love with their immediate contextone word to the left and one word to the rightare highlighted and the poem is displayed without line breaks to create one paragraph of run-on text.",
        "entities": [
            [
                237,
                241,
                "TERM"
            ]
        ]
    },
    {
        "text": "This case study demonstrated a complex design involving grammar, lexis and semantic categories.",
        "entities": [
            [
                65,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "This length of conversation increases the probability that a natural and coherent sample of speech can be extracted from this longer sample.",
        "entities": [
            [
                82,
                88,
                "TERM"
            ],
            [
                133,
                139,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the second part, we use character and numeric to create empty collector vectors to merge the hyphenated forms and their frequencies from all over the corpus, a for-loop to load each frequency list file, and, if there are hyphenated forms in the file, we merge them with subsetting, incrementing the vector counter on each iteration (as in Section 5.2.8).",
        "entities": [
            [
                153,
                159,
                "TERM"
            ],
            [
                185,
                199,
                "TERM"
            ]
        ]
    },
    {
        "text": "Knowing all of this, you isolate this one pronoun type because you are interested in the use of first person pronouns (I, me, we, us).",
        "entities": [
            [
                50,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "By default, AntConc uses UTF-8 encoding.",
        "entities": [
            [
                31,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "When you are extracting n-grams from a corpus, you can imagine that your sequences could be endless.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, by default, a general corpus includes examples of the variety considered as a language standard, or one of its main varieties.",
        "entities": [
            [
                31,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although it's of course somewhat easier to confine our corpus-based investigation to single lexical items, single words and their frequencies aren't the only interesting things we may want to analyse with the help of corpora.",
        "entities": [
            [
                55,
                67,
                "TERM"
            ],
            [
                55,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "This ensures the extracted sample corpus is reasonably clean and can therefore be expected to provide reliable output for standard corpus linguistic tasks.",
        "entities": [
            [
                27,
                40,
                "TERM"
            ],
            [
                34,
                40,
                "TERM"
            ],
            [
                131,
                137,
                "TERM"
            ],
            [
                27,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "Again, metonymy is a vastly under-researched area in corpus linguistics, so much work remains to be done.",
        "entities": [
            [
                53,
                71,
                "TERM"
            ],
            [
                53,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "Besides awareness of these difficulties, a more bottom-up and data-driven approach to describing diatypic text properties may, in the long term, provide the more satisfactory solutions.",
        "entities": [
            [
                106,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "These sequences seem easy enough to identify in a corpus (or in a list of hits for appropriately constructed queries), so a researcher studying the possessive may not even mention how they defined this construction.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Phonetic data was abstracted from the Diachronic Electronic Corpus of Tyneside English (DECTE), a digital corpus of audio-recorded and transcribed speech from Tyneside in North-East England.",
        "entities": [
            [
                106,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "Section 7.3 is devoted to comparative corpus annotations in the context of corpus-based typology.",
        "entities": [
            [
                75,
                87,
                "TERM"
            ],
            [
                38,
                44,
                "TERM"
            ],
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "Stubbs does not present the results of his procedure in detail and the corpus he uses is not accessible anyway, so let us use the BNC again and extract our own data.",
        "entities": [
            [
                71,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "The incorporation of a computational annotation system allows for systematic, rigorous annotation followed by statistical analysis.",
        "entities": [
            [
                37,
                47,
                "TERM"
            ],
            [
                87,
                97,
                "TERM"
            ]
        ]
    },
    {
        "text": "Here, we discuss issues related to the reliability of the database with respect to OCR (Optical Character Recognition) accuracy as well as problems pertaining to the balance of the database and the metadata associated with it.",
        "entities": [
            [
                198,
                206,
                "TERM"
            ],
            [
                166,
                173,
                "TERM"
            ]
        ]
    },
    {
        "text": "Indeed, we speculate that in years to come, much, if not all, pragmatics research will involve corpus linguistics.",
        "entities": [
            [
                95,
                113,
                "TERM"
            ],
            [
                95,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some proponents of 'pure' XML technology would even frown upon what we've done here and argue that XML was meant to be processed by the computer, anyway, and could then be rendered in whichever way it would be best viewed.",
        "entities": [
            [
                26,
                29,
                "TERM"
            ],
            [
                99,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "This choice reflects speakers' effort to find a balance between explicitness and economy.",
        "entities": [
            [
                48,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "Since the notion of word is a little ambiguous here, it is useful to introduce a common distinction between (word) type and (word) token.",
        "entities": [
            [
                131,
                136,
                "TERM"
            ],
            [
                115,
                119,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us look at what a corpus might tell us about splitting infinitives.",
        "entities": [
            [
                22,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we saw above, this is easy to remedy by simply determining the exact number of times that the phenomenon in question occurs in a given sample.",
        "entities": [
            [
                138,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "This issue, too, can be illustrated with the help of the same sample corpus from Hiltunen (2021), Corpus A, which comprises complete issues of the four newspapers sampled at 10-year intervals.",
        "entities": [
            [
                62,
                75,
                "TERM"
            ],
            [
                69,
                75,
                "TERM"
            ],
            [
                62,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "The more limited the topic contained in the corpus, the easier it'll become to identify the latter.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "I will leave it as an exercise to the reader to determine whether and in what direction these frequencies differ from what would be expected either under an assumption of equal proportions or given the proportion of female and male speakers in the corpus.",
        "entities": [
            [
                248,
                254,
                "TERM"
            ]
        ]
    },
    {
        "text": "This can be especially tricky, as there is often some variation in how these items appear across a corpus (or even within a text); for example, although the hyphenated form, well-being, is clearly the most common option found in the Corpus of Contemporary American English (COCA) (>8000 occurrences), the forms well being and wellbeing each occur several hundred times.",
        "entities": [
            [
                99,
                105,
                "TERM"
            ],
            [
                124,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, a topic examining gender differences could involve creating a corpus of fitness articles with females as the intended audience and comparing this to a corpus of fitness articles with males as the intended audience.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ],
            [
                164,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "This can be done by calculating frequency, variance, vmr, and t fid f values for each column of the data matrix, sorting each set of values in descending order of magnitude, z-standardizing for comparability, and then co-plotting.",
        "entities": [
            [
                194,
                207,
                "TERM"
            ]
        ]
    },
    {
        "text": "ICEweb already caters for some of that information by keeping a little text database that you can open with Excel or OpenOffice Calc.",
        "entities": [
            [
                71,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "In particular, all of the above approaches only deal with the minimal amount of information one should include-the more comprehensive information regarding token and type frequency distributions and entropies still awaits first exploration.",
        "entities": [
            [
                156,
                161,
                "TERM"
            ],
            [
                166,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "The basic distinction in (28) looks simple, so that any competent speaker of a language should be able to categorize the referents of nouns in a text accordingly.",
        "entities": [
            [
                145,
                149,
                "TERM"
            ]
        ]
    },
    {
        "text": "There may be more than one mode in a given sample.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "To study press reportage, for instance, it is only necessary to take from a given corpus all samples of press reportage, and to study within this sub-corpus whatever one wishes to focus on.",
        "entities": [
            [
                82,
                88,
                "TERM"
            ],
            [
                150,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, the study employs bootstrapping techniques and mixed-effects modeling to investigate issues such as the role of idiolectal differences and the validity of cross-corpus generalizations.",
        "entities": [
            [
                174,
                180,
                "TERM"
            ]
        ]
    },
    {
        "text": "We'll talk more about this type of issue in Section 4.4.1, where we'll explore ways of dealing with such features of the text in order to retain relatively 'clean' data.",
        "entities": [
            [
                27,
                31,
                "TERM"
            ],
            [
                121,
                125,
                "TERM"
            ]
        ]
    },
    {
        "text": "While we acknowledge the use and importance of combining these two approaches, in the rest of the book we will focus on the quantitative approach to corpus linguistics, which poses its own theoretical and methodological challenges.",
        "entities": [
            [
                149,
                167,
                "TERM"
            ],
            [
                149,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "The suffix has a relatively high token frequency: there are 2862 tokens in the fiction section of the BNC, and 7189 tokens in the newspaper section (including all sub-genres of newspaper language, such as reportage, editorial, etc.) (the data are provided in the Supplementary Online Material, file LAF3).",
        "entities": [
            [
                33,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "Bresnan et al. calculate several logistic regression models that all correctly predict more than 90 percent of the actual dative outcomes in the Switchboard collection of recorded telephone conversations and in a corpus of Wall Street Journal texts.",
        "entities": [
            [
                213,
                219,
                "TERM"
            ]
        ]
    },
    {
        "text": "Other things that will crop up frequently are bits of information related to the plays that form part of this 'corpus', such as references to the author, to acts and scenes within the plays.",
        "entities": [
            [
                111,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is no node word and no directional influence, and the purpose is not to find out more about an individual word.",
        "entities": [
            [
                12,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Below, we will use it to analyze a corpus based measure, namely the type-token ratio (TTR) of different texts that have the same overall length.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ],
            [
                73,
                78,
                "TERM"
            ],
            [
                68,
                72,
                "TERM"
            ],
            [
                68,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, in case of a monitor corpus, which tries to represent all possible text varieties, we may include all non-standard and ordinary text samples along with standard and established text samples.",
        "entities": [
            [
                32,
                46,
                "TERM"
            ],
            [
                40,
                46,
                "TERM"
            ],
            [
                86,
                90,
                "TERM"
            ],
            [
                147,
                151,
                "TERM"
            ],
            [
                196,
                200,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter has highlighted the growing recognition of the crucial role played by the register parameter in historical corpus linguistics.",
        "entities": [
            [
                120,
                138,
                "TERM"
            ],
            [
                120,
                126,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, the word Mme in line 94 is an abbreviation, indicated in the corpus by the sequence \\0 preceding it.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first part of this chapter surveys the development of corpus-based translation studies (CBTS), from the programmatic proposals in the early 1990s to recent developments and trends.",
        "entities": [
            [
                58,
                70,
                "TERM"
            ],
            [
                58,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "The DECTE data are generated by counting the frequency of phonetic segments in interviews, so completeness and accuracy should not be issues if the survey is carefully done using a reliable procedure; manual counting of features in physical text by direct observation is in general far less accurate than the software equivalent for electronic text.",
        "entities": [
            [
                241,
                245,
                "TERM"
            ],
            [
                344,
                348,
                "TERM"
            ]
        ]
    },
    {
        "text": "That being said, as we discussed in Chapter 2, it is difficult to identify certain pragmatic uses automatically by means of a corpus search, because these uses are not transparently linked with the linguistic form used.",
        "entities": [
            [
                126,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, personal letters are often less than 2,000 words, and a text sample can be comprised of complete letters totaling 2,000 words.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ],
            [
                70,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "The second was to avoid a prior division of our corpus into registers.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to avoid this problem, it would be necessary to collect a sample of texts, representative of the works of this period.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "This approach to Corpus Linguistics is based on the observation of pattern in concordance lines, where a word or short phrase is the node of the line and the few words occurring before and after the phrase are shown for each occurrence.",
        "entities": [
            [
                133,
                137,
                "TERM"
            ],
            [
                78,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "Comparing the features of target writers' texts with a much larger reference corpus of work in the same discipline can help to determine what is general in the norms of a community and what represents more personal choices.",
        "entities": [
            [
                77,
                83,
                "TERM"
            ],
            [
                67,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "This hypothesis has been partly confirmed through corpus studies, performed on a single language pair and limited to one translation direction.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, because texts to be included in a corpus will be edited with some kind of text editing program, it may be tempting to save computerized texts in a file format used by a word processing program (such as files with the extension .doc in Microsoft Word).",
        "entities": [
            [
                41,
                47,
                "TERM"
            ],
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, studies in corpus linguistics (and in the social sciences in general) often fail to report effect sizes, but we can usually calculate them from the data provided, and one should make a habit of doing so.",
        "entities": [
            [
                26,
                44,
                "TERM"
            ],
            [
                26,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "This includes errors (which were the focus of pre-corpus interlanguage studies), but also cases of under-or overuse, i.e. the use of significantly fewer or more instances of a particular item as compared to the reference corpus.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ],
            [
                221,
                227,
                "TERM"
            ],
            [
                211,
                227,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some programs (e.g. WordSmith, AntConc) run from the researcher's desktop computer; this means that the user can analyse any corpus they have available locally using these programs.",
        "entities": [
            [
                125,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "Second, in Section 6 we will consider the issue of variation within English, by looking primarily at genre coverage and balance in the corpora.",
        "entities": [
            [
                120,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, if you have a ready-made concordancer, you click a few buttons (and enter a search term) to get the job done.",
        "entities": [
            [
                44,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the English-French pair (remember that the TED corpus is unidirectional), these variations enabled the authors to compare the impact of this variable on the translations under scrutiny.",
        "entities": [
            [
                51,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we have described in previous chapters, one of the main focuses of corpus linguistic research is variation.",
        "entities": [
            [
                70,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although we can get a parameter estimate from this sample, we have no way of measuring the accuracy of our estimate without knowing the sampling distribution.",
        "entities": [
            [
                51,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the former, our table contains the frequencies of \"perl\" in each corpus part (in the column for TRUEs), which we can divide by the overall frequency of \"perl\" in the file to get percentages (to be stored in a vector called obs.percs), and we can use the function rowSums to compute the corpus part sizes in percentage in a vector exp.percs (which should all be really close to 10 percent, given how we split the corpus up into ten parts above), from which we can compute DP.",
        "entities": [
            [
                69,
                75,
                "TERM"
            ],
            [
                290,
                296,
                "TERM"
            ],
            [
                416,
                422,
                "TERM"
            ]
        ]
    },
    {
        "text": "After Tim Berners-Lee had invented the World Wide Web (WWW) in 1989, it was necessary to develop a new, and simpler, markup language in order to take full advantage of the new hypertext medium.",
        "entities": [
            [
                117,
                123,
                "TERM"
            ],
            [
                117,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will then review the different types of annotations we can add to a corpus, briefly present some tools for performing some annotations automatically or for making manual annotations easier.",
        "entities": [
            [
                71,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, the collocation box under Sense 4 of the verb support (\"to show that an idea, statement, theory etc. is true or correct\") lists eight abstract nouns that are frequently used as objects of the verb in academic texts: argument, claim, conclusion, contention, hypothesis, idea, theory, and view.",
        "entities": [
            [
                17,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus contains 48,569 texts -which are equivalent to web pages herecomprising 52,933,543 wordform tokens.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "First generation corpora, such as Brown and LOB, were relatively short (each of one million words in length), mainly because of the logistical difficulties that computerizing a corpus created.",
        "entities": [
            [
                177,
                183,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, Sketch Engine provides the option to search by lemma or by grammatical category.",
        "entities": [
            [
                60,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, with the advent of electronic corpora, the speed and systematicity with which diachronic -like synchronic -records can be queried has increased tremendously, opening up new research possibilities by dramatically facilitating at least some aspects of data collection.",
        "entities": [
            [
                104,
                114,
                "TERM"
            ],
            [
                87,
                97,
                "TERM"
            ]
        ]
    },
    {
        "text": "This case study analyzed variation in not contraction across year of publication, gender and region in a corpus of American letters to the editor.",
        "entities": [
            [
                105,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "As is obvious from the above, a lot of corpus-linguistic work does not discuss all their methodological aspects in sufficient detail, but in order to at least begin to approach the ideal of reproducibility, it is essential that all this information be provided at a sufficient level of detail.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "The central premise of corpus linguistics is that all of the language-internal andexternal contextual features are relevant to the way that people use language.",
        "entities": [
            [
                23,
                41,
                "TERM"
            ],
            [
                23,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "This problem can be handled with annotation during the actual transcription of the recording that marks certain sections as inaudible.",
        "entities": [
            [
                33,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Bringing an empirical dimension to the study of academic writing allows us not only to support intuitions, strengthen interpretations, and generally to talk about academic genres with greater confidence, but it contrasts markedly with impressionistic methods of text analysis which tend to produce partial and prescriptive findings, and with observation methods such as keystroke recording, which seek to document what writers do when they write.",
        "entities": [
            [
                262,
                266,
                "TERM"
            ]
        ]
    },
    {
        "text": "As an activity, compare multiple English corpora, such as the COCA or COHA, or look at multiple genres within one corpus.",
        "entities": [
            [
                114,
                120,
                "TERM"
            ]
        ]
    },
    {
        "text": "In fact a concordance of restraint and another of violen* in an 8-word span of on either/both/all sides yielded altogether 18 results, all of them contained in the Podium's turns.",
        "entities": [
            [
                10,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is because the longer a text becomes, the more likely it is to include any given feature.",
        "entities": [
            [
                29,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "This also requires the author to describe how, for instance, false hits, i.e. instances of something in a corpus that fits the structural description or regular expression used for data retrieval, but that turn out to not actually be instances of the phenomenon in question, were identified.",
        "entities": [
            [
                106,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "Beyond the world of the corpus linguistic researcher, frequency lists can be used directly or indirectly to support language learners by providing a way to focus on the more frequent words in a text, or suggesting priorities for language teachers when preparing lesson materials.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ],
            [
                194,
                198,
                "TERM"
            ]
        ]
    },
    {
        "text": "A frequency list generated with the second approach doesn't have that problem, which is why we will go with the second approach here.",
        "entities": [
            [
                2,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us assume that we conduct a corpus-based analysis of how speakers address each other in conversation.",
        "entities": [
            [
                32,
                44,
                "TERM"
            ],
            [
                32,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, it vividly illustrates, through the application of a corpus-based, bottom-up methodology, the close interrelationship between pragmatic function and context.",
        "entities": [
            [
                60,
                72,
                "TERM"
            ],
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each of the following sections is intended to illustrate one general problem associated with historical corpus linguistics by discussing individual studies that we have carried out previously.",
        "entities": [
            [
                104,
                122,
                "TERM"
            ],
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "At the very least, it is crucial to understand that tagging and other kinds of annotation are the result of applying operational definitions by other researchers and if we use tags or other forms of annotation, we must familiarize ourselves with these definitions by reading the fine manuals that typically accompany the corpus.",
        "entities": [
            [
                52,
                59,
                "TERM"
            ],
            [
                79,
                89,
                "TERM"
            ],
            [
                199,
                209,
                "TERM"
            ],
            [
                321,
                327,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus that has probably been the subject of the greatest number of studies of social dialect variation is the BNC, which is coded for a variety of demographic information, including age, gender, education level, and class.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once we have decided what to include in our corpus, we have to actually put together the different texts in such a way that we can analyse all data in essentially the same way concerning any particular research question.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "After all, the problems discussed here are not specifically corpus-linguistic ones.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "With massive amounts of computerized texts -now more easily obtained than ever before -at a keystroke one can generate a frequency list in a fraction of the time it would have taken to achieve the same task by hand.",
        "entities": [
            [
                121,
                135,
                "TERM"
            ]
        ]
    },
    {
        "text": "The English noun issue was used 1,957 times in the TED conference corpus.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "A first pilot annotation phase should be used for testing these categories, as well as for identifying problematic cases and leading to the preparation of a more or less detailed annotation manual.",
        "entities": [
            [
                14,
                24,
                "TERM"
            ],
            [
                179,
                189,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the corpus of spoken French from Quebec, there is no occurrence of the verb détester produced by men, versus 16 occurrences produced by women.",
        "entities": [
            [
                7,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "The virtue of working with a standard published corpus is that the corpus serves as a common basis between different researchers -allowing results to be tested and replicated by other scholars, for instance.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ],
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "The difference is that the sum of squared distances is divided not by the total number of corpus parts but by the total number of corpus parts minus 1 (the reason for this is connected with the notion of 'degrees of freedom' explained in Section 6.3).",
        "entities": [
            [
                90,
                96,
                "TERM"
            ],
            [
                130,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "The type of value assigned to any given variable depends on its meaning.",
        "entities": [
            [
                4,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "For a long time after the publication of the corpus in 1964, many people thought that 1 million words of text represented a general-enough sample to provide sufficient information about the makeup of the English language.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ],
            [
                139,
                145,
                "TERM"
            ],
            [
                105,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "An early trailblazer of corpus linguistics is George Kingsley Zipf.",
        "entities": [
            [
                24,
                42,
                "TERM"
            ],
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Improvements in speed and usability of corpus tools are important as well as interoperability between the tools.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "The need to use a large amount of data and the desire to quantify the presence of linguistic elements in a corpus corresponds to a quantitative research methodology.",
        "entities": [
            [
                107,
                113,
                "TERM"
            ]
        ]
    },
    {
        "text": "These modes differ from written texts in that the raw data is not readily amenable to inclusion in our corpus.",
        "entities": [
            [
                103,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "The following is the standard glm() call to estimate a model with the measure lemma (150 levels) as a fixed effect.",
        "entities": [
            [
                78,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "The frequencies of POS categoriesboth major categories such as pronouns and subcategories like personal or indefinite pronouns -were compared in two similar-sized corpora, a corpus of native novice writing, LOCNESS, and the French component of ICLE.",
        "entities": [
            [
                174,
                180,
                "TERM"
            ]
        ]
    },
    {
        "text": "Within the transcripts, it might be useful to include an annotation of the non-standard words used, for example, in verlan, with their equivalent standard so that they can be found in a concordancer.",
        "entities": [
            [
                57,
                67,
                "TERM"
            ],
            [
                186,
                198,
                "TERM"
            ]
        ]
    },
    {
        "text": "But the same can apply to written data -we might be interested in differences in how a word is used paragraph-initially versus medially or finally, for instance, and this can only be automated if the corpus has paragraph breaks marked up.",
        "entities": [
            [
                200,
                206,
                "TERM"
            ]
        ]
    },
    {
        "text": "It needs to be noted that in this section we have explored a type of logistic regression called binomial logistic regression, that is a logistic regression with an outcome variable with two categories like the and a/an.",
        "entities": [
            [
                61,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "Lemmatisation is conceptually the most straightforward of the word-level annotations; every word is, simply, annotated with the lemma to which it belongs (where each lemma is represented by its morphological base form, such as go for go, goes and went).",
        "entities": [
            [
                128,
                133,
                "TERM"
            ],
            [
                166,
                171,
                "TERM"
            ]
        ]
    },
    {
        "text": "If corpus linguistics wants to retain its scientific status, it should not be content with statements such as 'this feature was found in a large corpus that is, however, not available'.",
        "entities": [
            [
                3,
                21,
                "TERM"
            ],
            [
                3,
                9,
                "TERM"
            ],
            [
                145,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most of them rely on corpus linguistic methodology, but a few, mainly on the literary side of studies, focus on individual texts or passages and their interpretations.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, if the corpus is to be used primarily for grammatical analysis (e.g. the analysis of relative clauses or the structure of noun phrases), the corpus can consist simply of text excerpts rather than complete texts, and will minimally need part-of-speech tags.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ],
            [
                155,
                161,
                "TERM"
            ],
            [
                184,
                188,
                "TERM"
            ]
        ]
    },
    {
        "text": "The York-Toronto-Helsinki Parsed Corpus of Old English Prose (YCOE) is a 1.5-million-word syntactically annotated corpus representing Old English prose, with texts dating from before 850 up to 1150.",
        "entities": [
            [
                114,
                120,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus is available on request from the authors.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "The architecture chosen for a certain corpus refers to the conceptual division of different types of objects contained in a corpus, such as texts, annotations and metadata.",
        "entities": [
            [
                38,
                44,
                "TERM"
            ],
            [
                124,
                130,
                "TERM"
            ],
            [
                163,
                171,
                "TERM"
            ]
        ]
    },
    {
        "text": "If a text is collected, and saved for later computerization and annotation, the individual who collected the text may not be around to answer questions, and information about the text may consequently be lost.",
        "entities": [
            [
                64,
                74,
                "TERM"
            ],
            [
                5,
                9,
                "TERM"
            ],
            [
                109,
                113,
                "TERM"
            ],
            [
                179,
                183,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can refer to the former type as snapshot corpora, whereas the common term for the latter is monitor corpora.",
        "entities": [
            [
                27,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "The primary goal of research in corpus linguistics is to be able to draw conclusions in relation to a linguistic phenomenon, not only at the level of the observed data sample, but also to generalize it to all data of the same type.",
        "entities": [
            [
                32,
                50,
                "TERM"
            ],
            [
                32,
                38,
                "TERM"
            ],
            [
                168,
                174,
                "TERM"
            ],
            [
                226,
                230,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, lemmatisation allows frequency lists to be compiled at the level of the dictionary headword, which may subsume many distinct word-forms.",
        "entities": [
            [
                14,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a general sense, a corpus can refer to any collection of texts that serve as the basis for analysis.",
        "entities": [
            [
                22,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first was to generate new dimensions from a corpus of articles from a single academic journal (Global Environmental Change).",
        "entities": [
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, they can be estimated with a certain degree of confidence from an observed sample drawn from the population.",
        "entities": [
            [
                84,
                90,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, it is more likely that a word will occur in 6 out of 10 corpus parts than for that same word to occur in 600 out of 1000 corpus parts.",
        "entities": [
            [
                69,
                75,
                "TERM"
            ],
            [
                134,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "By providing a manually checked, dual POS tag which encodes both form and function (VOICE Project 2013), the XML corpus can be searched for all cases of an \"innovative\" form, in Cogo and Dewey's terms.",
        "entities": [
            [
                109,
                112,
                "TERM"
            ],
            [
                113,
                119,
                "TERM"
            ]
        ]
    },
    {
        "text": "VERB lemma, SPEAKER, TEXT, and COUNTY are non-repeatable effects, as a second study relying on randomly chosen verbs, speakers, texts, and counties would result in a different sample.",
        "entities": [
            [
                5,
                10,
                "TERM"
            ],
            [
                176,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "When we call them 4-grams, it does not matter how often they occur in a corpus; they are still called 4-grams.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "And once you've reached a more advanced level in your research, you might also want to consider using a 'proper' markup language, such as HTML or XML, for annotating and categorising your data.",
        "entities": [
            [
                146,
                149,
                "TERM"
            ],
            [
                113,
                119,
                "TERM"
            ],
            [
                113,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "At each step we consider and discuss both best practices as well as some of the many challenges unique to meta-analyzing research in corpus linguistics.",
        "entities": [
            [
                133,
                151,
                "TERM"
            ],
            [
                133,
                139,
                "TERM"
            ]
        ]
    },
    {
        "text": "The alignment is not complete; howeverwhile the critique in favour of introspection denies the utility of corpus linguistics on similar grounds to those of the anti-positivists, the scientia rationalis approach of the Chomskyans is clearly strongly aligned to a logical form of positivism.",
        "entities": [
            [
                106,
                124,
                "TERM"
            ],
            [
                106,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "Following this procedure, the sample corresponding to the first 18-year-old male participant from Marseille registered in the corpus would be saved in a file called \"221001.txt\".",
        "entities": [
            [
                126,
                132,
                "TERM"
            ],
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "The reality of contemporary corpus linguistics is that the corpora we rely on, in most cases, are simply too large for manually adding annotation, and the automated annotation of electronic texts has become the primary focus in the development of annotation methods.",
        "entities": [
            [
                135,
                145,
                "TERM"
            ],
            [
                165,
                175,
                "TERM"
            ],
            [
                247,
                257,
                "TERM"
            ],
            [
                28,
                46,
                "TERM"
            ],
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "Second, just like a corpus, a speaker's linguistic experience is limited to certain language varieties: most English speakers have never been to confession or planned an illegal activity, for example, which means they will lack knowledge of certain linguistic structures typical of these situations.",
        "entities": [
            [
                20,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "Consider again the major difference between published and private texts: where a text is published it is fixed to some medium in some basic format, whether digital or analogue.",
        "entities": [
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Recall from Section 3.6.3, this is a script in which we know the dimensions of the output in advance: If we have three words and 4,049 corpus files, we know, for instance, that the vector corresponding to sizes.of.files.in.words above will need to have 4,049 slots, and we know that the list that collects the three words' frequencies will need three components each with 4,049 slots.",
        "entities": [
            [
                135,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "As you'll have observed, the concordance output itself consists of the number of the hit, the name of the file it was found in -as a hyperlink -and the concordance result.",
        "entities": [
            [
                29,
                40,
                "TERM"
            ],
            [
                152,
                163,
                "TERM"
            ]
        ]
    },
    {
        "text": "Experimental subjects used concordances to work with their new words exclusively, inferring meanings from multiple concordance lines and only using a dictionary to confirm their inferences, while controls used the same software but with a bilingual dictionary as the information source.",
        "entities": [
            [
                115,
                126,
                "TERM"
            ]
        ]
    },
    {
        "text": "Only a closer examination of these features in the corpus can provide us with evidence to support the analysis.",
        "entities": [
            [
                51,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus contains conversations during spoken exams and in informal contexts, and amounts to approximately 15,000 words, 9,500 of which were produced by learners.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "Type in \"say_spoken\" under \"Create new list\" above the sample concordance lines and save the list.",
        "entities": [
            [
                55,
                61,
                "TERM"
            ],
            [
                62,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "If every rank value occurred only once in our sample, rank value and rank position would be the same.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, in some specific cases, a corpus can include the whole population.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "This database also provides access to the Corpus représentatif des premiers texts français or CORPTEF, which brings together texts from the 9th to the 12th Centuries, and to the Passage du latin au français corpus or PALAFRALAT, which aims to document the linguistic transitions between Latin and French.",
        "entities": [
            [
                207,
                213,
                "TERM"
            ]
        ]
    },
    {
        "text": "But while corpora are certainly essential linguistic resources, it is important to realize that no corpus, regardless of its size, will contain every relevant example of a particular linguistic construction or be able to provide a fully complete picture of how the construction is used.",
        "entities": [
            [
                99,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "Header elements may for instance be the page title (contained in the <title>…</title> tag, where the forward slash indicates the end of the tag in the closing part), which then appears in the title bar of your browser, or possibly meta-information (<meta>…</meta>), such as the text (content) type or encoding/character set (charset), as well as style (sheet) information/references (<style>…</style> or <link rel=\"stylesheet\" href=\"./corpus.css\" type=\"text/css\" />, in our case) responsible for some of the page formatting.",
        "entities": [
            [
                435,
                441,
                "TERM"
            ],
            [
                301,
                309,
                "TERM"
            ],
            [
                293,
                297,
                "TERM"
            ],
            [
                447,
                451,
                "TERM"
            ],
            [
                278,
                282,
                "TERM"
            ],
            [
                453,
                457,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us begin with a brief discussion of tokenization and part-of-speech (POS) tagging, two phenomena whose operational definitions are typically decided on and applied by the corpus makers and implicitly accepted by the researchers using a corpus.",
        "entities": [
            [
                78,
                85,
                "TERM"
            ],
            [
                175,
                181,
                "TERM"
            ],
            [
                240,
                246,
                "TERM"
            ]
        ]
    },
    {
        "text": "The young speakers included in the corpus should proportionally represent the two genders and have different socio-economic profiles.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "This obviously requires careful consideration and also to develop at least some initial hypotheses about what you'll encounter in which type(s) of data, which techniques to apply, etc.",
        "entities": [
            [
                136,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "The more a corpus satisfies these four criteria, the more prototypical it would be.",
        "entities": [
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, the latter type of operational definition is more common in linguistics (and the social sciences in general), but there are procedures to deal with the problem of subjectiveness at least to some extent.",
        "entities": [
            [
                26,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "I shall survey the applications of corpus-linguistic methods in historical pragmatics by a selection of articles that illuminate recent trends within the field, demonstrate the range, and indicate future avenues for research.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "In statistical terminology, this word simply means that the results obtained in a study based on one particular sample are unlikely to be due to chance and can therefore be generalized, with some degree of certainty, to the entire population.",
        "entities": [
            [
                112,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, considering the plethora of textbooks in the field, it is the practical aspects of this process that are dealt with least out of the three key phases of corpus-linguistics methodology.",
        "entities": [
            [
                168,
                174,
                "TERM"
            ]
        ]
    },
    {
        "text": "In these cases, we have to create our own annotation schemes.",
        "entities": [
            [
                42,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "This example is somewhat unusual in that the authors do not collect the data themselves, but instead use a selection of data from an existing corpus.",
        "entities": [
            [
                142,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "This type of information is highly useful, as it not only makes it possible to study and compare different types of narrative, but it also shows how the corpus is balanced (or not) with respect to type of narrative.",
        "entities": [
            [
                153,
                159,
                "TERM"
            ],
            [
                5,
                9,
                "TERM"
            ],
            [
                197,
                201,
                "TERM"
            ]
        ]
    },
    {
        "text": "Many of the classic and larger corpora of English contain PoS tagging, for example, COCA or the Brown family corpora.",
        "entities": [
            [
                62,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "A subset of the ELFA corpus was used to gain a maximal diversity of L1 backgrounds of the speakers.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "Several corpus techniques, for example, keyword and key-cluster tools, have the specific aim of facilitating comparison.",
        "entities": [
            [
                8,
                14,
                "TERM"
            ],
            [
                40,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this case, the quality of the automatic annotation is measured in comparison with a reference annotation produced by human annotators.",
        "entities": [
            [
                43,
                53,
                "TERM"
            ],
            [
                97,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most corpus tools require plain text versions with optional XML encoding, so where material is sourced in another form, some format conversions will be in order.",
        "entities": [
            [
                60,
                63,
                "TERM"
            ],
            [
                5,
                11,
                "TERM"
            ],
            [
                64,
                72,
                "TERM"
            ],
            [
                32,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "A little example of something I came across in an undergrad corpus linguistics course was that we generated a concordance of in and found that in one of the SGML-annotated files of the BNC that we looked at, the word in was tagged as VBZ, which means \"third person singular form of to be\".",
        "entities": [
            [
                60,
                78,
                "TERM"
            ],
            [
                60,
                66,
                "TERM"
            ],
            [
                110,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although the texts are accessible, there are copyright restrictions in both cases, which limits the availability of published texts for corpus-building enterprises severely.",
        "entities": [
            [
                136,
                142,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another way of dealing with the copyright problem during corpus distribution would be to allow users to search for concordances in the corpus, but not to visualize it in its entirety.",
        "entities": [
            [
                57,
                63,
                "TERM"
            ],
            [
                135,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this book, we offer multiple opportunities to work on corpus projects by first including an entire chapter dedicated to smaller corpus projects (Chapter 4) and then providing students with information on how to build and analyze their own corpora (Part III).",
        "entities": [
            [
                57,
                63,
                "TERM"
            ],
            [
                131,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "In particular, spelling variation causes problems for POS tagging, concordancing, keywords, n-grams, and collocation techniques.",
        "entities": [
            [
                58,
                65,
                "TERM"
            ],
            [
                105,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "This research specifies that all forms of the lemma acteur will be retrieved from the corpus when a word tagged as an adjective appears to its right.",
        "entities": [
            [
                46,
                51,
                "TERM"
            ],
            [
                86,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, the focus on words is also due to the fact that the results of corpus linguistic research quickly showed that words (individually and in groups) are more interesting and show a more complex behavior than traditional, grammarfocused theories of language assumed.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter will focus on a few kinds of statistical analyses that are often used in corpus linguistics and will try to get you in a position to turn a research question into something specific and testable.",
        "entities": [
            [
                86,
                104,
                "TERM"
            ],
            [
                86,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "This solution can be realistic when creating a corpus drawn from a limited number of sources.",
        "entities": [
            [
                47,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "Mostly these corpora are explored on computer, only 24 using exclusively or in part printed activities derived from a corpus.",
        "entities": [
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "The boilerplate removal process usually goes hand in hand with the stripping of HTML markup code from web documents as HTML can offer clues about what is boilerplate and what is the main textual content.",
        "entities": [
            [
                85,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "The crawling for the WordPress and Blogger sub-corpus of the BBC took place without relying on commercial search engines.",
        "entities": [
            [
                47,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "The current standard method for adding tags to a corpus is by means of XML (the eXtensible Markup Language).",
        "entities": [
            [
                71,
                74,
                "TERM"
            ],
            [
                49,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "For some of these there is self-evident redundancy: between personality type and motivation, say, or between scholastic record and family background, where support for learning at home is reflected in performance in school.",
        "entities": [
            [
                72,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most relevant for general linguistic concerns is the register perspective on text varieties since this offers important insights into the functionality of linguistic structures in use.",
        "entities": [
            [
                77,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once we have cleaned up our concordances (available in the Supplementary Online Material, file LMY7), we will find that -icle has a token frequency of 20 772 -more than ten times that of mini-, which occurs only 1702 times.",
        "entities": [
            [
                132,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "In cases where researchers need to compile specialized corpora, the question of representativeness is posed a little differently.",
        "entities": [
            [
                80,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "A similar thing can be done by expanding abbreviations to their full form, but with both lemmatisation and expansion, one always has to bear in mind that the individual forms may potentially also cause a change in meaning of the whole textual unit in which they occur, or may have been used deliberately as a (stylistic) feature of a particular type of genre.",
        "entities": [
            [
                89,
                102,
                "TERM"
            ],
            [
                345,
                349,
                "TERM"
            ]
        ]
    },
    {
        "text": "For text analysis and similar contexts, the use of LL scores leads to considerably improved statistical results.",
        "entities": [
            [
                4,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "Yet, their inclusion in the corpus does serve the community' s interest.",
        "entities": [
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "In one sense, the distinction between corpus-driven and corpus-based research methods can be misleading.",
        "entities": [
            [
                56,
                68,
                "TERM"
            ],
            [
                38,
                44,
                "TERM"
            ],
            [
                56,
                62,
                "TERM"
            ],
            [
                38,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus is fully available to the public and can be viewed free of charge via an online interface.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "Similar to taggers, once the parsers are trained, they automatically annotate the text for you.",
        "entities": [
            [
                82,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "The particular information collected will very much depend on the kind of corpus being created and the variables that future users of the corpus will want to investigate.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ],
            [
                138,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "We'll explore plain-text-based file formats, such as HTML and XML, that may contain such markup further in later sections, as well as discussing their use(fulness) for linguistic annotation/analysis.",
        "entities": [
            [
                179,
                189,
                "TERM"
            ],
            [
                62,
                65,
                "TERM"
            ],
            [
                89,
                95,
                "TERM"
            ],
            [
                20,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "Section 4 concludes the paper by bringing the two strands of the discussion together by showing how Open Corpus Linguistics can contribute to overcome several widely discussed problems in corpus linguistics.",
        "entities": [
            [
                188,
                206,
                "TERM"
            ],
            [
                188,
                194,
                "TERM"
            ]
        ]
    },
    {
        "text": "We fed each tweet in its raw text form as a single sequence into BERT, which then produced context-informed vectors for each token in the tweet.",
        "entities": [
            [
                125,
                130,
                "TERM"
            ],
            [
                29,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "Altering the span of the window around the node word where possible collocate words are considered can also significantly affect the results.",
        "entities": [
            [
                43,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, corpus linguists have long paid insufficient attention to this (and I include much of my own research in this criticism).",
        "entities": [
            [
                15,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "The replication crisis in linguistics is highly relevant to corpus-based research: Many corpus studies are not directly replicable as the data on which they are based are not readily available.",
        "entities": [
            [
                60,
                72,
                "TERM"
            ],
            [
                60,
                66,
                "TERM"
            ],
            [
                88,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now we will consider the defining characteristics of corpus linguistics as they will be used in this book.",
        "entities": [
            [
                53,
                71,
                "TERM"
            ],
            [
                53,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "On top of that, being a monitor corpus, it also makes it possible to track potential changes across different periods in the same way.",
        "entities": [
            [
                24,
                38,
                "TERM"
            ],
            [
                32,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "A 'random sample' is a sample where every member of the population has Random sample equal probability of being included in the sample.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ],
            [
                23,
                29,
                "TERM"
            ],
            [
                78,
                84,
                "TERM"
            ],
            [
                128,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, rather than focussing on the quantity of data in a corpus, it is always sensible to emphasize varieties of data.",
        "entities": [
            [
                62,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "As the results of corpus-based research on grammatical change accumulate and as the methods of analysis become more sophisticated, the corpus ceases to be merely a tool and becomes an active ingredient in the further development of usage-based theoretical models.",
        "entities": [
            [
                18,
                30,
                "TERM"
            ],
            [
                18,
                24,
                "TERM"
            ],
            [
                135,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "As discussed in 3.1.6, a good first step in this process is to elicit names for text varieties or speech events from native speakers.",
        "entities": [
            [
                80,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Sketch Engine corpus creation and management platform, discussed in Chapter 5, also automatically transforms the format of files downloaded from the Web.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "A final and very important point is to ensure that copyright is respected, either because the text is copyright-free or because the author has provided written consent granting permission to include their text in the corpus.",
        "entities": [
            [
                217,
                223,
                "TERM"
            ],
            [
                94,
                98,
                "TERM"
            ],
            [
                205,
                209,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, the corpus should contain French literature, which restricts the literary subject to works written in original French, rather than translations.",
        "entities": [
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "This has a number of methodological consequences concerning the practicability, the statistical evaluation and the epistemological status of collocation research.",
        "entities": [
            [
                141,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "The annotations are called 'tags' because they are appended to corpus words, as shown in example (7.5) from the Brown corpus.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ],
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "Corpora are not defined in terms of specific properties of texts, so texts can be of any type and may exhibit a large range of diverse properties (cf. Chapter 3 on corpus composition).",
        "entities": [
            [
                164,
                170,
                "TERM"
            ],
            [
                89,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first distinction we can make among all the existing corpora is the one that classifies them into a sample corpus and a monitor corpus.",
        "entities": [
            [
                104,
                117,
                "TERM"
            ],
            [
                124,
                138,
                "TERM"
            ],
            [
                111,
                117,
                "TERM"
            ],
            [
                132,
                138,
                "TERM"
            ],
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, this type of research is corpus-based, because it starts from a hypothesis (e.g. \"passive sentences tend to be used more frequently with state verbs\"), and seeks to verify it in the corpus, which, in that way, only works as an analysis tool.",
        "entities": [
            [
                44,
                56,
                "TERM"
            ],
            [
                44,
                50,
                "TERM"
            ],
            [
                201,
                207,
                "TERM"
            ],
            [
                24,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "Similarly, a corpus may contain samples of present-day use of a language, while the other may contain samples from old texts; a corpus may be monolingual with a collection of data from a single language, while another may be bilingual or multilingual by including texts from two or more languages; texts included in a corpus may be collected from one source, two sources or many sources of a particular field or across fields.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ],
            [
                128,
                134,
                "TERM"
            ],
            [
                318,
                324,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once a corpus is built and stored in an archive, we need robust schemes for regular maintenance, upgradation, and augmentation of the resource.",
        "entities": [
            [
                7,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "One of the most useful CLAN commands is the combo command, which helps you to look up words or word sequences produced by specific speakers in the corpus.",
        "entities": [
            [
                147,
                153,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Chapters 3 and 4, we will cover some of the specific directions we can explore in the corpus through software programs that allow for different types of analysis.",
        "entities": [
            [
                89,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "Size filters are designed to remove very short and very long documents from the corpus.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "Here again, whilst we agree that newspapers usually contain more passive forms than some other text types and that many learners (who often underuse the passive) need practice in using passive sentences, we feel that the exercise presented here might be counterproductive.",
        "entities": [
            [
                95,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, having chosen to sample such things as popular novels, or technical writing, best-seller lists and library circulation statistics were consulted to select particular examples of them.",
        "entities": [
            [
                23,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "The primary clustering of the DECTE speakers therefore has a clear sociolinguistic interpretation based on educational level and employment type.",
        "entities": [
            [
                140,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "Ideally, a language development corpus presents an ecologically valid and representative picture of the linguistic development of language learners.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "Over the years, scholars have noted and discussed the occasionally elusive nature of the challenges and suggested solutions to the problems, tackling broader and abstract notions such as representativeness and balance of corpora, but also more concrete questions like sampling, various levels of annotation, precision and recall of corpus queries, dispersion of search hits across a corpus, statistical evaluation, among other points.",
        "entities": [
            [
                296,
                306,
                "TERM"
            ],
            [
                332,
                338,
                "TERM"
            ],
            [
                383,
                389,
                "TERM"
            ],
            [
                210,
                217,
                "TERM"
            ],
            [
                187,
                205,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, although inserting \"structural\" markup into a text is separate from the process of actually computerizing the text, there are many instances where markup can be inserted while texts are being computerized.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ],
            [
                156,
                162,
                "TERM"
            ],
            [
                55,
                59,
                "TERM"
            ],
            [
                119,
                123,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once annotated, the elements of the corpus can be searched by their POS tags by means of a concordancer.",
        "entities": [
            [
                91,
                103,
                "TERM"
            ],
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "As far as possible, the chosen tag sets should be based on annotation standards which have been broadly accepted in the literature.",
        "entities": [
            [
                59,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "Type frequencies are then lower than token frequencies, and the type/token ratio can reveal interesting insights into properties of texts, essentially telling us how lexically variable a text or corpus is.",
        "entities": [
            [
                195,
                201,
                "TERM"
            ],
            [
                37,
                42,
                "TERM"
            ],
            [
                69,
                74,
                "TERM"
            ],
            [
                64,
                68,
                "TERM"
            ],
            [
                187,
                191,
                "TERM"
            ]
        ]
    },
    {
        "text": "That is, the distribution in the \"sample\" could be projected to the distribution of the \"population\".",
        "entities": [
            [
                34,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "There have almost been shadow developments occurring between corpus linguistics and the social sciences in this area.",
        "entities": [
            [
                61,
                79,
                "TERM"
            ],
            [
                61,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "As this is a kind of formatting that we'll equally want to apply to all such units, it would be cumbersome to have to type this out repeatedly, so we can take advantage of a feature of CSS that allows us to list the different elements a definition applies to by separating them from each other by a comma, just like in an ordinary written list.",
        "entities": [
            [
                118,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "Contemporary corpora are used for studying language in a synchronic way, that is, at a given moment during its evolution, whereas historical corpora make it possible to carry out studies from a diachronic point of view, that is, on the evolution of language.",
        "entities": [
            [
                57,
                67,
                "TERM"
            ],
            [
                194,
                204,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus labeling process can be carried out manually by the same user or allow access to the platform to a set of annotators and to supervise their work.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, we cannot take for granted that this method yields a balanced sampling, especially in the case of a small corpus.",
        "entities": [
            [
                115,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "Future versions of this work aim to efficiently implement analysis considering the role of stop words in the corpus.",
        "entities": [
            [
                109,
                115,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such manual sorting tasks can actually be avoided if the words in the corpus have been previously annotated into grammatical categories.",
        "entities": [
            [
                70,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, an annotation can be tested from the point of view of its reliability.",
        "entities": [
            [
                12,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, those who wish to compile a corpus involving complex types of information or do advanced types of (semi-)automatic corpus searches would be helped by collaborating with a computational linguist or computer programmer (see Chap. 9).",
        "entities": [
            [
                37,
                43,
                "TERM"
            ],
            [
                124,
                130,
                "TERM"
            ]
        ]
    },
    {
        "text": "Among other things, the corpus-based study of (small set of) source domain words may provide insights into the systematicity of metaphor (cf. esp. Deignan 1999b).",
        "entities": [
            [
                24,
                36,
                "TERM"
            ],
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will also discuss best practices to follow when making a manual annotation and present the different ways to assess the reliability of such annotations.",
        "entities": [
            [
                67,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "Allowance for an additional layer of comparisonbetween different layers of annotation -allows for an integrated and informative perspective on social cognition aspects of language.",
        "entities": [
            [
                75,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "The latter term is to be understood here in a broad and non-technical sense, meaning simply that in order for a range of texts to form a corpus they need to be compiled in some form and accessible in some way.",
        "entities": [
            [
                137,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "If, in this case, one of the students produces 80% of the occurrences and the other two students produce 10% each, it would be inappropriate to conclude that the distribution is homogeneous in the 15% of the corpus where this word appears.",
        "entities": [
            [
                208,
                214,
                "TERM"
            ]
        ]
    },
    {
        "text": "In particular, a corpus-based approach is especially conducive to the analysis of quantitative grammatical variation, because it allows for large samples of natural language to be collected for analysis, and for dialect variation to be observed and compared across a variety of communicative situations.",
        "entities": [
            [
                17,
                29,
                "TERM"
            ],
            [
                17,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "One of the ways in which corpus linguistics has changed our view of language, I believe, is in the now widespread recognition that grammar and lexis are not separate components of language, but that they interpenetrate.",
        "entities": [
            [
                25,
                43,
                "TERM"
            ],
            [
                25,
                31,
                "TERM"
            ],
            [
                143,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "But, before we do, we would like to briefly describe what we mean by a corpus.",
        "entities": [
            [
                71,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "And as Furthermore, if the lexicographer desires a copy of the sentence in which a word occurs, it can be automatically extracted from the text and stored in a file, making obsolete the handwritten citation slip stored in a filing cabinet.",
        "entities": [
            [
                139,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "When comparing two corpora, it often happens that a word that occurs frequently in one corpus is absent from the other corpus.",
        "entities": [
            [
                87,
                93,
                "TERM"
            ],
            [
                119,
                125,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is because, due to their occurrence both in headings and the text, some of the key words that we find in the headings may occur with a higher overall frequency in the text, and thus help us to 'summarise' the content.",
        "entities": [
            [
                66,
                70,
                "TERM"
            ],
            [
                172,
                176,
                "TERM"
            ]
        ]
    },
    {
        "text": "Interestingly enough, though, AntConc does appear to have a secondary sort order based on the frequency because otherwise uppercase A would have to appear before lowercase a, and the latter is only ranked higher because it has a frequency of 161 as opposed to a single token of the former.",
        "entities": [
            [
                269,
                274,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, they are part of the text, they cannot simply be removed, as this may reduce the context or even render the text illegible.",
        "entities": [
            [
                40,
                44,
                "TERM"
            ],
            [
                127,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "The COCA is a web-based corpus.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Its wide temporal coverage and large scope of lexical types make the OED an ideal basis for studies that investigate diachronic type frequency changes in phenomena such as the way-construction.",
        "entities": [
            [
                128,
                132,
                "TERM"
            ],
            [
                117,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "A related issue concerns the form in which texts from various registers are available for inclusion in corpora: as manuscripts or in the form of text editions.",
        "entities": [
            [
                145,
                149,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although the use of bootstrapping methods in corpus linguistics is still in its infancy, writing this book chapter has given us reason to be optimistic about the future of bootstrapping in corpus linguistics.",
        "entities": [
            [
                45,
                63,
                "TERM"
            ],
            [
                189,
                207,
                "TERM"
            ],
            [
                45,
                51,
                "TERM"
            ],
            [
                189,
                195,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus-based approach to dialectology contrasts with the standard approach, which is based on analyzing language elicited through interviews and questionnaires.",
        "entities": [
            [
                4,
                16,
                "TERM"
            ],
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "The potential influences that these variables have on a corpus are summarized in the following categories.",
        "entities": [
            [
                56,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "If these figures come from corpora of different sizes, for example a written corpus of 3,179,546 words and a spoken corpus of 573,484 words, they cannot be compared directly.",
        "entities": [
            [
                77,
                83,
                "TERM"
            ],
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "An etymologically annotated text addresses all the questions and challenges related to the etymology of words.",
        "entities": [
            [
                28,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "Representativeness, albeit also difficult to measure, may be more easily achievable, especially for domain-specific corpora or limited fields of investigation, because often there are relatively clearly definable criteria for what represents a certain genre of text or domain.",
        "entities": [
            [
                261,
                265,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are 314.31 degrees of freedom in our sample (as calculated using the formula in 16), which means that 𝑝 < 0.001.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "Like the phase 2 work outlined above, there is an attempt to rely on information that emerges from the text ('trust the text', as Sinclair says), rather than on information that is presupposed.",
        "entities": [
            [
                103,
                107,
                "TERM"
            ],
            [
                120,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "If an XML document conforms with one of these two types of specification, we talk of a valid document.",
        "entities": [
            [
                6,
                9,
                "TERM"
            ]
        ]
    },
    {
        "text": "Weekly and pre-post tests recorded word knowledge on both definitional and novel-text gap-fill measures.",
        "entities": [
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "The header section contains metadata, a description of the file, the encoding, the text profile, mainly the language, the context or participants, and even a history of its revisions.",
        "entities": [
            [
                69,
                77,
                "TERM"
            ],
            [
                28,
                36,
                "TERM"
            ],
            [
                83,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "But there is another dimension to extensibility: The reliability of a particular annotation can also \"vanish\" because it turns out to be misguided, for whatever reason.",
        "entities": [
            [
                81,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "In most cases, identification must be done on raw data, sowhenever possible -it is important to find one or more lexical elements that can be automatically identified by a concordancer.",
        "entities": [
            [
                172,
                184,
                "TERM"
            ]
        ]
    },
    {
        "text": "In summary, DP is clearly more effective than D at discriminating between uniform versus skewed distributions in a corpus, especially when it is computed based on a large number of corpus-parts.",
        "entities": [
            [
                115,
                121,
                "TERM"
            ],
            [
                181,
                187,
                "TERM"
            ]
        ]
    },
    {
        "text": "The next method in the expanding corpus toolbox is usually referred to in the computational linguistics community as n-grams.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "Of course, it is not obvious where the line should be drawn when considering whether a text of a certain length should be considered an outlier, but from the point of view of the data, the best practice would be to have the length limit as low as possible.",
        "entities": [
            [
                87,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "In OALD8 and CALD3, there is no collocation box for verbs of evidence: a limited number of collocations and phraseological units are highlighted in bold in example sentences.",
        "entities": [
            [
                32,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Keyness in corpus linguistics is but the first statistical step in the analysis of texts.",
        "entities": [
            [
                11,
                29,
                "TERM"
            ],
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "But other text types can prove more difficult to parse, resulting in lower accuracy rates.",
        "entities": [
            [
                10,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can also address different levels of annotation at different positions in a query.",
        "entities": [
            [
                40,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "The genre features found in a piece of fiction can also be used to extend an argument regarding the intertextual properties of a text in such a way that the intellectual context of the writing can be connected to the written text.",
        "entities": [
            [
                129,
                133,
                "TERM"
            ],
            [
                225,
                229,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, an explanatory variable can be the genre/register or date of publication of a text as well as speaker's age, gender and language proficiency, to name only a few.",
        "entities": [
            [
                92,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "The complexity of the corpus architecture results from its annotations: as the data is collected, student annotators iteratively apply a large number of annotation schemes to their data using different formats and tools, including document structure in TEI XML, POS tagging, syntactic parsing, entity and coreference annotations and discourse parses in Rhetorical Structure Theory.",
        "entities": [
            [
                266,
                273,
                "TERM"
            ],
            [
                153,
                163,
                "TERM"
            ],
            [
                257,
                260,
                "TERM"
            ],
            [
                22,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "Wolk et al.'s study exemplifies how diachronic corpus studies can precisely document changes in grammatical structure and simultaneously address issues of speakers' knowledge of language.",
        "entities": [
            [
                47,
                53,
                "TERM"
            ],
            [
                36,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to verify these hypotheses, they used a written corpus (Le Soir newspaper) and a spoken corpus (Valibel database), both representing the variety of French spoken in Belgium.",
        "entities": [
            [
                57,
                63,
                "TERM"
            ],
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "This might be due to the different methods used, or to the fact that I excluded business, which is disproportionally fre-9 Morphology quent in male speech and writing in the BNC and would thus reduce the diversity in the male sample substantially.",
        "entities": [
            [
                226,
                232,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you have chosen your favourite keyword list for American English, you might be interested in knowing which procedure was used to identify these keywords.",
        "entities": [
            [
                34,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "Write three 5-gram sequences in English that you think may have a chance of being repeated more than once in a corpus.",
        "entities": [
            [
                111,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "This annotation makes it possible to exclusively look for the noun occurrences of ferme, for example.",
        "entities": [
            [
                5,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "Every summer, a large number of students from different parts of the world come to Lancaster to learn about corpora and statistics during a week of Lancaster summer schools in corpus linguistics.",
        "entities": [
            [
                176,
                194,
                "TERM"
            ],
            [
                176,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "Focusing on the first kind for a moment, it would be possible of course to manually annotate texts using any standard word processor, but here it is useful to have software tools that check annotation as it is added, e.g. to ensure that typos in tags or category labels do not occur, and to allow standard mark-up formats (such as XML) to be employed consistently and correctly in the resulting corpus, e.g. as in the Dexter software.",
        "entities": [
            [
                190,
                200,
                "TERM"
            ],
            [
                331,
                334,
                "TERM"
            ],
            [
                395,
                401,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, semantic tagging involves annotating a corpus with markup that specifies various features of meaning.",
        "entities": [
            [
                23,
                30,
                "TERM"
            ],
            [
                53,
                59,
                "TERM"
            ],
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each observation (i.e., each text with each normed count) will be in a different row.",
        "entities": [
            [
                29,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "With the inclusion of Twitter metrics, this tool gives all exploration opportunities to understand the whole corpus.",
        "entities": [
            [
                109,
                115,
                "TERM"
            ]
        ]
    },
    {
        "text": "This form of standard deviation (SD p or σ [sigma]) differs slightly from the sample standard deviation (see below).",
        "entities": [
            [
                78,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "Download the files and make sure they are saved in text format (see the website referenced above on how to do that).",
        "entities": [
            [
                51,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "A histogram is a type of bar graph that groups values into a series of intervals (or bins).",
        "entities": [
            [
                17,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the next major section (Chapters 5-10), we then investigated various techniques for analysing language data using established methods of corpus linguistics.",
        "entities": [
            [
                140,
                158,
                "TERM"
            ],
            [
                140,
                146,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, in a sentence such as The boy is seen by the ghost, even though the boy is still in the subject position of the sentence, it is the ghost who is doing the seeing in this type of sentence.",
        "entities": [
            [
                183,
                187,
                "TERM"
            ]
        ]
    },
    {
        "text": "It would be ideal to be able to align corpus linguistics and the social sciences and identify those areas which align and those which do not.",
        "entities": [
            [
                38,
                56,
                "TERM"
            ],
            [
                38,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpus linguistics, we are almost always dealing with nominal data.",
        "entities": [
            [
                3,
                21,
                "TERM"
            ],
            [
                3,
                9,
                "TERM"
            ]
        ]
    },
    {
        "text": "The overload in corpus linguistics is symptomatic of a more general trend.",
        "entities": [
            [
                16,
                34,
                "TERM"
            ],
            [
                16,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "The main reason is that I have found, in my many years of teaching corpus linguistics, that most available textbooks are either too general or too specific.",
        "entities": [
            [
                67,
                85,
                "TERM"
            ],
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "When considering the term 'web as corpus', the first question we must ask is whether the web can actually be classed as a corpus according to the criteria set out in Chap. 1.",
        "entities": [
            [
                34,
                40,
                "TERM"
            ],
            [
                122,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "Inexperienced writers most frequently produce text messages with opening and closing expressions.",
        "entities": [
            [
                46,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "The second type of treebank annotations encodes dependency relations.",
        "entities": [
            [
                11,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moving beyond the sample, 95% confidence intervals can be calculated.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "The notions of systematicity and objectivity can also be observed in the metaanalytic approach to extracting information across the sample of studies that are obtained.",
        "entities": [
            [
                132,
                138,
                "TERM"
            ]
        ]
    },
    {
        "text": "Instead, the aim is to provide an overview of the main approaches to the problem and a discussion of the methods that are most often used and / or seem to the author to be most intuitively accessible and effective for corpus linguists.",
        "entities": [
            [
                218,
                224,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, POS tagging is not usually done by skilled, experienced annotators, bringing us to the second, completely different way in which POS tags are based on operational definitions.",
        "entities": [
            [
                13,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "One could collect only articles written by a single author, but this again might lead to a misrepresentation of the type of writing typically found in a genre.",
        "entities": [
            [
                116,
                120,
                "TERM"
            ]
        ]
    },
    {
        "text": "Due to these levels, it was claimed that corpus linguists give more importance to descriptive adequacy while generative grammarians focus on explanatory adequacy.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus it's generally advisable to first check any output of a frequency list produced by some program to see whether it may exhibit any unusual features that could influence the analysis negatively.",
        "entities": [
            [
                61,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "Depending on their origin, this can be rather easy or more difficult: usual word processors generally have a text format saving functionality, but extracting text from a PDF file can be difficult.",
        "entities": [
            [
                109,
                113,
                "TERM"
            ],
            [
                158,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "Lexical tagging is crucial because it will enable the factor analysis program to determine where the various parts of speech occur: e.g. first person pronouns in more interactive texts; passive verbs in more informational texts.",
        "entities": [
            [
                8,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "The last point to discuss in this section is the appropriate test for statistical significance that can be used with cross-tabulation; a statistical significance test evaluates the amount of evidence against the null hypothesis (see Section 1.3).",
        "entities": [
            [
                149,
                166,
                "TERM"
            ],
            [
                70,
                94,
                "TERM"
            ],
            [
                137,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some morphologists also consider these lists as a form of corpus, because they make it possible to gather large amounts of data.",
        "entities": [
            [
                58,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "An affix may have a high TTR because it was productively used at the time of the sample, or because it was productively used at some earlier period in the history of the language in question.",
        "entities": [
            [
                81,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "Based on a comparison of our value (32.69) with the distribution, we can make a judgement about the statistical significance (pvalue) of the result.",
        "entities": [
            [
                100,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the case of at first, out of 100 randomly selected concordance lines, 84 exemplars of at first in its phrasal adverbial sense remained -or 84 percent of the original total.",
        "entities": [
            [
                54,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "When we ask about word types we are asking about how many different word forms there are in the text/corpus.",
        "entities": [
            [
                101,
                107,
                "TERM"
            ],
            [
                96,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "Yet, the conversion of linear corpus annotations into multi-layered ones still constitutes an unsolved challenge.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are 373 stem types occurring with -ic in the LOB corpus, with a mean length of 7.32 and a sample variance of 5.72; there are 153 stem types occurring with -ical, with a mean length of 6.60 and a sample variance of 4.57.",
        "entities": [
            [
                55,
                61,
                "TERM"
            ],
            [
                96,
                102,
                "TERM"
            ],
            [
                201,
                207,
                "TERM"
            ]
        ]
    },
    {
        "text": "Having an annotation tool which supports a complex data model may be of little use if the annotated data cannot be accessed and used in sensible ways later on.",
        "entities": [
            [
                10,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "With less data-a smaller sample-the claims one is able to make based on one's corpus findings will be more modest.",
        "entities": [
            [
                78,
                84,
                "TERM"
            ],
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "They can equally well apply to tags within a corpus, if any levels of annotation have been applied.",
        "entities": [
            [
                70,
                80,
                "TERM"
            ],
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to build a corpus to address this issue, you would need to make sure that there is an adequate number of newspaper articles that have been written at different time periods.",
        "entities": [
            [
                20,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, the linguist can compensate for this to some degree by acquiring a thorough understanding of the corpus and its description.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some browsers will remove the HTML and only leave plain-text content, while others may retain some bits of HTML, such as, for example, email addresses contained in mailto links (i.e. those that allow you to fire up an email client when you click on them), etc.",
        "entities": [
            [
                56,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, in order to assess the productivity of a morphological rule, or even to assess word formation, that is, whether certain words made up from derivation or morphological composition exist, a corpus can offer much more information than the one found in a dictionary.",
        "entities": [
            [
                195,
                201,
                "TERM"
            ]
        ]
    },
    {
        "text": "Perceived shortcomings relating to the size, scope (and representativeness and reusability) and the level of availability of current multimodal corpora have been mentioned, along with some of the challenges regarding the representation and analysis of multimodal corpora.",
        "entities": [
            [
                56,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "As this textbook is more practical in nature than other textbooks on corpus linguistics, at the end of almost all chapters, I've also added a section entitled 'Sources and Further Reading'.",
        "entities": [
            [
                69,
                87,
                "TERM"
            ],
            [
                69,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "Many written ones (emails, text messages, etc.) are not preserved either.",
        "entities": [
            [
                27,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "Quite commonly one and the same verb takes different kinds of complement with different relative frequencies, such that one type is preferred and other ones are more marginal.",
        "entities": [
            [
                124,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "The last of these, standing for Twitter Archiving Google Sheet, automatically downloads tweets matching particular search parameters into a spreadsheet which can subsequently be used to build a corpus.",
        "entities": [
            [
                194,
                200,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although they are not necessarily viewed as such, some existing techniques in corpus linguistics can be considered as visualisations.",
        "entities": [
            [
                78,
                96,
                "TERM"
            ],
            [
                78,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most aspects of this script should be straightforward, given that everything happening in the loop is relatively simple text and data processing.",
        "entities": [
            [
                120,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "All of the figures obtained for each portion of the corpus are then added, and divided by 2.",
        "entities": [
            [
                52,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a result, any web-derived corpus is likely to include documents that are either exact duplicates of one another or are very similar.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "Whether a corpus is adequate in terms of its representative depends on the research question(s) at hand.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "The concept of Pattern Grammar (PG) came out of the COBUILD project, a large-scale lexicographical exercise that was unique when it began, in that the compilers relied on a very large (for its time) corpus of English to identify frequent usages and phraseologies of words.",
        "entities": [
            [
                199,
                205,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given that linguistics is descriptive at its core, many linguists study how language is used based on some linguistic sample.",
        "entities": [
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "The line between raising the level of analysis and the more general approach of principled metadata-based combining becomes blurred, however, in the case of, for example, combining Twitter tweets with their replies together to form individual texts.",
        "entities": [
            [
                91,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "As with many of the levels of usage we have described here, certain annotations help corpus linguists look for the particular kinds of phenomena relevant to their studies of discourse.",
        "entities": [
            [
                85,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, in order to investigate the collocates of fair, you simply type fair in the box next to 'WORD(S)', and then click on 'COL-LOCATES'.",
        "entities": [
            [
                65,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because the formatting and linking capabilities offered by HTML were not always sufficient for all needs in document handling, and SGML proved too unwieldy and error-prone, a new hypertext format, XML (eXtensible Markup Language) Version 1.0, was eventually created and released by the W3C (World Wide Web Consortium) in 1998.",
        "entities": [
            [
                197,
                200,
                "TERM"
            ]
        ]
    },
    {
        "text": "If a word is repeated, it counts as a new token but not as a new type.",
        "entities": [
            [
                42,
                47,
                "TERM"
            ],
            [
                65,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "Extremely large text archives, such as Google Books 3 6.",
        "entities": [
            [
                16,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "Obtaining detailed metadata is another challenge facing anyone wishing to compile a parallel corpus.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ],
            [
                19,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "Furthermore, the question of sample and population is often quite complex in most real research projects and requires a lot more attention than what was given to it in section 6.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a consequence, it is usually impossible to extract a complete sample of a given phenomenon manually, and this has lead to a widespread use of computers and corpus linguistic software applications in the field.",
        "entities": [
            [
                159,
                165,
                "TERM"
            ],
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "In what follows we will attempt to outline ways in which corpus-assisted discourse studies (CADS) can help build upon traditional qualitative linguistic analysis, what \"added value\" it can bring.",
        "entities": [
            [
                57,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "This point is crucial considering how additional target children multiply the amount of time and money required to compile a corpus with minimum annotation standards.",
        "entities": [
            [
                145,
                155,
                "TERM"
            ],
            [
                125,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "The results can then be displayed in the concordance format familiar to corpus linguistics with the search feature (e.g. rise tone or low key) centered in the concordance.",
        "entities": [
            [
                72,
                90,
                "TERM"
            ],
            [
                72,
                78,
                "TERM"
            ],
            [
                41,
                52,
                "TERM"
            ],
            [
                159,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "The frequency list based on lemmas confirms our initial assumption (based on Zipf's law) about the number of words with the frequency of 30 and over: there are 3,196 such lemmas in the corpus.",
        "entities": [
            [
                185,
                191,
                "TERM"
            ],
            [
                4,
                18,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most typically, we delete concordance lines and/or clip the context window in the interest of saving space.",
        "entities": [
            [
                26,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, by type frequency, bimorphemic and 3-morpheme word types are most frequent.",
        "entities": [
            [
                12,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is important to remember that even if a result is significantly unlikely to be obtained by chance, it is still possible to be randomly obtained, and that statistical significance in a model does not directly translate to real-world importance.",
        "entities": [
            [
                157,
                181,
                "TERM"
            ]
        ]
    },
    {
        "text": "Generally speaking, the larger and the more similar the reference corpus is to the corpus of interest the more reliable and focused the comparison is.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ],
            [
                83,
                89,
                "TERM"
            ],
            [
                56,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "If we only look up the word since in the corpus, we will also find occurrences which do not correspond to the use of this word as a causal adverb, but to its use as a preposition, for example in \"I haven't seen Mary since Christmas\".",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "This bias can be introduced either indirectly by the topic of the task in that, for example, a large batch of essays on the topic of friendship in a corpus will lead to a disproportionally high frequencies of words and phrases that belong to the lexical field of friendship.",
        "entities": [
            [
                149,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us look at one example from the case study chapter below, the collocation of alphabetical order.",
        "entities": [
            [
                66,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, the metadata of a corpus will include a list of correspondences between the chosen phonetic alphabet and the IPA.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ],
            [
                15,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "But, as shown in the case study carried out in this chapter, it should be feasible to draw up a list of core corpus findings worth including in all types of grammar books.",
        "entities": [
            [
                109,
                115,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us now think about how the different notions of a 'word' (type, lemma and lexeme) influence the kind of analysis we can carry out in corpus linguistics.",
        "entities": [
            [
                68,
                73,
                "TERM"
            ],
            [
                137,
                155,
                "TERM"
            ],
            [
                137,
                143,
                "TERM"
            ],
            [
                62,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "For this encoding, each PDV symbol was assigned a unique fourdigit code.",
        "entities": [
            [
                9,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "One of the advantages of this approach is that corpus can be exported by consensus: since the same tweet can be classified by different annotators, the number of tweets to export can be limited and retrieve those tweets that have achieved strong consensus among annotators.",
        "entities": [
            [
                47,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "We use the generic term \"book\" on purpose as the titles we have selected are not homogeneous in type, with some being closer to reference grammars, some others to pedagogical grammars, while the last type deals with grammar integrated with other language skills (reading, writing, etc.).",
        "entities": [
            [
                96,
                100,
                "TERM"
            ],
            [
                200,
                204,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, the CLAWS tagging simply 'lumps' all these meanings together, using a single general adverb tag for all of them, which again proves the point that taggers like CLAWS are really optimised for written language, but often still have a number of problems when it comes to dealing with spoken language appropriately.",
        "entities": [
            [
                25,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "Conversely, many other annotations made on corpus studies are devoted to a single type of element to be studied.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ],
            [
                82,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "It should be noted here that there is a budding line of meta-analytic methods largely outside of linguistics that attempts to use text mining to carry out certain aspects of the synthetic coding process.",
        "entities": [
            [
                130,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "This approach provides a comprehensive linguistic picture of the text under consideration and allows for a functional interpretation of the relevant linguistic features.",
        "entities": [
            [
                65,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to straightforward concordancing, though, also explore other ways of investigating the results, such as those that the sorting options/restrictions for the concordance lines offer.",
        "entities": [
            [
                168,
                179,
                "TERM"
            ]
        ]
    },
    {
        "text": "It also demonstrated that such corpus-based studies may result in very specific hypotheses about the function of lexicogrammatical structures that may become the basis for claims about mental representation.",
        "entities": [
            [
                31,
                43,
                "TERM"
            ],
            [
                31,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "These categories are called the sampling frame.",
        "entities": [
            [
                32,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "Any given item thus enters into a range of collocation, the items with which it is collocated being ranged from more to less probable...",
        "entities": [
            [
                43,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "The main corpus, BFM 2016, includes 153 texts, corresponding to more than 4 million words.",
        "entities": [
            [
                9,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "The main point really is that interested users have access to the data and can understand how it can be used, which in turn requires metadata on the corpus as a whole.",
        "entities": [
            [
                149,
                155,
                "TERM"
            ],
            [
                133,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus builders have thus augmented the existing data by adding various types of information-about the speakers (sex, age, social class, region of origin, educational background), about the text (type of narrative; whether a stand-alone story or part of a 'narrative chain') and about the utterance (the roles of the participants visà-vis the narration; type of quotative verb used to signal who said what in a narrative; to what degree the discourse is represented as being verbatim or more or less indirect).",
        "entities": [
            [
                4,
                10,
                "TERM"
            ],
            [
                200,
                204,
                "TERM"
            ],
            [
                358,
                362,
                "TERM"
            ],
            [
                194,
                198,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, consider the task of part-of-speech (POS) annotation (i.e., determining the correct POS of each word in a given sentence of a text).",
        "entities": [
            [
                56,
                66,
                "TERM"
            ],
            [
                140,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "If, on the other hand, as was my case, there is a lot of data available (the sample was approximately 200,000 words), the statistical approach is called for.",
        "entities": [
            [
                77,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we haven't discussed any of the issues in processing such text samples yet, it may not be immediately obvious to you that these different types of register may potentially require different analysis approaches, depending on what our exact aims in analysing them are.",
        "entities": [
            [
                61,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given how labour-intensive manual data annotation is, it is difficult to meet the growing need to annotate larger samples for robust statistical research.",
        "entities": [
            [
                39,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "In certain written genres, such as scientific writing, it is often difficult to achieve gender balance because writers in these genres are predominantly malean unfortunate reality of modern society.",
        "entities": [
            [
                95,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are various issues relating to the design, generation, and management of a corpus.",
        "entities": [
            [
                81,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "The next script does something seemingly elementary -we will create a frequency list of word-tag combinations (so as to be able to distinguish run as a noun from run as a verb) -but we will do it on a relatively large data set, the complete BNC World Edition with XML annotation, and we will use the annotation well by utilizing information provided by the BNC's multi-word tags, i.e., tags that mark multi-word units such as because of, in spite of, on behalf of, etc.",
        "entities": [
            [
                268,
                278,
                "TERM"
            ],
            [
                300,
                310,
                "TERM"
            ],
            [
                264,
                267,
                "TERM"
            ],
            [
                70,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we have explained in Chapter 2, texts have different properties on two different dimensions, text-internal/linguistic and text-external/situational.",
        "entities": [
            [
                96,
                100,
                "TERM"
            ],
            [
                125,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if the sampling frame for a corpus of French spoken in Switzerland includes different criteria such as gender, age, socio-economic level or place of residence, an equivalent number of samples should be chosen to match each selected criterion.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ],
            [
                20,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "Numeric values are relevant if you have frequencies of a linguistic feature (e.g., the number of personal pronouns in a text).",
        "entities": [
            [
                120,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this does not necessarily mean that the text must be excluded from the corpus, since there is annotation that can be included in a corpus indicating that certain sections of a sample are \"extra-corpus\" material; that is, material not considered part of the corpus for purposes of word counts, generating KWIC (key word in context), and so forth.",
        "entities": [
            [
                103,
                113,
                "TERM"
            ],
            [
                80,
                86,
                "TERM"
            ],
            [
                140,
                146,
                "TERM"
            ],
            [
                203,
                209,
                "TERM"
            ],
            [
                266,
                272,
                "TERM"
            ],
            [
                185,
                191,
                "TERM"
            ],
            [
                319,
                338,
                "TERM"
            ],
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such a focus in representativeness is motivated by a concomitant focused research agenda; for example, the communication during air traffic control (ATC) between pilots and air traffic controllers.",
        "entities": [
            [
                16,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section, we are discussing a few areas that we feel should be on corpus linguists' radar; they involve.",
        "entities": [
            [
                73,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "An early corpus of spoken British English, the London-Lund Corpus, contains 5,000-word samples.",
        "entities": [
            [
                9,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "Frequently, perhaps even typically, corpus linguistic research questions will be more complex, and we will be confronted with designs where both the dependent and the independent variable will have (or be treated as having) more than two values.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "The best way to achieve this is to draw a complete sample of the phenomenon in question, i.e. to retrieve all instances of it from the corpus (issues of retrieval are discussed in detail in Chapter 4).",
        "entities": [
            [
                135,
                141,
                "TERM"
            ],
            [
                51,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "As mentioned in Sect. 2.2.1, this is a common task in corpus development, and one on which other forms of linguistic annotation (e.g., lemmatization, syntactic annotation) often rely.",
        "entities": [
            [
                117,
                127,
                "TERM"
            ],
            [
                160,
                170,
                "TERM"
            ],
            [
                54,
                60,
                "TERM"
            ],
            [
                135,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "As the results are now in random order, if we do want to know which particular category of the corpus (or 'genre') the individual result was found in, we need to check the category details.",
        "entities": [
            [
                95,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have also seen that corpus linguistics often resorts to a quantitative methodology, studying a large sample of data which is representative of the phenomenon studied, with the aim of generalizing the observations to the whole of the language or to a language's register.",
        "entities": [
            [
                23,
                41,
                "TERM"
            ],
            [
                23,
                29,
                "TERM"
            ],
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "Besides, it is also necessary to determine which metadata will be associated with each corpus sample.",
        "entities": [
            [
                87,
                93,
                "TERM"
            ],
            [
                94,
                100,
                "TERM"
            ],
            [
                49,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "When \"doing\" corpus linguistics, students need to gain experience searching a corpus and interpreting the results of their corpus searches so that they can use this information to explain why their analysis and findings are important or relevant.",
        "entities": [
            [
                13,
                31,
                "TERM"
            ],
            [
                13,
                19,
                "TERM"
            ],
            [
                78,
                84,
                "TERM"
            ],
            [
                123,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "Hint: the number bigram tokens in a corpus/string will always be one less than the number of lexeme tokens.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Brown Corpus was also the first corpus to be lexically tagged.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "The independent variables in our annotation layer are detailed in the following.",
        "entities": [
            [
                33,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Any metadata subdivisions present within a target corpus or reference corpus should be better explored via comparison so that they are not hidden; the corpora should be carefully designed and constructed with the aim of answering specific research questions and facilitating comparability; issues such as tokenisation, lemmatisation, capitalisation, identification of n-grams and multi-word expressions, and spelling variation should be considered; and differences as well as similarities should be taken into account when undertaking the analysis of the keyword results.",
        "entities": [
            [
                319,
                332,
                "TERM"
            ],
            [
                50,
                56,
                "TERM"
            ],
            [
                70,
                76,
                "TERM"
            ],
            [
                4,
                12,
                "TERM"
            ],
            [
                555,
                562,
                "TERM"
            ],
            [
                60,
                76,
                "TERM"
            ],
            [
                275,
                288,
                "TERM"
            ]
        ]
    },
    {
        "text": "The most important predictors are the speaker's age, polarity, type of determination and proximity.",
        "entities": [
            [
                63,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is for this reason that it is difficult to maintain a perfect balance between the different parts of these corpora, whose representativeness cannot be fully guaranteed.",
        "entities": [
            [
                65,
                72,
                "TERM"
            ],
            [
                125,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "These annotations thus abstract away from the language-specific structures that morphological glossing and most PoS-tagging capture.",
        "entities": [
            [
                116,
                123,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given the wealth of speech that exists, as well as the logistical difficulties involved in recording and transcribing it, collecting data for the spoken part of a corpus is much more labor-intensive than collecting written samples.",
        "entities": [
            [
                163,
                169,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are many considerations for formatting corpus material in ways that follow current standards and best practice.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is therefore crucial to the success of any corpus undertaking that accurate information be kept about each text to be considered for inclusion in the corpus.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ],
            [
                153,
                159,
                "TERM"
            ],
            [
                110,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "It also depends on the decision of how many text categories are kept in a corpus, how many text samples are put in each category, and how many words are kept in each sample.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ],
            [
                166,
                172,
                "TERM"
            ],
            [
                44,
                48,
                "TERM"
            ],
            [
                91,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "For mini-, the type-token ratio is much higher: it occurs in 382 different words, so its TTR is 382 /1702 = 0.2244.",
        "entities": [
            [
                20,
                25,
                "TERM"
            ],
            [
                15,
                19,
                "TERM"
            ],
            [
                15,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another element to take into consideration before deciding to download an entire corpus is its size.",
        "entities": [
            [
                81,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "This handout is primarily directed towards corpus linguistics, but as mentioned in section 5 above, we sometimes deal with ordinal data in linguistics, typically in the context of an experimental or sociolinguistic study.",
        "entities": [
            [
                43,
                61,
                "TERM"
            ],
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "Six words later, there is another occurrence of a, so type and hapax counts remain, respectively, at 12 and 11 as the token count rises to 14, and so on.",
        "entities": [
            [
                118,
                123,
                "TERM"
            ],
            [
                54,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "While it is generally accepted that any level below .05 indicates statistical significance, it is quite common for more stringent significance levels to be employed (e.g. p≦:001).",
        "entities": [
            [
                66,
                90,
                "TERM"
            ]
        ]
    },
    {
        "text": "Secondly, corpus linguists need to be clear when marking this distinction.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "All these reasons call for new visualisation techniques, or at least the adaptation of existing ones, in order to specifically address the particular needs of corpus linguistics in terms of scalability, and support for iterative exploration.",
        "entities": [
            [
                159,
                177,
                "TERM"
            ],
            [
                159,
                165,
                "TERM"
            ]
        ]
    },
    {
        "text": "Among those analyses are: KWIC (keyword in context), n-grams, collocates in a particular text, and word lists.",
        "entities": [
            [
                32,
                39,
                "TERM"
            ],
            [
                89,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "The most common form to display a keyword in context (KWIC) is through concordance lines.",
        "entities": [
            [
                34,
                41,
                "TERM"
            ],
            [
                71,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a result, we have one vector with only -ic tokens (both.adjectives), but another one that says which suffix each token was attested with originally (their.suffixes), which we can then tabulate for both raw frequencies and percentages.",
        "entities": [
            [
                116,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, you could type this to load the package dplyr: library(dplyr) ¶.",
        "entities": [
            [
                24,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "Regarding the latter, you may now, quite rightly, expect to find at least the other two question words what and who in the same concordance list, as they can certainly be followed by the same clitic, but, due to the tagging rules of CLAWS, these are in fact classified in different ways from the other question words.",
        "entities": [
            [
                216,
                223,
                "TERM"
            ],
            [
                128,
                139,
                "TERM"
            ]
        ]
    },
    {
        "text": "Due to the difficulty of collecting and transcribing spoken data, the question of the amount of data needed for creating a corpus is even more acute than for written data.",
        "entities": [
            [
                123,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, despite the fact that interrupted words are very common in spoken language, even that of highly fluent speakers, the CLAWS tagset provides no tag for this, something that is probably due to the CLAWS tagsets originally having been created for the morpho-syntactic annotation of written language, and later adjusted for spoken language to some extent.",
        "entities": [
            [
                273,
                283,
                "TERM"
            ]
        ]
    },
    {
        "text": "Compared to, say, the 1980s or even the 1990s, there is now a huge and constantly growing number of studies in corpus linguistics that tackle phenomena of interest with methods that allow researchers to study the effect of multiple independent variables, or predictors, on the dependent variable, or response, of interest.",
        "entities": [
            [
                111,
                129,
                "TERM"
            ],
            [
                111,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpora that do not include whole texts but only text samples (like the Brown family) it is therefore important to achieve a balance in terms of the different sections of texts represented.",
        "entities": [
            [
                128,
                135,
                "TERM"
            ],
            [
                52,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "The remainder of the chapter then focuses more specifically on the individual methodological considerations (e.g. ensuring that a corpus is \"balanced\") that anyone planning to create a corpus needs to address.",
        "entities": [
            [
                130,
                136,
                "TERM"
            ],
            [
                185,
                191,
                "TERM"
            ]
        ]
    },
    {
        "text": "Research of this typereferred to as a \"corpus-driven\" approach -identifies strong tendencies for words and grammatical constructions to pattern together in particular ways, while other theoretically possible combinations rarely occur.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ],
            [
                39,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "The download and processing progress will be reported in the text window on the right, and a number of sub-folders will be created once the pages have been downloaded and processed successfully.",
        "entities": [
            [
                61,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, the COCA treats all clitics as separate wordforms whereas the Brown corpus (and other corpora developed in that tradition) treat clitics plus their host as a wordform.",
        "entities": [
            [
                82,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "Of course, the issue of genre balance also affects smaller diachronic corpora like the Helsinki Corpus, because some genres may disappear and new ones appear over time, and compromises must be made in the compilation process in terms of representativeness vs. diachronic comparability.",
        "entities": [
            [
                59,
                69,
                "TERM"
            ],
            [
                260,
                270,
                "TERM"
            ],
            [
                30,
                37,
                "TERM"
            ],
            [
                237,
                255,
                "TERM"
            ],
            [
                271,
                284,
                "TERM"
            ]
        ]
    },
    {
        "text": "This type of basic initial coding needn't be very complex, but can consist of a few easily identifiable markers that you insert somewhere in a text.",
        "entities": [
            [
                5,
                9,
                "TERM"
            ],
            [
                143,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "CEA, on the other hand, provided the opportunity to ponder on the notion of error and introduce a higher degree of standardization at each level of the error analysis process: from error identification to error interpretation through error annotation and counting methods.",
        "entities": [
            [
                240,
                250,
                "TERM"
            ]
        ]
    },
    {
        "text": "They can be made using a set of predefined labels, such as outof-domain, positive, negative, neutral, do-notknow-do-not-answer or define a new set of tags for the corpus.",
        "entities": [
            [
                163,
                169,
                "TERM"
            ]
        ]
    },
    {
        "text": "Combining the levels of GRAID and RefIND annotations will open up further possibilities: for instance, we can search for all instances where an annotation appears on the RefIND tier combined with a search for a syntactic function on the GRAID tier to get all functions in which a discourse referent is introduced.",
        "entities": [
            [
                144,
                154,
                "TERM"
            ]
        ]
    },
    {
        "text": "This shows that text B (academic text) is more lexically diverse than text A (informal speech).",
        "entities": [
            [
                16,
                20,
                "TERM"
            ],
            [
                33,
                37,
                "TERM"
            ],
            [
                70,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, if the user chose \"XML\" then menu made that a 1 and switch then assigns TRUE to xml.version.",
        "entities": [
            [
                25,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "That meticulous counting method resulted in what was probably a more accurate representation of the nature of the lexis in the corpus from which the 1953 GSL was derived, with counts that reflected separate lexemes, including multi-word expressions.",
        "entities": [
            [
                127,
                133,
                "TERM"
            ],
            [
                114,
                119,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpora, this assumption is usually violated to some extent due to the nature of language, where linguistic features are interconnected, and also due to corpus sampling that is done at the level of texts, not individual linguistic features.",
        "entities": [
            [
                156,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is to be stored as metadata in a header file.",
        "entities": [
            [
                22,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "The paper presents its findings as a number of case studies, moving from a study based on a single lemma, cause, to ones based on grammatical categories such as the imperative and the past tense.",
        "entities": [
            [
                99,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "A corpus is useful to observe the variation of these properties in constellation with each other and see how each of these independent variables tend to affect our dependent variable.",
        "entities": [
            [
                2,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "All of the corpora also use the same search interface so that once you learn how to \"ask\" for information in one corpus, you can conduct searches in all of the available corpora.",
        "entities": [
            [
                113,
                119,
                "TERM"
            ]
        ]
    },
    {
        "text": "Primarily, this difference is attributed to the ability of instantaneous revisions of the text.",
        "entities": [
            [
                90,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "Representations of foreigners were largely concerned with political institutions like the foreign office, although a sample of 21 out of 100 concordance lines taken at random (using an online random number generator) showed negative constructions of foreigners involving stereotyping, implying they were taking up British resources or jobs, or controlling British interests.",
        "entities": [
            [
                117,
                123,
                "TERM"
            ],
            [
                141,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "The importance of a corpus is acknowledged because it contributes to making new findings, helps in utilizing data in applications, provides scopes for modifying old observations, generates opportunities for formulating new theories, and prepares new fields for applying language data in direct service to society.",
        "entities": [
            [
                20,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "All we have to do to achieve this is first to declare them as inline elements and then write the appropriate content definitions, where we use the same text as in the actual elements, but get their relevant attribute values using the attr() syntax we used previously for retrieving the turn numbers.",
        "entities": [
            [
                152,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you are dealing with multiple file formats, exporting or converting everything to plain text format is probably the simplest way to compile it all together.",
        "entities": [
            [
                91,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to information on collocation and frequency, a corpus will also allow us to examine the extent to which certain types of prescriptive rules are followed.",
        "entities": [
            [
                59,
                65,
                "TERM"
            ],
            [
                30,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "The very fact that the corpus is a sample means that we need to think carefully about how our sample relates to the population, which means we need a detailed and critical awareness of the process of sampling that has been used in corpus construction.",
        "entities": [
            [
                231,
                250,
                "TERM"
            ],
            [
                23,
                29,
                "TERM"
            ],
            [
                231,
                237,
                "TERM"
            ],
            [
                35,
                41,
                "TERM"
            ],
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "Ethnographic information is important because those using the ultimate corpus that is created might wish to investigate whether gender, for instance, affects conversational style, or whether younger individuals speak differently than older individuals.",
        "entities": [
            [
                71,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "The process of annotating a corpus involves running software that can (1) tag a corpus (add part-of-speech tags to all of the words in the corpus, such as nouns, prepositions, and verbs), or (2) parse a corpus (add markup that identifies larger structures, such as verb phrases, prepositional phrases, and adverbials).",
        "entities": [
            [
                28,
                34,
                "TERM"
            ],
            [
                80,
                86,
                "TERM"
            ],
            [
                139,
                145,
                "TERM"
            ],
            [
                203,
                209,
                "TERM"
            ],
            [
                215,
                221,
                "TERM"
            ]
        ]
    },
    {
        "text": "The motivation for this study is that no previous studies have used corpus linguistic methods to investigate differences in the use of linguistic features by patients and nurses across the phases of an interaction.",
        "entities": [
            [
                68,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "This can be done by taking a random subsample of linguistic features from the corpus.",
        "entities": [
            [
                78,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "In some other sections of LGSWE the information about lexis is more extensive.",
        "entities": [
            [
                54,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "Sometimes Sample the sample is carefully collected based on pre-defined criteria.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "Here, sadly, the designers of the architecture have introduced a serious flaw in the system that may well affect the overall calculations of the collocation statistics very strongly, which is to treat punctuation tokens (and their types) as equivalent to words.",
        "entities": [
            [
                145,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because of these advantages, corpus-based dialect studies have greatly expanded our knowledge of dialect variation, showing that social and regional linguistic variation are far more complex and pervasive than has previously been assumed.",
        "entities": [
            [
                29,
                41,
                "TERM"
            ],
            [
                29,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "Callies concludes his chapter by addressing potential bias in annotation methods within Learner Corpus Research (LCR) and related disciplines.",
        "entities": [
            [
                62,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "After the loop, we'll pick the most frequent n adjectives (something like n = 2,000 for the learner data case study and n = 5,000 for the Brown corpus case study) occurring in it and tag all occurrences of these forms in the untagged corpus files, and then we will retrieve sequences of two adjective tags and whatever they tag from these corpus files; with the ICLE corpus, we will actually save the tagged corpus files before we search them, with the Brown corpus example, we'll tag the files and immediately search them while they are still in memory.",
        "entities": [
            [
                144,
                150,
                "TERM"
            ],
            [
                234,
                240,
                "TERM"
            ],
            [
                339,
                345,
                "TERM"
            ],
            [
                367,
                373,
                "TERM"
            ],
            [
                408,
                414,
                "TERM"
            ],
            [
                459,
                465,
                "TERM"
            ]
        ]
    },
    {
        "text": "Sometimes, the collocates of a node word (or larger expressions) fall into a more or less clearly recognizable semantic class that is difficult to characterize in terms of denotational properties of the node word.",
        "entities": [
            [
                31,
                35,
                "TERM"
            ],
            [
                203,
                207,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, unless you need to prune the reference list extensively, it can certainly allow you to identify some key terms much more quickly, and may therefore be seen as an alternative way of looking at single-word lists for identifying genredependent or semantic features of a corpus.",
        "entities": [
            [
                276,
                282,
                "TERM"
            ]
        ]
    },
    {
        "text": "The significance test calculates the significance of the difference in frequency between the word in the target data and in the reference corpus.",
        "entities": [
            [
                4,
                21,
                "TERM"
            ],
            [
                138,
                144,
                "TERM"
            ],
            [
                128,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "But the easy access to textual data online has allowed quantitative corpus linguists to cast a wider net in terms of their research topics than ever before.",
        "entities": [
            [
                68,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, the annotation of speech acts requires setting up a list of the acts to be annotated, for example, requesting, promising, asserting, threatening, etc.",
        "entities": [
            [
                17,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "It should also be noted that they can be easily extended or adapted to carry out tasks that are quite difficult or impossible to achieve with the most popular tools used in corpus linguistics today.",
        "entities": [
            [
                173,
                191,
                "TERM"
            ],
            [
                173,
                179,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, that demographers will have the answer to how to build a perfectly representative spoken corpus.",
        "entities": [
            [
                102,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "The query will capture interrogatives, imperatives, subordinate clauses and other contexts that cannot contain tag questions, so let us draw a sample of 100 hits from both samples and determine how many of the hits are in fact declarative sentences with positive polarity that could (or do) contain a tag question.",
        "entities": [
            [
                143,
                149,
                "TERM"
            ]
        ]
    },
    {
        "text": "It involves the notion of lexical frequency profiles, which is a corpus-based approach in applied linguistics concerned with the amount and the kind of vocabulary second/foreign-language learners use in their speaking and writing (see Laufer & Nation 1995 for an introduction; Meara 2005 for a critique; and Laufer 2005 for a response).",
        "entities": [
            [
                65,
                77,
                "TERM"
            ],
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "Obviously, a corpus tagged for parts of speech could improve the precision of our search results somewhat, by excluding cases like (9c-d), but others, like (9a), 4.1 Retrieval could never be excluded, since they are identical to the ditransitive as far as the sequence of parts-of-speech is concerned.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "After that we store the results we obtain by sapplying functions to the list to count lengths and compute type-token ratios (with an anonymous/inline function); we compute a mean type-token ratio using all types and tokens, and a mean of all lengths of utterances with mean, but to avoid the effect that outliers might have we use the argument trim=0.05 to discard both the smallest and the largest 5 percent of the data.",
        "entities": [
            [
                111,
                116,
                "TERM"
            ],
            [
                184,
                189,
                "TERM"
            ],
            [
                106,
                110,
                "TERM"
            ],
            [
                179,
                183,
                "TERM"
            ],
            [
                179,
                195,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section, we will discuss a number of heuristic techniques that can be used to interrogate the syntagmatic-paradigmatic organization across the whole lexicogrammatical continuum, and we will illustrate their potential relevance to diachronic corpus linguistics.",
        "entities": [
            [
                249,
                267,
                "TERM"
            ],
            [
                249,
                255,
                "TERM"
            ],
            [
                238,
                248,
                "TERM"
            ]
        ]
    },
    {
        "text": "A similar practice has been followed in the annotation of the Spanish Learner Language Oral Corpora (SPLLOC), a set of corpora of L2 Spanish that were transcribed using the CHAT system developed by the CHILDES project.",
        "entities": [
            [
                44,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first part of this chapter reviews the growing body of research that analyzes dialect variation in corpora, including research on variation across nations, regions, genders, ages, and classes, in both speech and writing, and from both a synchronic and diachronic perspective, with a focus on dialect variation in the English language.",
        "entities": [
            [
                241,
                251,
                "TERM"
            ],
            [
                256,
                266,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is no consistent terminology to describe research of this kind, but the phrase \"Lexical Grammar\" directs us to the combination of lexis and grammar embodied in it.",
        "entities": [
            [
                136,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "This annotation has sentence structures represented in a tree-like structure showing hierarchical dependencies, which is useful for testing assumptions of some theories of grammar.",
        "entities": [
            [
                5,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "Hence, it can be strategic to separate these two transcription tasks and this can be done best if the media recording is directly linked with its annotation.",
        "entities": [
            [
                146,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "They tend to look at predictors such as salience, accessibility, referential distance, and animacy to explain the choice of one type of reference over another.",
        "entities": [
            [
                128,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "The study also demonstrates that the distribution of particular metaphorical expressions across varieties, which can easily be determined in corpora that contain the relevant metadata, may shed light on the function of those expressions (and of metaphor in general).",
        "entities": [
            [
                175,
                183,
                "TERM"
            ]
        ]
    },
    {
        "text": "The resulting sorted list contains two kinds of keyword: positive (those which are unusually frequent in the target corpus relative to the reference corpus) and negative (words which are unusually infrequent in the target corpus).",
        "entities": [
            [
                116,
                122,
                "TERM"
            ],
            [
                149,
                155,
                "TERM"
            ],
            [
                222,
                228,
                "TERM"
            ],
            [
                48,
                55,
                "TERM"
            ],
            [
                139,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each sample was 2,000 words in length, enabling valid comparisons between the different registers in the corpus.",
        "entities": [
            [
                105,
                111,
                "TERM"
            ],
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "Walker's study is a good example of a diachronic corpus-based investigation where the author needs to consider the special nature of his or her data and carefully assess the reliability of the data sources used.",
        "entities": [
            [
                49,
                61,
                "TERM"
            ],
            [
                49,
                55,
                "TERM"
            ],
            [
                38,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "As an alternative to some of the steps we modelled as regexes above, and for slightly more convenient manual annotation of the remaining XML structure, you could also use an annotation tool, such as my Simple Corpus Tool, which actually includes an editor that'll allow you to add these tags and attributes through the click of a button.",
        "entities": [
            [
                109,
                119,
                "TERM"
            ],
            [
                174,
                184,
                "TERM"
            ],
            [
                137,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, at this point in time, quantitative corpus linguistics is becoming more and more established also in specific linguistic subdisciplines, which raise their own, more specialized problems.",
        "entities": [
            [
                45,
                63,
                "TERM"
            ],
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, syntactic annotation tools are still imperfect and sometimes too complex to implement or use.",
        "entities": [
            [
                19,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "We also introduced some basic principles regarding sample collection and balancing.",
        "entities": [
            [
                51,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, if the corpus is made available to others, they need to know what is in it in order to make an informed decision about whether the design of the corpus is appropriate for answering their specific research questions.",
        "entities": [
            [
                20,
                26,
                "TERM"
            ],
            [
                158,
                164,
                "TERM"
            ]
        ]
    },
    {
        "text": "In all cases, it is important to systematically avoid including the same portions of text, for example, always the beginnings or the endings.",
        "entities": [
            [
                85,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Chapter 7, we will see that errors can be systematically annotated in a corpus, in the same way as syntactic or semantic information is provided.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, geographic region becomes a relevant trait for the sampling frame of a spoken French corpus.",
        "entities": [
            [
                96,
                102,
                "TERM"
            ],
            [
                62,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "If we do not find a word in our corpus, this may be because there is no such word in English, or because the word just happens to be absent from our corpus, or because it does occur in the corpus but we missed it.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ],
            [
                149,
                155,
                "TERM"
            ],
            [
                189,
                195,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, there are also diachronic or historical corpora, which contain texts from earlier periods of English.",
        "entities": [
            [
                24,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "When it comes to creating a reference corpus, the data collection phase is so time-consuming that it can only be tackled by a group of experts.",
        "entities": [
            [
                38,
                44,
                "TERM"
            ],
            [
                28,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, at the same time, this narrow corpus-methodological focus makes it possible to systematically complement the quantitative findings with a detailed qualitative analysis.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "The data collection mode makes this corpus unsuitable for many types of research but provides a very useful interface for lexical searches, offering the possibility of looking for simple or compound words and having access to all the occurrences within the context, with an indication of the source for each occurrence.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "The initially perhaps odd-seeming type sil is further proof of this, as it represents an abbreviation for 'silence', that is, a pause of undefined length, while utt represents markup for an utterance.",
        "entities": [
            [
                176,
                182,
                "TERM"
            ],
            [
                34,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "Concordancing programs retrieve structures and present them in KWIC (key word in context) concordances.",
        "entities": [
            [
                69,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first independent variable concerns the type of conversation from which the examples are drawn.",
        "entities": [
            [
                44,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "A corpus can be representative of all the possible linguistic features of a language (covering all possible structures that are part of language user's competence), or it can be representative of all the external or situational variables of different texts that are produced in a given language.",
        "entities": [
            [
                2,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "This will return you to the basic single-corpus COCA interface.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, a closer look into the instances of lifespan informs us that all the 3,700 hits are found in only 83 texts, which suggests the word probably has a very uneven dispersion across the corpus.",
        "entities": [
            [
                190,
                196,
                "TERM"
            ]
        ]
    },
    {
        "text": "These are reasonable arguments, but if possible, it seems a good idea to complement any analysis done with Google Books with an analysis of a more rigorously constructed balanced corpus.",
        "entities": [
            [
                179,
                185,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now, even if you are aware of all the relevant forms you may need to identify, and search for each of these forms separately in a row in a concordance program, you can only save the results, maybe even print them out, and then compare them afterwards.",
        "entities": [
            [
                139,
                150,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, fitting a tree with a lower minimal criterion may be useful in a pilot study performed for exploratory purposes; • minimum 20 observations in a node for a split to be considered, specified by minsplit = 20; • according to the default settings, there should be at least seven observations in one node after a split, minbucket = 7.",
        "entities": [
            [
                157,
                161,
                "TERM"
            ],
            [
                308,
                312,
                "TERM"
            ]
        ]
    },
    {
        "text": "The second independent variable is the type of newspaper, which is a categorical variable, since it falls into three distinct categories, namely The Times, the Daily Telegraph, and the Guardian.",
        "entities": [
            [
                39,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Name several advantages and disadvantages of using a small, genre-specific corpus, and list possible research questions that could be answered with a small genre-specific corpus.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ],
            [
                171,
                177,
                "TERM"
            ]
        ]
    },
    {
        "text": "These can be extracted relatively straightforwardly even from an untagged corpus using the following queries: The query in (12a) will find all finite forms of the verb be (as non-finite forms cannot occur in tag questions), followed by the negative clitic n't, followed by a pronoun; the query in (12b) will do the same thing for the full form of the particle not, which then follows rather than precedes the pronoun.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "In situations like these, it is possible to train some kinds of annotation software to apply new tagging conventions to your corpus sources.",
        "entities": [
            [
                97,
                104,
                "TERM"
            ],
            [
                64,
                74,
                "TERM"
            ],
            [
                125,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "This tension is determined by the text(s) under analysis.",
        "entities": [
            [
                34,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "Needless to say, corpus linguistic studies of this sort cannot explain why languages opt for one or the other type of subject and object encoding, and the explanation for this lies in deep and intricate histories of language evolution with many stages of development, each a story worth telling in itself.",
        "entities": [
            [
                17,
                23,
                "TERM"
            ],
            [
                137,
                145,
                "TERM"
            ],
            [
                110,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "For annotations of a specific linguistic phenomenon (in the situation presented at the end of section 7.2), one solution would be to retrieve the relevant data from the corpus, and then to annotate them separately.",
        "entities": [
            [
                169,
                175,
                "TERM"
            ]
        ]
    },
    {
        "text": "The concordancer is an excellent way of locating examples of such prosodic clash.",
        "entities": [
            [
                4,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have to realise that in corpora we typically sample data at the level of texts/speakers.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first computer corpus, the Brown Corpus (a general-purpose corpus), contained various kinds of writing, such as press reportage, fiction, learned, and popular writing.",
        "entities": [
            [
                19,
                25,
                "TERM"
            ],
            [
                63,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now, simply click again to re-create the frequency list including the two extra characters, and observe the changes in the list by scrolling through it.",
        "entities": [
            [
                41,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "In less radical usage-based models of language, such as Langacker's, the corpus is not a model of linguistic competence -the latter is seen as a consequence of linguistic input perceived and organized by human minds with a particular structure (such as the capacity for figure-ground categorization).",
        "entities": [
            [
                73,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "It throws open the notion of 'aboutness' and uses a data-driven way of organising the content of a large corpus.",
        "entities": [
            [
                105,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "Pasting the token counts from the 'Make/edit subcorpora' page also presents no problem because, this time, we only have one single piece of 'text' without HTML codes, so there's nothing to misinterpret for the spreadsheet program.",
        "entities": [
            [
                12,
                17,
                "TERM"
            ],
            [
                141,
                145,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, as the examples from the exercise will hopefully have shown you, if we use a concordancer to investigate enough data, we're bound to find examples that may run counter to our imagination, and also help us deepen our knowledge/understanding of how words are used, which is one of the reasons why concordances are not only useful for research in lexicology or lexicography, but also as a means for native and non-native speakers to develop their language skills.",
        "entities": [
            [
                86,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "Usually, these kinds of keywords are lexical items (nouns, adjectives, verbs) that give us an idea of the topics in the corpus.",
        "entities": [
            [
                120,
                126,
                "TERM"
            ]
        ]
    },
    {
        "text": "As Exercise 63 will have shown you, the keyword list, at least in our case and for positive keywords, may not necessarily provide you with more information than a frequency list that has been filtered well through the use of stopwords.",
        "entities": [
            [
                40,
                47,
                "TERM"
            ],
            [
                163,
                177,
                "TERM"
            ]
        ]
    },
    {
        "text": "Next, the chapter explains the basic building blocks of all software programs, and then provides a number of criteria that can be used to assess the suitability of a programming language for a particular corpus linguistics project.",
        "entities": [
            [
                204,
                222,
                "TERM"
            ],
            [
                204,
                210,
                "TERM"
            ]
        ]
    },
    {
        "text": "We test whether the data from that sample \"fit\" with that of the population.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "In sum, concordancers make it possible to analyze recurrent properties in a corpus, such as its frequent words, its collocations and its keywords from a quantitative point of view, something which is not possible to infer from simply reading texts. This is why they represent essential tools for grasping the quantitative properties of a corpus.",
        "entities": [
            [
                76,
                82,
                "TERM"
            ],
            [
                338,
                344,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although the comparison of such wildly different subcorpora in terms of size is, admittedly, not very useful in general, the list of unique items in the written component immediately reveals a number of interesting features of the BNC tagging and composition, or rather, the way BNCweb allows you to work with them.",
        "entities": [
            [
                235,
                242,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, by taking a small sample of the instances and going back to the document images, we discovered that about a third of the instances of \"economy\" were in fact OCR errors for \"oeconomy\".",
        "entities": [
            [
                27,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each sample cluster contains three representative tweets published in Montreal and occurring in a single original cluster output by our analysis.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each letter is also annotated for its date of publication, facilitating the analysis of temporal variation in this corpus.",
        "entities": [
            [
                115,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "Above, we mostly looked at retrieving the data values of our XML data, but of course we want to also use the often detailed annotation that is within the tags.",
        "entities": [
            [
                124,
                134,
                "TERM"
            ],
            [
                61,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "This definition has been understood by collocation researchers in two different (but related) ways.",
        "entities": [
            [
                39,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most concordancers are also stream-based, which means that they 'suppress' line breaks by replacing them with spaces, so that the text is essentially read as a continuous stream of words.",
        "entities": [
            [
                130,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "It expresses the probability of the sample data being observed if the null hypothesis were true in the population.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "Considering the names in which royal with a capital initial is tagged as an adjective instead of a proper noun, the types of entities in question is reflected in the tagging, as noted in the BNC2 manual; in the names of institutions or charters, royal is an adjective, in the names of locations it is treated as a proper name.",
        "entities": [
            [
                166,
                173,
                "TERM"
            ]
        ]
    },
    {
        "text": "The median token frequency is 1 morpheme, the median type frequency is 2 morphemes.",
        "entities": [
            [
                11,
                16,
                "TERM"
            ],
            [
                53,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, studies based on such corpora must be regarded as falling somewhere between corpus linguistics and psycholinguistics and they must therefore meet the design criteria of both corpus linguistic and psycholinguistic research designs.",
        "entities": [
            [
                82,
                100,
                "TERM"
            ],
            [
                82,
                88,
                "TERM"
            ],
            [
                180,
                186,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even for single units that are clearly delimited by spaces or punctuation, we may end up having problems assigning them to one and the same type because of such issues as polysemy discussed above, but also alternative spellings (colour vs. color) due to dialectal or historical variants, typos (teh instead of the), or capitalisation/non-capitalisation.",
        "entities": [
            [
                140,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "Obviously, we need rchoose.dir to define the directory containing the corpus files and dir to retrieve all the file names from that directory.",
        "entities": [
            [
                70,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "Concordancers vary greatly in terms of what analyses, other than basic concordance searches, they allow.",
        "entities": [
            [
                71,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "Hence, corpus-based typologists need to carefully evaluate the specific properties of the corpora they use vis-à-vis the phenomena they are researching. .",
        "entities": [
            [
                7,
                19,
                "TERM"
            ],
            [
                7,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although arriving at a definition of a linguistic corpus may seem like a fairly straightforward process, it is actually a more complicated undertaking than it initially appears.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Ideally, this would be achieved by truly random sampling 10 where each text ever produced and each spoken interaction that has ever taken place would have the same chance of appearing in the sample.",
        "entities": [
            [
                191,
                197,
                "TERM"
            ],
            [
                71,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the following sections, we will discuss in depth the different central points of the definition, indicated in bold, in order to better understand the theoretical and methodological anchoring of corpus linguistics.",
        "entities": [
            [
                197,
                215,
                "TERM"
            ],
            [
                197,
                203,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, it is possible to build a comparable corpus of parliamentary debates in France and the UK.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "As an alternative, corpora can be stored in external data services such as clouds with corpus access for example by compressed media streaming.",
        "entities": [
            [
                87,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "One is that we're now loading a file with Windows's version of Unicode UCS-2LE and so it is particularly useful to load this file with readLines(file(...)) and the encoding argument set to \"UCS-2LE\".",
        "entities": [
            [
                164,
                172,
                "TERM"
            ]
        ]
    },
    {
        "text": "This explains in part why documentarians' work differs from that of classical descriptive and typological linguists in its primary focus on data collection rather than analysis and comparison, and creating a corpus is part of a documentation project.",
        "entities": [
            [
                208,
                214,
                "TERM"
            ]
        ]
    },
    {
        "text": "Section 2 of this chapter provides a brief outline of different approaches to digital text analysis.",
        "entities": [
            [
                86,
                90,
                "TERM"
            ]
        ]
    },
    {
        "text": "It should be noted that this is fundamentally rather similar to the procedure of a key items analysis, except that we are comparing the vicinity of the node to the rest of the corpus, rather than comparing two different corpora, and some of the same considerations apply.",
        "entities": [
            [
                152,
                156,
                "TERM"
            ],
            [
                176,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "Often these nodes and edges will be annotated with labels, which usually have a category name and a value (e.g. POS=NOUN); in some complex architectures, annotations can potentially include more complex data types, such as hierarchical feature structures, in which annotations can contain not only simple values, but also further nested annotations (see ISO 24612 for a standardized representation for such structures in corpus markup).",
        "entities": [
            [
                421,
                427,
                "TERM"
            ],
            [
                428,
                434,
                "TERM"
            ]
        ]
    },
    {
        "text": "As such, the only type of information we could report is the frequency with which every variable condition appeared in the data.",
        "entities": [
            [
                18,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, potentially conflicting desiderata such as comparability and representativeness make it necessary for scholars to consider carefully the make-up of their corpora and the extent to which results based on a selection of registers can be generalized to the language as a whole.",
        "entities": [
            [
                71,
                89,
                "TERM"
            ],
            [
                53,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "Including different versions of the same translation would also prove to be rewarding (e.g. draft, unedited, and edited versions of the translated text).",
        "entities": [
            [
                147,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Notepad++, you can also specify the default encoding for any files you create under 'Settings→Preferences→New Document', where I'd recommend you set the option for 'UTF-8 without BOM', as well as use the additional setting 'Apply to opened ANSI files'.",
        "entities": [
            [
                47,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "Bootstrapping could be used as a method for evaluating the linguistic representativeness of a corpus (cf. Chap. 1).",
        "entities": [
            [
                94,
                100,
                "TERM"
            ],
            [
                70,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "For language archives, one will either have to fill in metadata forms, for instance, the metadata catalogue of PARADISEC (catalog.paradisec.org.au/), or adhere to a standard metadata format, for instance in the DoBeS (tla.mpi.nl/project/dobes/) or the ELAR (soas. ac.uk/elar/) archive.",
        "entities": [
            [
                55,
                63,
                "TERM"
            ],
            [
                89,
                97,
                "TERM"
            ],
            [
                174,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is an alternative, however: speakers sometimes use adverbs that explicitly refer to the type of beginning.",
        "entities": [
            [
                94,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, the larger our corpus is (and most corpus-linguistic research requires corpora that are much larger than the four million words used here), the less feasible it becomes to do so.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ],
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "To verify the results for any particular type in either subcorpus, you can use the hyperlinks in the columns labelled 'TOKENS 1' and 'TOKENS 2', respectively to have KWIC concordances displayed in the frame in the bottom half.",
        "entities": [
            [
                41,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "Like its name suggests, the type-token ratio is the ratio of the number of different words in a text (types) to the number of all words in the text (tokens).",
        "entities": [
            [
                33,
                38,
                "TERM"
            ],
            [
                28,
                32,
                "TERM"
            ],
            [
                28,
                44,
                "TERM"
            ],
            [
                96,
                100,
                "TERM"
            ],
            [
                143,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "Original text corpora are thus an option where the phenomenon of interest can be considered ubiquitous enough to be represented sufficiently in the corpus (cf. Seifart In Press).",
        "entities": [
            [
                148,
                154,
                "TERM"
            ],
            [
                9,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "The keyword that we are searching for here and now is \"say\".",
        "entities": [
            [
                4,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "Seeing the distributional patterns can also help in examining whether your findings for a given feature are, in fact, spread in your corpus or are found in a limited number of texts only.",
        "entities": [
            [
                133,
                139,
                "TERM"
            ]
        ]
    },
    {
        "text": "Second, statistical significance has nothing to do with theoretical relevance.",
        "entities": [
            [
                8,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "In multilingual translation projects, there are also cases where there is no single \"source\" text, as translators translate a given text while accessing some of its already available translations (e.g. when confronted with an ambiguous passage).",
        "entities": [
            [
                93,
                97,
                "TERM"
            ],
            [
                132,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, Cowden-Clarke (1881) took sixteen years to manually produce a complete concordance of all words (apart from a small set of words considered insignificant and occurring frequently such as be, do, and have) in Shakespeare's writings.",
        "entities": [
            [
                84,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "In some cases, the abundance of metadata requires the use of a precise syntax for tags, based on the conventions of computer languages for XML or SGML coding.",
        "entities": [
            [
                139,
                142,
                "TERM"
            ],
            [
                32,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "In diachronic research, scholars may focus on the specific usage of a word or a structure.",
        "entities": [
            [
                3,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, sample corpus analyses are included to illustrate the many theoretical and practical applications that linguistic corpora have.",
        "entities": [
            [
                13,
                26,
                "TERM"
            ],
            [
                20,
                26,
                "TERM"
            ],
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each time you run the search, even with the same keyword (by choosing the button \"KWIC\" in the top left corner of COCA), it will display a different set of randomly selected examples.",
        "entities": [
            [
                49,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "When discussing sizes of spoken-language corpora within documentary linguistics, the time length of primary audio and/or video data is often cited (see Thieberger 2006:7 on the corpus of Nafsan (formally South Efate)).",
        "entities": [
            [
                177,
                183,
                "TERM"
            ]
        ]
    },
    {
        "text": "When the text of a file is not displayed correctly in AntConc, the encoding used can be changed to make it match the file's encoding, for example, the ISO 8859-1 format (Latin.1).",
        "entities": [
            [
                67,
                75,
                "TERM"
            ],
            [
                124,
                132,
                "TERM"
            ],
            [
                9,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "Of course, depending on your corpus, you may also find some rather unexpected words that have nothing whatsoever to do with the verb want; for instance, because my test corpus for trying out regexes contains more 'archaic' language, I also found the adjective wanton, as well as some other constructions, this way.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ],
            [
                169,
                175,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we've seen before, this makes a lot of sense because it not only allows us to distinguish features on different linguistic levels more easily, actually making them countable, but also to possibly exclude some parts of the data from our specific analyses, for instance by ensuring that we don't perform n-gram/collocation analyses across syntactic boundaries.",
        "entities": [
            [
                312,
                323,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the main text, things seem to be going better.",
        "entities": [
            [
                12,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Instead, they seem to interpret balance in terms of the related but distinct property diversity.",
        "entities": [
            [
                32,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "It started life, however, as a corpus for lexicographic research which explains its great time-depth and wide coverage in terms of genres.",
        "entities": [
            [
                31,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "When tri-grams occur with a particular frequency (e.g., 20 times) and in one specific register in a corpus, they are often called lexical bundles.",
        "entities": [
            [
                100,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "Annotated concordance data enable the researcher to perform statistical analyses over hundreds or thousands of data points, identifying distributional patterns that might otherwise escape the researcher's attention.",
        "entities": [
            [
                10,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "Comparability is sometimes complicated by rather technical reasons such as different choices of file formats, corpus formats and syntax, and coding schemes.",
        "entities": [
            [
                110,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "Depending on what your end goal is, you may want to not only sort (and sort in different ways to obtain different perspectives on your data), but also prune a concordance.",
        "entities": [
            [
                159,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "They allow us to see what words appear (and do not appear) in a text, and give an indication of their prominence if we sort the list in frequency order.",
        "entities": [
            [
                64,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "Since this function is central to very many corpus loading operations to be discussed below, we will discuss it and a variety of its arguments in some detail.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a matter of fact, a larger corpus increases the probability of finding more occurrences of a phenomenon.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "In many early corpus linguistics works, you will find frequency tables as a primary account of data.",
        "entities": [
            [
                14,
                32,
                "TERM"
            ],
            [
                14,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "Words used by different characters in classic literary works have been a very popular topic for keyword analyses.",
        "entities": [
            [
                96,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a matter of fact, if a certain annotation turns out to be impossible to achieve in a convergent manner for human annotators, this indicates that the phenomenon may be poorly defined or that the categories have been poorly delimited.",
        "entities": [
            [
                34,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to being organized along the temporal dimension, diachronic corpora often include information on other lectal and diatypic properties of the texts they contain.",
        "entities": [
            [
                61,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the context of corpus linguistics, the most obvious role for the Fisher exact test is to measure dependencies between collocations, or in the case of Stefanowitsch and Gries, dependencies between words and constructions.",
        "entities": [
            [
                18,
                36,
                "TERM"
            ],
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this paper, a look will be taken at the area of corpus linguistics.",
        "entities": [
            [
                51,
                69,
                "TERM"
            ],
            [
                51,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to improve the reliability of annotations made by humans and to help define clear categories, a commonly used method is to have the same annotation made by two different annotators.",
        "entities": [
            [
                146,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "We won't go into issues of designing DTDs or schemas here because they're fairly complex, but will at least have a look at some of the rendering options for XML documents using style sheets.",
        "entities": [
            [
                157,
                160,
                "TERM"
            ]
        ]
    },
    {
        "text": "Conversely, tagging can disambiguate the words: break is both a noun and a verb, and broken is both a participle and an adjective -POS tags allow a computer to distinguish the different grammatical functions.",
        "entities": [
            [
                12,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "While syntactic structures can be assigned to sentences manually (and may be necessary when developing a corpus for a language for which few syntacticallyannotated corpus resources have already been developed; see Sect. 2.3), it is more common for syntactic annotations to be added automatically by a syntactic parser, a program that provides information about different kinds of syntactic relationships that exist between words in a given text (parses).",
        "entities": [
            [
                105,
                111,
                "TERM"
            ],
            [
                164,
                170,
                "TERM"
            ],
            [
                440,
                444,
                "TERM"
            ]
        ]
    },
    {
        "text": "The idea that collocation is of high or indeed primary importance to understanding the meaning of a word or other linguistic form originates with J.R. Firth and is very important in the neo-Firthian school of corpus linguistics; but collocation analysis itself is a commonplace of most or all approaches to corpus linguistics.",
        "entities": [
            [
                209,
                227,
                "TERM"
            ],
            [
                307,
                325,
                "TERM"
            ],
            [
                209,
                215,
                "TERM"
            ],
            [
                307,
                313,
                "TERM"
            ],
            [
                14,
                25,
                "TERM"
            ],
            [
                233,
                244,
                "TERM"
            ]
        ]
    },
    {
        "text": "A search for this same connective in the COBUILD corpus of spoken English showed a frequency of one occurrence every 500 words, which matches the use by witnesses rather than the police.",
        "entities": [
            [
                49,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "As the above discussion already indicated, however, the distinction between corpora and text archives is often blurred.",
        "entities": [
            [
                88,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpus linguistics, the explicandum is typically some aspect of language structure and/or use, while the explicans may be some other aspect of language structure or use (such as the presence or absence of a particular linguistic element, a particular position in a discourse, etc.), or some language external factor (such as the speaker's sex or age, the relationship between speaker and hearer, etc.).",
        "entities": [
            [
                3,
                21,
                "TERM"
            ],
            [
                3,
                9,
                "TERM"
            ]
        ]
    },
    {
        "text": "The line we just inserted identifies the document as being in XML for any application that's capable of displaying it, at the same time specifying its encoding as UTF-8.",
        "entities": [
            [
                62,
                65,
                "TERM"
            ],
            [
                151,
                159,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once generated, the concordance was saved and then a special command -\"delete to N\" -was used to reduce the concordance lines to a random sample of just 100.",
        "entities": [
            [
                138,
                144,
                "TERM"
            ],
            [
                20,
                31,
                "TERM"
            ],
            [
                108,
                119,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will finally see that the task of creating a corpus carries with it a certain number of ethical and legal issues which must be dealt with.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "One approach would seem to be to try and tweak hyperparameters of fitting trees, such as (1) the minimum decreases in deviance that define when trees stop splitting, (2) the minimum sample sizes per node, or (3) the tree depth.",
        "entities": [
            [
                199,
                203,
                "TERM"
            ],
            [
                182,
                188,
                "TERM"
            ]
        ]
    },
    {
        "text": "We discussed in Chapter 3.1 how the size and composition of a corpus reflect in various degrees its representativeness and saturation.",
        "entities": [
            [
                62,
                68,
                "TERM"
            ],
            [
                100,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to informative writing, the corpus contains differing types of imaginative prose, such as general fiction and science fiction.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "Before making claims, it is important to consider a sample of expanded concordance lines and to maintain vigilance in terms of spotting lines that potentially may be functioning differently to a first glance.",
        "entities": [
            [
                52,
                58,
                "TERM"
            ],
            [
                71,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is a possible explanation, but it seems more likely that the differences have to do with the production circumstances related to constructing texts individually as opposed to constructing texts as writers are interacting with another person to produce a single text collaboratively.",
        "entities": [
            [
                266,
                270,
                "TERM"
            ]
        ]
    },
    {
        "text": "Perhaps most corpus studies of academic writing have followed what Tognini-Bonelli (2001) calls a corpus-based approach, where the researcher begins with a pre-selected list of potentially productive items and uses the corpus to examine their frequencies and the ways they behave in different contexts.",
        "entities": [
            [
                98,
                110,
                "TERM"
            ],
            [
                13,
                19,
                "TERM"
            ],
            [
                98,
                104,
                "TERM"
            ],
            [
                219,
                225,
                "TERM"
            ]
        ]
    },
    {
        "text": "Again, the example of bogus refugees is cited in this text in order to be critical of it, arguing that such representations do not help to support genuine refugees, although the speaker still makes a distinction between genuine and bogus refugees.",
        "entities": [
            [
                54,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is often only possible if tools ensuring consistency across layers are developed (e.g. the underlying text, and perhaps also tokenization must be kept consistent across tools and formats).",
        "entities": [
            [
                107,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this book, I have focused on corpus linguistics as a methodology, more precisely, as an application of a general observational scientific procedure to large samples of linguistic usage.",
        "entities": [
            [
                32,
                50,
                "TERM"
            ],
            [
                32,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, any of the articles could pretty much randomly occur in any position, as there is no relationship between the position and the type of article used.",
        "entities": [
            [
                143,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is not yet standard in corpus linguistics, but it is a good idea to plan and document your research as though it already were.",
        "entities": [
            [
                28,
                46,
                "TERM"
            ],
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, a concordance of a word w is a display of every occurrence of w together with a user-specified context; it is often referred to as KWIC (Key Word In Context) display.",
        "entities": [
            [
                8,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "In very basic cases, the language of the corpus is rearranged so that a reader is presented with an altered and focused view.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, one cannot use a simple frequency list of an English engineering corpus, because its most frequent words would still be the, of, in, . . . -these are frequent everywhere.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ],
            [
                33,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some corpora contain language samples produced by learners of different mother tongues, and this information can be found in the metadata (see Chapter 6, section 6.4).",
        "entities": [
            [
                129,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "The type/token ratio was 0.24.",
        "entities": [
            [
                9,
                14,
                "TERM"
            ],
            [
                4,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "The same applies to artificial corpora of experimentally elicited texts: even where participants produce texts narrating the exact same content under the same experimental conditions, as with the Pear Film experiment, it is vital for the corpus to cover speakers with different demographic features, as the corpora are meant to represent the behavioural reaction to the stimulus characteristic of the language community as a whole.",
        "entities": [
            [
                238,
                244,
                "TERM"
            ]
        ]
    },
    {
        "text": "This attitude was largely a consequence of the conflict between what Chomskyan and corpus linguists considered \"sufficient\" evidence for linguistic analysis.",
        "entities": [
            [
                83,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "So, for example, bat is a lemma which can correspond to two different lexemes, as this word is polysemic and may either refer to a flying mamal or an object used to hit a ball.",
        "entities": [
            [
                26,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "For this reason, many corpus linguists prefer to describe it as a 'methodology'.",
        "entities": [
            [
                22,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, the first reference corpora (such as the Brown corpus developed for American English in the early 1960s) were about this size.",
        "entities": [
            [
                61,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "To prevent this, the ICE Project has special markup that encloses the entire sequence of repetitions (<}_><}/_>) and then places special markup (<=_>the police boat<=/>) around the last instance of the repetition, the only instance counted in analyses done by ICECUP, the text analysis program used in the ICE Project.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ],
            [
                137,
                143,
                "TERM"
            ],
            [
                272,
                276,
                "TERM"
            ]
        ]
    },
    {
        "text": "This way we can investigate patterns in larger units such as a text.",
        "entities": [
            [
                63,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "The type/token ratio can only be used for comparing texts of similar length.",
        "entities": [
            [
                9,
                14,
                "TERM"
            ],
            [
                4,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are five word tokens that contain this suffix (directly, briefly, wisely, truly, and wisely), so its token frequency is five; however, there are only four types, since wisely occurs twice, so its type frequency in this passage is four.",
        "entities": [
            [
                107,
                112,
                "TERM"
            ],
            [
                202,
                206,
                "TERM"
            ]
        ]
    },
    {
        "text": "We then addressed some concrete problems, related to data coding and transcription into a corpus, and concluded that these questions needed to be resolved before starting the data collection phase.",
        "entities": [
            [
                90,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, U. Gut the interoperability between tools is still one of the major challenges for spoken corpus use and re-use across linguistic subdisciplines as discussed in Sect. 11.3.",
        "entities": [
            [
                99,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "Often a concordance display gives information about the word by putting that word in the middle of a line with a certain amount of words preceding and following it.",
        "entities": [
            [
                8,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "The fourth step consists in collecting data -in the case of corpus linguistics, in retrieving them from a corpus.",
        "entities": [
            [
                60,
                78,
                "TERM"
            ],
            [
                60,
                66,
                "TERM"
            ],
            [
                106,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let's recall Obama's speech cited above: this is an example of a text produced in (American) English.",
        "entities": [
            [
                65,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a result, the British Library Newspapers database is an attractive alternative for the corpus-linguistic analysis of historical newspaper prose.",
        "entities": [
            [
                90,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "Perhaps the only major limitation here, though, is that the BYU interface only provides a single collocation score measure, which is MI.",
        "entities": [
            [
                97,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "Also, the effects of demographic information on the use of specific linguistic constructions could be explored with the help of a corpus designed as a historical or diachronic corpus.",
        "entities": [
            [
                130,
                136,
                "TERM"
            ],
            [
                176,
                182,
                "TERM"
            ],
            [
                165,
                175,
                "TERM"
            ]
        ]
    },
    {
        "text": "Obviously, if the goal of a lexical analysis is to create a dictionary, the examination of a small corpus will not give the lexicographer complete information concerning the range of vocabulary that exists in English and the varying meanings that these vocabulary items will have.",
        "entities": [
            [
                99,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "The more specific corpus tools and methods that are employed comprise relatively basic techniques: the retrieval of clusters, key comparisons, concordance searches, and the identification of (significant) collocates.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ],
            [
                143,
                154,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus can be queried online.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "For languages with other scripts, for example, Cyrillic scripts in many languages of Eastern Europe and Central Asia or various scripts of East Asian languages (Mandarin, Japanese, etc.) corpus builders will either need to use encoding such as Unicode (cf. 5.11) or add a layer of transliteration to the corpus text.",
        "entities": [
            [
                187,
                193,
                "TERM"
            ],
            [
                304,
                310,
                "TERM"
            ],
            [
                227,
                235,
                "TERM"
            ],
            [
                311,
                315,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is therefore necessary to prepare a sample of the population of a more modest size, to whom it might be possible to ask such a question.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "Topics discussed herecollocations, keywords and manual coding of concordance linesplay a key role both in the study of semantics ('dictionary' meanings of words) and in discourse analysis.",
        "entities": [
            [
                65,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "Corpus linguists' most-cited publications which served as the foundations of corpus linguistics were constantly referenced.",
        "entities": [
            [
                77,
                95,
                "TERM"
            ],
            [
                77,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "We give examples of corpus linguistic research in Chapter 4, showing that the corpus linguistic approach is possible for many levels of linguistic analysis and diverse languages.",
        "entities": [
            [
                20,
                26,
                "TERM"
            ],
            [
                78,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "After deciding on the research question(s), the researcher should test the corpus to determine whether it can answer particular research questions.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "The solutions adopted by corpus compilers vary, from limiting the context shown through the search interface (Mark Davies' corpora) to releasing corpora for download with the sentences shuffled into a random order (COW corpora).",
        "entities": [
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "Inspect the results visually by reading through them and trying to identify roughly what kind of a distribution in terms of nouns and verbs you may have in your random sample.",
        "entities": [
            [
                168,
                174,
                "TERM"
            ]
        ]
    },
    {
        "text": "Should these standards be lacking, it would be a good idea to consider the annotation schemes used in previous studies.",
        "entities": [
            [
                75,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Measures of collocation strength differ with respect to the data needed to calcuate them, their computational intensiveness and, crucially, the quality of their results.",
        "entities": [
            [
                12,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "When extracting keywords for one of the newspapers, the comments of the readers from the other newspaper acted as a reference corpus in order to highlight words specific to the Guardian or Daily Mail readership.",
        "entities": [
            [
                126,
                132,
                "TERM"
            ],
            [
                116,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "The main one is probably that, in addition text-processing capabilities, R offers a large number of ready-made functions for the statistical evaluation and graphical representation of data, which allows you to perform just about all corpus-linguistic tasks within only one programming environment.",
        "entities": [
            [
                233,
                239,
                "TERM"
            ],
            [
                43,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "At best, a corpus can provide only a \"snapshot\" of language usage.",
        "entities": [
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, the Corpus Français de l'université de Leipzig, which is not actually a corpus stricto sensu as it contains a set of isolated sentences rather than whole texts, brings together different sources such as newspapers and web pages, as well as entries from the participative encyclopedia, Wikipedia.",
        "entities": [
            [
                81,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "Your corpus has 4,049 files, so you know you will have one results vector for all files' lengths in words (with 4,049 slots), and another results vector for all files' lengths in sentences (with 4,049 slots) (see Section 5.2.4 for a similar application).",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "If we calculate the normalized frequency of first-person pronouns in this text, we get as the result 200 first-person pronouns per 1,000 words.",
        "entities": [
            [
                74,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "In doing so, this chapter showcases applications of regression techniques in corpus-linguistic research.",
        "entities": [
            [
                77,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if you want to generate a frequency list of a corpus or a concordance of a word in a corpus with R, you must write a small script or a little bit of code in a programming language, which is the technical way of saying you write lines of text that are instructions to R.",
        "entities": [
            [
                59,
                65,
                "TERM"
            ],
            [
                98,
                104,
                "TERM"
            ],
            [
                39,
                53,
                "TERM"
            ],
            [
                71,
                82,
                "TERM"
            ],
            [
                250,
                254,
                "TERM"
            ]
        ]
    },
    {
        "text": "A crucial characteristic of a diachronic corpus is that the texts it contains are comparable across periods.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ],
            [
                30,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "It only means that they did not have an opportunity to produce them in the corpus.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are many excellent textbooks in print, providing thorough introductions to the methods of corpus linguistics, surveys of available corpora, and general reviews of previous research.",
        "entities": [
            [
                96,
                114,
                "TERM"
            ],
            [
                96,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let's consider relevant instances of our case example like in the Brown corpus, given in (7.6): Tagging of corpora is done with a clearly defined and confined inventory of tags (a controlled vocabulary) that is called a tagset.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "Logistic regression models are easier to fit and easier to interpret than multinomial regression, and are what you will see most commonly in multivariate quantitative corpus linguistics.",
        "entities": [
            [
                167,
                185,
                "TERM"
            ],
            [
                167,
                173,
                "TERM"
            ]
        ]
    },
    {
        "text": "A portion of the corpus, including works from the 18th to the 20th Century, can be downloaded for free from the Ortolang website.",
        "entities": [
            [
                17,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, the researcher should also be ready for changes during the course of data collection since the process of text compilation may not be as smooth as expected.",
        "entities": [
            [
                115,
                119,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is easiest done by using the meta-information supplied by the corpus makers, which includes the category \"commerce\" as a subcategory of \"newspaper\" (cf.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "Part-of-speech (POS) tagging is the assignment to each word of a single label indicating that word's grammatical category membership.",
        "entities": [
            [
                21,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "To check on 'strange items' in the list, you can use a right mouse click on the frequency to display a concordance of the item in a new tab.",
        "entities": [
            [
                103,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will repeatedly refer back to Chapters 4 and 5 where different types of annotation were relevant.",
        "entities": [
            [
                75,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "A small spoken or signed corpus, therefore, can still be a good representation of how people use their language.",
        "entities": [
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "But despite the difficulties of creating a truly balanced corpus, designers of the BNC made concerted efforts to produce a corpus that was balanced for such variables as age and gender, and that was created so that information on these variables could be extracted by various kinds of software programs.",
        "entities": [
            [
                58,
                64,
                "TERM"
            ],
            [
                123,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "As you may have noticed, this editor is really not optimised for handling large files, so to just view the frequency list without the ability to concordance on it, a dedicated editor, such as Notepad++, would be far better.",
        "entities": [
            [
                107,
                121,
                "TERM"
            ],
            [
                145,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "Furthermore, the annotation itself is accompanied by a hermeneutic dimension, which reflects the annotators' point of view about the text.",
        "entities": [
            [
                17,
                27,
                "TERM"
            ],
            [
                133,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "There, we concentrate on our strength: variationist corpus linguistics.",
        "entities": [
            [
                52,
                70,
                "TERM"
            ],
            [
                52,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the one hand, corpus linguistics has the advantage of favoring the observation of natural data, that is, those which are not influenced by an experimental context.",
        "entities": [
            [
                17,
                35,
                "TERM"
            ],
            [
                17,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "In your first language, think of text varieties that you encounter in the form of digital writing (published or shared on websites, in social media channels, etc., or as part of private communication) and that may qualify as genres.",
        "entities": [
            [
                33,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although far less common, a corpus-based approach to data collection also has several advantages, including allowing for dialectologists to collect large amounts of data from a large number of informants, observe dialect variation across a range of communicative situations, and analyze quantitative linguistic variation in large samples of natural language.",
        "entities": [
            [
                28,
                40,
                "TERM"
            ],
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "Selection of a reference corpus will impact the results, and some care should be taken to select an appropriate 'benchmark' to highlight differences aligned with a given research question.",
        "entities": [
            [
                25,
                31,
                "TERM"
            ],
            [
                15,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "The measure lemma and the kind noun lemma were specified as varying-intercept random effects.",
        "entities": [
            [
                12,
                17,
                "TERM"
            ],
            [
                36,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, the bulk of the corpus contains various kinds of informative prose, including press reportage, editorials, and reviews; government documents; differing types of learned writing; learned writing from, for instance, the humanities and social sciences.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "This bias is a simple reflection of the fact that those creating the BNC and ICE Corpora felt that spontaneous dialogues are a very important type of spoken English and should therefore be amply represented.",
        "entities": [
            [
                142,
                146,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are many linguistic and technical issues relating to corpus sanitation (e.g., text normalization, orthographic error correction, spelling error correction, real word-error correction, grammatical error correction, punctuation error removal, and tokenization).",
        "entities": [
            [
                59,
                65,
                "TERM"
            ],
            [
                84,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "A corpus of journalistic texts includes real productions by journalists, which are not produced for the purpose of being observed.",
        "entities": [
            [
                2,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is nonetheless true that a corpus can only show that which it contains, and therefore the absence of evidence that a word or a structure exists in a corpus cannot constitute definitive proof of their absence from the language.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ],
            [
                152,
                158,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, semantic prosody or discourse prosody refers to a broad function or meaning which tends to co-occur with the node but which may be variously realised.",
        "entities": [
            [
                118,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "But linguistic corpora do not (and cannot) contain only well-known authors, and so checking the individual demographic data for every speaker in a corpus may be difficult to impossible.",
        "entities": [
            [
                147,
                153,
                "TERM"
            ]
        ]
    },
    {
        "text": "If this type of search is not enabled by the interface, all the verbal forms must be looked up one by one with their exact forms.",
        "entities": [
            [
                8,
                12,
                "TERM"
            ]
        ]
    },
    {
        "text": "For more general info about how to report the results of a quantitative corpus-based study, see also Chap. 26.",
        "entities": [
            [
                72,
                84,
                "TERM"
            ],
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "I hope you can already foresee that we will use table a lot to generate frequency lists of corpora: once a corpus is stored in R such that every word is a vector element, using table is all it takes.",
        "entities": [
            [
                107,
                113,
                "TERM"
            ]
        ]
    },
    {
        "text": "Second, as with key items, a rigorous collocation analysis will always go beyond the raw list of statistical collocates to look at actual instances of those collocates in usage alongside the node.",
        "entities": [
            [
                191,
                195,
                "TERM"
            ],
            [
                38,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "The author has a clear role in controlling the text and refers to the parties of the dispute known to all with general nouns: THO I have been much solicited, to shew my Opinion, about the Debate betwixt the two Physicians, concerning . . . and violently oppos'd by a certain Club of Physicians; . . .",
        "entities": [
            [
                47,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "As for the latter problem, lexical gravity G (see Daudaravic ˇius and Marcinkevic ˇiene ˙2004) is an interesting attempt to include type frequencies of collocations in association measures.",
        "entities": [
            [
                132,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "Headings fulfil multiple functions in a text.",
        "entities": [
            [
                40,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are many applications of the principles and methods of bootstrapping that need to be further explored by corpus researchers.",
        "entities": [
            [
                111,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Brown, LOB corpus, and Survey of English Usage (SEU), for instance, contain a wide variety of text types, and therefore, they are considered much better representatives of English.",
        "entities": [
            [
                15,
                21,
                "TERM"
            ],
            [
                98,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "As presented in Chaps. 1 and 2, annotations and metadata are sometimes relatively simple: markup can be added to set them apart from the text and control their inventories.",
        "entities": [
            [
                90,
                96,
                "TERM"
            ],
            [
                48,
                56,
                "TERM"
            ],
            [
                137,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "The sample variance S 2 = P(1-P), and for a very small P value, it is roughly equivalent to P, namely x in this case.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "A 'null hypothesis', or H 0 , is a term used to denote the default assumption Null hypothesis of most statistical test, namely that all the variation in the sample data is due to random variation.",
        "entities": [
            [
                157,
                163,
                "TERM"
            ]
        ]
    },
    {
        "text": "The study also confirms the variation between written and spoken texts, with textbooks containing twice as many different words as classroom teaching, despite their broadly similar instructional purposes, largely due to their use of specialized lexis.",
        "entities": [
            [
                245,
                250,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to address this question, historical corpus linguists need to intensify collaborations with researchers in sociolinguistics and psycholinguistics, who have long been concerned with the social and cognitive processes that shape grammar and that ultimately also shape grammatical change.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we have discussed earlier in this chapter, in the KWIC section, you could then see your keyword in a textual context.",
        "entities": [
            [
                91,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "And this is especially true when the corpus is created by a small team and with limited resources.",
        "entities": [
            [
                37,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is precisely the situation where exhaustive retrieval can only be achieved by a manual corpus search, i.e., by reading the entire corpus and deciding for each word, phrase or clause, whether it constitutes an example of the phenomenon we are looking for.",
        "entities": [
            [
                92,
                98,
                "TERM"
            ],
            [
                135,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "While this seems like a very high accuracy rate, in a large corpus, the remaining 3 percent of words with multiple tags can constitute a very sizable number of words.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "The difficult point to assemble this corpus relates to the way of balancing its content between different literary genres.",
        "entities": [
            [
                37,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "The fact that this colligation with its changing realization (that, it) occurs in both predicative and existential matrices suggests that the so-called it-extraposition construction is part of a larger class of evolving complementation constructions, even though, because of the different matrix syntax, reference to the complement is obligatory in predicative and optional in existential matrices.",
        "entities": [
            [
                19,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, a recent trend in corpus-based research of World Englishes is the detailed statistical modeling of variation, often including ENL, ESL, and EFL varieties.",
        "entities": [
            [
                27,
                39,
                "TERM"
            ],
            [
                27,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "We address several applications of bootstrapping, including the measurement of sample estimate accuracy, the validation of statistical models, the estimation of corpus homogeneity, and random forests.",
        "entities": [
            [
                161,
                167,
                "TERM"
            ],
            [
                79,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "So, if our token is she, in the sentence the cat jumped on the couch and then she went to sleep, and has the same referent as the cat, the antecedent of she is the cat.",
        "entities": [
            [
                11,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Examples of type a) allow us to work with different dialectal variants, or sometimes also to cover spelling variants in historical texts, where the spelling may not yet have been standardised, so that even one and the same text may contain alternate forms that represent exactly the same word meaning.",
        "entities": [
            [
                12,
                16,
                "TERM"
            ],
            [
                223,
                227,
                "TERM"
            ]
        ]
    },
    {
        "text": "A typical example of this type of data is the corpus that contains newspaper archives or parliamentary debates.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ],
            [
                26,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpus linguistics, we worry about both type frequency and token frequency (cf. 2.2.3) that can tell us different things about our corpora.",
        "entities": [
            [
                3,
                21,
                "TERM"
            ],
            [
                3,
                9,
                "TERM"
            ],
            [
                62,
                67,
                "TERM"
            ],
            [
                43,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first is that the phenomenon of the unequal distribution of lexis accounts for much more about naturally occurring text than might be expected from reading any of the papers discussed so far.",
        "entities": [
            [
                64,
                69,
                "TERM"
            ],
            [
                119,
                123,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Sketch Engine platform, which we presented in Chapter 6, automatically performs this tagging process when a new corpus is created and this can be done for several languages (see below).",
        "entities": [
            [
                89,
                96,
                "TERM"
            ],
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is equally important to consider the quality and type of microphone to be used to make recordings.",
        "entities": [
            [
                52,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Comparing the texts shared by ECCO and ECCO-TCP, we find that more than 90% of the hapax legomena in the ECCO sample (henceforth ECCO-OCR) are not found in ECCO-TCP.",
        "entities": [
            [
                110,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "A study that involves time as a variable is called a diachronic or longitudinal study.",
        "entities": [
            [
                53,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "The two most basic forms of data which we can extract from a corpus are the concordance and the frequency list.",
        "entities": [
            [
                61,
                67,
                "TERM"
            ],
            [
                96,
                110,
                "TERM"
            ],
            [
                76,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, the dispersion of a collocation across a reference corpus had only a weak relationship with knowledge (more widely spread collocations were better recognized), and this relationship was significant only in the BNC.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ],
            [
                29,
                40,
                "TERM"
            ],
            [
                50,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "In fact, interpreting other people's utterances, as we must do in corpus linguistic research, may actually lead to more intersubjectively stable results, as interpreting other people's utterances is a more natural activity than interpreting our own: the former is what we routinely engage in in communicative situations, the latter, while not exactly unnatural, is a rather exceptional activity.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "A random sample of 2,000 words was taken for each MP, with MPs excluded who had used less than 2,000 words (thereby removing only 3 MPs).",
        "entities": [
            [
                9,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "Depending on the purpose of the corpus, this agreement should also consider data sharing with third parties.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a 'pilot' study, the paper with a corpus only comprising six recordings of circa 7 min each, problematizes the collection, annotation and analysis of multimodal corpora for research.",
        "entities": [
            [
                126,
                136,
                "TERM"
            ],
            [
                37,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "In ECL1, it is noted that \"as more and more corpora have been created, we have gained considerable knowledge of how to construct a corpus that is balanced and representative and that will yield reliable grammatical information\" (138).",
        "entities": [
            [
                131,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the source material is available in hardcopy form, e.g. a printed book or magazine, then a scanner is required in order to turn the printed version into a digital image and then OCR software creates a machine-readable version of the text contained in the image.",
        "entities": [
            [
                236,
                240,
                "TERM"
            ]
        ]
    },
    {
        "text": "The availability of historical corpora and other electronic resources has multiplied from one pioneer corpus, HC, in 1991 to almost anything ever printed readily available as research data.",
        "entities": [
            [
                102,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "A heterogeneous monitor corpus includes text samples from all subject areas and the individuality of the source of a text and its writer are well attested.",
        "entities": [
            [
                16,
                30,
                "TERM"
            ],
            [
                24,
                30,
                "TERM"
            ],
            [
                40,
                44,
                "TERM"
            ],
            [
                117,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "We need to do this because these line breaks, as indeed anything that doesn't really form part of our text, may in fact interfere with the processing of the text later and even create a number of problems that could affect the meaningfulness of at least part of your data for linguistic analyses.",
        "entities": [
            [
                102,
                106,
                "TERM"
            ],
            [
                157,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "As discussed in Section 3.2.2.1 of Chapter 3, this brings with it its own problems, as automatic tagging and grammatical parsing are far from perfect.",
        "entities": [
            [
                97,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "The third analytical step addresses this question with a quantitative analysis that compares formations with -ment across the diachronic stages with regard to several structural and semantic variables.",
        "entities": [
            [
                126,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "The main advantage of downloadable corpora is their great flexibility for carrying out word or structure searches using a concordancer (see section 5.6).",
        "entities": [
            [
                122,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, corpus analyses have documented the existence of linguistic constructs that are not recognized by current linguistic theories.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "It should be a synchronic corpus, corresponding to current uses of the language.",
        "entities": [
            [
                15,
                25,
                "TERM"
            ],
            [
                26,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, the larger the proportion of the texts in the corpus which fall under the chosen length limit, the more problematic the exclusion method becomes.",
        "entities": [
            [
                55,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section, we discuss how two of the central desiderata in corpus linguistics apply to historical registers: representativeness and comparability.",
        "entities": [
            [
                65,
                83,
                "TERM"
            ],
            [
                65,
                71,
                "TERM"
            ],
            [
                115,
                133,
                "TERM"
            ],
            [
                138,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, essentially, all the cases of collocations identified through the tscore stat that I've just discussed, strictly speaking, represent cases of colligation.",
        "entities": [
            [
                153,
                164,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is therefore imperative that corpus linguists follow the lead of recent developments in psycholinguistics and make mixed-effects/multi-level modeling a central analytical tool: without it, we will never know how much of an effect is interesting, and how much is just due to particular speakers sampled in a corpus.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ],
            [
                310,
                316,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given the considerable interest in utilizing the corpus linguistic approach, in addition to the dynamic and interdisciplinary nature of current studies involving partnerships among disciplines, a comprehensive and systematic overview of the development of and relationships among individual research in the fields of corpus linguistics is called for.",
        "entities": [
            [
                317,
                335,
                "TERM"
            ],
            [
                49,
                55,
                "TERM"
            ],
            [
                317,
                323,
                "TERM"
            ]
        ]
    },
    {
        "text": "If we're working in the area of lexicography, though, and are trying to create a comprehensive dictionary of a particular type of (sub-)language, we may well want to start with an alphabetically sorted list first, and then investigate the individual types according to their specific features that would allow us to classify and describe them optimally.",
        "entities": [
            [
                122,
                126,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this balance needs to be redressed and projects such as the Role Play Learner Corpus and the Louvain International Database of Spoken English Interlanguage are particularly welcome.",
        "entities": [
            [
                14,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "The majority of ICE corpora were released without detailed bibliographical background information on individual texts included in the corpus or biographical information for the spontaneous spoken conversations, notable exceptions being ICE-NZ and ICE-IRE.",
        "entities": [
            [
                134,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a nutshell, the keyword list of a corpus is very useful to identify its main topics, provided that the comparison with the reference corpus is appropriate.",
        "entities": [
            [
                37,
                43,
                "TERM"
            ],
            [
                136,
                142,
                "TERM"
            ],
            [
                19,
                26,
                "TERM"
            ],
            [
                126,
                142,
                "TERM"
            ]
        ]
    },
    {
        "text": "As mentioned, Wmatrix performs both automatic annotation and retrieval.",
        "entities": [
            [
                46,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, taking into account than young men are underrepresented in the corpus compared to old men, there is a clear preference of all men for the of -construction.",
        "entities": [
            [
                79,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Along the same lines, the next example does something similar but does not retrieve data values, but values of an attribute, namely lemma annotation.",
        "entities": [
            [
                132,
                137,
                "TERM"
            ],
            [
                138,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "Almost all texts, apart from maybe certain text types including telegrams and recipes, tend to have a rather high occurrence of high frequency function words, something we've just seen during our first explorations of frequency lists. Since these words don't actually tell us much about the lexical richness or the content of a text/corpus, anyway, they're often regarded as redundant and thus lists that exclude them, at least in theory, ought to help us develop better insights into the nature of any text or corpus under investigation.",
        "entities": [
            [
                333,
                339,
                "TERM"
            ],
            [
                511,
                517,
                "TERM"
            ],
            [
                43,
                47,
                "TERM"
            ],
            [
                328,
                332,
                "TERM"
            ],
            [
                503,
                507,
                "TERM"
            ]
        ]
    },
    {
        "text": "Case studies assume that there is an equal amount of male and female speech in the corpus, so the question is what to compare these frequencies against.",
        "entities": [
            [
                83,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is no way to create frequency listing from text archives, at least via the standard interfaces for these resources.",
        "entities": [
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "No element in the corpus should make it possible to identify any participant.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "The difference might be attributed to other situational variables such as the difference between an exam and an in-class activity or the relationship between participants and the text construction.",
        "entities": [
            [
                179,
                183,
                "TERM"
            ]
        ]
    },
    {
        "text": "We should also consider which words would get highlighted as keywords had we chosen a different reference corpus.",
        "entities": [
            [
                106,
                112,
                "TERM"
            ],
            [
                96,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this case, the span (collocation window) is one word to the left and one word to the right, sometimes abbreviated to 1L, 1R.",
        "entities": [
            [
                24,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, given that there is, by now, a large number of corpus-linguistic textbooks available, ranging from the very decent to the excellent, a few words seem in order to explain why I feel that it makes sense to publish another one.",
        "entities": [
            [
                56,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "If, for instance, we have a corpus containing both writing and speech, we may on occasion wish to search just within the spoken texts, or to compare the results of some analysis in the written data versus the spoken data.",
        "entities": [
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is particularly the case of requests concerning the attribution of a text to one or more alleged authors.",
        "entities": [
            [
                74,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "Include part-of-speech (PoS) filters to find the most common adjective and determiner w-1 and the most common verb and noun w+1 in each corpus.",
        "entities": [
            [
                136,
                142,
                "TERM"
            ]
        ]
    },
    {
        "text": "This allows us to draw conclusions about the population from the sample.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "While it is true that corpus linguistics has imposed itself in an incontestable manner in the English-speaking world and that a significant proportion of French-speaking researchers currently use these methods, the teaching of corpus linguistics still remains marginalized in France.",
        "entities": [
            [
                22,
                40,
                "TERM"
            ],
            [
                227,
                245,
                "TERM"
            ],
            [
                22,
                28,
                "TERM"
            ],
            [
                227,
                233,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, most of the best-known taggers that have been developed over the years, such as, for example, the CLAWS system, for which a number of tagsets, such as the C7 discussed above, have been developed, are generally not freely available to the public or may require the purchase of a commercial licence for tagging suitable quantities of text.",
        "entities": [
            [
                316,
                323,
                "TERM"
            ],
            [
                347,
                351,
                "TERM"
            ]
        ]
    },
    {
        "text": "These corpora must also contain diachronic information, for example regarding the evolution of pronunciation from the second half of the 20th Century to the present day.",
        "entities": [
            [
                32,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "The absence of an annotation in the second slot is read as 'non-human' .",
        "entities": [
            [
                18,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "They should keep the speech transcriptions and the written data in ASCII (text) format as it is the standard format used in corpus linguistics.",
        "entities": [
            [
                124,
                142,
                "TERM"
            ],
            [
                124,
                130,
                "TERM"
            ],
            [
                74,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "Hyperlinks are preserved and rendered in angle brackets (<…>), italicised text surrounded by forward slashes (/…/), and underlined text surrounded by underscores (_…_).",
        "entities": [
            [
                74,
                78,
                "TERM"
            ],
            [
                131,
                135,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, a factor drastically lowering the representativeness of written corpora is the fact that we often do not know anything about specific circumstances of text production and editing before the written texts were published.",
        "entities": [
            [
                48,
                66,
                "TERM"
            ],
            [
                165,
                169,
                "TERM"
            ]
        ]
    },
    {
        "text": "But as corpus linguistics developed alongside the dominant paradigm of generative grammar, obvious differences and disputes resulted.",
        "entities": [
            [
                7,
                25,
                "TERM"
            ],
            [
                7,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this way, we can see how corpus linguistics can provide translators with tools that may help them adapt their translation choices on the basis of a better identification of the recurrent linguistic properties at work in a text.",
        "entities": [
            [
                28,
                46,
                "TERM"
            ],
            [
                28,
                34,
                "TERM"
            ],
            [
                225,
                229,
                "TERM"
            ]
        ]
    },
    {
        "text": "All words without a subscript are new types and hapax legomena at the point at which they appear in the text; if a word has a subscript, it means that it is a repetition of a previously mentioned word, the subscript is its token frequency at this point in the text.",
        "entities": [
            [
                223,
                228,
                "TERM"
            ],
            [
                104,
                108,
                "TERM"
            ],
            [
                260,
                264,
                "TERM"
            ]
        ]
    },
    {
        "text": "These are generally captured in corpus linguistics as part of the external contextual features.",
        "entities": [
            [
                32,
                50,
                "TERM"
            ],
            [
                32,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if we want to know whether learners of French as a foreign language at an advanced level are able to use collocations as native speakers do (collocations such as \"prendre une décision\" -to make a decision -or \"pleuvoir à verse\" -to pour with rain), we can search for occurrences of these expressions in text corpora produced by learners and compare the number of times these expressions appear -and their frequency -in a corpus of similar textual productions made by native speakers.",
        "entities": [
            [
                434,
                440,
                "TERM"
            ],
            [
                316,
                320,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, I use it as a superordinate term for text-linguistic terms like genre, register, style, and medium as well as sociolinguistic terms like dialect, sociolect, etc.",
        "entities": [
            [
                53,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "The chapter opens with a discussion of how to define a corpus, and then traces the history of corpus linguistics, noting, for instance, that corpus-based research began as early as the fifteenth century, when biblical concordances were created based on passages from the Bible.",
        "entities": [
            [
                94,
                112,
                "TERM"
            ],
            [
                141,
                153,
                "TERM"
            ],
            [
                55,
                61,
                "TERM"
            ],
            [
                94,
                100,
                "TERM"
            ],
            [
                141,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "We argue in this chapter that bootstrapping is underused in corpus linguistics, and that quantitative corpus linguists would do well to add this tool to their repertoire.",
        "entities": [
            [
                60,
                78,
                "TERM"
            ],
            [
                60,
                66,
                "TERM"
            ],
            [
                102,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, under the definition of corpus linguistics adopted in this book, Sinclair's observations would be just the first step towards a full analysis.",
        "entities": [
            [
                33,
                51,
                "TERM"
            ],
            [
                33,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "One striking feature is that the corpus comes with various predefined subcorpora, varying in size or in the period that is represented, so as to meet different research needs.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "The most striking difference in type frequency for types occurring in both subcorpora is that for upon, which occurs more than 10 times as frequently in the general corpus (ratio 10.604).",
        "entities": [
            [
                165,
                171,
                "TERM"
            ],
            [
                32,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "While the study of pragmatic items can be challenging in a corpus, it is eminently possible.",
        "entities": [
            [
                59,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "The components highlighted as interesting from a linguistic perspective are features such as style, intended readership, intended function and the context in which the text is intended to fulfill a communicative purpose.",
        "entities": [
            [
                168,
                172,
                "TERM"
            ]
        ]
    },
    {
        "text": "Word processing software often include this feature, simply by choosing the \"text format\" option from the \"save as\" command.",
        "entities": [
            [
                77,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "No matter the way of acquiring data, an important point is to save the corpus files into a format which can then be used by a concordancer.",
        "entities": [
            [
                126,
                138,
                "TERM"
            ],
            [
                71,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, a monitor corpus becomes a worthy representation of texts that are ever produced in a language.",
        "entities": [
            [
                8,
                22,
                "TERM"
            ],
            [
                16,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us further assume that we can assign all other uses of pavement in the sample to the reading 'paved surface', and that two of the four examples of sidewalk in the British English corpus are genuine counterexamples.",
        "entities": [
            [
                183,
                189,
                "TERM"
            ],
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then, we will present two types of descriptive statistics that, respectively, make it possible to measure lexical diversity (the type/token ratio), and to calculate lexical dispersion in a corpus.",
        "entities": [
            [
                189,
                195,
                "TERM"
            ],
            [
                134,
                139,
                "TERM"
            ],
            [
                129,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "These data are typically not part of the corpus itself, but are listed in the metadata (see Chapter 6).",
        "entities": [
            [
                41,
                47,
                "TERM"
            ],
            [
                78,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is necessary to neutralize the differences in the type of data used in order to bring out the differences between languages.",
        "entities": [
            [
                53,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "Often, the next kind of information the reader needs to learn about is some descriptive statistics of the data of the type discussed in Chap. 17.",
        "entities": [
            [
                118,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, the AntConc concordancer that we discuss can only process text format files (or files with XML or HTML tags which can also be treated as text files).",
        "entities": [
            [
                25,
                37,
                "TERM"
            ],
            [
                104,
                107,
                "TERM"
            ],
            [
                71,
                75,
                "TERM"
            ],
            [
                150,
                154,
                "TERM"
            ]
        ]
    },
    {
        "text": "Looking at the results, we can first notice that there are specific tokenisation and tagging issues that result in inappropriate 'compound' forms. These, we can perhaps safely ignore, bearing in mind that the modals contained in them would normally contribute relatively little to the overall token counts of the genuine types.",
        "entities": [
            [
                85,
                92,
                "TERM"
            ],
            [
                293,
                298,
                "TERM"
            ]
        ]
    },
    {
        "text": "First of all, when you take a close look at the listing of words + tags in the table, you'll notice that they're in fact hyperlinks that, once clicked, provide you with a concordance of exactly the combination specified, so that you can already narrow down your search in this way.",
        "entities": [
            [
                171,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "One thing to watch out for with PoS tagging is that it is often automated.",
        "entities": [
            [
                36,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, we removed the content posted before 2016 in order to limit the likelihood of picking up diachronic effects; the tweets in the original corpus date back to 2006.",
        "entities": [
            [
                143,
                149,
                "TERM"
            ],
            [
                96,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "Often, stylistic, grammatical, or syntactical features of the target corpus are highlighted through keyness comparison with a general reference corpus.",
        "entities": [
            [
                69,
                75,
                "TERM"
            ],
            [
                144,
                150,
                "TERM"
            ],
            [
                134,
                150,
                "TERM"
            ]
        ]
    },
    {
        "text": "Clearly, the texts need to share relevant characteristics (or variables) that meet your selection criteria for inclusion in the corpus.",
        "entities": [
            [
                128,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "To do this, it is necessary to use inferential statistics, a tool that makes it possible to know whether it is correct to generalize the results found, at the level of a sample, to a population.",
        "entities": [
            [
                170,
                176,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter discusses the important role of programming in corpus linguistics.",
        "entities": [
            [
                60,
                78,
                "TERM"
            ],
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "Uncheck the box for 'N-Grams', and type in fair as your search term.",
        "entities": [
            [
                35,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "The comparison revealed that non-corpus-informed materials fail to include important information on the passive.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "The various interrelations between utterances in a discourse lead to (text/discourse) coherence so that interlocutors (or writers/readers) share the meaning built up during production and reception.",
        "entities": [
            [
                70,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Contemporary Historical Corpus of American English (COHA) is an example of a diachronic corpus.",
        "entities": [
            [
                92,
                98,
                "TERM"
            ],
            [
                81,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "Different analyses can thus lead to different lemma assignments; accordingly, many lemmatization tools are careful to document the language-specific lemmatization guidelines that they follow.",
        "entities": [
            [
                46,
                51,
                "TERM"
            ],
            [
                83,
                96,
                "TERM"
            ],
            [
                149,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the case of corpus studies, this is not a problem, however, since the files will not be read by humans, but processed by a concordancer.",
        "entities": [
            [
                126,
                138,
                "TERM"
            ],
            [
                15,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another approach, which usually looks at a larger span of potentially discontinuous words, is that of calculating the degree of relatedness of words that occur near a particular node word.",
        "entities": [
            [
                178,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even if works related to corpus linguistics have existed for a long time (such as the indexing of the Bible by theologians or the file-based construction of dictionaries by scholars like Antoine Furetière in French or Samuel Johnson in English), this discipline was only able to properly take off after the arrival of computing.",
        "entities": [
            [
                25,
                43,
                "TERM"
            ],
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the late 1990s, corpus-driven studies of recurrent lexical phrases in English registers began to appear.",
        "entities": [
            [
                19,
                25,
                "TERM"
            ],
            [
                19,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, speech recognition software is not yet accurate enough to automatically create text from sound recordings unless they are of broadcast quality.",
        "entities": [
            [
                94,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "The primary purpose of the transcription is to make the spoken text searchable.",
        "entities": [
            [
                63,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "For each request, the interface returns an indication of the frequency rank of the word looked up in the corpus.",
        "entities": [
            [
                105,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the simplest case, the texts are combined based on some metadata in which we are interested in our analysis.",
        "entities": [
            [
                59,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "In contrast, the type frequency of an affix is a fairly direct reflection of the importance of the affix for the lexicon of a language: obviously an affix that occurs in many different words is more important than one that occurs only in a few words.",
        "entities": [
            [
                17,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the stylistic analysis of one of Pope's poems, for instance, norms with varying contextual relationships include English eighteenth-century poetry, the corpus of Pope's work, all poems written in English in rhymed pentameter couplets, or, for greater contrast as well as comparison, the poetry of Wordsworth.",
        "entities": [
            [
                156,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "Different XML tags are used for markup, metadata and annotation.",
        "entities": [
            [
                53,
                63,
                "TERM"
            ],
            [
                10,
                13,
                "TERM"
            ],
            [
                32,
                38,
                "TERM"
            ],
            [
                40,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "All concordance tools provide for searching by a simple word and some tools permit searching for suffixes, multiple word phrases, regular expressions, part-of-speech tags, other annotation embedded within the corpus, or more complex contextual patterns.",
        "entities": [
            [
                178,
                188,
                "TERM"
            ],
            [
                209,
                215,
                "TERM"
            ],
            [
                4,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is referred to as lemmatisation (c.f. also Section 8.1.8, where we looked at lemma queries in BNCweb), and many programs that produce frequency lists offer this kind of facility.",
        "entities": [
            [
                82,
                87,
                "TERM"
            ],
            [
                23,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Introduction defined corpus linguistics for the purposes of the present discussion as a methodology in the service of the science of language.",
        "entities": [
            [
                25,
                43,
                "TERM"
            ],
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "This first official type of markup language, however, as we'll see further below, was relatively complex and also had a number of serious drawbacks.",
        "entities": [
            [
                28,
                34,
                "TERM"
            ],
            [
                20,
                24,
                "TERM"
            ],
            [
                28,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even the best fully automated annotation still needs to be checked for errors by human editors, although, as we've seen in the many examples of mis-tagging in the BNC and COCA, this is often not done for reasons of time and cost involved, especially the larger the amount of data processed becomes.",
        "entities": [
            [
                148,
                155,
                "TERM"
            ],
            [
                30,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "Note that it is not given that the results of a Fisher exact test can be extended beyond the corpus, due to the mathematical assumptions it is based on.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because of the complexity of the TEI system of annotation for speech, the discussion will be more illustrative than comprehensive.",
        "entities": [
            [
                47,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is important for corpus users to be aware of such potential differences in the orthographic transcriptions as they may lead to the missing of tokens in a word-based corpus search: in a search for 'because', for instance, transcribed forms such as 'coz' and 'cos' will not be found.",
        "entities": [
            [
                20,
                26,
                "TERM"
            ],
            [
                168,
                174,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such differences are important to understand for anyone working with the these corpora, as they will influence the way in which we have to search the corpus (see further Section 4.1.1 below) -before working with a corpus, one should always read the full manual.",
        "entities": [
            [
                150,
                156,
                "TERM"
            ],
            [
                214,
                220,
                "TERM"
            ]
        ]
    },
    {
        "text": "Lexically tagging a corpus has become quite routine, particularly because the accuracy of current tagging programs is quite high.",
        "entities": [
            [
                10,
                17,
                "TERM"
            ],
            [
                98,
                105,
                "TERM"
            ],
            [
                20,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "Different types of texts have different types of character encoding associated with them.",
        "entities": [
            [
                59,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "Two sources of important citation data, most-cited journal titles and the individual publications, were analyzed to understand citation patterns in corpus linguistics.",
        "entities": [
            [
                148,
                166,
                "TERM"
            ],
            [
                148,
                154,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we have moved towards the 'web for corpus' approach, a new challenge has emerged concerning the legality of distributing corpora crawled from the web.",
        "entities": [
            [
                38,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "The primary aim of corpus linguistics is to understand linguistic patterns and explore how and why they occur.",
        "entities": [
            [
                19,
                37,
                "TERM"
            ],
            [
                19,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, when considering diachronic representativeness, we need to deal with certain limitations inherent in historical data.",
        "entities": [
            [
                30,
                40,
                "TERM"
            ],
            [
                41,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "But while many features of writing can be annotated in a written corpus with TEI-conformant markup, annotating all of these features may prove to be unnecessary.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ],
            [
                92,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such semi-structured elicitation techniques may also be used where a phenomenon is frequent enough in a typical corpus, but where the researcher wants to vary certain aspects systematically, or where the researcher wants to achieve comparability across speakers or even across languages.",
        "entities": [
            [
                112,
                118,
                "TERM"
            ],
            [
                232,
                245,
                "TERM"
            ]
        ]
    },
    {
        "text": "Exercise 6 has hopefully already alerted you to the fact that it isn't easily possible to just use any document that we can read in some way on the computer equally well as a source for our corpus-linguistic analysis, simply because it contains text.",
        "entities": [
            [
                190,
                196,
                "TERM"
            ],
            [
                245,
                249,
                "TERM"
            ]
        ]
    },
    {
        "text": "Regardless of the stylistic genre targeted, the use of quantitative methods linked to corpus linguistics has led to many advances in lexicography and has been one of its main application areas.",
        "entities": [
            [
                86,
                104,
                "TERM"
            ],
            [
                86,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "Semantic tagging is a harder task for a computer than POS tagging.",
        "entities": [
            [
                9,
                16,
                "TERM"
            ],
            [
                58,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if you call up a concordance of the word difference, then you will most certainly find that the most frequent L1 collocate is the while the most frequent R1 collocate is between.",
        "entities": [
            [
                30,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "Accordingly, corpus linguistics is bound to be, and has been, used as one methodological approach amongst many in studies which use mixed methods and orient to triangulation.",
        "entities": [
            [
                13,
                31,
                "TERM"
            ],
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "In fact, most of the time, the study of lexicon can be done directly on a raw corpus, or in some cases, on a corpus that has been annotated with part-ofspeech tagging.",
        "entities": [
            [
                159,
                166,
                "TERM"
            ],
            [
                78,
                84,
                "TERM"
            ],
            [
                109,
                115,
                "TERM"
            ]
        ]
    },
    {
        "text": "The diary examples were extracted from the LiveJournal corpus, developed by Dirk Speelman (University of Leuven).",
        "entities": [
            [
                55,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "As before, we are defining what counts as a hapax legomenon not with reference to the individual subsamples of male and female speech, but with respect to the combined sample.",
        "entities": [
            [
                168,
                174,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once a draft version of a text contains \"metadata\" and \"textual markup\", it can then be placed into a \"lexical (pending proofreading)\" directory to indicate that the text will be ready for use as a lexical version of the corpus once it has been proofread.",
        "entities": [
            [
                221,
                227,
                "TERM"
            ],
            [
                64,
                70,
                "TERM"
            ],
            [
                41,
                49,
                "TERM"
            ],
            [
                26,
                30,
                "TERM"
            ],
            [
                166,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "To understand how to apply the situational variables to different text types, we provide three examples of situational analyses below.",
        "entities": [
            [
                66,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, usage conventions may vary considerably between languages even when the same text genre exists in both, which makes them difficult to compare.",
        "entities": [
            [
                90,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "The marriage of corpus linguistics and social science seems, initially, straightforward.",
        "entities": [
            [
                16,
                34,
                "TERM"
            ],
            [
                16,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another measure of central tendency is the median, placed at the middle of the different values found in the corpus, so that the data set is divided into the lower half and the upper half.",
        "entities": [
            [
                109,
                115,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the one hand, including information concerning paralinguistic features makes a corpus more authentic than it would be if this information was simply discarded.",
        "entities": [
            [
                82,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "In terms of attributes, you should be able to find 27, where 'n' represents numerical identifiers for all the 14 textual elements, 'pos' the 12 PoS categories for the words, and 'type' which type of punctuation is present at the end of the syntactic unit.",
        "entities": [
            [
                179,
                183,
                "TERM"
            ],
            [
                191,
                195,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, he considered such factors as whether the formality of the particular type of writing influenced the choice of either retaining or deleting that; whether that deletion was less common in formal writing than in informal writing; whether the particular verb influenced use or non-use of that; and whether including or not including that resulted in a difference in meaning.",
        "entities": [
            [
                84,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the midst of these important developments, one issue that deserves more attention is frequency list generalizability.",
        "entities": [
            [
                88,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, as XML forbids the use of overlapping tags, and overlap passages span across different speaker turns, using <overlap>…</overlap> elements would break the document's well-formedness, so it's best to use the empty tags <overlap type=\"start\" /> and <overlap type=\"end\" />, possibly in combination with a number ('n') attribute.",
        "entities": [
            [
                12,
                15,
                "TERM"
            ],
            [
                235,
                239,
                "TERM"
            ],
            [
                264,
                268,
                "TERM"
            ]
        ]
    },
    {
        "text": "This restriction allows for a certain degree of flexibility as well, as it would permit a variety of different speakers and writers of British English to be represented in the corpus.",
        "entities": [
            [
                176,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, for a corpus made up of texts written by 20 students, if the word nonobstant is used by three of them, we can say that its dispersion is 3/20, or that this word is found in 15% of the corpus.",
        "entities": [
            [
                19,
                25,
                "TERM"
            ],
            [
                197,
                203,
                "TERM"
            ]
        ]
    },
    {
        "text": "For yes and no answers, we can employ a similar type of traffic signal analogy and encode them like one-way street signs.",
        "entities": [
            [
                48,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "In some national laws the speaker can withdraw his or her consent at any later point 11 Spoken Corpora 251 in time, which poses serious challenges for corpus dissemination.",
        "entities": [
            [
                151,
                157,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, when a certain linguistic phenomenon is not found in the corpus, it does not necessarily mean that the child or patient recorded in the corpus does not have the competence to produce such types of words or sentences.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ],
            [
                145,
                151,
                "TERM"
            ]
        ]
    }
]