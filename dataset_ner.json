[
    {
        "text": "Whether a corpus is adequate in terms of its representative depends on the research question(s) at hand.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "It can be used to rank-order words in a frequency list to highlight the most frequent and evenly dispersed items.",
        "entities": [
            [
                40,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "To narrow your search and make an analysis more manageable, you can choose a smaller number of texts to analyze or even create a smaller, virtual corpus.",
        "entities": [
            [
                146,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "Any rara (rare phenomena) are unlikely to be found in a small corpus, or if found, will be infrequent.",
        "entities": [
            [
                62,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "If annotating overlapping segments of speech is done separately from the actual transcription of the text, the individual doing the annotation will have to go through the tape repeatedly to reconstruct the overlapsa process that could be done more efficiently by the person doing the transcription.",
        "entities": [
            [
                132,
                142,
                "TERM"
            ],
            [
                101,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are a number of reasons why a sample might be biased.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, sample corpora need to be recollected at regular intervals.",
        "entities": [
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each ICE component consists of texts in two main directoriesone containing all the spoken texts included in the corpus, the other all the written texts.",
        "entities": [
            [
                112,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "Methods and tools for corpus linguistics have developed in tandem with the increasing power of computers and so it is to the computational side that I look in order to take a peek into the future of corpus software.",
        "entities": [
            [
                22,
                40,
                "TERM"
            ],
            [
                199,
                205,
                "TERM"
            ]
        ]
    },
    {
        "text": "Part of this information about the corpus is a citation so that it can be referenced, as we do in this book.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, under the definition of corpus linguistics adopted in this book, Sinclair's observations would be just the first step towards a full analysis.",
        "entities": [
            [
                33,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "Also, any kind of more advanced corpus statistic -for instance, association measures (see Chap. 7) or key words statistics (see Chap. 6) is ultimately based on the observation of, and computations based upon, such frequencies.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "This case study demonstrated a complex design involving grammar, lexis and semantic categories.",
        "entities": [
            [
                65,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "By reference to a specific research question, you will learn how to build your own corpus and then analyze it using both the register functional analysis approach covered in Chapter 2 and the corpus software programs covered in Chapter 3.",
        "entities": [
            [
                83,
                89,
                "TERM"
            ],
            [
                192,
                198,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpora available range from a corpus of American English, the Corpus of Contemporary American English (COCA), to the Coronavirus Corpus, a corpus containing texts retrieved from the Web containing discussions of the Covid-19 virus.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ],
            [
                144,
                150,
                "TERM"
            ]
        ]
    },
    {
        "text": "More bottom-up text-based approaches to text classification, for instance, can reduce the need to rely on more aprioristic classifications.",
        "entities": [
            [
                15,
                19,
                "TERM"
            ],
            [
                40,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "Options include the FireAnt package designed specifically for corpus linguists, as well as general purpose software such as IFTTT, Import.io, and TAGS.",
        "entities": [
            [
                62,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "The relative frequency needs to be normalized to the appropriate basis that is similar in size to the corpus or its parts (subcorpora or texts) that we are interested in.",
        "entities": [
            [
                102,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus was compiled in 2005 and remains one of the largest freely accessible multimodal corpora in existence.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "The replication crisis in linguistics is highly relevant to corpus-based research: Many corpus studies are not directly replicable as the data on which they are based are not readily available.",
        "entities": [
            [
                60,
                72,
                "TERM"
            ],
            [
                88,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, a frequency list of a corpus is usually a two-column table with all words occurring in the corpus in one column and the frequency with which they occur in the corpus in the other column.",
        "entities": [
            [
                8,
                22,
                "TERM"
            ],
            [
                28,
                34,
                "TERM"
            ],
            [
                97,
                103,
                "TERM"
            ],
            [
                165,
                171,
                "TERM"
            ]
        ]
    },
    {
        "text": "If spoken material is to be included in the corpus, it needs to be transcribed, that is, rendered in written form to be searchable by computer.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "This corpus established a methodology for corpus creation and analysis that has continued until the present.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ],
            [
                42,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "As for the literary genre, the Frantext corpus brings together many literary texts ranging from ancient to modern French, in a corpus which totals more than 250 million words.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ],
            [
                127,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, while the statistical properties of language are a worthwhile and actively researched area, they are not the primary object of research in corpus linguistics.",
        "entities": [
            [
                148,
                166,
                "TERM"
            ]
        ]
    },
    {
        "text": "Especially where the body of historical data is finite, disparate and severely biased, or where a corpus is to be used to study change over very long time periods, this is a perfectly defendable strategy.",
        "entities": [
            [
                98,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the written mode, an academic research article has gone through an extensive planning, drafting, and revising process; in a social media post or text message, generally this is not the case.",
        "entities": [
            [
                148,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, most popular part-of-speech taggers are trained on newspaper text, a register which tends to follow fairly strict style guides and contain few errors.",
        "entities": [
            [
                74,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "Secondly, corpus linguists need to be clear when marking this distinction.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "The second type of treebank annotations encodes dependency relations.",
        "entities": [
            [
                11,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "This explains in part why documentarians' work differs from that of classical descriptive and typological linguists in its primary focus on data collection rather than analysis and comparison, and creating a corpus is part of a documentation project.",
        "entities": [
            [
                208,
                214,
                "TERM"
            ]
        ]
    },
    {
        "text": "On closer inspection, however, it becomes apparent that we may be dealing with a different type of exception here: the word pavement has additional senses to the one cited in (5a) above, one of which does exist in American English.",
        "entities": [
            [
                91,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "In arriving at the definition of corpus linguistics adopted in this book, we stressed the need to investigate linguistic phenomena exhaustively, which we took to mean \"taking into account all examples of the phenomenon in question\" (cf. Chapter 2).",
        "entities": [
            [
                33,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "That means that each observation is a text in which we look for the particular variable that we hope to see variation in (i.e., the dependent variable).",
        "entities": [
            [
                38,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "The FoudonReboul corpus is a longitudinal corpus of eight children with autism spectrum disorder (ASD), recorded between the ages of 4 and 9 years.",
        "entities": [
            [
                17,
                23,
                "TERM"
            ],
            [
                42,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most recently (i.e., since the late 2000s), corpus tools were more commonly used by various groups, including not only researchers, but also language teachers and students, who finally had direct access to corpus.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ],
            [
                206,
                212,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, longitudinal designs and developmental questions require tracking participants and collecting metadata such as full names, addresses, and birth dates, which makes the raw data quite the opposite of anonymous.",
        "entities": [
            [
                104,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "Only when corpus compilers have received the written consent of the speakers recorded for the corpus that their data can be used for research and be disseminated can corpora be used and shared.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ],
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "All of the corpora also use the same search interface so that once you learn how to \"ask\" for information in one corpus, you can conduct searches in all of the available corpora.",
        "entities": [
            [
                113,
                119,
                "TERM"
            ]
        ]
    },
    {
        "text": "This type can be seen as the prototype of the early borrowings with which the word-formation process originated.",
        "entities": [
            [
                5,
                9,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let's recall Obama's speech cited above: this is an example of a text produced in (American) English.",
        "entities": [
            [
                65,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "An example is DeReKo -Deutsches Referenzkorpus 'German Reference Corpus' , whose purpose is to make available a large corpus of German amenable to a large variety of research questions.",
        "entities": [
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "But we want to add one little twist to the discussion: A vocabulary-growth curve is dependent -to some degree at least -on the exact order of the words in the corpus.",
        "entities": [
            [
                159,
                165,
                "TERM"
            ]
        ]
    },
    {
        "text": "These annotations thus abstract away from the language-specific structures that morphological glossing and most PoS-tagging capture.",
        "entities": [
            [
                116,
                123,
                "TERM"
            ]
        ]
    },
    {
        "text": "One of the most useful CLAN commands is the combo command, which helps you to look up words or word sequences produced by specific speakers in the corpus.",
        "entities": [
            [
                147,
                153,
                "TERM"
            ]
        ]
    },
    {
        "text": "A possible solution could be to insert these marking elements inside tags, something that the concordancer will be able to ignore.",
        "entities": [
            [
                94,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is therefore best to test whatever capabilities your browser has in this respect and download a sample page, which you can then compare with the original.",
        "entities": [
            [
                99,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "Specific scientific requirements -corpus linguists may need to manipulate, randomise, or control for different situations, often particularly relevant in experimental or comparative research designs.",
        "entities": [
            [
                34,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "While annotation facilitates linguistic research and enables more immediate access to certain kinds of patterns in a corpus, one should acknowledge the potential for valuable linguistic research to be carried out even on unannotated corpora (cf. Chap. 8).",
        "entities": [
            [
                6,
                16,
                "TERM"
            ],
            [
                117,
                123,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if the purpose is to study the use of specific collo-cations, lemmas, or n-grams, the researcher can use concordance programs such as Wordsmith or AntConc.",
        "entities": [
            [
                118,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is clear that corpus composition must have an influence on the identification of important lexical phrases.",
        "entities": [
            [
                17,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "Following this procedure, the sample corresponding to the first 18-year-old male participant from Marseille registered in the corpus would be saved in a file called \"221001.txt\".",
        "entities": [
            [
                126,
                132,
                "TERM"
            ],
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a consequence, it is usually impossible to extract a complete sample of a given phenomenon manually, and this has lead to a widespread use of computers and corpus linguistic software applications in the field.",
        "entities": [
            [
                159,
                165,
                "TERM"
            ],
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "With its 24.4 million words it is a sizeable corpus, but what really sets it apart is the kind of text material it contains, with published transcripts of the spoken interactions in court.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ],
            [
                98,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Brown, LOB corpus, and Survey of English Usage (SEU), for instance, contain a wide variety of text types, and therefore, they are considered much better representatives of English.",
        "entities": [
            [
                15,
                21,
                "TERM"
            ],
            [
                98,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "This represented the first attempt to create a historical corpus conforming to the standards of TEI.",
        "entities": [
            [
                58,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpus linguistics, we worry about both type frequency and token frequency (cf. 2.2.3) that can tell us different things about our corpora.",
        "entities": [
            [
                3,
                21,
                "TERM"
            ],
            [
                62,
                67,
                "TERM"
            ],
            [
                43,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "Ideally, this would be achieved by truly random sampling 10 where each text ever produced and each spoken interaction that has ever taken place would have the same chance of appearing in the sample.",
        "entities": [
            [
                191,
                197,
                "TERM"
            ],
            [
                71,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "While grammatical and functional information can be found often even in a small corpus, it is not the only thing linguists want to study.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "This combination across three dimensions will therefore allow a user to explore the corpus on many different interconnected levels and visualisations.",
        "entities": [
            [
                84,
                90,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another kind of higher-level annotation is syntactic parsing, which aims to provide information about the grammatical structure of sentences in a corpus.",
        "entities": [
            [
                29,
                39,
                "TERM"
            ],
            [
                146,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "Apart from that, diachronic corpora differ widely in size, composition, scope, annotation, and the nature of their textual material.",
        "entities": [
            [
                17,
                27,
                "TERM"
            ],
            [
                79,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, we are also aware, when we do this, that we cannot be certain about the population, only about the sample.",
        "entities": [
            [
                108,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is hard to see how, without the corpus techniques or some extremely time-consuming substitute for them, any firm, objective statements on these matters could be made.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "This separation, incidentally, is possible because most XML processors simply ignore any whitespace they 'perceive' as redundant.",
        "entities": [
            [
                56,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the one hand, these kinds of studies are relatively easy to carry out without the necessary background knowledge for a more sophisticated type of study.",
        "entities": [
            [
                141,
                145,
                "TERM"
            ]
        ]
    },
    {
        "text": "More specifically, when researchers reuse a corpus created by other teams, they must mention in their publication the Internet link where the data were downloaded or retrieved from.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "Considerable progress has also been made in the annotation of corpora.",
        "entities": [
            [
                48,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once the corpus is created and annotated, the most crucial part will be using the corpus for analysis.",
        "entities": [
            [
                9,
                15,
                "TERM"
            ],
            [
                82,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "And as more text is considered, there is a greater chance (particularly in humanities texts) that new words will be encountered.",
        "entities": [
            [
                12,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "To get samples of roughly equal size for expository clarity, let us select every sixth case of the of -possessive, giving us 25 cases (note that in a real study, there would be no good reason to create such roughly equal sample sizes -we would simply use all the data we have).",
        "entities": [
            [
                221,
                227,
                "TERM"
            ]
        ]
    },
    {
        "text": "Similarly, a person working on comparative studies between two or more languages requires a multilingual comparable corpus than a monitor one.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "One commonly used tagset is CLAWS (Constituent Likelihood Automatic Word-tagging System), available in different versions (e.g., CLAWS 5 contains just over 60 tags, while CLAWS 7 contains over 160).",
        "entities": [
            [
                73,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, with the advent of electronic corpora, the speed and systematicity with which diachronic -like synchronic -records can be queried has increased tremendously, opening up new research possibilities by dramatically facilitating at least some aspects of data collection.",
        "entities": [
            [
                87,
                97,
                "TERM"
            ],
            [
                104,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "It requires considerable resources to create balanced corpora, such as the BNC, whereas COCA contains texts downloaded from websites, requiring much less effort than building a corpus such as the BNC.",
        "entities": [
            [
                177,
                183,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is particularly the case of requests concerning the attribution of a text to one or more alleged authors.",
        "entities": [
            [
                74,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "The second type of voice in English is called the passive voice.",
        "entities": [
            [
                11,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "The higher the keyness value for the words, the more likely that they appear in the target versus the reference corpus.",
        "entities": [
            [
                102,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "The review is in two main parts: the first part outlines work on quantitative methods in corpus linguistics to serve as a context for the second, which deals with the cluster analytic work specifically.",
        "entities": [
            [
                89,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "A general corpus comprises texts represented by various types, including written or spoken language.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Both CONE and GraphColl permit partial exploration of graphs, accentuating this issue: a user chooses which nodes to expand (and thus compute collocates for), and this means it is possible to deliberately or unintentionally miss significant links to second-order collocates (or symmetric links back from a collocate to a node word).",
        "entities": [
            [
                321,
                325,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is precisely the situation where exhaustive retrieval can only be achieved by a manual corpus search, i.e., by reading the entire corpus and deciding for each word, phrase or clause, whether it constitutes an example of the phenomenon we are looking for.",
        "entities": [
            [
                92,
                98,
                "TERM"
            ],
            [
                135,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have already discussed some of the challenges inherent in the creation of large corpora, in terms of accurate metadata and word-level annotation.",
        "entities": [
            [
                137,
                147,
                "TERM"
            ],
            [
                113,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "Considering the names in which royal with a capital initial is tagged as an adjective instead of a proper noun, the types of entities in question is reflected in the tagging, as noted in the BNC2 manual; in the names of institutions or charters, royal is an adjective, in the names of locations it is treated as a proper name.",
        "entities": [
            [
                166,
                173,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then, we saw that the important methodological trait to be respected when creating a corpus is datarepresentativeness.",
        "entities": [
            [
                85,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "Of course, it is not obvious where the line should be drawn when considering whether a text of a certain length should be considered an outlier, but from the point of view of the data, the best practice would be to have the length limit as low as possible.",
        "entities": [
            [
                87,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "The indication is that the primary differentiating factor among the Gateshead speakers is gender, though the existence of cluster B suggests that educational level and type of employment are also factors.",
        "entities": [
            [
                168,
                172,
                "TERM"
            ]
        ]
    },
    {
        "text": "If your browser indicates an error, go back to the XML file and first verify whether you've set all start and end tags correctly, as this is generally the most common error.",
        "entities": [
            [
                51,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "Language documentation shares with corpus linguistics the basic goal of representativeness.",
        "entities": [
            [
                72,
                90,
                "TERM"
            ],
            [
                35,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Chapter 3, we will show you how to search an existing corpus for the linguistic variables you may be interested in (whether lexical or grammatical), and in Chapter 4, we will take you through several projects that will help you learn how to do studies of this kind.",
        "entities": [
            [
                57,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "At a glance, it may seem clear that at first is an adverbial expression (\"initially\"), but with each potential phrasal expression identified an additional concordance of that item was run, and then it would become clear that at first also has non-phrasal expression manifestations, as in love at first sight.",
        "entities": [
            [
                155,
                166,
                "TERM"
            ]
        ]
    },
    {
        "text": "Their maybe most extreme, and thus worrying, result is that the exact same distribution of a target word -a uniform distribution across 10% of a corpus -can result in a D value of 0.0 when the computation is based on a corpus split into 10 parts, versus a D value of 0.905 when the computation is based on a corpus split into 1000 parts.",
        "entities": [
            [
                145,
                151,
                "TERM"
            ],
            [
                219,
                225,
                "TERM"
            ],
            [
                308,
                314,
                "TERM"
            ]
        ]
    },
    {
        "text": "Residual errors are either corrected manually or in the case of very large corpora such as the Google Books corpus, they are left as such, because their prevalence is low enough not to significantly bias the results of a research.",
        "entities": [
            [
                108,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "These are, roughly speaking, the words most typical for the collocational framework: when we encounter the framework (in a corpus or in real life), these are the words that are most probable to fill the slot between a and of.",
        "entities": [
            [
                123,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Brown corpus comes with its own tagset comprising 87 different tags.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Other textual markup is internal to the text, and in a spoken text would include such information as speaker IDs, and the beginnings and ends of overlapping speech.",
        "entities": [
            [
                14,
                20,
                "TERM"
            ],
            [
                40,
                44,
                "TERM"
            ],
            [
                62,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "For yes and no answers, we can employ a similar type of traffic signal analogy and encode them like one-way street signs.",
        "entities": [
            [
                48,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "A handful of examples of a particular token is not enough to give a confident sense of the full range of its behaviour, even if they can give a general sense of meaning.",
        "entities": [
            [
                38,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first step of annotation is called the structural markup, which gives descriptive information about the text; thus, structural markup is used to create the text's metadata.",
        "entities": [
            [
                18,
                28,
                "TERM"
            ],
            [
                167,
                175,
                "TERM"
            ],
            [
                54,
                60,
                "TERM"
            ],
            [
                131,
                137,
                "TERM"
            ],
            [
                108,
                112,
                "TERM"
            ],
            [
                160,
                164,
                "TERM"
            ]
        ]
    },
    {
        "text": "This restriction allows for a certain degree of flexibility as well, as it would permit a variety of different speakers and writers of British English to be represented in the corpus.",
        "entities": [
            [
                176,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, this program is able to show you how the word (or collocate or lexical bundle or any n-gram) is distributed within each of your texts (a concordance plot) as well as how many texts include examples of your search term.",
        "entities": [
            [
                150,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "According to Chomsky, another problem related to corpus linguistics stems from the fact that corpora are not representative of the language as a whole.",
        "entities": [
            [
                49,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "I briefly discuss here a few well-known corpus processing techniques for understanding these technical issues.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is worthwhile to explore various tools whether you are new to corpus linguistics or are a seasoned veteran.",
        "entities": [
            [
                65,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because written texts are primarily linear in structure, they can easily be encoded in text format: Most features of standard orthography, such as punctuation, can be maintained, and those features requiring some kind of description can be annotated with a TEI-conformant tag.",
        "entities": [
            [
                87,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "To illustrate the point of the relative heterogeneity of any two corpora, let's compare two excerpts taken from a corpus of American (AmE06) and a corpus of British (BE06) English respectively, each excerpt consisting of exactly 100 words.",
        "entities": [
            [
                114,
                120,
                "TERM"
            ],
            [
                147,
                153,
                "TERM"
            ]
        ]
    },
    {
        "text": "A second step may be to manipulate the actual linguistic data (that is, what the A. Ã„del people represented in the corpus said or wrote) by changing also names and places mentioned which could in some way give away the source. In the case of image data, this would involve masking participants' identity in various ways.",
        "entities": [
            [
                115,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "The with an uppercase T does not occur in the tagged LOB corpus, because case is normalized such that only proper names are capitalized.",
        "entities": [
            [
                57,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the purposes of illustration, all occurrences of the word love with their immediate contextone word to the left and one word to the rightare highlighted and the poem is displayed without line breaks to create one paragraph of run-on text.",
        "entities": [
            [
                237,
                241,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, if this sample is biased in some way, as most samples are, then our estimated rate of occurrence (i.e. mean) for nouns will be different from the actual rate of nouns in the population.",
        "entities": [
            [
                17,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "In LibreOffice Calc, you choose the Menu \"File: Save As . . . \" and choose \"Text CSV (.csv)\" from the \"Save as type\"/Formats menu.",
        "entities": [
            [
                111,
                115,
                "TERM"
            ]
        ]
    },
    {
        "text": "Just as with auxiliaries and pronouns, we also ought to be very careful when eliminating prepositions and conjunctions from our frequency lists because they may equally tell us something about the domain or genre of a particular text. Imagine, for example, a text from the domain of finance about developments on the stock market, where certain values rise above/to or fall below/down to certain thresholds, etc., where the verbs on their own may not give us enough grounds to distinguish the type of domain, just like the verbs that form part of phrasal/prepositional verb combinations are often semantically relatively empty.",
        "entities": [
            [
                229,
                233,
                "TERM"
            ],
            [
                259,
                263,
                "TERM"
            ],
            [
                493,
                497,
                "TERM"
            ]
        ]
    },
    {
        "text": "We then addressed some concrete problems, related to data coding and transcription into a corpus, and concluded that these questions needed to be resolved before starting the data collection phase.",
        "entities": [
            [
                90,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such results can only be obtained by dense corpus studies allowing us to detect relatively rare phenomena such as passive constructions.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is very little agreement in the collocates recorded in the three collocation dictionaries: only 3 percent of the total number of collocates listed are found in all three dictionaries, and 82 percent appear in only one of the three dictionaries.",
        "entities": [
            [
                71,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, all newly created files for a corpus should be directly saved into text format.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ],
            [
                78,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a final step, we need to make the corpus accessible to the scientific community in order to fulfil the scientific imperative of accountability and to enable further scientific developments based thereupon.",
        "entities": [
            [
                37,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the degree of expansion is high, then saturation is low (as is representativeness).",
        "entities": [
            [
                66,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "This issue prevents the inclusion of recently published texts in a corpus that have not yet fallen into the public domain.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "Exercise 6 has hopefully already alerted you to the fact that it isn't easily possible to just use any document that we can read in some way on the computer equally well as a source for our corpus-linguistic analysis, simply because it contains text.",
        "entities": [
            [
                190,
                196,
                "TERM"
            ],
            [
                245,
                249,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the one hand, corpus linguistics has the advantage of favoring the observation of natural data, that is, those which are not influenced by an experimental context.",
        "entities": [
            [
                17,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "Like its name suggests, the type-token ratio is the ratio of the number of different words in a text (types) to the number of all words in the text (tokens).",
        "entities": [
            [
                28,
                44,
                "TERM"
            ],
            [
                96,
                100,
                "TERM"
            ],
            [
                143,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "The difference between bi-grams and collocations is the fact that bi-grams are identified based on two words that happen to be next to each other in a corpus while collocations are two words co-occurring more frequently than by chance.",
        "entities": [
            [
                151,
                157,
                "TERM"
            ]
        ]
    },
    {
        "text": "To a certain extent, restrictions on copyright may be alleviated through concepts such as 'fair use', as texts in a corpus are typically used for research or teaching purposes only, with no bearing on the market.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a corpus of general song lyrics, you would want to include lyrics from different types of music (rock, rap, country, popular music, etc.) in order to achieve balance in your corpus.",
        "entities": [
            [
                161,
                168,
                "TERM"
            ],
            [
                5,
                11,
                "TERM"
            ],
            [
                177,
                183,
                "TERM"
            ]
        ]
    },
    {
        "text": "A common phrase in this corpus was 'see your doctor', which implied that journalists placed trust in doctors (as long as they were not foreign).",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Any corpus is fundamentally a sample.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ],
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "The most common annotation is syntactic parsing.",
        "entities": [
            [
                16,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then we group the frequencies by the lemmas with tapply and sum up all frequencies of each lemma (we don't do the insertion into a long vector with counter here because, since we're only looking at BNC folder A, the data set is small enough for this to work even on a computer that's not state-of-the-art).",
        "entities": [
            [
                91,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "The differences seen in the rates of samurai in named entities potentially also reflect some cultural differences and the interests of the writers represented in the corpus: the named entities including samurai in the GB and US sections included more references to drama films (The Seven Samurai, The Last Samurai), the Asian sections featured references to food-related items, computer software (Market Samurai, a keyword research tool), action toy figures (Samurai Predator AC-01).",
        "entities": [
            [
                415,
                422,
                "TERM"
            ],
            [
                166,
                172,
                "TERM"
            ]
        ]
    },
    {
        "text": "For annotations of a specific linguistic phenomenon (in the situation presented at the end of section 7.2), one solution would be to retrieve the relevant data from the corpus, and then to annotate them separately.",
        "entities": [
            [
                169,
                175,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is a well-known fact in corpus linguistics that words occur in combinations that we call collocations.",
        "entities": [
            [
                27,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "In particular they need to be annotated, at least transcribed, and it is the transcription that will eventually resemble our corpus text.",
        "entities": [
            [
                125,
                131,
                "TERM"
            ],
            [
                132,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "In many ways we can then say that the challenges do not only relate to corpora and their use themselves, but also to how we educate new corpus users and inform them about the fundamental concepts and concerns.",
        "entities": [
            [
                136,
                142,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are only limited possibilities of collocation with preceding adjectives, among which the commonest are silly, obstinate, stupid, awful, occasionally egregious.",
        "entities": [
            [
                40,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is done by introducing codes into the text to represent the beginning and end points of all the phrases.",
        "entities": [
            [
                43,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, the use of adjectives is a stable enough linguistic variable, so there is no need to worry about the representativeness too much.",
        "entities": [
            [
                110,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "Speech corpora are based on spoken language but necessitate detailed annotation including not only written transcription but transcription in phonetic alphabets and careful connections with the time course of speaking.",
        "entities": [
            [
                69,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "The perspective that we will take is, as you can tell from the title of the book, related to an area of language study called corpus linguistics.",
        "entities": [
            [
                126,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "In fact, if metadata is included at the top or bottom of the file, it may be read as text rather than meta-information about the text.",
        "entities": [
            [
                12,
                20,
                "TERM"
            ],
            [
                85,
                89,
                "TERM"
            ],
            [
                129,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "This type of information is nonetheless crucial for the quantitative comparison of linguistic productions between the two genders.",
        "entities": [
            [
                5,
                9,
                "TERM"
            ]
        ]
    },
    {
        "text": "ICEweb already caters for some of that information by keeping a little text database that you can open with Excel or OpenOffice Calc.",
        "entities": [
            [
                71,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "It should be obvious that we can calculate the mean length of words or other constituents in a corpus, a particular sample, a particular position in a grammatical construction, etc.",
        "entities": [
            [
                95,
                101,
                "TERM"
            ],
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "All text samples should be collected from genuine use of speech and writing.",
        "entities": [
            [
                4,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the following, we will look at some typical examples of collocation research, i.e. cases where both variables consist of (some part of) the lexicon and the values are individual words.",
        "entities": [
            [
                59,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "Notable improvements could also be gained by the increased collaboration between traditional corpus linguists and scholars in the fields of computational linguistics and NLP, of which there are already encouraging examples.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "Representations of foreigners were largely concerned with political institutions like the foreign office, although a sample of 21 out of 100 concordance lines taken at random (using an online random number generator) showed negative constructions of foreigners involving stereotyping, implying they were taking up British resources or jobs, or controlling British interests.",
        "entities": [
            [
                141,
                152,
                "TERM"
            ],
            [
                117,
                123,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpus linguistics, sampling is rarely truly random (a random person from a population, or a random text from all existing texts), and is more often a convenience sample (who we can record, what we can find on the web, which newspapers we have access to, etc.) (cf. Chapters 6 and 10).",
        "entities": [
            [
                3,
                21,
                "TERM"
            ],
            [
                166,
                172,
                "TERM"
            ],
            [
                103,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "At this point, we concordanced month-by-month the items violence and side(s) and the co-text of the resulting occurrences were read.",
        "entities": [
            [
                88,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "And again, the same sampling considerations of general corpora apply for special corpora: we sample either to achieve proportional equivalence or in order to reflect the population as closely as possible.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we will see in this section, the best solution may be to take the texts from a text archive or the Web (containing billions of words of data), and then combine this with a robust corpus architecture.",
        "entities": [
            [
                182,
                188,
                "TERM"
            ],
            [
                82,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "Other times, however, we refer to a word not to designate the total number of character strings, but the number of different words that a corpus contains.",
        "entities": [
            [
                138,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "One of the simplest ways to record metadata is as a simple table, which can be stored in a comma or tab-delimited value format (CSV or TSV).",
        "entities": [
            [
                35,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "The major difference between creating and analyzing a corpus, however, is that while the creator of a corpus has the option of adjusting what is included in the corpus to compensate for any complications that arise during the creation of the corpus, the corpus analyst is confronted with a fixed corpus, and has to decide whether to continue with an analysis if the corpus is not entirely suitable for analysis, or find a new corpus altogether.",
        "entities": [
            [
                54,
                60,
                "TERM"
            ],
            [
                102,
                108,
                "TERM"
            ],
            [
                161,
                167,
                "TERM"
            ],
            [
                242,
                248,
                "TERM"
            ],
            [
                254,
                260,
                "TERM"
            ],
            [
                296,
                302,
                "TERM"
            ],
            [
                366,
                372,
                "TERM"
            ],
            [
                426,
                432,
                "TERM"
            ]
        ]
    },
    {
        "text": "In many cases, this piece of information can be obtained by contacting the corpus creators.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are numerous compression formats, but the most common one is .zip, for which most operating systems not only provide direct support, but also generally have options to create and manage this type of archive from within whichever graphical file manager they offer.",
        "entities": [
            [
                197,
                201,
                "TERM"
            ]
        ]
    },
    {
        "text": "Those wishing to answer more general questions (e.g. 'aboutness') may choose to make use of a general reference corpus.",
        "entities": [
            [
                102,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us assume that we find 67 hits in the female-speaker sample and 71 hits in the male-speaker sample to be such sentences.",
        "entities": [
            [
                57,
                63,
                "TERM"
            ],
            [
                96,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, it is possible to build a comparable corpus of parliamentary debates in France and the UK.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Imagine a corpus that is overall fairly representative in terms of size and composition, but lacking metadata.",
        "entities": [
            [
                101,
                109,
                "TERM"
            ],
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Primarily, this difference is attributed to the ability of instantaneous revisions of the text.",
        "entities": [
            [
                90,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "That the two words have roughly the same frequency in our corpus, while undeniably a fact about their distribution, is not very enlightening.",
        "entities": [
            [
                58,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "While in corpus linguistics concordancing has become a mainstream method, in literary criticism it does not seem to play a major role.",
        "entities": [
            [
                9,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "These are small assignments which you should try to complete before you read on; answers to them follow immediately in the text.",
        "entities": [
            [
                123,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "The discourse elements that are best suited for a corpus quantitative analysis are those easily identified on the basis of raw data.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each Brown family corpus thus consists of approximately one million words of written English (500 Ã— 2,000).",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "The solutions adopted by corpus compilers vary, from limiting the context shown through the search interface (Mark Davies' corpora) to releasing corpora for download with the sentences shuffled into a random order (COW corpora).",
        "entities": [
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given this assumption, the procedure described here clearly falls under our definition of corpus linguistics.",
        "entities": [
            [
                90,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "If a corpus samples only certain sections, e.g. by taking the first or the last 2,000 words of each text, these sections will be overrepresented.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ],
            [
                100,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, as useful as an ordinary KWIC concordance may be, AntConc also offers us the functionality to create much better views of our search results by providing options for sorting the results based on their immediate left or right contexts.",
        "entities": [
            [
                39,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this encoding does not correspond to text files containing French characters, because of accented characters.",
        "entities": [
            [
                14,
                22,
                "TERM"
            ],
            [
                46,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "If these figures come from corpora of different sizes, for example a written corpus of 3,179,546 words and a spoken corpus of 573,484 words, they cannot be compared directly.",
        "entities": [
            [
                77,
                83,
                "TERM"
            ],
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "Underneath this waveform are two annotation tiers.",
        "entities": [
            [
                33,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this word will probably never be used in other texts in the corpus covering different fields, unlike words such as analysis, hypothesis or conclusion, which will probably be used in all scientific fields.",
        "entities": [
            [
                69,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "These need to be collected in the form of audio files which are later transcribed to become analyzable with corpus searching tools.",
        "entities": [
            [
                108,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "In contrast, if you don't know what you want to look for ahead of time, but you are interested in the possibilities a corpus may have, you can either design a new computer program for yourself and run your own data, or run the n-gram program already available to you (e.g., through AntConc, a software that we discuss more in Chapter 5).",
        "entities": [
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "Universal Dependencies (UD) (cf. 7.3.1) provide a system of consistent, crosslinguistic annotation of grammar (parts of speech, morphological features, and syntactic dependencies).",
        "entities": [
            [
                88,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is a phenomenon we'll frequently encounter in our analyses from now on, and it requires us to always have an open mind and the willingness to let the data 'drive' our interpretation, rather than trying to force the data to fit the theory, which is something I've frequently observed, for example, when colleagues who were doing literary analysis were not working closely enough to the actual text, but always somehow tried very hard to make the text fit the theory they were using.",
        "entities": [
            [
                397,
                401,
                "TERM"
            ],
            [
                450,
                454,
                "TERM"
            ]
        ]
    },
    {
        "text": "Granger's results are, however, disconfirmed for the corpus-informed materials as we obtained a clear Yes for almost 70 percent of the cells on the checklist. There nonetheless remains room for improvement as 11 percent of the cells received a negative evaluation.",
        "entities": [
            [
                53,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this textbook, we attempt to counter-balance the traditional focus on written texts and refer to corpora of non-written language texts as much as possible.",
        "entities": [
            [
                40,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "A corpus that has been annotated with the needs of linguists in mind can greatly facilitate the exploration of such phenomena by reducing the time and effort involved.",
        "entities": [
            [
                2,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "These categories are called the sampling frame.",
        "entities": [
            [
                32,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "But in this case, a version without misspellings should also be included so that the words can be found by a concordancer.",
        "entities": [
            [
                109,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "Choosing the right texts to be included in a corpus should also be the object of careful reflection, since any kind of analysis carried out on data that are not representative of the target genre (see section 6.2) could be largely invalid.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, a text that does use the word elephant once is then rather likely to go on and use it several more times (for example, if it is a text about elephants).",
        "entities": [
            [
                11,
                15,
                "TERM"
            ],
            [
                139,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this case, if we purely look at individual (untagged) words and don't actually analyse the context, we won't necessarily be able to group the second part (i.e. the clitic) with its appropriate full counterpart in a frequency list (something we'll discuss in detail in Section 9.2).",
        "entities": [
            [
                218,
                232,
                "TERM"
            ]
        ]
    },
    {
        "text": "We already saw that the issue of data annotation is extremely complex even in the case of individual lexical items, and the preceding chapter discussed some more complicated examples.",
        "entities": [
            [
                38,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "Size filters are designed to remove very short and very long documents from the corpus.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "Parsing a corpus is a more complicated undertaking, since larger structures, such as phrases and clauses, must be identified.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the following section, we will be concerned with how to load files containing text.",
        "entities": [
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Methods of corpus interrogation will be affected by how linguistic organization is conceived.",
        "entities": [
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, assuming (as we did above) that language structure and use are not infinitely variable, size will correlate with the representativeness of a corpus at least to some extent with respect to particular linguistic phenomena (especially frequent phenomena, such as general vocabulary, and/or highly productive processes such as derivational morphology and major grammatical structures).",
        "entities": [
            [
                136,
                154,
                "TERM"
            ],
            [
                160,
                166,
                "TERM"
            ]
        ]
    },
    {
        "text": "Instead of an absolute path, where you move down the XML tree via the single slash-separated parts, you can also use relative paths indicated by two slashes to skip multiple intervening levels.",
        "entities": [
            [
                53,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, in a corpus containing scientific articles, the word linguistics may appear relatively frequently, due to the fact that a portion of the corpus is devoted to this field.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ],
            [
                150,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "The idea is that the less meaningful words are excluded, giving someone more insight into the corpus.",
        "entities": [
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "The following illustration shows how this relationship may be represented by referring to the negative (left-hand) or positive (right-hand) positions relative to the node.",
        "entities": [
            [
                166,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "Furthermore, concordancers, such as AntConc, generally also allow us to search for XML tags because they simply represent plain searchable text, but may also sometimes provide options to hide them when we don't want to display them.",
        "entities": [
            [
                139,
                143,
                "TERM"
            ],
            [
                83,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "The next script does something seemingly elementary -we will create a frequency list of word-tag combinations (so as to be able to distinguish run as a noun from run as a verb) -but we will do it on a relatively large data set, the complete BNC World Edition with XML annotation, and we will use the annotation well by utilizing information provided by the BNC's multi-word tags, i.e., tags that mark multi-word units such as because of, in spite of, on behalf of, etc.",
        "entities": [
            [
                70,
                84,
                "TERM"
            ],
            [
                268,
                278,
                "TERM"
            ],
            [
                300,
                310,
                "TERM"
            ],
            [
                264,
                267,
                "TERM"
            ]
        ]
    },
    {
        "text": "The plot() function will here display the relative frequency of each clause type order (mc-sc or sc-mc) per conjunction (when, before, after or because); that is, this function can be used to plot the variables ORDER and CONJ, using the code below.",
        "entities": [
            [
                76,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, journalistic text translations are generally carried out by journalists, who are language professionals but not translation professionals.",
        "entities": [
            [
                22,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "The main point really is that interested users have access to the data and can understand how it can be used, which in turn requires metadata on the corpus as a whole.",
        "entities": [
            [
                133,
                141,
                "TERM"
            ],
            [
                149,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will conclude this chapter with a discussion of a point that may, at first, appear merely practical but that is crucial in carrying out corpus-linguistic research (and that has some methodological repercussions, too): the question of how to store our data and annotation decisions.",
        "entities": [
            [
                263,
                273,
                "TERM"
            ],
            [
                139,
                145,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first step in building a corpus is to decide what the ultimate purpose of the corpus will be.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ],
            [
                82,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "With a corpus such as the BNC, we know precisely what kinds and types of English are being analyzed.",
        "entities": [
            [
                7,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "After that we use rchoose.files to define Eve's corpus files and the function vector (with and without mode=\"list\") to define collector structures.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "This might be due to the different methods used, or to the fact that I excluded business, which is disproportionally fre-9 Morphology quent in male speech and writing in the BNC and would thus reduce the diversity in the male sample substantially.",
        "entities": [
            [
                226,
                232,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, this type of information includes the date of a newspaper article, the place where a conversation was recorded or the characteristics of the speakers taking part in the dialogue.",
        "entities": [
            [
                18,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "Written texts, in contrast, are now widely available in digital formats and can easily be incorporated in a corpus after permission has been received to use a given text.",
        "entities": [
            [
                108,
                114,
                "TERM"
            ],
            [
                165,
                169,
                "TERM"
            ]
        ]
    },
    {
        "text": "We likely can think of examples when a writer has either deleted or regretted a particular tweet, social media post, or text message.",
        "entities": [
            [
                120,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to get around this slight limitation of AntConc, you can of course always use your favourite plain-text editor and do a search-and-replace operation where you replace the search term by something like >>> [search term] <<< (leaving out the square brackets).",
        "entities": [
            [
                108,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "I hope that the specific perspective taken in this book, along with the case studies and the possibility to study the full data sets, will help both beginning and seasoned researchers gain an understanding of the underlying logic of corpus linguistic research.",
        "entities": [
            [
                233,
                239,
                "TERM"
            ]
        ]
    },
    {
        "text": "As mentioned, Wmatrix performs both automatic annotation and retrieval.",
        "entities": [
            [
                46,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "All of these are negative, but no significant collocate was found for the two node words.",
        "entities": [
            [
                78,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "The second part of the riddle was clear and matched the type of language in the sample.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ],
            [
                56,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, if you're working on a relatively sizable corpus, be prepared to wait for a few minutes for n-gram calculations to finish.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "As discussed in 3.1.6, a good first step in this process is to elicit names for text varieties or speech events from native speakers.",
        "entities": [
            [
                80,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "The synthesist's domain-specific knowledge here is indispensable concerning what type(s) of questions have been sufficiently addressed in the primary literature, for example, or what questions are theoretically and/or practically relevant to address.",
        "entities": [
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "It also offers a starting point for corpus-driven investigations of academic corpora by generating list of items which can be further explored in more detail using concordance analyses.",
        "entities": [
            [
                36,
                49,
                "TERM"
            ],
            [
                164,
                175,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then, the researcher should transfer the results obtained through the concordance programs to statistical software programs such as Excel or SPSS.",
        "entities": [
            [
                70,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "All we have to do to achieve this is first to declare them as inline elements and then write the appropriate content definitions, where we use the same text as in the actual elements, but get their relevant attribute values using the attr() syntax we used previously for retrieving the turn numbers.",
        "entities": [
            [
                152,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the former, for example, arguing strongly and argued strongly would both count as cases of the collocation argue strongly.",
        "entities": [
            [
                98,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "A very large set of questions in corpus linguistics can be answered without going beyond standard, widely available corpora.",
        "entities": [
            [
                33,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "For such rank measures, a collocation x y is explored by -computing all AMs for collocations with x, ranking them, and noting the rank for x y; -computing all AMs for collocations with y, ranking them, and noting the rank for x y; -comparing the difference in ranks.",
        "entities": [
            [
                26,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "Here, it is not our intention to argue that the texts included in big-data corpora should be sampled manually; indeed, when the corpus includes samples from tens or even hundreds of thousands of individual texts, it is obviously not feasible to check all the data sources individually.",
        "entities": [
            [
                128,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then we calculate the distances between the individual occurrences of the word (w 1 ) in the corpusto do this we need to use the corpus positions.",
        "entities": [
            [
                129,
                135,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, note that -ify has a token frequency that is less than half of that of -ise/-ize, so the sample is much smaller: as in the example of lexical richness in Pride and Prejudice, this means that the TTR and the HTR of this smaller sample are exaggerated and our comparisons in Tables 9.4 and 9.5 as well as the accompanying statistics are, in fact, completely meaningless.",
        "entities": [
            [
                98,
                104,
                "TERM"
            ],
            [
                236,
                242,
                "TERM"
            ],
            [
                30,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "To transfer and align the data is probably the most difficult and time-consuming part of the exercise because it's easy enough to make mistakes when creating new rows and moving the data around, as well as adding the noughts to the relevant cells where a type doesn't exist in one of the corpora.",
        "entities": [
            [
                255,
                259,
                "TERM"
            ]
        ]
    },
    {
        "text": "A researcher should then balance the efforts and rewards of making changes throughout an entire corpus; keeping some glosses underspecified, as described above, is a relevant technique here.",
        "entities": [
            [
                25,
                32,
                "TERM"
            ],
            [
                96,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "For simplicity, and to improve readability, always separate each c-unit text from the tags by line breaks again, so that both container tags and text end up on separate lines.",
        "entities": [
            [
                72,
                76,
                "TERM"
            ],
            [
                145,
                149,
                "TERM"
            ]
        ]
    },
    {
        "text": "Imagine also that there were no associations between words in the poem and words appeared randomly in the text.",
        "entities": [
            [
                106,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "These modes differ from written texts in that the raw data is not readily amenable to inclusion in our corpus.",
        "entities": [
            [
                103,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, once we have extracted and -if necessary -manually cleaned up our data set, we are faced with a problem that does not present itself when studying lexis or grammar: the very fact that affixes do not occur independently but always as parts of words, some of which (like wordform-centeredness in the first sentence of this chapter) have been created productively on the fly for a specific purpose, while others (like ingenuity in the same sentence) are conventionalized lexical items that are listed in dictionaries, even though they are theoretically the result of attaching an affix to a known stem (like ingen-, also found in ingenious and, confusingly, its almost-antonym ingenuous).",
        "entities": [
            [
                156,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, a word+construction combination with a high collostruction strength in a given corpus may actually not occur particularly frequently.",
        "entities": [
            [
                95,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "The usual data creation approach of abstracting and counting the collocates of target words from a corpus was modified by including only the covarying collexemes of target words, that is, words which occur in a defined slot of the same construction as the target word (see Chap. 7).",
        "entities": [
            [
                99,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "The building of bespoke corpora from the web usually requires considerable technical skill and, thus, may not be an option for all corpus linguists, especially beginners.",
        "entities": [
            [
                131,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "I will leave it as an exercise to the reader to determine whether and in what direction these frequencies differ from what would be expected either under an assumption of equal proportions or given the proportion of female and male speakers in the corpus.",
        "entities": [
            [
                248,
                254,
                "TERM"
            ]
        ]
    },
    {
        "text": "In these cases, we have to create our own annotation schemes.",
        "entities": [
            [
                42,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "Consequently, his style of speaking has drawn considerable interest from corpus linguists.",
        "entities": [
            [
                73,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this small sample, we not only see differences in nouns (\"English\" is the third most frequent word in the individual corpus and \"students\" is the fourth most frequent word in the collaborative corpus) but also differences in function words (\"in\" is the fourth most frequent word in the individual texts and \"of\" is the fifth most frequent words in the collaborative texts).",
        "entities": [
            [
                120,
                126,
                "TERM"
            ],
            [
                196,
                202,
                "TERM"
            ],
            [
                14,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, semantic tagging involves annotating a corpus with markup that specifies various features of meaning.",
        "entities": [
            [
                23,
                30,
                "TERM"
            ],
            [
                53,
                59,
                "TERM"
            ],
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "Other things that will crop up frequently are bits of information related to the plays that form part of this 'corpus', such as references to the author, to acts and scenes within the plays.",
        "entities": [
            [
                111,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "Repeat the same process for the newspaper corpus.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "These 15 columns correspond to the 15 text categories.",
        "entities": [
            [
                38,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to the genre-based specification, a researcher may restrict the corpus to a time frame, a social setting, or a given topic.",
        "entities": [
            [
                76,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "A select overview of research conducted on this corpus makes this point very clear.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "We argue in this chapter that bootstrapping is underused in corpus linguistics, and that quantitative corpus linguists would do well to add this tool to their repertoire.",
        "entities": [
            [
                60,
                78,
                "TERM"
            ],
            [
                102,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now, while of course it's generally not possible for us to directly change the design of any corpus tools we may be using to allow us to deal with this issue, we at least ought to bear this 'handicap' in mind in many of our analyses, and see whether at least some of the tools allow us to avoid any of these problems, or whether we may be able to find a way to work around certain issues by manipulating our data ourselves in simple ways.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, this is one area where, despite their merits, current big data projects may (for now) be exacerbating the problem by their tendency to go where the data is and harvest text materials indiscriminately.",
        "entities": [
            [
                178,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "Yet in practice, the selection is guided by text selection principles (see below) to avoid bias in the selection process.",
        "entities": [
            [
                44,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "But as we will see in the next subsection, we can always specify the exact proportion of counterexamples that we would expect to find if there was a random relationship between our variables, and we can then use a sample whether such a random relationship holds (or rather, how probable it is to hold).",
        "entities": [
            [
                214,
                220,
                "TERM"
            ]
        ]
    },
    {
        "text": "Strictly speaking, a concordance does not have to list every occurrence of a word in a corpus.",
        "entities": [
            [
                21,
                32,
                "TERM"
            ],
            [
                87,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "This requires that texts be similar in two regards: text data format and pre-processing and annotation.",
        "entities": [
            [
                92,
                102,
                "TERM"
            ],
            [
                52,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Imagine that you would like to find out about the relationship between article type (a, an, the, zero article) and their position (subject or object).",
        "entities": [
            [
                79,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "Furthermore, new strategies for corpus dissemination are being proposed to ensure long-term access to spoken corpora.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is therefore crucial to the success of any corpus undertaking that accurate information be kept about each text to be considered for inclusion in the corpus.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ],
            [
                153,
                159,
                "TERM"
            ],
            [
                110,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, annotation and analysis should be separated from normative, oftentimes (over)prescriptive interpretation.",
        "entities": [
            [
                9,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a study of that-complementation in English, for each hit in the corpus, the researchers considered external variables such as the L1 of the speaker who had produced the hit and whether the hit came from a written or spoken mode.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given the recent overarching knowledge-building practices and the methodological roles of corpus linguistics, it is necessary to review how a certain body of knowledge has been created according to the common denominator of corpus linguistics.",
        "entities": [
            [
                90,
                108,
                "TERM"
            ],
            [
                224,
                242,
                "TERM"
            ]
        ]
    },
    {
        "text": "A balanced news writing corpus would either include texts of sports, lifestyle, and general news texts or would select only one of these text types for analysis.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ],
            [
                137,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "The women contribute one sample each, while there are 33 speech samples from the male group.",
        "entities": [
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "The median token frequency is 1 morpheme, the median type frequency is 2 morphemes.",
        "entities": [
            [
                11,
                16,
                "TERM"
            ],
            [
                53,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "This includes errors (which were the focus of pre-corpus interlanguage studies), but also cases of under-or overuse, i.e. the use of significantly fewer or more instances of a particular item as compared to the reference corpus.",
        "entities": [
            [
                211,
                227,
                "TERM"
            ],
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "As with many of the levels of usage we have described here, certain annotations help corpus linguists look for the particular kinds of phenomena relevant to their studies of discourse.",
        "entities": [
            [
                85,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "Complex questions, involving large data sets and requiring specialized knowledge of diverse domains such as language history, text traditions, and computational techniques, can be handled if information passes between specialists efficiently.",
        "entities": [
            [
                126,
                130,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can start enumerating the differences between the texts by pointing out that text A is about American politics, while text B is a part of a story about a person called Rincewind.",
        "entities": [
            [
                80,
                84,
                "TERM"
            ],
            [
                121,
                125,
                "TERM"
            ]
        ]
    },
    {
        "text": "The main response to such criticism is that these areas are based on the use of quantitative methods (namely inferential statistics), which make it possible to draw conclusions from a sample and to extrapolate them to an entire population.",
        "entities": [
            [
                184,
                190,
                "TERM"
            ]
        ]
    },
    {
        "text": "Text A uses American spelling (defense), whereas text B sticks with the British spelling conventions (colour).",
        "entities": [
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "Hyperlinks are preserved and rendered in angle brackets (<â€¦>), italicised text surrounded by forward slashes (/â€¦/), and underlined text surrounded by underscores (_â€¦_).",
        "entities": [
            [
                74,
                78,
                "TERM"
            ],
            [
                131,
                135,
                "TERM"
            ]
        ]
    },
    {
        "text": "As for the former, if answering the research questions requires an unannotated corpus to be automatically tagged or parsed, details about the tool used will need to be provided.",
        "entities": [
            [
                79,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Bringing an empirical dimension to the study of academic writing allows us not only to support intuitions, strengthen interpretations, and generally to talk about academic genres with greater confidence, but it contrasts markedly with impressionistic methods of text analysis which tend to produce partial and prescriptive findings, and with observation methods such as keystroke recording, which seek to document what writers do when they write.",
        "entities": [
            [
                262,
                266,
                "TERM"
            ]
        ]
    },
    {
        "text": "To make the sampling manageable, corpus designers often start with a set of categories within which they aim to collect an unbiased sample.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ],
            [
                132,
                138,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to charting the history and development of keyword research (in Section 1), our discussions have been designed to emphasize that key lexical items should be used as a guide for what to analyze qualitatively, and not considered the end product in themselves.",
        "entities": [
            [
                55,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "NVivo has some strengths that corpus linguists should consider seriously.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "For languages with other scripts, for example, Cyrillic scripts in many languages of Eastern Europe and Central Asia or various scripts of East Asian languages (Mandarin, Japanese, etc.) corpus builders will either need to use encoding such as Unicode (cf. 5.11) or add a layer of transliteration to the corpus text.",
        "entities": [
            [
                227,
                235,
                "TERM"
            ],
            [
                187,
                193,
                "TERM"
            ],
            [
                304,
                310,
                "TERM"
            ],
            [
                311,
                315,
                "TERM"
            ]
        ]
    },
    {
        "text": "In doing so, he determines per text (and thus per speaker) what he calls its referential density (RD).",
        "entities": [
            [
                31,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "We do this to understand discourse and pragmatic strategies deployed in a text.",
        "entities": [
            [
                74,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first distinction we can make among all the existing corpora is the one that classifies them into a sample corpus and a monitor corpus.",
        "entities": [
            [
                124,
                138,
                "TERM"
            ],
            [
                104,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "A thorough synthesis that answers this question would be very useful to corpus linguists.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "As mentioned above, Multi-CAST is available in various formats, and all data can be downloaded from the corpus website.",
        "entities": [
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, before, say, \"pressing down\" can be used as an operational definition, at least three questions need to be asked: first, what type of object is to be used for pressing (what material it is made of and what shape it has); second, how much pressure is to be applied; and third, how the \"difficulty\" of pressing down is to be determined.",
        "entities": [
            [
                135,
                139,
                "TERM"
            ]
        ]
    },
    {
        "text": "The fact that this colligation with its changing realization (that, it) occurs in both predicative and existential matrices suggests that the so-called it-extraposition construction is part of a larger class of evolving complementation constructions, even though, because of the different matrix syntax, reference to the complement is obligatory in predicative and optional in existential matrices.",
        "entities": [
            [
                19,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "This research specifies that all forms of the lemma acteur will be retrieved from the corpus when a word tagged as an adjective appears to its right.",
        "entities": [
            [
                86,
                92,
                "TERM"
            ],
            [
                46,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this case, it is essential to properly outline the research question that will be studied on the basis of new data, since the latter will have a crucial influence on the whole process, both during the data collection and the annotation phases.",
        "entities": [
            [
                228,
                238,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, this very redundancy may help us to classify -or even identify the exact genre ofa text better.",
        "entities": [
            [
                102,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "We begin by examining positive contributions of our computational system, focusing on the help it provided in distinguishing between conventional and contact-related uses based on documented patterns from the corpus.",
        "entities": [
            [
                209,
                215,
                "TERM"
            ]
        ]
    },
    {
        "text": "An existing Quechuan corpus (cf. Bakker and Hekking 2012) of 80,000 words was used to identify 54 wordforms with -ero~-era, 47 of which were complex loan words with this suffix.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "And even though the language in the latter sample seems fairly natural, we can still easily see that it comes from a scripted text, partly because of the indication of speakers (which I've highlighted in bold-face), and partly due to the stage instructions included in square brackets.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ],
            [
                126,
                130,
                "TERM"
            ]
        ]
    },
    {
        "text": "The genre features found in a piece of fiction can also be used to extend an argument regarding the intertextual properties of a text in such a way that the intellectual context of the writing can be connected to the written text.",
        "entities": [
            [
                129,
                133,
                "TERM"
            ],
            [
                225,
                229,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is no node word and no directional influence, and the purpose is not to find out more about an individual word.",
        "entities": [
            [
                12,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "A key concern in corpus linguistics is to explain the variable use of wordforms and other structures in dependence on both types of contextual factors.",
        "entities": [
            [
                17,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "This part already contains information on how to tag your data morpho-syntactically, using freely available tagging resources, and how to make use of tagging in your analyses.",
        "entities": [
            [
                108,
                115,
                "TERM"
            ],
            [
                150,
                157,
                "TERM"
            ]
        ]
    },
    {
        "text": "A portion of the corpus contains narrative texts produced by CP and CE1 students (6-7 years old), while the other section is made up of a series of argumentative texts produced by CE2 and CM1 students (8-9 years old).",
        "entities": [
            [
                17,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, though, there's no facility for creating n-gram lists, probably because these could potentially get very large, working with such a big corpus.",
        "entities": [
            [
                151,
                157,
                "TERM"
            ]
        ]
    },
    {
        "text": "This example is somewhat unusual in that the authors do not collect the data themselves, but instead use a selection of data from an existing corpus.",
        "entities": [
            [
                142,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is of interest to note that negative appears on the collocation list of result.",
        "entities": [
            [
                55,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another measure of central tendency is the median, placed at the middle of the different values found in the corpus, so that the data set is divided into the lower half and the upper half.",
        "entities": [
            [
                109,
                115,
                "TERM"
            ]
        ]
    },
    {
        "text": "Third, in the process of corpus construction we have to think about the relationship between the population and the sample in a somewhat different way to how this is done in fields where sampling can be done on a random basis.",
        "entities": [
            [
                25,
                44,
                "TERM"
            ],
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "Linguists would probably agree that the design of the ICE corpora is \"more representative\" than that of the BNC Baby, which is in turn \"more representative\" than that of the BROWN corpus and its offspring.",
        "entities": [
            [
                180,
                186,
                "TERM"
            ]
        ]
    },
    {
        "text": "This annotation is useful since a pronoun like he is not an autonomous referential expression, meaning that it does not by itself make it possible to identify the referent in question if we ignore the context.",
        "entities": [
            [
                5,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is exactly what the methodology of corpus linguistics offers to researchers in disciplines beyond linguistics.",
        "entities": [
            [
                40,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "A similar practice has been followed in the annotation of the Spanish Learner Language Oral Corpora (SPLLOC), a set of corpora of L2 Spanish that were transcribed using the CHAT system developed by the CHILDES project.",
        "entities": [
            [
                44,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, if we want to create a corpus of classroom writing and ask students to volunteer and contribute their texts, we may end up with texts from highly motivated students that will not reflect the written production of the class as such.",
        "entities": [
            [
                37,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Importantly, only a sample of candidate predictors is randomly drawn for each individual CITs.",
        "entities": [
            [
                20,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "The data collection mode makes this corpus unsuitable for many types of research but provides a very useful interface for lexical searches, offering the possibility of looking for simple or compound words and having access to all the occurrences within the context, with an indication of the source for each occurrence.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "This involves not only collecting data (speech and writing) but encoding it: transcribing recorded speech, for instance, as well as adding annotation to it, such as markup indicating in a conversation when one person's speech overlaps another speaker's, and in writing where such features as paragraph boundaries occur in written texts.",
        "entities": [
            [
                139,
                149,
                "TERM"
            ],
            [
                64,
                72,
                "TERM"
            ],
            [
                165,
                171,
                "TERM"
            ]
        ]
    },
    {
        "text": "The logic behind this principle was that the larger the corpus, the more likely it would contain occurrences of rare linguistic phenomena.",
        "entities": [
            [
                56,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although each chapter includes a broad summary of previous research, the primary focus is on a more detailed description of the most important corpus-based studies in this area, with discussion of what those studies found and why they are especially important.",
        "entities": [
            [
                143,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "The sample variance S 2 = P(1-P), and for a very small P value, it is roughly equivalent to P, namely x in this case.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "The English noun issue was used 1,957 times in the TED conference corpus.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "Rather than using two different corpora entirely, some researchers use various subcorpora from the same (reference) corpus for the 'target' and 'reference' sets, and this approach is further exemplified in the two representative studies summarised below.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "A further complication is that much writing, particularly scientific writing, is co-written, and if males and females collaborate, it will be difficult to determine precisely whose writing is actually represented in a sample.",
        "entities": [
            [
                218,
                224,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are, after all, only a handful of texts in LOB and BROWN that mention either of the two words at all (three in each corpus).",
        "entities": [
            [
                122,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, corpus comparability needs to be addressed in a critical evaluation of ICE for the study of World Englishes.",
        "entities": [
            [
                13,
                26,
                "TERM"
            ],
            [
                6,
                12,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this study would require the assembly of a corpus which tangibly represents the legal language, such as court decisions, because these writings properly match the targeted field of study, that is, the legal language.",
        "entities": [
            [
                52,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "The question of influence and significance also comes back to the question of availability, since it is of course more difficult to collect a large and representative corpus of post cards or shopping lists than of newspaper articles.",
        "entities": [
            [
                167,
                173,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, those who wish to compile a corpus involving complex types of information or do advanced types of (semi-)automatic corpus searches would be helped by collaborating with a computational linguist or computer programmer (see Chap. 9).",
        "entities": [
            [
                37,
                43,
                "TERM"
            ],
            [
                124,
                130,
                "TERM"
            ]
        ]
    },
    {
        "text": "The form of annotation I introduced you to above already contains many different bits of information, so that it may appear fairly complex to you.",
        "entities": [
            [
                12,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "There was a significant association between the context type and article type (Ï‡2 (1) = 85.25, p < .001).",
        "entities": [
            [
                56,
                60,
                "TERM"
            ],
            [
                73,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "A corpus can be representative of all the possible linguistic features of a language (covering all possible structures that are part of language user's competence), or it can be representative of all the external or situational variables of different texts that are produced in a given language.",
        "entities": [
            [
                2,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "Hand-tagging an entire corpus, even a small one, is a monumental effort.",
        "entities": [
            [
                5,
                12,
                "TERM"
            ],
            [
                23,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "So, in a corpus of a million words, there will be a million word tokens.",
        "entities": [
            [
                9,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "Biber is not the only linguist to observe this (Halliday does this in a more theoretically-informed way, and Matthiessen, as noted, has added statistical rigour to that model), but Biber has carried out more extensive investigations of this type than anyone else.",
        "entities": [
            [
                241,
                245,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each file was converted from PDF by saving as text from Adobe Reader.",
        "entities": [
            [
                46,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "With regard to the use of a corpus for academic purposes, there are also problems with ethical 'right, wrong, legal or illegal'.",
        "entities": [
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "In written corpora, there is one level other than the lexical that is (or can be) directly represented: the text.",
        "entities": [
            [
                108,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "We could compare the frequency of the to that of other words on the frequency list, and observe whether it is more or less frequently used than those other words.",
        "entities": [
            [
                68,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "A higher z-score indicates a greater degree of collocability of an item with the node word.",
        "entities": [
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is necessary to neutralize the differences in the type of data used in order to bring out the differences between languages.",
        "entities": [
            [
                53,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "One of the major issues we've repeatedly encountered, especially concerning the mega corpora we've worked with, is that the creation of large-scale resources may frequently lead to the compilers taking shortcuts when it comes to ensuring the quality of the data in terms of tokenisation and annotation.",
        "entities": [
            [
                291,
                301,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section, we take a look at a technique which is somewhat similar to factor analysis discussed in Chapter 5 (Section 5.4), but that has been primarily developed for the analysis of cross-tabulation tables with categorical data, the type of data which was discussed in Chapter 4 (Section 4.3).",
        "entities": [
            [
                239,
                243,
                "TERM"
            ]
        ]
    },
    {
        "text": "As an example, see Chap. 8 and the subsection on quantitative analysis of concordance lines.",
        "entities": [
            [
                74,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this corpus, there are 14,021 different words (types).",
        "entities": [
            [
                8,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, lexical simplicity implies that the number of different words should be smaller than in an original text.",
        "entities": [
            [
                113,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "Other stages of building a corpus are also discussed, ranging from the administrative (how to keep records of texts that have been collected) to the practical, such as the various ways to transcribe recordings of speech.",
        "entities": [
            [
                27,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "For this study, a good starting point would be to look for relative pronouns such as who or which in order to find occurrences of relative sentences in the corpus.",
        "entities": [
            [
                156,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "The green ones rank as the top 501-3,000 most frequently occurring words in the corpus, and the yellow ones are marked for those that are in the rank of less commonly used vocabulary in the corpus (beyond the rank of 3,000).",
        "entities": [
            [
                80,
                86,
                "TERM"
            ],
            [
                190,
                196,
                "TERM"
            ]
        ]
    },
    {
        "text": "This can be extremely useful, for instance, when you know where in a line of annotation, say, the three-character identifier of a speaker is located (as may be the case in CHAT files from the CHILDES database) or when you want to access the line numbers in some version of the Brown corpus, which are always the first eight characters of each line, etc. (see, for example, Sections 5.4.5 and 5.4.9).",
        "entities": [
            [
                77,
                87,
                "TERM"
            ],
            [
                283,
                289,
                "TERM"
            ]
        ]
    },
    {
        "text": "A worthy research project has a number of different components, including providing a motivation of the significance of the topic, a clear description of the corpus and the methods used in the study, presentation of results, a discussion of the results, and a conclusion that provides a summary and \"takeaway message\" of the research.",
        "entities": [
            [
                158,
                164,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us further assume that we can assign all other uses of pavement in the sample to the reading 'paved surface', and that two of the four examples of sidewalk in the British English corpus are genuine counterexamples.",
        "entities": [
            [
                183,
                189,
                "TERM"
            ],
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us begin by discussing how we compute type-token ratios and vocabulary-growth curves using a small vector tokens as a 'corpus', something that I always recommend to get started on a new project: Create a data set realistic enough in its make-up but small enough to be seen on one screen, and start developing your code with that.",
        "entities": [
            [
                123,
                129,
                "TERM"
            ],
            [
                47,
                52,
                "TERM"
            ],
            [
                42,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "More specifically, a bi-directional parallel corpus should be used, since the equivalences are often variable depending on the direction of translation.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "Often this is fast and unproblematic and I must admit that the vast majority of my work with XML files is really just that.",
        "entities": [
            [
                93,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you want to check any text of your choice, all you have to do is copy and paste the text in the textbox and the words will be marked up for your text in the same way as it is done in the examples.",
        "entities": [
            [
                25,
                29,
                "TERM"
            ],
            [
                87,
                91,
                "TERM"
            ],
            [
                148,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section we look at the other side of the coin and discuss studies that begin with lexis and investigate grammatical aspects of their context.",
        "entities": [
            [
                90,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "Bootstrapping could be used as a method for evaluating the linguistic representativeness of a corpus (cf. Chap. 1).",
        "entities": [
            [
                70,
                88,
                "TERM"
            ],
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "Incidentally, the level of redundancy would increase even further if we analysed the whole text, including the front matter, because there the headings might show up once more inside the table of contents (TOC) of the document, where their meaning is 'purely' to serve as a navigational aid by listing them side by side with their respective page numbers.",
        "entities": [
            [
                91,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "COCA is not a published article; rather, it is a web-based corpus complied of a 520 million-word database from newspapers, magazines, fiction, and other academic text documents.",
        "entities": [
            [
                59,
                65,
                "TERM"
            ],
            [
                162,
                166,
                "TERM"
            ]
        ]
    },
    {
        "text": "In our case study, we illustrated how this distinction is not absolute: some previous studies of discontinuous lexical frames (like Biber 2009 and Ro Â¨mer 2010) are intermediate along this continuum, beginning with a corpus-driven approach to identify a set of continuous lexical sequences, but carrying out the corpus-based investigation of only those sequences, to analyze the extent to which they occur as discontinuous frames.",
        "entities": [
            [
                217,
                230,
                "TERM"
            ],
            [
                312,
                324,
                "TERM"
            ]
        ]
    },
    {
        "text": "We discussed in Chapter 3.1 how the size and composition of a corpus reflect in various degrees its representativeness and saturation.",
        "entities": [
            [
                100,
                118,
                "TERM"
            ],
            [
                62,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is nonetheless true that a corpus can only show that which it contains, and therefore the absence of evidence that a word or a structure exists in a corpus cannot constitute definitive proof of their absence from the language.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ],
            [
                152,
                158,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some browsers will remove the HTML and only leave plain-text content, while others may retain some bits of HTML, such as, for example, email addresses contained in mailto links (i.e. those that allow you to fire up an email client when you click on them), etc.",
        "entities": [
            [
                56,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "While investigating position '2 Right' with the same restriction, you'll have to ignore many examples where the node verb form may in fact be an auxiliary, followed by a finite verb and then the preposition, as these examples are really only similar to what we just investigated.",
        "entities": [
            [
                112,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although WebCorp Live offers advantages over direct use of commercial search engines (and is still widely used for this reason), it does not solve the underlying problems of the web as corpus approach.",
        "entities": [
            [
                185,
                191,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, this type of test can be used in studies seeking to find out whether advanced learners produce significantly more discourse connectives than intermediate learners, or whether speakers produce more fallacious arguments when speaking at political party meetings or at electoral campaigns.",
        "entities": [
            [
                18,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "This shows that text B (academic text) is more lexically diverse than text A (informal speech).",
        "entities": [
            [
                16,
                20,
                "TERM"
            ],
            [
                33,
                37,
                "TERM"
            ],
            [
                70,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "Overall the authors were able to take advantage of a well-annotated corpus and apply a fitting quantitative analysis to show that factors from both processing and conversational norms interact and have an effect on conversational interactions.",
        "entities": [
            [
                68,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once we have identified all text varieties that should be included, we need to decide how to collect relevant specimens and which ones of these to select for inclusion.",
        "entities": [
            [
                28,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another consideration in sharing corpus resources involves how to make these accessible to others and how to preserve digital data.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "Also move the full copy of the Sherlock Holmes text here.",
        "entities": [
            [
                47,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "If one computes the MI of in spite of in the untagged Brown corpus by comparing the observed frequency of in spite of of 54 against an expected frequency based on complete independence, MI becomes an extremely high value of 12.25.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "You look at a corpus of student presentations that includes nine presentations from each area (a total of 27 texts).",
        "entities": [
            [
                14,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "The choice of lemmatization software often depends on the kinds of language found in the corpus materials.",
        "entities": [
            [
                14,
                27,
                "TERM"
            ],
            [
                89,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "Following from that, we consider how data processing procedures in corpus linguisticsin terms of corpus mark-up, annotation and exploitationappear to be converging, to an extent, with those in (especially qualitative) social science.",
        "entities": [
            [
                113,
                123,
                "TERM"
            ],
            [
                67,
                73,
                "TERM"
            ],
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "Corpus linguists' most-cited publications which served as the foundations of corpus linguistics were constantly referenced.",
        "entities": [
            [
                77,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, the metadata of a corpus will include a list of correspondences between the chosen phonetic alphabet and the IPA.",
        "entities": [
            [
                15,
                23,
                "TERM"
            ],
            [
                29,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "This handbook aims to address all these areas with contributions by many of their leading experts, to be a comprehensive practical resource for junior and more v vi Introduction senior corpus linguists, and to represent the whole research cycle from corpus creation, method, and analyses to reporting results for publication.",
        "entities": [
            [
                185,
                191,
                "TERM"
            ],
            [
                250,
                256,
                "TERM"
            ]
        ]
    },
    {
        "text": "The components highlighted as interesting from a linguistic perspective are features such as style, intended readership, intended function and the context in which the text is intended to fulfill a communicative purpose.",
        "entities": [
            [
                168,
                172,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, most of the best-known taggers that have been developed over the years, such as, for example, the CLAWS system, for which a number of tagsets, such as the C7 discussed above, have been developed, are generally not freely available to the public or may require the purchase of a commercial licence for tagging suitable quantities of text.",
        "entities": [
            [
                316,
                323,
                "TERM"
            ],
            [
                347,
                351,
                "TERM"
            ]
        ]
    },
    {
        "text": "Its wide temporal coverage and large scope of lexical types make the OED an ideal basis for studies that investigate diachronic type frequency changes in phenomena such as the way-construction.",
        "entities": [
            [
                117,
                127,
                "TERM"
            ],
            [
                128,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "As against SLA studies which have traditionally prioritized morphology and grammar, LCR is characterized by a strong focus on lexis, lexico-grammar, and a range of discourse phenomena.",
        "entities": [
            [
                126,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "These are genre markers: linguistic features of genres are not pervasive, rather they occur often only once, in specific positions in a text.",
        "entities": [
            [
                136,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to find only the occurrences of who and which as relative pronouns, we should use a corpus in which the syntactic structure of each sentence has been analyzed in such a way that we can assign a grammatical function to each word and group them into syntactic constituents.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "Metadata and textual markup are important because they can narrow the range of possible choices when a corpus is searched.",
        "entities": [
            [
                103,
                109,
                "TERM"
            ],
            [
                21,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "Typically, privacy laws require corpus compilers to ask for the formal written authorisation by each speaker to be recorded for the corpus and to allow the transcription, sharing and re-use of his or her data.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ],
            [
                132,
                138,
                "TERM"
            ]
        ]
    },
    {
        "text": "This case study analyzed variation in not contraction across year of publication, gender and region in a corpus of American letters to the editor.",
        "entities": [
            [
                105,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each individual word in the corpus is assigned a lexical tag (e.g. noun, verb, preposition, etc.).",
        "entities": [
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "I will focus in particular on three things: (1) how speaker-specific information can be retrieved; (2) how you can search and retrieve information from different levels of the XML tree; and (3) some XPath syntax aspects that allow for simple character processing.",
        "entities": [
            [
                176,
                179,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus contains interviews, narrations based on videos, and images.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "On top of that, being a monitor corpus, it also makes it possible to track potential changes across different periods in the same way.",
        "entities": [
            [
                24,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "While perfect solutions may not yet exist, Liimatta offers useful insights to the study of linguistic questions within the context of varying text lengths.",
        "entities": [
            [
                142,
                146,
                "TERM"
            ]
        ]
    },
    {
        "text": "To annotate a corpus is to insert codes into the running text to represent a linguistic analysis.",
        "entities": [
            [
                14,
                20,
                "TERM"
            ],
            [
                57,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "The authors hope that the use of the corpus \"will advance the linguistic theory of narrative as a primary mode of everyday spoken interaction\" (315).",
        "entities": [
            [
                37,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Transcription is often the bottleneck of corpus development.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "Against this background, it is interesting to note that Rissanen felt compelled to discuss some potential pitfalls related to historical corpus linguistics two years prior to the publication of the Helsinki Corpus.",
        "entities": [
            [
                137,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "A further layer of annotation vital for many corpora is a free translation into a major world language (Schultze-Berndt 2006).",
        "entities": [
            [
                19,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can turn this claim into a hypothesis involving two variables (Variety and Suffix Variant), but not one of the type \"All x are y\".",
        "entities": [
            [
                114,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, using such an editor would only allow you to search through, but not concordance, on the file.",
        "entities": [
            [
                88,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "Assuming that the entire population of texts is inaccessible, our next best option for measuring the degree of bias in our current sample is to collect additional samples of size n from the population and measure the mean rate of nouns in those corpora.",
        "entities": [
            [
                131,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "List 5 IVs and 5 DVs for each variable type.",
        "entities": [
            [
                39,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is only fair to mention, however, that (1) error collections have proven extremely useful in spite of what, from a strict corpus linguistic perspective, may be considered shortcomings, and that (2) compilers of corpora of lesser-spoken languages such as typologists investigating languages with few written records suffer from just the same data scarcity problems.",
        "entities": [
            [
                125,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Contemporary Historical Corpus of American English (COHA) is an example of a diachronic corpus.",
        "entities": [
            [
                81,
                91,
                "TERM"
            ],
            [
                92,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, many journals specializing in different areas of linguistics, such as Journal of Pragmatics, Journal of Sociolinguistics and Journal of French Language Studies, regularly publish corpus studies.",
        "entities": [
            [
                192,
                198,
                "TERM"
            ]
        ]
    },
    {
        "text": "It involves the notion of lexical frequency profiles, which is a corpus-based approach in applied linguistics concerned with the amount and the kind of vocabulary second/foreign-language learners use in their speaking and writing (see Laufer & Nation 1995 for an introduction; Meara 2005 for a critique; and Laufer 2005 for a response).",
        "entities": [
            [
                65,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "That is, the distribution in the \"sample\" could be projected to the distribution of the \"population\".",
        "entities": [
            [
                34,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "The aim of this work is to spot the patterns of linguistic variation among registers in a corpus of English texts.",
        "entities": [
            [
                90,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "Current conceptions of corpus linguistics started with the creation of the Quirk Corpus (which contained print samples of spoken and written English) in 1955 at the Survey of English Usage at University College London.",
        "entities": [
            [
                23,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "The tagged version of the BROWN corpus does not contain quotation marks because they have intentionally been stripped from the text.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ],
            [
                127,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "Rather than attempting to create a complete and exhaustive list, I focus on a handful of corpora (and related resources, such as text archives and the \"Web as Corpus\") that are representative of general classes of corpora.",
        "entities": [
            [
                129,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "For these foreign language learners, it seems that the number of times a collocation occurs is a far more important factor than the strength of association between components.",
        "entities": [
            [
                73,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "This made accurate timing impossible, unless we were to take a more representative sample and check all the document images manually, which would have been a very labour-intensive task.",
        "entities": [
            [
                83,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "While the Web has increasingly become a corpus used for linguistic analysis, the other two sources of dataan archive of tweets and a collection of Trump's speeches and interviewsare specific to this particular analysis.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "Depending on different research questions, the corpus could also be loaded with all three time periods.",
        "entities": [
            [
                47,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "That is, if we did a difference type of test (e.g., like ANOVA), there would not be a significant difference between teacher and student presentations in terms of the use of \"I mean\".",
        "entities": [
            [
                32,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "The z-score test is a measure which adjusts for the general frequencies of the words involved in a potential collocation and shows how much more frequent the collocation of a word with the node word is than one would expect from their general frequencies.",
        "entities": [
            [
                109,
                120,
                "TERM"
            ],
            [
                158,
                169,
                "TERM"
            ],
            [
                189,
                193,
                "TERM"
            ]
        ]
    },
    {
        "text": "You may now be tempted to investigate further why you can find these American spelling variants in the corpus, and of course the easiest option for this is to click on the link for 'colour' in the frequency breakdown to get to the concordance for the results, and then checking the meta-information for each result.",
        "entities": [
            [
                231,
                242,
                "TERM"
            ],
            [
                103,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "Obtaining detailed metadata is another challenge facing anyone wishing to compile a parallel corpus.",
        "entities": [
            [
                19,
                27,
                "TERM"
            ],
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have a sample, for instance, of 30 Matukar Panau speakers, speaking for a total of 40 hours in a specific setting.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now, some corpora (e.g., COCA) have POS tags attached to each word, and some corpora (e.g., Michigan Corpus of Academic Spoken English [MICASE], and Michigan Corpus of Undergraduate Student Papers [MICUSP]) do not have that feature in addition to the actual words in a corpus.",
        "entities": [
            [
                269,
                275,
                "TERM"
            ]
        ]
    },
    {
        "text": "If possible, try to create a corpus that can be published freely under an open license.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, the hopefully not too high-flying goal of this paper is to become for corpus linguistics what the abovequoted papers have become for psycholinguistics: a first go-to resource that explains to corpus linguists what (generalised) linear mixed-effects/multilevel modelling ((G)LMM/MLM) has to offer and that provides them with a concrete example and some instructions on how to perform such analyses.",
        "entities": [
            [
                76,
                94,
                "TERM"
            ],
            [
                198,
                204,
                "TERM"
            ]
        ]
    },
    {
        "text": "Any corpus relies on metadata to correlate the speech of the child and her surroundings with social variables.",
        "entities": [
            [
                21,
                29,
                "TERM"
            ],
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "The preparation of samples to be included in the corpus poses two important methodological questions: on the one hand, the appropriate size for each sample, and, on the other hand, how to balance the portions of the corpus in such a way that the result is truly representative of the genre.",
        "entities": [
            [
                188,
                195,
                "TERM"
            ],
            [
                49,
                55,
                "TERM"
            ],
            [
                216,
                222,
                "TERM"
            ],
            [
                149,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "Later on, we'll move on to learning about ways of extracting text data from files that contain formatted text, where of course the same, or at least similar, clean-up operations might be necessary after the main data extraction has been performed.",
        "entities": [
            [
                61,
                65,
                "TERM"
            ],
            [
                105,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "You can also determine the relative length and complexity of phrases (understood as dependency structures) by considering the number of head indices in the head column cross-referencing the head word of the phrase in question, or all phrases dependent on the verb node.",
        "entities": [
            [
                264,
                268,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is probably quite common -not only in corpus linguistics but also in other domains, for example, when it comes to publishing programming scripts.",
        "entities": [
            [
                43,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "The remainder of the chapter explores these considerations in greater detail, focusing on such topics as the factors determining, for instance, how lengthy a corpus should be, what kinds of texts should be included in a corpus, and other issues relevant to the design of linguistic corpora.",
        "entities": [
            [
                158,
                164,
                "TERM"
            ],
            [
                220,
                226,
                "TERM"
            ]
        ]
    },
    {
        "text": "Both devices project the author as a participant in the text, indicating that the writer is prepared to debate issues and contribute half of a dialogue with readers.",
        "entities": [
            [
                56,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "The text should be free from any annotation that carries linguistic and extralinguistic information.",
        "entities": [
            [
                33,
                43,
                "TERM"
            ],
            [
                4,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "The remainder of Part I of this book will expand this definition into a guideline for conducting corpus linguistic research.",
        "entities": [
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even the resulting, somewhat weaker statement is quite clearly true, and will remain true no matter how large a corpus we are dealing with.",
        "entities": [
            [
                112,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "The KWIC (keyword in context) concordances show the narrow linguistic co-text and provide perhaps the easiest and most useful way of getting acquainted with the material.",
        "entities": [
            [
                10,
                17,
                "TERM"
            ],
            [
                73,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Good for a genre-specific corpus, and a starting point for some research questions.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "An example of a domain-specific literary corpus would be the collected works of an author, which can be used to investigate the style of this particular author, or even to verify disputes about the authorship of a piece of literature where this may be contentious.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Base du franÃ§ais mÃ©diÃ©val (Guillot-Barbance et al. 2017) offers access to different diachronic corpora.",
        "entities": [
            [
                88,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let's consider relevant instances of our case example like in the Brown corpus, given in (7.6): Tagging of corpora is done with a clearly defined and confined inventory of tags (a controlled vocabulary) that is called a tagset.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, when a certain linguistic phenomenon is not found in the corpus, it does not necessarily mean that the child or patient recorded in the corpus does not have the competence to produce such types of words or sentences.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ],
            [
                145,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "My corpus of Cameron's published writing consists of 21 single-authored papers made available by the author.",
        "entities": [
            [
                3,
                9,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have also seen that corpus linguistics often resorts to a quantitative methodology, studying a large sample of data which is representative of the phenomenon studied, with the aim of generalizing the observations to the whole of the language or to a language's register.",
        "entities": [
            [
                23,
                41,
                "TERM"
            ],
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "For each request, the interface returns an indication of the frequency rank of the word looked up in the corpus.",
        "entities": [
            [
                105,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "He develops software programs that are extremely useful for corpus linguistic analyses and he makes them freely available (although you are able to make a donation should you choose to do so).",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even if an automatically annotated corpus is unlikely to meet all the expectations of a researcher in terms of its categories of annotation, it can still be an invaluable resource.",
        "entities": [
            [
                129,
                139,
                "TERM"
            ],
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a consequence, many corpus linguists have chosen not to do any statistical analysis, and work instead with frequency counts.",
        "entities": [
            [
                23,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "Next, they look at concordances of the remaining words to determine first, which senses are most frequent and thus most relevant for the observed differences, and second, whether the words are actually distributed across the respective corpus, discarding those 10 Text whose overall frequency is simply due to their frequent occurrence in a single file (since those words would not tell us anything about cultural differences).",
        "entities": [
            [
                236,
                242,
                "TERM"
            ]
        ]
    },
    {
        "text": "At each stage of analysis, to avoid duplication of work, it is most efficient to have a single person work on a text; at the proofreading stage, it is best to have the text proofread by someone not involved with any prior version of the text, since he or she will bring a \"fresh\" perspective to the text.",
        "entities": [
            [
                112,
                116,
                "TERM"
            ],
            [
                168,
                172,
                "TERM"
            ],
            [
                237,
                241,
                "TERM"
            ],
            [
                299,
                303,
                "TERM"
            ]
        ]
    },
    {
        "text": "The observed proportions are calculated by taking, again one-by-one, the absolute frequencies of the word or phrase of interest in the corpus parts and dividing these by the absolute frequency of the word or phrase in the whole corpus.",
        "entities": [
            [
                135,
                141,
                "TERM"
            ],
            [
                228,
                234,
                "TERM"
            ]
        ]
    },
    {
        "text": "The term 'annotation layer' refers to the issue of whether different types of annotation are integrated together in one linear transcription or whether they are represented individually on separate layers.",
        "entities": [
            [
                10,
                20,
                "TERM"
            ],
            [
                78,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "When starting an annotation project, it is advisable to gather information about the existence of such standards and to consult previous studies to decide on the best way to annotate data.",
        "entities": [
            [
                17,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we saw in (6.1), individual passages in the text refer to passages in the recording through time code information that allows users to navigate across the two files.",
        "entities": [
            [
                47,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "The process of annotating a corpus involves running software that can (1) tag a corpus (add part-of-speech tags to all of the words in the corpus, such as nouns, prepositions, and verbs), or (2) parse a corpus (add markup that identifies larger structures, such as verb phrases, prepositional phrases, and adverbials).",
        "entities": [
            [
                28,
                34,
                "TERM"
            ],
            [
                80,
                86,
                "TERM"
            ],
            [
                139,
                145,
                "TERM"
            ],
            [
                203,
                209,
                "TERM"
            ],
            [
                215,
                221,
                "TERM"
            ]
        ]
    },
    {
        "text": "Posts were inspected to extract only those written by people with cancer (as opposed to family members, carers, or those experiencing symptoms that may be associated with cancer), which resulted in a final corpus comprising 12,757 posts and 1,629,370 words.",
        "entities": [
            [
                206,
                212,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, the ratio for the above example, which we obtain by dividing the relative frequency of text 1 by that of text 2, would be 1.6, which clearly indicates that modals are more than 1Â½ times as frequent in text 1.",
        "entities": [
            [
                101,
                105,
                "TERM"
            ],
            [
                119,
                123,
                "TERM"
            ],
            [
                215,
                219,
                "TERM"
            ]
        ]
    },
    {
        "text": "One big advantage, at least in comparison to HTML, is that a large set of tag definitions/DTDs for linguistic purposes, such as for the TEI (Text Encoding Initiative), were originally designed for SGML, although more and more of these have been or are being 'ported' to XML these days, too.",
        "entities": [
            [
                270,
                273,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each MP sample was compared against every other MP using two similarity measures: Jaccard and Log Likelihood.",
        "entities": [
            [
                8,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, their size is the only argument in their favor, as their creators and their users must not only give up any pretense that they are dealing with a representative corpus, but must contend with a situation in which they have no idea what texts and language varieties the corpus contains and how much of it was produced by speakers of English (or by human beings rather than bots).",
        "entities": [
            [
                170,
                176,
                "TERM"
            ],
            [
                277,
                283,
                "TERM"
            ]
        ]
    },
    {
        "text": "Alongside corpus text data we have to integrate metadata.",
        "entities": [
            [
                48,
                56,
                "TERM"
            ],
            [
                10,
                16,
                "TERM"
            ],
            [
                17,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "This corpus includes four original works in French and their translation into English, as well as four original works in English and their translation into French.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the time being, it is not possible for linguists to observe how the French language works through the study of a single corpus.",
        "entities": [
            [
                124,
                130,
                "TERM"
            ]
        ]
    },
    {
        "text": "Nevertheless, these data do not necessarily represent a corpus stricto sensu, since they do not contain extracts of language produced naturally.",
        "entities": [
            [
                56,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most of them rely on corpus linguistic methodology, but a few, mainly on the literary side of studies, focus on individual texts or passages and their interpretations.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "Creating a new POS tagging model is often an iterative process: small samples of text are manually annotated and used as training data to create a provisional POS tagger, which then automatically annotates more texts.",
        "entities": [
            [
                19,
                26,
                "TERM"
            ],
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you enter a specific word in the search box, the interface will allow you to calculate an MI score for the node and that particular collocate, while selecting from the 'POS LIST' options will allow you to look for colligations directly.",
        "entities": [
            [
                110,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "The third type usually either specifies formatting instructions, such as line breaks, etc., contains links to external resources, such as a style sheet that specifies the layout and formatting options, or can be used to include other information that doesn't require a containing element, such as, for example, a comment on a specific piece of data.",
        "entities": [
            [
                10,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "In general, the investigation is top-down, in the sense that a question is asked of the corpus and means devised to find the answer to the question.",
        "entities": [
            [
                88,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "Allowance for an additional layer of comparisonbetween different layers of annotation -allows for an integrated and informative perspective on social cognition aspects of language.",
        "entities": [
            [
                75,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "In contrast, languages such as Java, Perl, Python, Ruby, and R have features tailored for both web and desktop environments, making them a common choice for many corpus tools.",
        "entities": [
            [
                162,
                168,
                "TERM"
            ]
        ]
    },
    {
        "text": "The remainder of this paper is organized as follows: Section 2 describes our proposal, and Section 3 contains information regarding studies based on corpus compiled with this tool, as well as the description of future lines of action.",
        "entities": [
            [
                149,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, an important aspect in constructing a query is to annotate a random sample of our corpus manual for the phenomenon we are interested in, and then to check our query against this manual annotation.",
        "entities": [
            [
                191,
                201,
                "TERM"
            ],
            [
                88,
                94,
                "TERM"
            ],
            [
                74,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "Nevertheless, there is still a lot of room left for the development of new ways to analyze datasets with a wide range of text lengths, and particularly datasets which contain extremely short texts, which are more common today than ever.",
        "entities": [
            [
                121,
                125,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, when dealing with diachronic comparisons, we need to assess whether the observed differences in frequencies are related to change in the discourse/language over time or whether these are related to other sources of variation.",
        "entities": [
            [
                31,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then, we only need to adapt the \"show_corpus\" function from Script 5 to process each file and count all the words in the corpus.",
        "entities": [
            [
                121,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although you need to register in order to use the corpus, as we mentioned in the previous chapter, access to the corpora is free of charge.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "A similar problem to the one above could also exist for the singular and plural forms of the noun guess because they look identical to the base form of the verb and the 3rd person singular present, but luckily an investigation of the data reveals that those don't actually occur in our text.",
        "entities": [
            [
                286,
                290,
                "TERM"
            ]
        ]
    },
    {
        "text": "A frequency list generated with the second approach doesn't have that problem, which is why we will go with the second approach here.",
        "entities": [
            [
                2,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Obviously, the distribution of such pairs or sets with respect to other words in a corpus can provide insights into their similarities and differences.",
        "entities": [
            [
                83,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "A type of speaker (e.g. male or female, young or old) or a type of context (e.g. syntactic position) which favours the use of a particular variant of the sociolinguistic variable.",
        "entities": [
            [
                2,
                6,
                "TERM"
            ],
            [
                59,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "As constructing the BNC was a major exercise involving the digitisation of very large amounts of text, sorting out meta-information as much as possible, and PoS tagging and annotating the data in a number of ways, the care taken in checking and correcting the final result of the tagging has, at least to some extent, been sub-optimal.",
        "entities": [
            [
                161,
                168,
                "TERM"
            ],
            [
                280,
                287,
                "TERM"
            ],
            [
                97,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "And where the corpus text is in a language that is not known to the scientific community it needs to be translated to a more widely known language.",
        "entities": [
            [
                14,
                20,
                "TERM"
            ],
            [
                21,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "The result is unambiguous: The p-value is much larger than the usual threshold value of 0.05 so we conclude that the frequencies of the two constructions in Gries's sample do not differ from a random distribution.",
        "entities": [
            [
                165,
                171,
                "TERM"
            ]
        ]
    },
    {
        "text": "The motivation was to prepare it for the linguistic analysis within the corpus.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, we should bear in mind that the usefulness of lemmatization may change significantly from language to language.",
        "entities": [
            [
                55,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "All of these programs are designed to assign various lexical tags to every word in a corpus.",
        "entities": [
            [
                85,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "Learner corpora, particularly those containing academic texts, often include instances of multilingual practices, code-switching, and borrowed content, presenting difficulties for annotation and analysis.",
        "entities": [
            [
                180,
                190,
                "TERM"
            ]
        ]
    },
    {
        "text": "Create a frequency list based on the new subcorpus, import it into a spreadsheet, and sort it as we just did in the previous exercise.",
        "entities": [
            [
                9,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if words a and b occur 1,000 and 100 times in a corpus, a will be recognized faster than b, but not 1000 / 100 =10 times as fast but maybe log 1000 / log 100 =1.5 times as fast.",
        "entities": [
            [
                61,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "Parameters include, for instance, the letter writer's gender, year of birth, occupation, rank, their father's rank, their education, religion, place of residence, any history of migration, their careers and social mobility, the general type of contents of their letters, and how well their letters can be authentified.",
        "entities": [
            [
                236,
                240,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, although diachronic comparability improves, it may still not be optimal, because genres themselves tend to be moving targets.",
        "entities": [
            [
                30,
                43,
                "TERM"
            ],
            [
                19,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "Usually a tagger is trained on a smaller hand-annotated sample and then applied (tested) on a larger corpus.",
        "entities": [
            [
                101,
                107,
                "TERM"
            ],
            [
                56,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, if we were to identify a set of 100 collocations with ð‘-values of 0.001 in a corpus, we are potentially treating all of them as important, even though it is very probable that at least one of them reached this level of significance by chance.",
        "entities": [
            [
                86,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "At the symposium presentation, there is a lack of spontaneous interaction, or immediate requests for clarification; there is no room for immediate negotiation of the text.",
        "entities": [
            [
                166,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "These data are typically not part of the corpus itself, but are listed in the metadata (see Chapter 6).",
        "entities": [
            [
                78,
                86,
                "TERM"
            ],
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "As is noted in the chapter, collecting and transcribing spoken language is one of the more labor-intensive parts of creating a corpus.",
        "entities": [
            [
                127,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "The copy-and-paste versions retrieved from Chrome (ver. 31 and above) and Safari (ver. 5 on Windows, ver. 8 on the Mac) seem to be almost identical in that they generally strip all the formatting and hyperlinks from the document and simply leave the text with a minimal degree of formatting.",
        "entities": [
            [
                250,
                254,
                "TERM"
            ]
        ]
    },
    {
        "text": "As you'll hopefully observe while doing the online exercise (and can verify again in the exercise paragraph replicated below), the computer search for our fairly common sample words managed to find this, but not This, in as a word, but also many other occurrences of the character (letter) sequence i+n (where both are lowercase characters) that you would probably not have expected to find.",
        "entities": [
            [
                169,
                175,
                "TERM"
            ]
        ]
    },
    {
        "text": "The data come from a corpus of spoken York English at the turn of the twenty-first century.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "Over the last 20 or so years, multifactorial modeling has taken much of corpus linguistics by storm.",
        "entities": [
            [
                72,
                90,
                "TERM"
            ]
        ]
    },
    {
        "text": "These methodological considerations are generally disregarded in corpus-driven studies of phraseology.",
        "entities": [
            [
                65,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the AntConc concordancer, discussed in Chapter 5, it is possible to inform the program about the existence of tags and not to consider the information they contain.",
        "entities": [
            [
                15,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, less speech is needed to reach these necessary numbers of words for the particular corpus being created.",
        "entities": [
            [
                89,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a result, corpus-driven studies of lexical phrases (both continuous and discontinuous) have shown that lexical patterning is ubiquitous in English, and basic to the discourse structure of both spoken and written texts.",
        "entities": [
            [
                13,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "We hope this textbook provides a good first foundation for corpus linguistics and generates your excitement about this large and diverse field.",
        "entities": [
            [
                59,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, the larger our corpus is (and most corpus-linguistic research requires corpora that are much larger than the four million words used here), the less feasible it becomes to do so.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ],
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, an annotation of the grammatical categories associated with each word requires establishing a list of these categories.",
        "entities": [
            [
                12,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "Exploring a corpus qualitatively allows the analyst to provide descriptive information about the results that cannot be presented strictly quantitatively.",
        "entities": [
            [
                12,
                18,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will discuss this topic in Chapter 6, which is devoted to the methodological principles underlying the construction of a corpus.",
        "entities": [
            [
                124,
                130,
                "TERM"
            ]
        ]
    },
    {
        "text": "If a word is repeated, it counts as a new token but not as a new type.",
        "entities": [
            [
                42,
                47,
                "TERM"
            ],
            [
                65,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "UDPipe uses two models that facilitate the tagging process and improve the overall accuracy by employing different classification feature sets.",
        "entities": [
            [
                43,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this is of very little help in retrieving transitive verbs even from a POS-tagged corpus, since many noun-phrases following a verb will not be direct objects (Sam slept the whole day) and direct objects do not necessarily follow their verb (Sam, I have not seen); in addition, noun phrases themselves are not trivial to retrieve.",
        "entities": [
            [
                91,
                97,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this case, we could use the MyConc class as a foundation for a more complete corpus toolkit that could be released as an open source project allowing it to be used and extended by others.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "Non-corpus-informed materials slightly outperform corpus-informed materials on two fronts: the contextualization of the examples (in 3 cases out of 4, versus 2 out of 4 for corpus-informed books) and the integration of grammar within skills (in 3 cases out of 4, versus 2 out of 4 in corpus-informed books).",
        "entities": [
            [
                4,
                10,
                "TERM"
            ],
            [
                50,
                56,
                "TERM"
            ],
            [
                173,
                179,
                "TERM"
            ],
            [
                284,
                290,
                "TERM"
            ]
        ]
    },
    {
        "text": "Large text archives, such as Lexis-Nexis 5.",
        "entities": [
            [
                6,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "We may also want to use mode and medium when referring to different types of written language found on the internet or cellular phones (such as social media posts, tweets, and text messages), which vary in grades of permanence depending on the topic and potential effect they have.",
        "entities": [
            [
                176,
                180,
                "TERM"
            ]
        ]
    },
    {
        "text": "The problem, after all, is not so much that each data point becomes less reliable if we add more annotation categories, but rather that we often do not have enough data points to obtain a truly informative picture when addressing research questions that require us to take many categories into account simultaneously.",
        "entities": [
            [
                97,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, it should specify the manner in which the corpus has been segmented into words, sentences, utterances or discourse segments.",
        "entities": [
            [
                55,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "The next fifteen columns correspond to the text categories.",
        "entities": [
            [
                43,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "But with a hypothesis stated in terms of proportions, matters are different: even if the majority or even all of the cases in our data contradict it, this does not preclude the possibility that our hypothesis is true -our data will always just constitute a sample, and there is no telling whether this sample corresponds to the totality of cases from which it was drawn.",
        "entities": [
            [
                257,
                263,
                "TERM"
            ],
            [
                302,
                308,
                "TERM"
            ]
        ]
    },
    {
        "text": "Note that in order to compare type frequencies, we have to correct for the size of the sample: all else being equal, a larger sample will contain more types than a smaller one simply because it offers more opportunities for different types to occur (a point we will return to in more detail in the next subsection).",
        "entities": [
            [
                87,
                93,
                "TERM"
            ],
            [
                126,
                132,
                "TERM"
            ],
            [
                30,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "The type of value assigned to any given variable depends on its meaning.",
        "entities": [
            [
                4,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "The difference is that the sum of squared distances is divided not by the total number of corpus parts but by the total number of corpus parts minus 1 (the reason for this is connected with the notion of 'degrees of freedom' explained in Section 6.3).",
        "entities": [
            [
                90,
                96,
                "TERM"
            ],
            [
                130,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "Recall that corpus linguistics includes both quantitative and qualitative analysis.",
        "entities": [
            [
                12,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "A study of the word (in either or both of its senses) would obviously require that we look at the lemma PAVEMENT, comprising at least the word forms pavement (singular), pavements (plural) and, depending on how the corpus is prepared, pavement's (possessive).",
        "entities": [
            [
                215,
                221,
                "TERM"
            ],
            [
                98,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "By contrast, it is more rarely found in collocation with words indicating a role, as in he played an important role in his failure, in texts destined for children than in texts for adults.",
        "entities": [
            [
                40,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "When you look at journal articles reporting on corpus linguistic studies where researchers are using multiple regression, you will see many ways to describe it.",
        "entities": [
            [
                47,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us use the adjective-noun sequence good example from the LOB corpus (but horse lovers need not fear, we will return to equine animals and their properties below).",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "The statistical significance of a correlation is directly related to the number of observations (cases).",
        "entities": [
            [
                4,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "The version of the corpus which is available free of charge online includes 1,300,000 aligned sentences or fragments, amounting to approximately 2 million words per language.",
        "entities": [
            [
                19,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "The occurrence of v. demonstrates that parts of the general subcorpus contain references to legal matters, where the type is one of the two possible abbreviations for versus (the other being vs.).",
        "entities": [
            [
                117,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even for very restricted corpora in terms of text types, like ATC corpora, variability in situational features is relevant, and so these will have to contain text specimens produced by female and male pilots of different age groups, different linguistic backgrounds, and so forth.",
        "entities": [
            [
                45,
                49,
                "TERM"
            ],
            [
                158,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, data for a study of student performance at university might include variables like personality type, degree of motivation, score on intelligence tests, scholastic record, family background, class, ethnicity, age, and health.",
        "entities": [
            [
                108,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "That being done, bilingual concordancers search directly for the occurrences of a word in one of the two languages of the corpus, and simultaneously extract the matching sentence in the other language.",
        "entities": [
            [
                122,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, although authenticity is not a demarcation criterion for corpora, spoken texts in particular should come from common text varieties as well and not be restricted to scripted or semi-scripted TV, radio, or otherwise broadcasted texts or texts elicited in experimental setups.",
        "entities": [
            [
                127,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, corpus researchers need an understanding of the issues that arise in corpus construction even if they never build any corpora of their own.",
        "entities": [
            [
                78,
                97,
                "TERM"
            ],
            [
                9,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the residence history on the biographical form is unclear, it is also possible to interview the individual afterwards, provided that he or she can be located; if the individual does not fit the criteria for inclusion, his or her text can be discarded.",
        "entities": [
            [
                232,
                236,
                "TERM"
            ]
        ]
    },
    {
        "text": "For a given lexical item, our method produces computational representations of its occurrences in the corpus and splits them into groups based on semantic similarity, prioritizing those that are expected to reflect the influence of French.",
        "entities": [
            [
                102,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "This figure represents the first 2,000 words in any given text, plus the number of words to complete a sentence started so that the text snippets included contain all complete sentences.",
        "entities": [
            [
                58,
                62,
                "TERM"
            ],
            [
                132,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "The primary idea is that we should have a general corpus that includes 'benchmarked' and 'standard' data so that we can collect information about how accepted standards are commonly used in mainstream linguistic activities.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "We carry out a more indepth analysis of two of the four research questions listed above, namely how corpus-based research applications are presented, and how (and how much) corpus-based research has been incorporated into materials.",
        "entities": [
            [
                100,
                112,
                "TERM"
            ],
            [
                173,
                185,
                "TERM"
            ]
        ]
    },
    {
        "text": "You can do your data processing, data retrieval, annotation, statistical evaluation, graphical representation . . . everything within just one environment, whereas if you wanted to do all these things in Perl or Python, you would require a huge amount of separate programming.",
        "entities": [
            [
                49,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "But this is not true for all written text, for example, text messages may be formulated fairly quickly and without much planning.",
        "entities": [
            [
                37,
                41,
                "TERM"
            ],
            [
                56,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this assignment and the next, we turn to a completely different corpus format.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "If we categorize data in terms of such a nominal variable, the only way to quantify them is to count the number of observations of each category in a given sample and express the result in absolute frequencies (i.e., raw numbers) or relative frequencies (such as percentages).",
        "entities": [
            [
                156,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the vast majority of corpus linguistic research issues, we will be dealing with designs that are at least bivariate (i.e., that involve the intersection of at least two variables), like the one discussed in the preceding section.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Options to avoid the time-consuming manual orthographic transcription are beginning to materialise: for example, it is possible to train speech-to-text software such as the one included in GoogleDocs on one's voice and then record oneself repeating the content of the raw data file.",
        "entities": [
            [
                147,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "In extralinguistic annotation, we annotate a text with that kind of information, which is not physically available inside a text.",
        "entities": [
            [
                19,
                29,
                "TERM"
            ],
            [
                45,
                49,
                "TERM"
            ],
            [
                124,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, what you've just seen on the exercise page is not only an issue in corpus linguistics, but actually represents a much more prevalent problem on the internet.",
        "entities": [
            [
                76,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "Imagine, finally, the frequency range he is currently interested in is between 35 and 40 words per million words and, as he browses the frequency list for good words to use, he comes across an adjective and a verbenormous and staining -that he thinks he can use because they both occur 37 times in the Brown corpus (and are even equally long) so he notes them down for later use and goes on.",
        "entities": [
            [
                136,
                150,
                "TERM"
            ],
            [
                308,
                314,
                "TERM"
            ]
        ]
    },
    {
        "text": "Second, when we analyse a corpus we must always be aware of dispersionlooking out for the difference, for instance, between a word that occurs 100 times in our corpus where all 100 instances are bunched close together in one text, and a word with the same 100 occurrences that are spread out across the whole corpus.",
        "entities": [
            [
                26,
                32,
                "TERM"
            ],
            [
                160,
                166,
                "TERM"
            ],
            [
                309,
                315,
                "TERM"
            ],
            [
                225,
                229,
                "TERM"
            ]
        ]
    },
    {
        "text": "But let us assume, for the moment, that the cross-section of published material read by the editors of Merriam Webster's dictionary counts as a linguistic corpus.",
        "entities": [
            [
                155,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "Frequency-based collocates are therefore fairly generic (we can expect a similar set of collocates for almost any node) and have only a limited usefulness.",
        "entities": [
            [
                114,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "A small corpus, unless designed to contain particular data, will be unhelpful in investigating the behaviour of particular infrequent words or collocations.",
        "entities": [
            [
                8,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to informative writing, the corpus contains differing types of imaginative prose, such as general fiction and science fiction.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "For some research questions, these lists can be very useful, whereas in other cases, it is necessary to resort to a real corpus containing linguistic productions in their context of use.",
        "entities": [
            [
                121,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "This first official type of markup language, however, as we'll see further below, was relatively complex and also had a number of serious drawbacks.",
        "entities": [
            [
                28,
                43,
                "TERM"
            ],
            [
                20,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, it is advisable for corpus linguists to be cognisant of such concepts and the debates surrounding them, as these are likely to colour the perception that social scientists form of corpus linguistics.",
        "entities": [
            [
                190,
                208,
                "TERM"
            ],
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "His focus is on the second hypothesis, which he tests on the LOB corpus by, first, identifying all occurrences of both verbs with both complementation patterns and, second, categorizing them according to whether the verb in the complement clause refers to an activity, a process or a state.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "I highlight some limitations of the existing tools and methods, which include for example limited support of manual categorization of concordance lines and categorization of key words.",
        "entities": [
            [
                134,
                145,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are ways to get transcriptions of spontaneous speech, but mainly from conversations broadcast on radio or television, a highly restricted type of language.",
        "entities": [
            [
                144,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "It also demonstrated that such corpus-based studies may result in very specific hypotheses about the function of lexicogrammatical structures that may become the basis for claims about mental representation.",
        "entities": [
            [
                31,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "We'll explore plain-text-based file formats, such as HTML and XML, that may contain such markup further in later sections, as well as discussing their use(fulness) for linguistic annotation/analysis.",
        "entities": [
            [
                179,
                189,
                "TERM"
            ],
            [
                89,
                95,
                "TERM"
            ],
            [
                20,
                24,
                "TERM"
            ],
            [
                62,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "As already mentioned, corpus linguistics has been criticized in relation to its suitability for the study of speech acts.",
        "entities": [
            [
                22,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a section devoted to qualitative analysis, we detail how a discourse-analytical approach, either on the basis of unannotated concordance lines or on the basis of output generated by a prior quantitative examination of the data, can help describe and, crucially, explain the observable patterns, for instance by recourse to concepts such as semantic prosody.",
        "entities": [
            [
                128,
                139,
                "TERM"
            ]
        ]
    },
    {
        "text": "If there is not enough evidence, or the evidence is biased towards, for example, a certain genre or certain types of speakers/writers (see 'diachronic representativeness' above), the patterns we observe are ambiguous.",
        "entities": [
            [
                151,
                169,
                "TERM"
            ],
            [
                140,
                150,
                "TERM"
            ]
        ]
    },
    {
        "text": "From the point of view of functional words, texts intended for children in the corpus mainly refer to the question of space, whereas the texts intended for adults focus primarily on the temporal dimension.",
        "entities": [
            [
                79,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Recall, once again, that at the end of Chapter 2, we defined corpus linguistics as the investigation of linguistic research questions that have been framed in terms of the conditional distribution of linguistic phenomena in a linguistic corpus.",
        "entities": [
            [
                61,
                79,
                "TERM"
            ],
            [
                237,
                243,
                "TERM"
            ]
        ]
    },
    {
        "text": "Imagine, for example, your data contain dates in the American-English format, with the month preceding the day (i.e., Christmas would be written as \"12/25/2016\") and you want to reverse the order of the month and the day so that your data could be merged with corpus files that already use this ordering.",
        "entities": [
            [
                260,
                266,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, it does not follow the principle of separating distinct semantic layers (such as segments vs. morpheme functions) in the annotation syntax, thus making this format harder to read, process, and convert than others.",
        "entities": [
            [
                128,
                138,
                "TERM"
            ]
        ]
    },
    {
        "text": "As mentioned above, concordance lines highlight the word you pick and provide additional text around it.",
        "entities": [
            [
                20,
                31,
                "TERM"
            ],
            [
                89,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the rest of Chapter 4, we will describe example studies from all of these levels as well as corpus studies of sign and gesture.",
        "entities": [
            [
                95,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will also discuss best practices to follow when making a manual annotation and present the different ways to assess the reliability of such annotations.",
        "entities": [
            [
                67,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Chapter 3, we implicitly treated the second issue as a problem of retrieval, noting in passing that we queried our corpus in such a way as to capture all variants of the lemma PAVEMENT.",
        "entities": [
            [
                118,
                124,
                "TERM"
            ],
            [
                173,
                178,
                "TERM"
            ]
        ]
    },
    {
        "text": "This corpus was collected and transcribed in 2012 and includes 50 interactions between registered nurses working at a US hospital and standardized patients (SPs).",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "Both approaches have their place in different kinds of corpus-based study.",
        "entities": [
            [
                55,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "As this is a kind of formatting that we'll equally want to apply to all such units, it would be cumbersome to have to type this out repeatedly, so we can take advantage of a feature of CSS that allows us to list the different elements a definition applies to by separating them from each other by a comma, just like in an ordinary written list.",
        "entities": [
            [
                118,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, in the LittÃ©racie avancÃ©e corpus, the five most frequent cooccurrences to the right of the word avis are avis sur, which appears 11 times and then avis et (six times), avis de (five times), avis divergent (four times) and avis des (three times).",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "The sample used here is the Diachronic Electronic Corpus of Tyneside English (henceforth DECTE), a collection of interviews with Tyneside English speakers that will be fully described in due course.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "If we have chosen unrepresentative data or if we have extracted or annotated our data sloppily, the statistical significance of the results is meaningless.",
        "entities": [
            [
                100,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although we all encounter a number of different file formats containing text on a daily basis while using the computer, many people generally tend not to be aware of the fact that the text contained in these files may not always be easy to process.",
        "entities": [
            [
                72,
                76,
                "TERM"
            ],
            [
                184,
                188,
                "TERM"
            ]
        ]
    },
    {
        "text": "One sub-type is a reference corpus: a general corpus taken to be a standard reference for corpus-based research on a given language.",
        "entities": [
            [
                18,
                34,
                "TERM"
            ],
            [
                90,
                102,
                "TERM"
            ],
            [
                46,
                52,
                "TERM"
            ],
            [
                8,
                12,
                "TERM"
            ]
        ]
    },
    {
        "text": "After this initial exploration, to answer the research question about the prominent topics in British public discourse we need to look at the weather terms in the context of other words (lemmas) in the corpus.",
        "entities": [
            [
                202,
                208,
                "TERM"
            ]
        ]
    },
    {
        "text": "Spoken language does not generally have the same type of planning and opportunities for revision that we find in many types of written language.",
        "entities": [
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, for a question-answering system, some of the typical features (or functions) involve the recognition of a linguistic expression as a question, analysis of the type of the question, understanding the syntactic structure of a question, capturing meaning embedded into it, recognizing the sentiment hidden in the question, searching out an appropriate document that may carry an answer, extraction of the answer from a document, evaluation of the answer before responding, and finally generating the answer either in text or speech mode.",
        "entities": [
            [
                527,
                531,
                "TERM"
            ],
            [
                172,
                176,
                "TERM"
            ]
        ]
    },
    {
        "text": "When the probability level is very low (p <.001), we can feel confident that we are not committing a Type 1 error described above, and that our sample group of students differs from other groups who may have taken the test in the past or who might take it in the future (population).",
        "entities": [
            [
                144,
                150,
                "TERM"
            ]
        ]
    },
    {
        "text": "They annotated 2,986 attestations captured as concordance lines for 14 variables that were previously shown to impact native speakers' choices, including the semantic relation encoded by the noun phrases, the morphological number marking on the noun phrases, their animacy, specificity, complexity, and, crucially, the L1 background of the learners, among others.",
        "entities": [
            [
                46,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this argument ignores the fact that, before any annotation is finished, it repeatedly, and often for very long periods of time, needs to be read and edited by humans, so that readability does indeed represent an issue in annotation.",
        "entities": [
            [
                57,
                67,
                "TERM"
            ],
            [
                230,
                240,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to study one of these areas specifically, it is preferable to resort to a specialized corpus.",
        "entities": [
            [
                95,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, the Universal Dependencies project is managed entirely on GitHub, including publicly available data in multiple languages and the use of GitHub pages and issue trackers for annotation guidelines and discussion.",
        "entities": [
            [
                186,
                196,
                "TERM"
            ]
        ]
    },
    {
        "text": "Using COCA and the Brown corpus, find collocates for duckling (only in COCA) and farmer.",
        "entities": [
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to protect the privacy of tweet authors, we only reproduce textual content without any metadata.",
        "entities": [
            [
                96,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "Lesser-studied languages typically lack these things, and here corpus linguistics often means to build corpora in the first instance, and these corpora will then often be relatively small, which then comes with various restrictions as to their usability in research.",
        "entities": [
            [
                63,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "This assumption requires reflection on what is meant by corpus representativeness.",
        "entities": [
            [
                63,
                81,
                "TERM"
            ],
            [
                56,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "A second portion of the corpus focuses on advanced learners who have all lived in France, for a period ranging from 1-2 years to more than 30 years (see Chapter 3, section 3.3 for a study based on these data).",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will now show that this approach continues to perform strongly when the data is taken from a corpus of specialized language and is annotated at finer levels of granularity (i.e. with more and subtler sense distinctions).",
        "entities": [
            [
                96,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "Two major types of pre-treatment can be distinguished, i.e. automatic annotation and sampling.",
        "entities": [
            [
                70,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "Letters, for instance, have several advantages as a source of historical text material.",
        "entities": [
            [
                73,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "These tools have been developed for simplifying searches within a corpus.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter focuses on the process of creating and annotating a corpus.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "As I generally use (more or less) the same text in the <title> tag of my pages, this effectively duplicates the text of the heading inside the saved text version.",
        "entities": [
            [
                43,
                47,
                "TERM"
            ],
            [
                112,
                116,
                "TERM"
            ],
            [
                149,
                153,
                "TERM"
            ]
        ]
    },
    {
        "text": "We then passed from the concordance to close reading of the co-text around occurrences of Mubarak, a very common process in corpus-assisted discourse studies.",
        "entities": [
            [
                24,
                35,
                "TERM"
            ],
            [
                124,
                130,
                "TERM"
            ],
            [
                63,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "The standard deviation is an indicator of the amount of variation in a sample (or sub-sample) that is frequently reported; it is good practice to report standard deviations whenever we report means.",
        "entities": [
            [
                71,
                77,
                "TERM"
            ],
            [
                86,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have discussed diachronic comparisons, but the parameters and entities to be compared can be various.",
        "entities": [
            [
                18,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "A novice student of linguistics could be excused for believing that corpus linguistics evolved in the past few decades, as a reaction against the dominant practice of intuition-based linguistics in the 1960s and 1970s.",
        "entities": [
            [
                68,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, studies based on such corpora must be regarded as falling somewhere between corpus linguistics and psycholinguistics and they must therefore meet the design criteria of both corpus linguistic and psycholinguistic research designs.",
        "entities": [
            [
                82,
                100,
                "TERM"
            ],
            [
                180,
                186,
                "TERM"
            ]
        ]
    },
    {
        "text": "This might eventually become a problem with a corpus, including thousands of different files.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "The 63 interviews that comprise the DECTE corpus differ substantially in length and so, consequently, do the phonetic transcriptions of them.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "Like the SBC, a corpus created with ELAN will have two components, namely, a set of media files with the raw audio and/or audio-visual data and a corresponding set of ELAN document files (a special kind of XML file).",
        "entities": [
            [
                16,
                22,
                "TERM"
            ],
            [
                206,
                209,
                "TERM"
            ]
        ]
    },
    {
        "text": "Again, the example of bogus refugees is cited in this text in order to be critical of it, arguing that such representations do not help to support genuine refugees, although the speaker still makes a distinction between genuine and bogus refugees.",
        "entities": [
            [
                54,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us test this hypothesis using the Corpus of Historical American English, which includes language from the early nineteenth to the very early twenty-first century -in a large part of the corpus, the twentieth century was thus entirely or partly in the future.",
        "entities": [
            [
                190,
                196,
                "TERM"
            ]
        ]
    },
    {
        "text": "We showed how we can do a corpus-based study with already identified language features, whether doing a lexical study or searching for the use of particular grammatical patterns.",
        "entities": [
            [
                26,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is especially important not to look at just the beginning of a concordance, as these early concordance lines may present examples from the early part of the corpus, which is not necessarily representative of the corpus as a whole.",
        "entities": [
            [
                66,
                77,
                "TERM"
            ],
            [
                94,
                105,
                "TERM"
            ],
            [
                160,
                166,
                "TERM"
            ],
            [
                215,
                221,
                "TERM"
            ]
        ]
    },
    {
        "text": "A reference corpus cannot in any sense represent the language, unless it is subdivided into text categories or subcorpora representing a broad range of registers, as in the BNC or the Bank of English.",
        "entities": [
            [
                2,
                18,
                "TERM"
            ],
            [
                92,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most corpora use Standard Generalized Markup Language (SGML), Text Encoding Initiative (TEI), or Extensible Markup Language (XML) to have a unified structural markup system.",
        "entities": [
            [
                159,
                165,
                "TERM"
            ],
            [
                125,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "While an increasing number of corpus compilers are eager to make their spoken corpora available to the research community, technological and ethical difficulties have to be met as discussed below.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "Both words occur frequently in the PP [through NP], sometimes preceded by a verb of seeing, which is not surprising given that they refer to a type of window.",
        "entities": [
            [
                143,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given this structure, the transcriptions entered in ELAN exhibit explicitly marked up structure in the XML output that can then be imported into other platforms and also is further analysed based on a more common vertical format, as will be shown shortly below.",
        "entities": [
            [
                103,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "Next, the predictions must be tested -in the case of corpus linguistics, corpora must be selected and data must be retrieved and annotated, something we will discuss in detail in the next chapter.",
        "entities": [
            [
                53,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "Adding an option for this will then provide us with an improved solution for the regex, \\b(((assum|believ|guess|suppos|think)(e?[ds]? |ing)?)|thought)\\b, increasing the number of hits to 414, and indicating the importance of the past tense form of think in the text.",
        "entities": [
            [
                261,
                265,
                "TERM"
            ]
        ]
    },
    {
        "text": "This practicality consideration may lead to creating a corpus that overrepresents easily obtainable texts.",
        "entities": [
            [
                55,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, for meaning (3), the Nouveau Petit Robert mentioned \"a woman's companion\", whereas the corpus showed that this use also extends to homosexual couples.",
        "entities": [
            [
                100,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, it severely complicates the study of certain types of research questions that rely on POS annotation, as will become apparent below.",
        "entities": [
            [
                99,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus amounts to approximately 100,000 words but only part is publicly available.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "As in all corpus-linguistic studies, research can be conducted with the \"top-down\" method that takes a linguistic feature or grammatical category as its point of departure; this is the deductive method.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although corpus-based studies of language structure can look back on a tradition of at least a hundred years, there is no general agreement as to what exactly constitutes corpus linguistics.",
        "entities": [
            [
                171,
                189,
                "TERM"
            ],
            [
                9,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, an explanatory variable can be the genre/register or date of publication of a text as well as speaker's age, gender and language proficiency, to name only a few.",
        "entities": [
            [
                92,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "In summary, in addition to being based on corpora with high comparability, contrastive studies should use neutral points of comparison that make it possible to establish comparisons between linguistic phenomena across languages, which are as relevant and adequate as possible.",
        "entities": [
            [
                60,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "In practice, some corpus tools let us set the minimum cut-off limits for the frequencies of words in C and R before considering them in the keyword procedure.",
        "entities": [
            [
                140,
                147,
                "TERM"
            ],
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpus linguistics (and the social sciences more generally), hypotheses of this type are the exception rather than the norm -we are more likely to deal with statements about tendencies (think Most swans are white or Most examples of windscreen are British English), where the search for counterexamples is not a viable research strategy.",
        "entities": [
            [
                3,
                21,
                "TERM"
            ],
            [
                83,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "This written form is what we treat as the corpus text since this is what can be searched and further annotated.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ],
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "The young speakers included in the corpus should proportionally represent the two genders and have different socio-economic profiles.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "Corpus linguistics takes real samples that are used to generalise about language, and corpus-based typology helps us to confirm (or confront the idea) that these assumptions are applicable for a more diverse sample.",
        "entities": [
            [
                86,
                98,
                "TERM"
            ],
            [
                208,
                214,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, in terms of research focus, we would hope the future would bring more discourse-level studies with a focus on text and associated features of genre, stance, etc., to complement the current dominance of studies on lexis and specific grammar points.",
        "entities": [
            [
                220,
                225,
                "TERM"
            ],
            [
                117,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "Both of these have their individual sections for restrictions further down the page, to allow you to narrow down your choices, based on domain information for the context-governed type, and age, social class, and sex of respondents -not the speakers, whose characteristics can be selected separately -for the demographically sampled data.",
        "entities": [
            [
                180,
                184,
                "TERM"
            ]
        ]
    },
    {
        "text": "Sometimes Sample the sample is carefully collected based on pre-defined criteria.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, the corpus-linguistic identification of keywords is analogous to the identification of differential collocates, except that it analyses the association of a word W to a particular text (or collection of texts) T in comparison to the language as a whole (as represented by the reference corpus, which is typically a large, balanced corpus).",
        "entities": [
            [
                292,
                308,
                "TERM"
            ],
            [
                20,
                26,
                "TERM"
            ],
            [
                347,
                353,
                "TERM"
            ],
            [
                196,
                200,
                "TERM"
            ]
        ]
    },
    {
        "text": "Indeed, it is no exaggeration to say that corpus linguistics using large computer-readable language data has established itself as the main methodology in historical pragmatics.",
        "entities": [
            [
                42,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "Interpretative information is classified into two types: (i) intralinguistic information, which is linked with linguistic features and properties of a text, and (ii) extralinguistic information, which is related to information not linked with linguistic properties and features of a text.",
        "entities": [
            [
                151,
                155,
                "TERM"
            ],
            [
                283,
                287,
                "TERM"
            ]
        ]
    },
    {
        "text": "First and overall, frequency and association data were found to be reliable predictors of learners' knowledge of collocation.",
        "entities": [
            [
                113,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "Examples include translations from EU Parliament debates into the 23 languages of the European Union, or the Canadian Hansard corpus, containing Canadian Parliament debates in English and French.",
        "entities": [
            [
                126,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "It also includes a much broader range of written text categories than previous corpora, including not just edited writing but also student writing and letters.",
        "entities": [
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this chapter, we focus on how to write the 'Methods' and 'Results' sections of a quantitative corpus linguistic paper since the 'Introduction' and 'Discussion' sections are so phenomenon-dependent that, apart from the general guidelines above, they defy easy discipline-specific characterization.",
        "entities": [
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "Below is an example concordance from COCA of adjective + woman, showing the first five lines.",
        "entities": [
            [
                20,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "If relevant, this section should also specify which version of the corpus and what types of annotations available with the corpus were used to answer the research questions.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ],
            [
                123,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the case of a spoken corpus in particular, it is essential for participants to know that they are being recorded and that their data will later be used for linguistic analyses.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each provides a different type of information about a distribution of values.",
        "entities": [
            [
                26,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Instead, spoken samples in this corpus consist entirely of transcriptions of numerous radio and television programs that were created by a thirdparty.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, while the newer lists should be lauded for their more careful compilation and choice of lemma over word family for its superior discrimination of different senses of meaning, perhaps a way forward is to explore the lexicon beyond single orthographic words, to aim instead for the lexeme over the lemma.",
        "entities": [
            [
                104,
                109,
                "TERM"
            ],
            [
                312,
                317,
                "TERM"
            ]
        ]
    },
    {
        "text": "These corpora certainly have their uses, but they push the definition of a linguistic corpus in the sense discussed above to their limit.",
        "entities": [
            [
                86,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "Longitudinal corpora imply regular recordings over at least several months, transcriptions of each utterance (ideally not only of the target child, but of all interlocutors), and a multitude of different annotation levels, depending on the questions of the respective project.",
        "entities": [
            [
                204,
                214,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, it must not be misunderstood to suggest that studying the distribution of linguistic phenomena is an end in itself in corpus linguistics.",
        "entities": [
            [
                125,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "Consequently, corpus linguists are very skeptical of the highly abstract and decontextualized discussions of language promoted by generative grammarians, largely because such discussions are too far removed from actual language usage.",
        "entities": [
            [
                14,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, the time saved in using second-party transcripts is worth the tolerance of a certain level of error, provided that some checking is done to ensure overall accuracy in the transcripts included in a corpus.",
        "entities": [
            [
                208,
                214,
                "TERM"
            ]
        ]
    },
    {
        "text": "A 15-word sample (91 clusters) was annotated by two annotators in order to test the reliability of the general procedure, obtaining a reasonably high interannotator agreement (Cohen's kappa coefficient of 0.55).",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "The keyword that we are searching for here and now is \"say\".",
        "entities": [
            [
                4,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "Try this with at least one of the downloaded HTML files and its corresponding text version.",
        "entities": [
            [
                78,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "Video recordings also allow us to document sign languages; see Chapter 4.3 for some details on their corpus-based investigation.",
        "entities": [
            [
                101,
                113,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have emphasized that frequency is not the only indicator of the prevalence of a word in a corpus and that its dispersion across the different portions of the corpus is also very important.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ],
            [
                161,
                167,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let's say we have a small corpus of Matukar Panau 4 that has been parsed and glossed.",
        "entities": [
            [
                26,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "Their application tends to be in areas other than linguistics research but where language, texts, or documents are key sources, e.g. for political text analysis or other social science research questions.",
        "entities": [
            [
                147,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "For a number of research questions, this type of information is crucial, for example, when it comes to determining the meaning of a derived word.",
        "entities": [
            [
                41,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can extend Script 3 in a different way to process an entire corpus.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Chapter 6, we discussed the importance of associating metadata with corpus files.",
        "entities": [
            [
                57,
                65,
                "TERM"
            ],
            [
                71,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "This involves manually annotating samples of corpus text as examples of how the new annotation categories should be assigned.",
        "entities": [
            [
                84,
                94,
                "TERM"
            ],
            [
                45,
                51,
                "TERM"
            ],
            [
                52,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "But there are caveats to the process of creating a corpus outlined in this section.",
        "entities": [
            [
                51,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "Using these operationalizations for the purposes of the case studies in this chapter, I retrieved and annotated a one-percent sample of each construction (the constructions are so frequent that even one percent leaves us with 222 sand 178 of -possessives (the full data set for the studies presented in this and the following two subsections can be found in the Supplementary Online Material, file HKD3).",
        "entities": [
            [
                126,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each observation (i.e., each text with each normed count) will be in a different row.",
        "entities": [
            [
                29,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "This software can be downloaded for free and used for converting any number of XML, HTML or sometimes even PDF files into text format.",
        "entities": [
            [
                122,
                126,
                "TERM"
            ],
            [
                79,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this study, we have presented UMUCor-pusClassifier, a NLP tool that assists in the compilation and annotation of linguistic corpus.",
        "entities": [
            [
                102,
                112,
                "TERM"
            ],
            [
                127,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus can be queried online.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once you're finished, you can just load the resulting file in AntConc instead of the original corpus, and filter out or sort the relevant entries in another concordance.",
        "entities": [
            [
                157,
                168,
                "TERM"
            ],
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "We believe that the applications of bootstrapping in corpus linguistics we have discussed in the previous four sections are just a beginning for corpus linguistics.",
        "entities": [
            [
                53,
                71,
                "TERM"
            ],
            [
                145,
                163,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Notepad++, you can also specify the default encoding for any files you create under 'Settingsâ†’Preferencesâ†’New Document', where I'd recommend you set the option for 'UTF-8 without BOM', as well as use the additional setting 'Apply to opened ANSI files'.",
        "entities": [
            [
                47,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, privacy rights require corpus compilers to anonymise the disseminated data (cf. Chap. 1): while this is easily achieved in the transcriptions, where references to people and places can be removed, complete anonymization in audio files, i.e. the changing of the voice quality, would run counter and make impossible many research purposes of the corpus.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ],
            [
                354,
                360,
                "TERM"
            ]
        ]
    },
    {
        "text": "Header elements may for instance be the page title (contained in the <title>â€¦</title> tag, where the forward slash indicates the end of the tag in the closing part), which then appears in the title bar of your browser, or possibly meta-information (<meta>â€¦</meta>), such as the text (content) type or encoding/character set (charset), as well as style (sheet) information/references (<style>â€¦</style> or <link rel=\"stylesheet\" href=\"./corpus.css\" type=\"text/css\" />, in our case) responsible for some of the page formatting.",
        "entities": [
            [
                301,
                309,
                "TERM"
            ],
            [
                435,
                441,
                "TERM"
            ],
            [
                278,
                282,
                "TERM"
            ],
            [
                453,
                457,
                "TERM"
            ],
            [
                293,
                297,
                "TERM"
            ],
            [
                447,
                451,
                "TERM"
            ]
        ]
    },
    {
        "text": "Many corpus linguists come from a tradition that has provided them with ample background in linguistic theory and the techniques of linguistic description but little experience of statistics.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "But despite the difference in length, each corpus contains many of the same registers, such as fiction, press reportage, and academic writing.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are still some artifacts of corpus construction: the codes F and J are used in BROWN to indicate that letter combinations and formulae have been removed.",
        "entities": [
            [
                34,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to information on collocation and frequency, a corpus will also allow us to examine the extent to which certain types of prescriptive rules are followed.",
        "entities": [
            [
                30,
                41,
                "TERM"
            ],
            [
                59,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "In 2008, Meunier and Gouverneur stated that publishers seem to acknowledge the importance of corpora in ELT but fail to give precise information on how exactly the corpus is used.",
        "entities": [
            [
                164,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "Stubbs does not present the results of his procedure in detail and the corpus he uses is not accessible anyway, so let us use the BNC again and extract our own data.",
        "entities": [
            [
                71,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "Besides, it is also necessary to determine which metadata will be associated with each corpus sample.",
        "entities": [
            [
                49,
                57,
                "TERM"
            ],
            [
                87,
                93,
                "TERM"
            ],
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "Exclusivity refers to a specific aspect of the collocation relationship where words occur only or predominantly in each other's company.",
        "entities": [
            [
                47,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter is dedicated entirely to the discussion of collocation.",
        "entities": [
            [
                56,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "Include part-of-speech (PoS) filters to find the most common adjective and determiner w-1 and the most common verb and noun w+1 in each corpus.",
        "entities": [
            [
                136,
                142,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, usage conventions may vary considerably between languages even when the same text genre exists in both, which makes them difficult to compare.",
        "entities": [
            [
                90,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, we might see the end most often at the end of a corpus of children's stories and rarely at the beginning or in the middle of the texts in that corpus.",
        "entities": [
            [
                62,
                68,
                "TERM"
            ],
            [
                157,
                163,
                "TERM"
            ]
        ]
    },
    {
        "text": "I've chosen extracts from these three particular texts and period for a number of reasons: a) their authors all died more than 70 years ago so the texts are in the public domain; in other words, there are no copyright issues, even when quoting longer passages; b) they are included in corpus compilations; and c) they not only illustrate register/genre differences but also how the conventions for these may change over time, as can be seen, for example, in the spelling of to-day in the final extract.",
        "entities": [
            [
                285,
                291,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Chapter 3 (see Sections 3.2 and 3.4), we have seen contingency tables that were constructed for collocation and keyword analyses to show all possibilities (contingencies) of word (co)occurrence.",
        "entities": [
            [
                99,
                110,
                "TERM"
            ],
            [
                115,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, corpus tools can be applied to individual texts, in helping decide whether a text is appropriate and what elements to focus on.",
        "entities": [
            [
                7,
                13,
                "TERM"
            ],
            [
                84,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "The next section explores in greater detail the differences between qualitative and quantitative corpus analyses.",
        "entities": [
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is important to note that the chapters on mixed effects regression modeling and generalized additive mixed models in particular are primarily meant for readers to get a grasp of what these techniques are (more and more corpus linguistic papers rely on such methods and it is important for corpus linguists to understand the current literature).",
        "entities": [
            [
                222,
                228,
                "TERM"
            ],
            [
                292,
                298,
                "TERM"
            ]
        ]
    },
    {
        "text": "The idea is that a larger number of different word forms (types) relative to the number of all words in text (tokens) points to a lexically more varied text.",
        "entities": [
            [
                104,
                108,
                "TERM"
            ],
            [
                152,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are various ways of processing (e.g., data analytics, concordance, collocation, keyword marking, local-word-grouping, lexical clustering, lemmatization, morphological processing, sentence processing, and named entity marking), which are applied to a corpus with appropriate technological supports.",
        "entities": [
            [
                144,
                157,
                "TERM"
            ],
            [
                60,
                71,
                "TERM"
            ],
            [
                73,
                84,
                "TERM"
            ],
            [
                86,
                93,
                "TERM"
            ],
            [
                256,
                262,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to investigate whether iconicity of sequence influences the positioning of English adverbial clauses, Diessel retrieved 600 complex sentences with the conjunctions when, after, before, once, and until from the ICE-GB corpus.",
        "entities": [
            [
                226,
                232,
                "TERM"
            ]
        ]
    },
    {
        "text": "They confirmed that some of the meanings frequently found in the corpus could not be adequately translated by their \"equivalent\".",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "Annotated concordance data enable the researcher to perform statistical analyses over hundreds or thousands of data points, identifying distributional patterns that might otherwise escape the researcher's attention.",
        "entities": [
            [
                10,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "A completely different response to the issue of comparability is to create singlegenre diachronic corpora that cover relatively short time spans and draw their data from a single historical source.",
        "entities": [
            [
                48,
                61,
                "TERM"
            ],
            [
                87,
                97,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the case of adjectives, their lemma is by convention the singular masculine form.",
        "entities": [
            [
                33,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, Sketch Engine provides the option to search by lemma or by grammatical category.",
        "entities": [
            [
                60,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to promote and make better use of corpus enrichment, there is a need for collaborative work between linguists with a deep knowledge of the needs to different areas such as Second Language Acquisition or Historical Linguistics and experts in Computational Linguistics or Natural Language Processing.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "The early tagging systems of the Brown and LOB corpora made no provision for discourse markers.",
        "entities": [
            [
                10,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Above all, it is fundamental that any child recorded in the corpus has been diagnosed with ASD according to the diagnostic tests recognized in the literature, rather than following the mere indication of the pediatrician.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "A news writing corpus would need to include the various types of news textssports and lifestyle news as well as state, local, national, and international news.",
        "entities": [
            [
                15,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some readers might also notice the unusual onomatopoeic word gloink in text B and words related to the war in Iraq (Bush, Iraq, terrorism, war etc.) in text A.",
        "entities": [
            [
                71,
                75,
                "TERM"
            ],
            [
                152,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "In situations like these, it is possible to train some kinds of annotation software to apply new tagging conventions to your corpus sources.",
        "entities": [
            [
                64,
                74,
                "TERM"
            ],
            [
                97,
                104,
                "TERM"
            ],
            [
                125,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "Section 4.5 discusses how corpus analyses can be quantitative, qualitative, or a combination of the two (sometimes termed mixed methods).",
        "entities": [
            [
                26,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "The problem we have with encodings is one of a similar nature, only that in this case it doesn't have anything to do with proprietary formats, but rather the way that individual characters are physically represented inside the computer, which is as a special type of number.",
        "entities": [
            [
                259,
                263,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, ICE uses two more tags relevant to the present discussion: <foreign> (for a \"word or sequence of words that is foreign and non-naturalised\") and <indig> (marking words which are \"non-English but are indigenous to the country in which the corpus is being compiled\").",
        "entities": [
            [
                251,
                257,
                "TERM"
            ]
        ]
    },
    {
        "text": "After that, ideally you choose \"Unicode (UTF-8)\" as the character set, \"{Tab}\" as the field delimiter and, usually, delete the text delimiter.",
        "entities": [
            [
                127,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "The mean rates for nouns drawn from every possible sample of size n that can be drawn from the population constitute the sampling distribution for this parameter.",
        "entities": [
            [
                51,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "Ru Â¨hlemann uses frequency counts to demonstrate the importance of laughter to conversation, for example, if \"between-speech laughter\" is considered as a linguistic item in and of itself, it would be placed in 29th position on the BNC conversational subcorpus frequency list.",
        "entities": [
            [
                260,
                274,
                "TERM"
            ]
        ]
    },
    {
        "text": "The verb lemma also influences the probability of either variant being used.",
        "entities": [
            [
                9,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "For this type of case, the use of a syntactically annotated corpus becomes compulsory.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ],
            [
                9,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the case of corpora containing texts as well as their translation, certain tools called aligners make it possible to align the content of the corpus sentence by sentence.",
        "entities": [
            [
                145,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "Becoming involved in a corpus creation project individually is realistic only in the case of specialized corpora, for example, if the task is narrowed to a specific language register or a regional variety, that is, a project of a smaller size.",
        "entities": [
            [
                23,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "Annotations of paralinguistic or linguistic features in a corpus impact its authenticity in complex ways.",
        "entities": [
            [
                58,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, the answers to both our research questions (Is corpus use effective for L2 learners -i.e. does it have a demonstrable effect? Is corpus use efficient for L2 learners -i.e. compared to other forms of learning?) are clearly Yes and Yes, based on the studies available to date.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ],
            [
                145,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the latter case, you won't need to re-run the concordance, but can simply click anywhere in the hits to remove all selections, although you'll still need to select the ones you want again.",
        "entities": [
            [
                49,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "Something similar, albeit not to signal a parenthetical but instead some kind of pseudo-punctuation, happens again for \"Yes-or\" a little further down in the text.",
        "entities": [
            [
                157,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "Development of a speech corpus involves issues and factors like purpose of use, selection of speakers, choice of settings, size of a corpus, use of recording instruments, manner of data sampling, manner of data elicitation, nature of transcription, types of data encoding, management of audio files, editing of input data, processing of spoken texts, annotation of speech, analysis of speech corpus, etc.",
        "entities": [
            [
                351,
                361,
                "TERM"
            ],
            [
                263,
                271,
                "TERM"
            ],
            [
                24,
                30,
                "TERM"
            ],
            [
                133,
                139,
                "TERM"
            ],
            [
                392,
                398,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, a semantic annotation of verb types could differentiate their aspect (state or event verbs).",
        "entities": [
            [
                20,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "When we call them 4-grams, it does not matter how often they occur in a corpus; they are still called 4-grams.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "This may not seem like a great nuisance to you but, before you go on reading, look at the last word and think about in what way this may be problematic for further corpus-linguistic application.",
        "entities": [
            [
                164,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "When the crawl is eventually complete, several other steps are usually carried out to 'clean up' the downloaded web documents before they are added to a corpus.",
        "entities": [
            [
                153,
                159,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is a visualisation of where a word or collocate occurs in a corpus.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "These are reasonable arguments, but if possible, it seems a good idea to complement any analysis done with Google Books with an analysis of a more rigorously constructed balanced corpus.",
        "entities": [
            [
                179,
                185,
                "TERM"
            ]
        ]
    },
    {
        "text": "Experimenting with the options should allow you to find that BNCweb also lets you list the PoS categories that collocate with the node by selecting 'collocations on POS-tags' next to 'Information'.",
        "entities": [
            [
                130,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, some semantic aspects are part of the typologically oriented annotation systems, and we will outline these in 7.3.",
        "entities": [
            [
                71,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "They finished and released their corpus, the Brown Corpus of edited written English \"for use with digital computers,\" in 1964, before Quirk (concentrating on detailed spoken transcription) had completed as much as a quarter of his.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "This problem arises somewhat differently in the case of judicial inquiries, in particular because of the type of linguistic material involved.",
        "entities": [
            [
                105,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "In being clear about what makes corpus linguistics distinct and what it has to offer, the role of corpus linguistics as offering one further methodological tool in the researcher's toolbox in the social sciences Corpus linguistics and social sciences will be easier to make, and the engagement of corpus linguistics with the social sciences will be more easily facilitated.",
        "entities": [
            [
                32,
                50,
                "TERM"
            ],
            [
                98,
                116,
                "TERM"
            ],
            [
                297,
                315,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, in light of the above discussion of representativeness, there is little reason to believe that any of these corpora, or the many others that fall somewhere between BROWN and ICE, even come close to approximating a random sample of (a given variety of) English in terms of the text categories they contain and the proportions with which they are represented.",
        "entities": [
            [
                45,
                63,
                "TERM"
            ],
            [
                230,
                236,
                "TERM"
            ],
            [
                285,
                289,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another study could aim to compare these uses across different speech styles, which should then be represented in the corpus in a balanced manner.",
        "entities": [
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "At the end of the corpus, Anne produced 230 word types against 182 for Max, which tends to confirm that her language was more advanced.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "Using your own corpus, you should be able to do KWIC searches through the concordance lines, and other types of lexical as much as grammatical analyses in your own texts.",
        "entities": [
            [
                74,
                85,
                "TERM"
            ],
            [
                15,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "Go through the above sample paragraph and make a list of how many elements there are and which type they belong to.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ],
            [
                95,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "Our first examples concerned problems related to part-of-speech annotation, and these challenges are hard to overcome entirely.",
        "entities": [
            [
                64,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the most general terms, our plea here is one for informed use of diachronic resources.",
        "entities": [
            [
                68,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "Words marked with the color blue are among the top 500 most frequently occurring words in the corpus.",
        "entities": [
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moving beyond the sample, 95% confidence intervals can be calculated.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "Occasionally, people refer to such collections as error corpora, but we will not use the term corpus for these.",
        "entities": [
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us further limit our sample to cases where both nouns are monosyllabic, as it is known from the existing research literature that length and stress patterns have a strong influence on the order of binomials.",
        "entities": [
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unlike in older forms of HTML, where case did not matter, XML is case sensitive, so that linguistic tags like <turn>, <Turn> & <TURN> for representing individual speaker turns in dialogues are all treated as being different from one another.",
        "entities": [
            [
                58,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this does not necessarily mean that the text must be excluded from the corpus, since there is annotation that can be included in a corpus indicating that certain sections of a sample are \"extra-corpus\" material; that is, material not considered part of the corpus for purposes of word counts, generating KWIC (key word in context), and so forth.",
        "entities": [
            [
                319,
                338,
                "TERM"
            ],
            [
                103,
                113,
                "TERM"
            ],
            [
                80,
                86,
                "TERM"
            ],
            [
                140,
                146,
                "TERM"
            ],
            [
                203,
                209,
                "TERM"
            ],
            [
                266,
                272,
                "TERM"
            ],
            [
                185,
                191,
                "TERM"
            ],
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, the category question could be defined as follows for an annotation of speech acts: \"Any utterance used in context as a request for information, whether a direct or indirect one\".",
        "entities": [
            [
                70,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "Rather, they should explain what they want, e.g. an ordered list of important words in the corpus.",
        "entities": [
            [
                91,
                97,
                "TERM"
            ]
        ]
    },
    {
        "text": "The model outputs multiple vector representations per token, each corresponding to a different hidden layer in the neural network architecture.",
        "entities": [
            [
                54,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Helsinki Corpus, which was to be published in 1991, would revolutionize the historical research of English for decades to come, and its importance for historical corpus linguistics cannot be overstated.",
        "entities": [
            [
                166,
                184,
                "TERM"
            ]
        ]
    },
    {
        "text": "Those compiling spoken corpora should therefore expect to gather much more speech than they will actually use to compensate for all the recordings they make that contain imperfections preventing their use in the ultimate corpus being created.",
        "entities": [
            [
                221,
                227,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is connected to a so-called 'whelk problem' (see Section 2.4) when some infrequent lexical items become dramatically overrepresented in the corpus.",
        "entities": [
            [
                145,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the period coverage of a study is considerable and a great deal of societal or politico-cultural change has affected language users during that time, it is likely that registers will have gained new features and conventions, developed into other registers, been replaced by new registers, or fallen into oblivion; such shifts affect the comparability of period samples.",
        "entities": [
            [
                340,
                353,
                "TERM"
            ]
        ]
    },
    {
        "text": "The last step consists of merging the frequency list files: We generate an empty table first, and then use another for-loop to load each frequency list file and merge them into one long table (with c).",
        "entities": [
            [
                38,
                52,
                "TERM"
            ],
            [
                137,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most phenomena that are of interest to linguists (and thus, to corpus linguists) require operational definitions that are more heavily dependent on interpretation.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the same vein, it's also important to understand that once we actually have extracted some relevant data from a corpus, this is rarely ever the 'final product'.",
        "entities": [
            [
                115,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "In summary, in addition to frequency indications, it is important to provide information about lexical dispersion in a corpus, either by simply calculating the percentage of texts in which a word is used, or by reporting a dispersion measurement, such as the deviation of proportions we have just described.",
        "entities": [
            [
                119,
                125,
                "TERM"
            ]
        ]
    },
    {
        "text": "A concept that is intrinsically related to representativeness is balance, which has to do with the proportions of the different samples included in the corpus.",
        "entities": [
            [
                43,
                61,
                "TERM"
            ],
            [
                65,
                72,
                "TERM"
            ],
            [
                152,
                158,
                "TERM"
            ]
        ]
    },
    {
        "text": "The reason that a carefully selected range of genres is not important in this corpus is that the corpus is not intended to permit genre studies but to, for instance, \"train\" taggers and parsers to analyze English: to present them with a sufficient amount of data so that they can \"learn\" the structure of numerous constructions and thus produce a more accurate analysis of the parts of speech and syntactic structures present in English.",
        "entities": [
            [
                78,
                84,
                "TERM"
            ],
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "Also, researchers can use ASCII files in parsers, concordance programs, and taggers.",
        "entities": [
            [
                50,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "The data considered here are drawn from the corpus of 116 individual studies described in the previous section.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "With new corpora containing billions of words and allowing complex searches by making use of various search functions and different types of linguistic anno-tation, novice corpus users may find it difficult to question the relevance of their search results adequately and carefully.",
        "entities": [
            [
                172,
                178,
                "TERM"
            ]
        ]
    },
    {
        "text": "One point that is made in the chapters is that fewer letters written by women are in the corpus than letters written by men.",
        "entities": [
            [
                89,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "A rhetorically developed text differs in choice of words, order of words, sentence structure, grammatical form, sense implication, and reference.",
        "entities": [
            [
                25,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "Speech act studies represent function-to-form mapping, which is more difficult to deal with than the form-to-functions direction of fit with corpus-linguistic methods.",
        "entities": [
            [
                141,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us take a look at an utterance from the York corpus (De Cat and Plunkett 2002): *CHI:tu me l'as donnÃ©.",
        "entities": [
            [
                49,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "Lexical tagging is crucial because it will enable the factor analysis program to determine where the various parts of speech occur: e.g. first person pronouns in more interactive texts; passive verbs in more informational texts.",
        "entities": [
            [
                8,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "Recall that the observed median animacy in our sample was 1 for the spossessive and 5 for the of -possessive, which deviates from the prediction of the H 0 in the direction of our H 1 .",
        "entities": [
            [
                47,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "It expresses the probability of the sample data being observed if the null hypothesis were true in the population.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the second, we can then construct one or more appropriate search patterns that'll allow us to create concordances that illustrate which word classes co-occur with which type of construction.",
        "entities": [
            [
                172,
                176,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you need to convert webtext, i.e., from html to text, follow the steps on this website: www.computerhope.com/issues/ch001877.htm#text.",
        "entities": [
            [
                51,
                55,
                "TERM"
            ],
            [
                132,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "McIntyre and Walker (2010) built a corpus of 200,000 words from blockbuster film scripts.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "This portion of the corpus comprises a longitudinal section, where each learner has produced four texts.",
        "entities": [
            [
                20,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "To find out what the current working directory is, type getwd() in the code editor and run the code.",
        "entities": [
            [
                51,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "Digital humanities scholars cite the work of Roberto Busa working with IBM in 1949, who produced his Index Thomisticus, a computer-generated concordance to the writings of Thomas Aquinas.",
        "entities": [
            [
                141,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "At the same time, corpus linguistic studies show that very frequent clusters (more commonly referred to as \"lexical bundles\") are associated with discourse functions and so become important textual building blocks.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "Among the highest-ranking nouns of this type is lifespan, followed by words such as database, policeman and classroom.",
        "entities": [
            [
                40,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "An alternative explanation for the emergence of the introductory references of corpus linguistics would be because the period was the optimal time for establishing corpus linguistics as a part of linguistics after a \"hodgepodge\" multi-directional development of corpus linguistics.",
        "entities": [
            [
                79,
                97,
                "TERM"
            ],
            [
                164,
                182,
                "TERM"
            ],
            [
                262,
                280,
                "TERM"
            ]
        ]
    },
    {
        "text": "But one issue that has not been discussed so far concerns the linguistic backgrounds of those whose speech or writing has been included in a corpus.",
        "entities": [
            [
                141,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this degree of power does come at a cost: In the beginning, it is undoubtedly more difficult to do things with R than with ready-made (free or commercial) concordancing software that has been written specifically for corpus-linguistic applications.",
        "entities": [
            [
                226,
                232,
                "TERM"
            ]
        ]
    },
    {
        "text": "A further feature desirable from a scientific point of view may be modifiability or manipulability, that is, we may want to offer the opportunity to add further texts to the corpus as appropriate in given research contexts or to modify the corpus composition in other ways (e.g. by removing some texts, etc.).",
        "entities": [
            [
                174,
                180,
                "TERM"
            ],
            [
                240,
                246,
                "TERM"
            ]
        ]
    },
    {
        "text": "Like semantic tagging, automated parsing has a much higher error rate than POS tagging, because the task is inherently more difficult.",
        "entities": [
            [
                14,
                21,
                "TERM"
            ],
            [
                79,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "The expected proportions are calculated by taking one-by-one the sizes of the corpus parts (number of tokens) and dividing them by the total number of tokens in the corpus; this is to establish their proportional contribution to the overall size of the corpus.",
        "entities": [
            [
                78,
                84,
                "TERM"
            ],
            [
                165,
                171,
                "TERM"
            ],
            [
                253,
                259,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most forms of traditional non-corpus-assisted discourse analysis have practiced the close-reading (that is, \"qualitative analysis\") of single texts or a small number of texts in the attempt to highlight both textual structures and also how meanings are conveyed.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, a general corpus of newspaper editorials would have to cover all the different types of editorials that exist, such as oped pieces and editorials produced by an editorial board.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "As is obvious, when the sample is increased by one order of magnitude, so is the chi-squared value.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "This annotation makes it possible to exclusively look for the noun occurrences of ferme, for example.",
        "entities": [
            [
                5,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "If, say for various reasons related to copyright, it is not possible to make the complete set of corpus files available to others, the corpus could still be made searchable online and concordance lines from the corpus be shown.",
        "entities": [
            [
                184,
                195,
                "TERM"
            ],
            [
                97,
                103,
                "TERM"
            ],
            [
                135,
                141,
                "TERM"
            ],
            [
                211,
                217,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is no alternative to knowing your corpora, this cannot be done more easily, and any concordance programs that come with more refined search options also require you to thoroughly consider the format of the corpus files even if their interface 'hides' such decisions behind clickable buttons with smiling corpus linguists on them, in settings, or in .ini files.",
        "entities": [
            [
                90,
                101,
                "TERM"
            ],
            [
                212,
                218,
                "TERM"
            ],
            [
                310,
                316,
                "TERM"
            ]
        ]
    },
    {
        "text": "The most ambitious pre-electronic corpus, the Quirk Corpus, served as a model for the modern-day electronic corpus.",
        "entities": [
            [
                34,
                40,
                "TERM"
            ],
            [
                108,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "This type of information is not a part of the text analysis but it can provide important interpretive information used in the functional analysis of your results.",
        "entities": [
            [
                46,
                50,
                "TERM"
            ],
            [
                5,
                9,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now that you have a basic idea regarding the formats and encodings a text might come in, and the issues involved in being able to work with them, we can move on to finding out how we can obtain our own texts for analysis purposes.",
        "entities": [
            [
                69,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, we show that cross-validated results also allow us to employ a powerful model comparison method that helps us determine which methods are worth deploying in future automatic annotation settings.",
        "entities": [
            [
                183,
                193,
                "TERM"
            ]
        ]
    },
    {
        "text": "Altering the span of the window around the node word where possible collocate words are considered can also significantly affect the results.",
        "entities": [
            [
                43,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter provides you with an opportunity to use readily available corpora to conduct corpus linguistics projects.",
        "entities": [
            [
                90,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus that has probably been the subject of the greatest number of studies of social dialect variation is the BNC, which is coded for a variety of demographic information, including age, gender, education level, and class.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "Conversely, the type nonattachment illustrates the prefixation of a bipartite ment-type, resulting in a right-branching structure.",
        "entities": [
            [
                16,
                20,
                "TERM"
            ],
            [
                83,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, we can easily rank speakers in a sample of university graduates based on the highest degree they have completed.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "Further exclusion criteria are needed for the purposes of a meta-analysis of this type; in particular, only experimental or quasi-experimental studies with a pre/post-test or a treatment/control group design, or both, can provide appropriate comparative data.",
        "entities": [
            [
                82,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "The presence of proper nouns in the keyword lists is very frequent because these words often specifically refer to a particular person, which is not used equally in different corpora.",
        "entities": [
            [
                36,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Our analyses rely on a particular type of linguistic data -a large, custombuilt corpus of tweets -as well as a recent computational approach to modeling lexical semantic phenomena -neural word embeddings.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ],
            [
                34,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you don't use the 'Paste Specialâ€¦' option, which in Calc even triggers the text import wizard, you'll end up with frequency values that the spreadsheet cannot interpret as numbers because they still contain some (hidden) HTML formatting.",
        "entities": [
            [
                78,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is obviously not immediately comparable to corpus sizes given in word tokens since time length does not relate directly to text size: texts may differ in the amount and length of pausing and the speech rate of speakers, so that texts of similar duration in time may exhibit very different numbers of wordform tokens.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ],
            [
                128,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this case, the quality of the automatic annotation is measured in comparison with a reference annotation produced by human annotators.",
        "entities": [
            [
                43,
                53,
                "TERM"
            ],
            [
                97,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, there are 36 types that occur only in the prose sample (for example, churchmanship, dreamership, librarianship and swordsmanship) and 12 that occur only in the newspaper sample (for example, associateship, draughtsmanship, trusteeship and sportsmanship).",
        "entities": [
            [
                61,
                67,
                "TERM"
            ],
            [
                183,
                189,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a corpus of spoken dialogues, for instance, it is necessary to include tags that identify who is speaking or which sections of speaker turns contain overlapping speech.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "Nevertheless, there are disadvantages to the corpus-based approach as well.",
        "entities": [
            [
                45,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "Sinclair's pioneering corpus work was first put into practice lexicographically in the Collins COBUILD English Language Dictionary (CCELD), a monolingual dictionary for learners of English published in 1987.",
        "entities": [
            [
                22,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "From the design properties of corpora and their texts, we move to the actual use of diachronic corpora for research.",
        "entities": [
            [
                84,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "The query will capture interrogatives, imperatives, subordinate clauses and other contexts that cannot contain tag questions, so let us draw a sample of 100 hits from both samples and determine how many of the hits are in fact declarative sentences with positive polarity that could (or do) contain a tag question.",
        "entities": [
            [
                143,
                149,
                "TERM"
            ]
        ]
    },
    {
        "text": "When creating a spoken corpus, one also needs to think about whether an orthographic representation of the text will be sufficient, whether the corpus should be represented in phonetic transcription, or whether it should support annotation on various different levels (see Chapter 11).",
        "entities": [
            [
                229,
                239,
                "TERM"
            ],
            [
                23,
                29,
                "TERM"
            ],
            [
                144,
                150,
                "TERM"
            ],
            [
                107,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "While the purpose of the analysis of texts may vary between corpus linguistics and studies interested in style, the methods, however, can still be similar.",
        "entities": [
            [
                60,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, the corpus should contain young speakers recorded under similar conditions in order to avoid any context-related bias.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "The marriage of corpus linguistics and social science seems, initially, straightforward.",
        "entities": [
            [
                16,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Brown family consists of 15 genre-based categories according to which the total of 500 2,000-word text samples are selected.",
        "entities": [
            [
                102,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "First of all, the 1 in Construction 1+Lemma+Givenness is R's way of encoding the fact that an intercept is part of the model.",
        "entities": [
            [
                68,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a section devoted to quantitative analysis, we discuss how concordance lines can be scrutinized for various properties of the search term and annotated accordingly.",
        "entities": [
            [
                62,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because the sentences included in the corpus were taken from news stories, the sentences did occur in a natural communicative setting.",
        "entities": [
            [
                38,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, much of the statistics we see for corpus linguistic data are multivariate rather than univariate as in Section 8.3.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "A drawback of this approach is that the 1988 model is dated; text messages, e-mails, and blogs are undoubtedly common registers for today's students, but they are not included in the model.",
        "entities": [
            [
                61,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, rather than focussing on the quantity of data in a corpus, it is always sensible to emphasize varieties of data.",
        "entities": [
            [
                62,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "This type of regression has subtypes such as logistic or multinomial and this distinction has to do with the distribution of the data and the type of DV, whether it is numeric or 2-way categorical or 2+-way categorical among other possibilities.",
        "entities": [
            [
                5,
                9,
                "TERM"
            ],
            [
                142,
                146,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, if you call up the concordances for these, you'll soon find out that they represent the initial parts of the negative contractions can't, won't, and shan't, which have been separated from the negation 'clitics' in the tagging process and are being treated as individual tokens.",
        "entities": [
            [
                227,
                234,
                "TERM"
            ]
        ]
    },
    {
        "text": "Very often, the authors of a corpus provide a bibliographic reference where they describe their corpus or the name of the team who compiled it.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ],
            [
                96,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "We begin with a very simple example: We want to determine the collocation strength of the collocation alphabetical order in the BNC but, for now, in a very simplistic way.",
        "entities": [
            [
                62,
                73,
                "TERM"
            ],
            [
                90,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "A corpus is a principled collection of language data taken from real-life contexts.",
        "entities": [
            [
                2,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "After that I will reflect on the current state of the art in corpus tools and methods.",
        "entities": [
            [
                61,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "CEA, on the other hand, provided the opportunity to ponder on the notion of error and introduce a higher degree of standardization at each level of the error analysis process: from error identification to error interpretation through error annotation and counting methods.",
        "entities": [
            [
                240,
                250,
                "TERM"
            ]
        ]
    },
    {
        "text": "In modern spoken corpora in general, a wealth of paralinguistic information is tagged, such as coughing or door slamming, much of which is of little importance; however, some of these features, such as laughter, are of significance to corpus pragmatics.",
        "entities": [
            [
                235,
                241,
                "TERM"
            ]
        ]
    },
    {
        "text": "Crucially, it would cover a procedure in which the linguistic corpus essentially serves as a giant citation file, that the researcher scours, more or less systematically, for examples of a given linguistic phenomenon.",
        "entities": [
            [
                62,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "Equally, it would be of great benefit to the research community if the metadata for already existing spoken corpora could still be made available, for example for some of the older ICE corpora.",
        "entities": [
            [
                71,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to study the distribution and prevalence of this type of structure in the French spoken in Parisian suburbs, all the occurrences of indirect questions were collected in a small oral corpus of approximately 350,000 words.",
        "entities": [
            [
                191,
                197,
                "TERM"
            ],
            [
                58,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "The reason for this is that relative frequency is used not only to compare frequencies of a particular type in two (or more) corpora, but it is also used to present evidence about the frequency of words and phrases in a form that is easier for a reader to grasp than the absolute frequency would be.",
        "entities": [
            [
                103,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "The idea of such a concordance arrangement predates the computer by quite a significant margin and scholars have in the past created concordances by hand for significant texts such as the Qur'an and the Bible.",
        "entities": [
            [
                19,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "The key to this is in the two words \"easily identifiable\" because whatever codes you may insert in your file, those shouldn't easily be confused/confusable with any regular text.",
        "entities": [
            [
                173,
                177,
                "TERM"
            ]
        ]
    },
    {
        "text": "Remember, however, that lexical category information will be contained in the PoS tagging that we have discussed above in its original Brown version, so that, for example, the NP-embedded PP would be fully annotated as in (7.8) (note that the separator in Penn tagging is forward slash / rather than underscore _): These searches will thus give us a count of NPs with and without recursive structures, that is, where an NP occurs embedded in a higher-order NP either as an initial possessor NP or as the complement of a preposition of an NP-embedded PP.",
        "entities": [
            [
                82,
                89,
                "TERM"
            ],
            [
                261,
                268,
                "TERM"
            ]
        ]
    },
    {
        "text": "We know that the maximum value of CV depends on the number of corpus parts and can be calculated as ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi no: of corpus parts Ã€ 1 p .",
        "entities": [
            [
                62,
                68,
                "TERM"
            ],
            [
                247,
                253,
                "TERM"
            ]
        ]
    },
    {
        "text": "Again, corpus linguistics is a uniquely useful tool to investigate this.",
        "entities": [
            [
                7,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "The introduction of a corpus in language study adds a new dimension to linguistics.",
        "entities": [
            [
                22,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the next major section (Chapters 5-10), we then investigated various techniques for analysing language data using established methods of corpus linguistics.",
        "entities": [
            [
                140,
                158,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to this, if we want to be able to exchange documents efficiently, we also need to develop a basic understanding of how exactly text may be represented on the computer, which is what we'll do next.",
        "entities": [
            [
                139,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, a \"draft\" directory is useful for early stages of corpus development and can contain spoken texts that are in the process of being transcribed or written texts that have been computerized but not proofread.",
        "entities": [
            [
                64,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another reason for why the number of tokens has risen here is that the hyphen in fact appears to be ill-defined; as in most instances in this particular type of data, it isn't actually a true hyphen as it would appear in hyphenated words or at the end of a line that has been hyphenated, which would not occur in this type of data, anyway.",
        "entities": [
            [
                153,
                157,
                "TERM"
            ],
            [
                318,
                322,
                "TERM"
            ]
        ]
    },
    {
        "text": "The second important question concerns the size of the sample that will be included in the corpus.",
        "entities": [
            [
                91,
                97,
                "TERM"
            ],
            [
                55,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you want to conduct research with this corpus, you have to go to the University of Oslo to reach the corpus.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ],
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first of these is the one you have already seen, a text form in natural human language.",
        "entities": [
            [
                55,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "In some cases, the abundance of metadata requires the use of a precise syntax for tags, based on the conventions of computer languages for XML or SGML coding.",
        "entities": [
            [
                32,
                40,
                "TERM"
            ],
            [
                139,
                142,
                "TERM"
            ]
        ]
    },
    {
        "text": "Different corpora follow different procedures here; for example, the Brown corpus follows the space-delimiter as we have done, counting aren't etc. as single tokens whereas the COCA treats such forms as two tokens (which means that in COCA you have to search for a two-word expression are n't in order to find instances of aren't).",
        "entities": [
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, I shall briefly comment on the underutilized notion of dispersion, that is, a measure that quantifies how evenly distributed elements are in a corpus, and thus also relates to the notion of corpus homogeneity.",
        "entities": [
            [
                156,
                162,
                "TERM"
            ],
            [
                203,
                209,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, since all texts in a normal-sized corpus are rarely close enough to each other in length, as a typical workaround, the ratio is calculated for a set number of words (such as 400 words) taken from the beginning of each text.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ],
            [
                227,
                231,
                "TERM"
            ]
        ]
    },
    {
        "text": "Likewise, the topics men and women talk about (identified from the keywords of the corpus) also differ.",
        "entities": [
            [
                83,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, if we are dealing with a variable that is likely to be of general interest, we should consider the possibility of annotating the corpus itself, instead of first extracting the relevant data to a raw data table and annotating them afterwards.",
        "entities": [
            [
                135,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "Actually, TED Talks are always made in English; as a result, English is the only source language, contrary to the Europarl corpus, where all languages are alternately source and target.",
        "entities": [
            [
                123,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "In practice, more specialised annotation is restricted to special corpora created for specific research purposes, but some larger corpora fall into these particular categories; for instance, COCA is a tagged corpus.",
        "entities": [
            [
                30,
                40,
                "TERM"
            ],
            [
                208,
                214,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, sidewalk is normally spelled as an uninterrupted sequence of the character S or s followed by the characters i, d, e, w, a, l and k, or as an uninterrupted sequence of the characters S, I, D, E, W, A, L and K, so (assuming that the corpus does not contain hyphens inserted at the end of a line when breaking the word across lines), there are just three orthographic forms; also, the word always has the same meaning.",
        "entities": [
            [
                245,
                251,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this balance needs to be redressed and projects such as the Role Play Learner Corpus and the Louvain International Database of Spoken English Interlanguage are particularly welcome.",
        "entities": [
            [
                14,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, it is more likely that a word will occur in 6 out of 10 corpus parts than for that same word to occur in 600 out of 1000 corpus parts.",
        "entities": [
            [
                69,
                75,
                "TERM"
            ],
            [
                134,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you are using the corpus for educational purposes and do not plan on selling the corpus or any information that would result from an analysis of the corpus (e.g., in publications), the likelihood of being prosecuted as a copyright violator is usually small.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ],
            [
                84,
                90,
                "TERM"
            ],
            [
                152,
                158,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each of these properties should then be mirrored by the corpus sample proportionally to its prevalence in the population.",
        "entities": [
            [
                56,
                62,
                "TERM"
            ],
            [
                63,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "At the same time, however, given that documentations target languages that are not known to a wider scientific community, a greater minimum of annotation is key for documentation corpora, as will be discussed further in 10.3 (cf. Chapter 7 on annotations for requirements on annotations and their added value).",
        "entities": [
            [
                143,
                153,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, since an item like at first has a frequency of over 5,000 in the corpus, line-by-line searching was not a viable option.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, we have seen that corpora can be very diverse in nature, depending on whether they are made up once and for all or incremental, general or specialized, annotated or not, monolingual or multilingual, synchronous or diachronic.",
        "entities": [
            [
                223,
                233,
                "TERM"
            ]
        ]
    },
    {
        "text": "These corpora were individually compared with a larger reference corpus representing a spectrum of current published work in applied linguistics and in the same genres as the target texts.",
        "entities": [
            [
                55,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have highlighted tools and techniques that are already used in corpus linguistics that can be considered as visualisation: concordances, concgrams, collocate clouds, and described new methods of collocational networks and exploratory language analysis in social networks.",
        "entities": [
            [
                66,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each word in the COCA corpus is classified into frequency bands.",
        "entities": [
            [
                22,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "It relates to the relative proportions of different types of data within a corpus.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "These collocations make perfect sense in view of the search terms used for creating the corpus.",
        "entities": [
            [
                88,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "Since these text segments are uneven in length (one is 157 words long and the other is 241 words long), we had to scale the raw frequency counts as if both texts were 100 words long.",
        "entities": [
            [
                12,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Alternatively, we may apply selective sampling methods that are used in the Brown Corpus and the LOB corpus or consider more suitable methods of text representation keeping in mind the goal and purpose of a corpus.",
        "entities": [
            [
                101,
                107,
                "TERM"
            ],
            [
                207,
                213,
                "TERM"
            ],
            [
                145,
                149,
                "TERM"
            ]
        ]
    },
    {
        "text": "A more complex parallel design is used by Ã˜veras (1998), who searches for shifts in cohesion/coherence in the English-Norwegian Parallel Corpus, a bidirectional corpus including STs in English and their Norwegian TTs and (comparable) STs in Norwegian and their English TTs.",
        "entities": [
            [
                161,
                167,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the first type, we solely extracted the contextualized embeddings of the target words, and used them as the only features for training traditional off-the-shelf classification algorithms.",
        "entities": [
            [
                13,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Longman Grammar of Spoken and Written English (1999) by Biber et al. can be taken as an example to illustrate how the corpus is used.",
        "entities": [
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "To be representative, a spoken French corpus should include speakers from different regions, different ages, both male and female.",
        "entities": [
            [
                38,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "Corpus annotation involves enormous amounts of work.",
        "entities": [
            [
                7,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Both word tokens and word types are identified based on the form of a word (external appearance, if you like). To identify lemmas and lexemes, we first need to perform linguistic analysis of the text; lemmas are based on grammatical (morphological) analysis, while lexemes are based on both grammatical and semantic analysis.",
        "entities": [
            [
                195,
                199,
                "TERM"
            ]
        ]
    },
    {
        "text": "It has been argued that an explanation for cooccurrence of lexeme and structure may sometimes be found in the more extensive co-text.",
        "entities": [
            [
                128,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "The TTR values are as follows: 0.36 (text 1), 0.33 (text 2) and 0.39 (text 3).",
        "entities": [
            [
                37,
                41,
                "TERM"
            ],
            [
                52,
                56,
                "TERM"
            ],
            [
                70,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the ICE Project, such incomplete utterances are given an orthographic spelling that best reflects the pronunciation of the incompletely uttered word, and then the incomplete utterance is enclosed in markup, <.> i </.>, that labels the expression as an instance of an incomplete word.",
        "entities": [
            [
                202,
                208,
                "TERM"
            ]
        ]
    },
    {
        "text": "Often, one uses the letters L and R (for 'left' and 'right') together with a number indicating the position of one collocate with respect to the main/node word to talk about collocations.",
        "entities": [
            [
                150,
                154,
                "TERM"
            ]
        ]
    },
    {
        "text": "She concludes that, in both translation directions, explicitating shifts (i.e. cases in which co-textually recoverable ST material is made explicit in the TT, e.g. when ellipsis in the ST is replaced by a noun in the TT) are more common than implicitating ones (in which an explicit ST item is rendered by one that relies more on the co-text for reader interpretation, e.g. when a lexical word in the ST is translated as a proform in the TT).",
        "entities": [
            [
                337,
                341,
                "TERM"
            ]
        ]
    },
    {
        "text": "In short, the goal of the second edition of English Corpus Linguistics is to provide a comprehensive description of all aspects of corpus linguistics, ranging from how to build a corpus to how to analyze a finished corpus.",
        "entities": [
            [
                131,
                149,
                "TERM"
            ],
            [
                179,
                185,
                "TERM"
            ],
            [
                215,
                221,
                "TERM"
            ]
        ]
    },
    {
        "text": "This would allow the teacher to tailor future lessons to the needs of the students as the corpus would help highlight any common or frequent errors and, hopefully, aid in discovering in why this type of error was made.",
        "entities": [
            [
                90,
                96,
                "TERM"
            ],
            [
                195,
                199,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, corpus linguists have actually uncovered a number of relationships between words and linguistic phenomena beyond lexicon and grammar without making use of such annotations.",
        "entities": [
            [
                9,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because all statistical tests make assumptions about types of data (they are quite picky), it is necessary to decide which type the data at hand most closely correspond to, in order to choose the most appropriate test.",
        "entities": [
            [
                123,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "Following this brief introduction, Section 2 explores the state of the art in collocation research, on the basis of which Section 3 presents a cross-linguistic study of the collocational behavior and semantic prosodies of a group of near synonyms in English and Chinese.",
        "entities": [
            [
                78,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "Furthermore, instead of revealing interesting combinations of content words, you'll often find more grammatical constructions or combinations of function + content words, especially if the corpus is not very homogeneous, as in our case.",
        "entities": [
            [
                189,
                195,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is done to establish how much proportionally each part of the corpus contributes to the overall frequency of the word or phrase.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "Using a relatively inexpensive piece of software called a concordancing program, the lexicographer can go through the stages of dictionary production described above, and instead of spending hours and weeks obtaining information on words, can obtain this information automatically from a computerized corpus.",
        "entities": [
            [
                301,
                307,
                "TERM"
            ]
        ]
    },
    {
        "text": "Of course, the issue of genre balance also affects smaller diachronic corpora like the Helsinki Corpus, because some genres may disappear and new ones appear over time, and compromises must be made in the compilation process in terms of representativeness vs. diachronic comparability.",
        "entities": [
            [
                237,
                255,
                "TERM"
            ],
            [
                271,
                284,
                "TERM"
            ],
            [
                59,
                69,
                "TERM"
            ],
            [
                260,
                270,
                "TERM"
            ],
            [
                30,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us repeat the study with the BROWN corpus.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "Concordance lines and short language samples (e.g., fewer than 25 words) are preferable over larger stretches of text.",
        "entities": [
            [
                113,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "Above, we mostly looked at retrieving the data values of our XML data, but of course we want to also use the often detailed annotation that is within the tags.",
        "entities": [
            [
                124,
                134,
                "TERM"
            ],
            [
                61,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "By resorting to many different speakers and including them in reference corpora of speakers coming from different geographical areas, corpus linguistics makes it possible to respond to this problem in a much more satisfactory way.",
        "entities": [
            [
                134,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "Users of the corpus will therefore be able to study the development over time of both individual words as well as a variety of different syntactic structures.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "The work produced by such researchers often aligns much more strongly with naturalism than corpus linguistics does.",
        "entities": [
            [
                91,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, the AntConc concordancer that we discuss can only process text format files (or files with XML or HTML tags which can also be treated as text files).",
        "entities": [
            [
                25,
                37,
                "TERM"
            ],
            [
                71,
                75,
                "TERM"
            ],
            [
                150,
                154,
                "TERM"
            ],
            [
                104,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "The goals of the CHECL are to complement, but not duplicate, the coverage of existing textbooks and handbooks on corpus linguistics.",
        "entities": [
            [
                113,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have to be comfortable with the application of modern toolkits on corpus as such devices help us execute many useful tasks on a corpus.",
        "entities": [
            [
                69,
                75,
                "TERM"
            ],
            [
                131,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "An important notion in corpus linguistics is that of context.",
        "entities": [
            [
                23,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "Definition (Final Version) Corpus linguistics is the investigation of linguistic research questions that have been framed in terms of the conditional distribution of linguistic phenomena in a linguistic corpus.",
        "entities": [
            [
                203,
                209,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we recalled above, it is not always optimal to include entire texts in a corpus when these are very long.",
        "entities": [
            [
                76,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "This raises the question as to why corpus creators go to the trouble of attempting to create representative corpora at all, and why some corpora seem to be more successful attempts than others.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "Few researchers would now claim that the web is a corpus in any meaningful sense, but the web as corpus approach can still be fruitful for certain kinds of research and it is particularly useful for introducing newcomers to the field.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ],
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "These issues are especially problematic given the otherwise positive trend that corpus-linguistic data and methods are now informing linguistic theorizing more than they have for a long time.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have selected one particular framework to guide the students in their interpretation of their corpus findings.",
        "entities": [
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the one hand, the possibility of representing language electronically rather than as visual marks on paper, together with the development of electronic media, infrastructure, and computational tools for creation, emendation, storage, and transmission of electronic text have led to a rapid increase in the number and size of corpora available to the linguist, and these are now at or beyond the limit of what an individual researcher can efficiently use in the traditional way.",
        "entities": [
            [
                268,
                272,
                "TERM"
            ]
        ]
    },
    {
        "text": "The pattern of cited publications also suggests that corpus linguistics has been specialized and branched out.",
        "entities": [
            [
                53,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this case, a series of linguistic indicators are used for measuring the formal similarities between this text and other reference works by different possible authors.",
        "entities": [
            [
                108,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "Obviously there are some problems with this approach due to the format of the data that will be retrieved, which often includes other types of information apart from the main text, but we'll deal with these issues only partially now, and explore the remaining options a little later.",
        "entities": [
            [
                175,
                179,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, as pointed out above, many (if not most) hypotheses in corpus linguistics do not take the form of universal statements (\"All X's are Y\", \"Z's always do Y\", etc.), but in terms of tendencies or preferences (\"X's tend to be Y\", \"Z's prefer Y\", etc.).",
        "entities": [
            [
                64,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us look at one more example of the type/token distinction before we move on.",
        "entities": [
            [
                44,
                49,
                "TERM"
            ],
            [
                39,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "With parametric tests, like the Two-Way ANOVA, we can generalize to the population that the sample was drawn from.",
        "entities": [
            [
                92,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "As corpus grammar provides frequency information, it can hardly be ignored that different subcorpora yield very different frequency profiles associated with their communicative functions -above all, in the contrast between speech and writing.",
        "entities": [
            [
                3,
                9,
                "TERM"
            ]
        ]
    },
    {
        "text": "These files would be immediately ready for inclusion in a specialised corpus for both individual classes and a group of classes.",
        "entities": [
            [
                70,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "The development of corpus linguistics has led to the creation of new methods for collecting and analyzing linguistic data, which were made possible thanks to the development of computers and the arrival of the Internet.",
        "entities": [
            [
                19,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "Yet, their inclusion in the corpus does serve the community' s interest.",
        "entities": [
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "To a large extent, these are reasons why the corpus-based approach is not more popular in dialectology and sociolinguistics today.",
        "entities": [
            [
                45,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "Why we might need such special programs for displaying the text is because we often want to be able to render it with special types of formatting, such as italics, boldface, etc., use a particular layout, or that we want to be able to generate a table of contents automatically in a word-processing application, where this is based on the headings inside the document.",
        "entities": [
            [
                59,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "As in the case of contrastive studies, translation studies has benefited from the availability of multilingual corpora, as well as theoretical and methodological advances in corpus linguistics.",
        "entities": [
            [
                174,
                192,
                "TERM"
            ]
        ]
    },
    {
        "text": "While word-class annotation is very well established in corpus linguistics, there are other types of annotation as well.",
        "entities": [
            [
                56,
                74,
                "TERM"
            ],
            [
                17,
                27,
                "TERM"
            ],
            [
                101,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "The results of searches can also help in establishing trends in a corpus.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "The annotations are called 'tags' because they are appended to corpus words, as shown in example (7.5) from the Brown corpus.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ],
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "With written texts, if two line breaks are inserted between paragraphs while a text is being computerized, then paragraph tags can be inserted automatically at a later stage.",
        "entities": [
            [
                79,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "The underlying theoretical idea of corpus linguistics is quite broad.",
        "entities": [
            [
                35,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "In these cases, the most common operationalization strategy found in corpus linguistics is reference to a dictionary or lexical database.",
        "entities": [
            [
                69,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "The other form is its 'translation' into a statistical form in mathematical language, which brings me to the issue of operationalization, the process of deciding how the variables in your text hypotheses shall be investigated.",
        "entities": [
            [
                188,
                192,
                "TERM"
            ]
        ]
    },
    {
        "text": "From both perspectives the underlying assumption is that repeated occurrences of sequences of words reflect their functional relevance in a specific text or a register more generally.",
        "entities": [
            [
                149,
                153,
                "TERM"
            ]
        ]
    },
    {
        "text": "This corpus was created for the study of grammatical variation in dialects rather than phonetic/phonological variation.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "In all cases, it is necessary to study the rights of use indicated by the respective sites before starting to compile the corpus.",
        "entities": [
            [
                122,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "While creative (or imaginative) writing was the most common type of writing in the BNC, in the ICE it is not as prominent.",
        "entities": [
            [
                60,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, at the same time, this narrow corpus-methodological focus makes it possible to systematically complement the quantitative findings with a detailed qualitative analysis.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "In register studies, as we saw in the previous chapters, contextual differences refer to differences in particular aspects of the situational characteristics in the construction and production of a given text.",
        "entities": [
            [
                204,
                208,
                "TERM"
            ]
        ]
    },
    {
        "text": "This both makes it easier to type in the speaker of an utterance during transcription and largely anonymizes the data (given that the metadata are stored in a different file).",
        "entities": [
            [
                134,
                142,
                "TERM"
            ],
            [
                29,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "A straightforward approach is to simply split a text into chunks of a certain number of words.",
        "entities": [
            [
                48,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "In most cases, the observed data in a sample provides the best possible insight into the population parameters.",
        "entities": [
            [
                38,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "The previous sections have discussed several methodological issues that need to be considered as one plans and creates a corpus.",
        "entities": [
            [
                121,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus it's generally advisable to first check any output of a frequency list produced by some program to see whether it may exhibit any unusual features that could influence the analysis negatively.",
        "entities": [
            [
                61,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "A 'sample' is a subset of the population that we want to study.",
        "entities": [
            [
                3,
                9,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the simplest case (which we 4.1 Retrieval assumed to hold in the examples discussed in the previous chapter), a corpus will contain plain text in a standard orthography and the software will be able to find passages matching a specific string of characters.",
        "entities": [
            [
                115,
                121,
                "TERM"
            ],
            [
                141,
                145,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are several projects gathering very large corpora on a broader range of web-accessible text.",
        "entities": [
            [
                93,
                97,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, one current issue for the study of phraseology in corpus linguistics concerns the best methods to be used for the identification of the most important lexical phrases in a corpus.",
        "entities": [
            [
                63,
                81,
                "TERM"
            ],
            [
                185,
                191,
                "TERM"
            ]
        ]
    },
    {
        "text": "Of course, a corpus of the size of the BNC cannot be easily analyzed without the use of some kind of specialized software to be able to observe patterns using all the data contained in it.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, the first reference corpora (such as the Brown corpus developed for American English in the early 1960s) were about this size.",
        "entities": [
            [
                61,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is why corpora such as the Santa Barbara Corpus of Spoken American English, which is approximately 249,000 words in length, required a team of transcribers to create the corpus.",
        "entities": [
            [
                175,
                181,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the present example with an untagged corpus, for example, there is no additional pattern that seems in any way promising.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "While a raw corpus is a highly useful resource, annotation provides an extra layer of information, which can be counted, sorted, and compared.",
        "entities": [
            [
                48,
                58,
                "TERM"
            ],
            [
                12,
                18,
                "TERM"
            ]
        ]
    },
    {
        "text": "The authors then manually classified 50 occurrences of each connective found in the spoken and written modes as either objective or subjective, that is, a total of 200 occurrences, randomly chosen from the corpus.",
        "entities": [
            [
                206,
                212,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to studying the distribution of word categories, such as nouns or prepositions, Biber (1993: 250) calculated the frequency with which new words are added to a sample as the number of words in the sample increases.",
        "entities": [
            [
                171,
                177,
                "TERM"
            ],
            [
                208,
                214,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the basis of this study and of a previous analysis of newspaper language, Laviosa proposes four \"core patterns of lexical use\" potentially applying to translated English in general, namely that: Translated texts have a relatively lower percentage of content words versus grammatical words (i.e. their lexical density is lower); the proportion of high frequency words versus low frequency words is relatively higher in translated texts; the list head of a corpus of translated texts accounts for a larger area of the corpus (i.e. the most frequent words are repeated more often); The list head of translated texts contains fewer lemmas.",
        "entities": [
            [
                458,
                464,
                "TERM"
            ],
            [
                519,
                525,
                "TERM"
            ]
        ]
    },
    {
        "text": "Clearly, it is, for all intents and purposes, impossible to include this variation in its entirety in a given corpus.",
        "entities": [
            [
                110,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, one of the occurrences of the word colline (hill) in the Le Monde corpus (year 2012) is \"Sur la colline, tout le monde est allÃ© voter\" (On the hill, everyone went voting).",
        "entities": [
            [
                79,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Added to this is a layer of inadvertent 'noise' created along the way as a corpus text travels from historical manuscript or print to digital edition.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ],
            [
                82,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now we use a computer to collect language data of any size, type, and variety; classify them, process them, analyze them, and utilize them in various works.",
        "entities": [
            [
                60,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "Part III, then, is organized in terms of the range of varieties that have been studied from a corpus perspective.",
        "entities": [
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, we can categorize a sample of speakers by their age and then calculate the mean age of our sample.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ],
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to the preprocessing decisions applied to the original corpus, we introduced additional filtering for the experiments presented in this paper.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "While syntactic structures can be assigned to sentences manually (and may be necessary when developing a corpus for a language for which few syntacticallyannotated corpus resources have already been developed; see Sect. 2.3), it is more common for syntactic annotations to be added automatically by a syntactic parser, a program that provides information about different kinds of syntactic relationships that exist between words in a given text (parses).",
        "entities": [
            [
                105,
                111,
                "TERM"
            ],
            [
                164,
                170,
                "TERM"
            ],
            [
                440,
                444,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, over the period 1940-2009, 171 collocates of the node war were identified.",
        "entities": [
            [
                62,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "Make sure to provide examples from the corpus to support your analysis of their meanings.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "The point of this case study was not to provide such an explanation but to show how an empirical basis can be provided using token frequencies derived from linguistic corpora.",
        "entities": [
            [
                125,
                130,
                "TERM"
            ]
        ]
    },
    {
        "text": "Nine covariates are tested, which represent such social factors as the sex, age and education level of the speakers, and such linguistic factors as polarity, type of determination and proximity of the copula to its referent.",
        "entities": [
            [
                158,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "It should therefore be clear that a specific piece of corpus software cannot always be pigeonholed into one of these three categories.",
        "entities": [
            [
                54,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, using a High Performance Cluster (multiple connected computers running small batches of text) at Lancaster, we were able to complete the task in three days.",
        "entities": [
            [
                97,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "Any document that purely contains text (plus potentially some form of markup, see Chapter 11), is generally referred to as a plain-text document and should be readable (and writable) with any basic text editor (see Section 4.2.1 for a more in-depth discussion of these).",
        "entities": [
            [
                70,
                76,
                "TERM"
            ],
            [
                34,
                38,
                "TERM"
            ],
            [
                131,
                135,
                "TERM"
            ],
            [
                198,
                202,
                "TERM"
            ]
        ]
    },
    {
        "text": "The utility of POS tagging, especially for languages like English, is that many words are ambiguous in terms of their part-of-speech.",
        "entities": [
            [
                19,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "As has been observed, corpus linguistics is a fairly new and rapidly growing discipline.",
        "entities": [
            [
                22,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "To some extent, these shortcomings are addressed by Gale's Digital Scholar Lab, 5 a text analytics platform through which the British Library Newspapers database can also be accessed.",
        "entities": [
            [
                84,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpus linguistics, bootstrapping has also been proposed as a method for quantifying the degree of homogeneity in a corpus sample, for validation of statistical results, and as a methodological step in random decision forests, an advanced classification method.",
        "entities": [
            [
                3,
                21,
                "TERM"
            ],
            [
                119,
                125,
                "TERM"
            ],
            [
                126,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "Luckily, these are problems that have already been overcome to some extent by the advent of web-based interfaces to these mega corpora, which, even if they may not allow us to do everything we might want to do with such a corpus, already provide many facilities for investigating the data in relatively complex ways that will probably satisfy the needs of most researchers.",
        "entities": [
            [
                222,
                228,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, it is possible to study the type of lexical errors made during various developmental stages or the diversification in the repertoire of speech acts which are available to the child.",
        "entities": [
            [
                42,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "Despite the somewhat bleak overall picture of the amount of corpus work completed hitherto on ELF, the first one-million-word spoken corpus, The Corpus of English as a Lingua Franca in Academic Settings (ELFA, www.helsinki.fi/elfa) was completed in 2008, very soon followed by The Vienna-Oxford International Corpus of English (VOICE, www.univie.ac.at/voice) of the same size.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ],
            [
                133,
                139,
                "TERM"
            ]
        ]
    },
    {
        "text": "The present paper is an attempt to provide a snapshot of current problems, both in corpus linguistics in general and in selected hot topic areas, as well as to provide ideas and (first) suggestions about how to cope with these problems; I hope it will succeed as a call to (methodological) arms, and thus trigger developments that will help our field advance once more.",
        "entities": [
            [
                83,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "Collocational statistics quantify the strength of association or repulsion between a node word and its collocates.",
        "entities": [
            [
                85,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "Part II is organized as a progression of the linguistic levels, beginning with corpus-based analyses of prosodic characteristics, moving on to chapters dealing with lexical characteristics (keywords, collocations, and phraseology), followed by chapters on grammatical features (descriptive grammar, grammatical variation, grammatical change, and the intersection of grammar and lexis), and finally concluding with chapters on the corpus-based study of discourse functions and pragmatics.",
        "entities": [
            [
                79,
                91,
                "TERM"
            ],
            [
                430,
                442,
                "TERM"
            ],
            [
                378,
                383,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to improve the reliability of annotations made by humans and to help define clear categories, a commonly used method is to have the same annotation made by two different annotators.",
        "entities": [
            [
                146,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "These all highlight the relationship between lexis and grammar and are useful to a language learner.",
        "entities": [
            [
                45,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "They are generally used in a span of French text within a codeswitched tweet where most tokens are in English; this explains why the tweets were tagged as written in English and retained in the corpus.",
        "entities": [
            [
                194,
                200,
                "TERM"
            ],
            [
                44,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "The much higher rate of complex NPs in written registers may also be due to considerations of mode and reception alone: a reader will have more time to process complex structures, and knowledge of this fact may carry over to considerations of text production.",
        "entities": [
            [
                243,
                247,
                "TERM"
            ]
        ]
    },
    {
        "text": "Furthermore, the design of the annotation and interfaces available may sometimes exhibit flaws from a linguistic perspective, as we've, for instance, seen for the CQP architecture behind BNCweb, which treats punctuation tokens in exactly the same way as genuine words, thereby potentially skewing all the statistics produced by the tool.",
        "entities": [
            [
                31,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you need to change the encoding, though, where exactly this can be done, and also how you can see this, may vary.",
        "entities": [
            [
                26,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "Type 5 (o = 174, e = 121.9) represents the most common pattern overall: in this type the suffix combines with a complex verbal stem that encodes a transitive action.",
        "entities": [
            [
                80,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "Referents that are important in a culture are more likely to be talked and written about than those that are not; thus, in a sufficiently large and representative corpus, the frequency of a linguistic item may be taken to represent the importance of its referent in the culture.",
        "entities": [
            [
                163,
                169,
                "TERM"
            ]
        ]
    },
    {
        "text": "Make sure to support your analysis with examples from the corpus.",
        "entities": [
            [
                58,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "Ideally, it would be desirable to include complete texts in corpora, since even if one is studying grammatical constructions, it is most natural to study these constructions within the context of a complete text rather than only part of that text.",
        "entities": [
            [
                207,
                211,
                "TERM"
            ],
            [
                242,
                246,
                "TERM"
            ]
        ]
    },
    {
        "text": "The compilers eventually arrived at a very elaborate coding scheme to describe the letter writers in their corpus, using 27 different parameters, some with very open information.",
        "entities": [
            [
                107,
                113,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, because the corpus contains private letters from a period before English was standardized, there is a great deal of spelling variation in the corpus.",
        "entities": [
            [
                22,
                28,
                "TERM"
            ],
            [
                152,
                158,
                "TERM"
            ]
        ]
    },
    {
        "text": "The data sample was analyzed with a binary (continued) logistic regression (Chap. 21) in which the dependent variable was the choice of genitive (-s vs. of ) and the 14 variables were the predictor variables.",
        "entities": [
            [
                9,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "They point out that this sentence will not occur in any given finite corpus, but that this does not allow us to declare it ungrammatical, since it could simply be one of infinitely many sentences that \"simply haven't occurred yet\".",
        "entities": [
            [
                69,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "For each spoken text, a record was kept of when the text was recorded, where the recording took place, who was recorded, who did the recording, and how long the recording was.",
        "entities": [
            [
                16,
                20,
                "TERM"
            ],
            [
                52,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will finally see that the task of creating a corpus carries with it a certain number of ethical and legal issues which must be dealt with.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is very valuable information to estimate the quantity and type of input a child is exposed to.",
        "entities": [
            [
                63,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will encounter the same problem when we compare the TTR or HTR of particular affixes or other linguistic phenomena, rather than that of a text.",
        "entities": [
            [
                141,
                145,
                "TERM"
            ]
        ]
    },
    {
        "text": "It seems to me that, in fact, corpus creators are not striving for representativeness at all.",
        "entities": [
            [
                67,
                85,
                "TERM"
            ],
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "But while gender balance is more easily achieved in modern corpora such as the BNC or COCA, in CEEC it was much more difficult, largely because literacy rates were much higher among men during this period than women.",
        "entities": [
            [
                17,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter has highlighted the growing recognition of the crucial role played by the register parameter in historical corpus linguistics.",
        "entities": [
            [
                120,
                138,
                "TERM"
            ]
        ]
    },
    {
        "text": "But linguistic corpora do not (and cannot) contain only well-known authors, and so checking the individual demographic data for every speaker in a corpus may be difficult to impossible.",
        "entities": [
            [
                147,
                153,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the moment, simply try to identify the 'head' and 'body' sections of the page and see whether you can possibly also understand which type of meta-information the different parts of the header may relate to.",
        "entities": [
            [
                137,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "Second, extremely short texts cannot be easily compared with other texts using many typical quantitative corpus-linguistic methods, such as normalization, because the normalization results become meaningless as the length of the text becomes increasingly short.",
        "entities": [
            [
                105,
                111,
                "TERM"
            ],
            [
                229,
                233,
                "TERM"
            ]
        ]
    },
    {
        "text": "The conversion of the concordance lines into a spreadsheet like in Fig.",
        "entities": [
            [
                22,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we saw in the preceding chapter, corpora fell out of favor just as linguistics grew into an academic discipline in its own right and as a result, corpus-based studies of language were relegated to the margins of the field.",
        "entities": [
            [
                149,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "Often a concordance display gives information about the word by putting that word in the middle of a line with a certain amount of words preceding and following it.",
        "entities": [
            [
                8,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "When it comes to creating a reference corpus, the data collection phase is so time-consuming that it can only be tackled by a group of experts.",
        "entities": [
            [
                28,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, the potential of finding unwanted or irrelevant items may in some cases vary between different sections of the corpus.",
        "entities": [
            [
                127,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is not yet standard in corpus linguistics, but it is a good idea to plan and document your research as though it already were.",
        "entities": [
            [
                28,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such processes are vital in order to ensure that the machine-readable text is as accurate as possible.",
        "entities": [
            [
                70,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "Monomodal text-only corpora in English are sometimes annotated automatically with the use of 'taggers' and 'parsers'.",
        "entities": [
            [
                10,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "This means that the number of the notional parts, and their length (v in equation (2.20)), depend on the frequency of the word in the corpus.",
        "entities": [
            [
                134,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "In all but the most basic examples, it is likely that the researcher will want to expand the corpus beyond the initial set of seeds.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, POS tagging should be done simultaneously with or after glossing.",
        "entities": [
            [
                10,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Before opening one or more files for them to be processed with AntConc, we have to make sure that the encoding chosen in AntConc for reading the characters is suitable for reading the file correctly.",
        "entities": [
            [
                102,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "In longer written text production, like a book, producers of texts may go through various rounds of pre-planning and rewriting a text before it is actually delivered.",
        "entities": [
            [
                18,
                22,
                "TERM"
            ],
            [
                129,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "We need to expand corpus studies into multimodal academic genres where writing is frequently used with graphical and visual semiotic forms, such as academic websites and textbooks.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "So, if our token is she, in the sentence the cat jumped on the couch and then she went to sleep, and has the same referent as the cat, the antecedent of she is the cat.",
        "entities": [
            [
                11,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Diversity is a useful safeguard for a monitor corpus against skewed representation.",
        "entities": [
            [
                38,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is well below the level required to claim statistical significance.",
        "entities": [
            [
                47,
                71,
                "TERM"
            ]
        ]
    }
]