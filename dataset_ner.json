[
    {
        "text": "It should be noted that this is fundamentally rather similar to the procedure of a key items analysis, except that we are comparing the vicinity of the node to the rest of the corpus, rather than comparing two different corpora, and some of the same considerations apply.",
        "entities": [
            [
                176,
                182,
                "TERM"
            ],
            [
                152,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "While corpus linguistics has very little to say to those with interests in, for instance, generative grammar, it is of great value to those who are interested in studying pragmatics: how language is used.",
        "entities": [
            [
                6,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "Before any material can be included in the corpus, however, each transcript needs to be checked against the recorded episode to ensure that the transcription is not only correct, but also sufficiently detailed for the specific research purposes.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "Despite its relatively well-developed state, corpus linguistic methodology has historically been unevenly distributed across the linguistics research community as a whole.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "One lexically tagged and grammatically parsed corpus is ICE-GB, the British component of the International Corpus of English.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "Here in the table below is a list of 20 occurrences drawn from the corpus with two possible annotations.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "But as much research in corpus linguistics has demonstrated, empirical data can both enhance and support the claims made in linguistic analyses.",
        "entities": [
            [
                24,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another way to store a corpus is to save it into a database.",
        "entities": [
            [
                23,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another example is the EXMARaLDA tool, which has been specifically developed to assist in the transcription and annotation of spoken corpora, and later be able to manage them.",
        "entities": [
            [
                112,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "The point of this case study was not to provide such an explanation but to show how an empirical basis can be provided using token frequencies derived from linguistic corpora.",
        "entities": [
            [
                125,
                130,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such a corpus is sometimes referred to as a balanced corpus.",
        "entities": [
            [
                7,
                13,
                "TERM"
            ],
            [
                53,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "If I were willing to speculate, I would consider the possibility that the rejection of corpora and corpus-linguistic methods in (some schools of) grammatical theorizing are based mostly on a desire to avoid having to deal with actual data, which are messy, incomplete and often frustrating, and that the arguments against the use of such data are, essentially, post-hoc rationalizations.",
        "entities": [
            [
                99,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to protect the privacy of tweet authors, we only reproduce textual content without any metadata.",
        "entities": [
            [
                96,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although this lemma occurs in a majority of corpus parts (Range 10) it has a very low Juilland's D (0.2).",
        "entities": [
            [
                44,
                50,
                "TERM"
            ],
            [
                14,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "Grammatical markup is inserted when a corpus is tagged or parsed.",
        "entities": [
            [
                12,
                18,
                "TERM"
            ],
            [
                38,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "These students often ask me what the best statistical test is to use with corpora, what the best collocation measure is etc.",
        "entities": [
            [
                97,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "Instead of a list of collocates displayed in a table (the usual format), the graph shows the relationship between the node and the collocates by displaying collocates closer to or further apart from the node.",
        "entities": [
            [
                118,
                122,
                "TERM"
            ],
            [
                203,
                207,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the two texts from the 'Think about' task the type/token ratio is 0.8 (28/35) and 0.93 (28/30) respectively.",
        "entities": [
            [
                55,
                60,
                "TERM"
            ],
            [
                50,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, we will discuss some facts that need to be considered before deciding to create a new corpus and highlight the advantages of reusing existing data whenever possible.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "Mastering these terms will make reading of the rest of the book, and many papers in corpus linguistics, much easier.",
        "entities": [
            [
                84,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "The primary purpose of the transcription is to make the spoken text searchable.",
        "entities": [
            [
                63,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus contains 48,569 texts -which are equivalent to web pages herecomprising 52,933,543 wordform tokens.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, the online interface on the OFROM corpus (see section 5.3) only offers the possibility of looking for productions by women or men, but for the moment does not indicate the total number of participants of each genre, or the number of words produced by each of them.",
        "entities": [
            [
                47,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "Since the late 1990s when linguists began to turn to the web as a corpus, search engines have actually become less advanced in terms of the options they offer.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "Methods of corpus interrogation will be affected by how linguistic organization is conceived.",
        "entities": [
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Compared to raw text, annotated text is complex in structure and difficult to access, but easier in analysis, better in interpretation, and more user-friendly in an application.",
        "entities": [
            [
                16,
                20,
                "TERM"
            ],
            [
                32,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "Before making claims, it is important to consider a sample of expanded concordance lines and to maintain vigilance in terms of spotting lines that potentially may be functioning differently to a first glance.",
        "entities": [
            [
                71,
                82,
                "TERM"
            ],
            [
                52,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the degree of expansion is low, then the original corpus was already nearly saturated and hence reasonably representative.",
        "entities": [
            [
                53,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "This annotation is useful since a pronoun like he is not an autonomous referential expression, meaning that it does not by itself make it possible to identify the referent in question if we ignore the context.",
        "entities": [
            [
                5,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, retrieving text from digital formats may have varying degrees of difficulty depending on the original format; for example, it can be very difficult to isolate the texts of different articles in a journal page formatted as a PDF document, or even impossible when the PDF file includes text images.",
        "entities": [
            [
                20,
                24,
                "TERM"
            ],
            [
                293,
                297,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the following section, we undertake a survey of some of the most important corpus investigations of phraseology carried out to date, grouped according to the considerations introduced above.",
        "entities": [
            [
                78,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "Various registers are also included in the corpus, such as law, philosophy, history, and fiction.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, I use it as a superordinate term for text-linguistic terms like genre, register, style, and medium as well as sociolinguistic terms like dialect, sociolect, etc.",
        "entities": [
            [
                53,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "This type of regression has subtypes such as logistic or multinomial and this distinction has to do with the distribution of the data and the type of DV, whether it is numeric or 2-way categorical or 2+-way categorical among other possibilities.",
        "entities": [
            [
                5,
                9,
                "TERM"
            ],
            [
                142,
                146,
                "TERM"
            ]
        ]
    },
    {
        "text": "Spoken language does not generally have the same type of planning and opportunities for revision that we find in many types of written language.",
        "entities": [
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, in case of a monitor corpus, which tries to represent all possible text varieties, we may include all non-standard and ordinary text samples along with standard and established text samples.",
        "entities": [
            [
                32,
                46,
                "TERM"
            ],
            [
                86,
                90,
                "TERM"
            ],
            [
                147,
                151,
                "TERM"
            ],
            [
                196,
                200,
                "TERM"
            ]
        ]
    },
    {
        "text": "Consequently, to adequately reflect gender differences in language usage, it is best to include in a corpus a variety of different types of conversations involving males and females: women speaking only with other women, men speaking only with other men, two women speaking with a single man, two women and two men speaking, and so forth.",
        "entities": [
            [
                101,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "This research is not usually interested in any particular collocation (or set of collocations), or in genuinely linguistic research questions; instead, the focus is on methods (ways of preprocessing corpora, which association measures to use, etc.).",
        "entities": [
            [
                58,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "We then need nchar to determine how many three-grams we will have to create/retrieve and then store, and a for-loop that applies substr to the cleaned text vector to extract the threegrams.",
        "entities": [
            [
                151,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpus linguistics, the explicandum is typically some aspect of language structure and/or use, while the explicans may be some other aspect of language structure or use (such as the presence or absence of a particular linguistic element, a particular position in a discourse, etc.), or some language external factor (such as the speaker's sex or age, the relationship between speaker and hearer, etc.).",
        "entities": [
            [
                3,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "This functional analysis also takes account of distributions across Dickens's texts and the nineteenth-century reference corpus and hones in on detailed textual examples discussed mainly from an intrinsically explanatory point of view.",
        "entities": [
            [
                111,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "I hope that the specific perspective taken in this book, along with the case studies and the possibility to study the full data sets, will help both beginning and seasoned researchers gain an understanding of the underlying logic of corpus linguistic research.",
        "entities": [
            [
                233,
                239,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the former, for example, arguing strongly and argued strongly would both count as cases of the collocation argue strongly.",
        "entities": [
            [
                98,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "Conversely, even the most sophisticated quantitative analysis typically entails item-by-item annotation of each data point, which equates to a qualitative analysis of sorts; likewise, the results of a quantitative analysis demand interpretation, which typically requires a qualitative approach.",
        "entities": [
            [
                93,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "The problem of manual tracking and counting of occurrences is all the more acute since corpus linguistics is often based on large amounts of data which have not been drawn from a single book, in view of observing the multiple occurrences of a certain linguistic phenomenon and thus apprehending its specificities.",
        "entities": [
            [
                87,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "Rather, the corpus itself is analyzed, inductively and typically automatically, to identify the lexical phrases that are especially noteworthy.",
        "entities": [
            [
                12,
                18,
                "TERM"
            ]
        ]
    },
    {
        "text": "A synchronic or diachronic corpus is representative to the extent that the study of that corpus can replace the study of the textual universe it represents.",
        "entities": [
            [
                16,
                26,
                "TERM"
            ],
            [
                2,
                12,
                "TERM"
            ],
            [
                27,
                33,
                "TERM"
            ],
            [
                89,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "Retrieving all cases of this construction from the syntactically parsed ICE-GB corpus, Hampe and Schönefeld use the Fisher-Yates exact test to identify verbs which are associated with it.",
        "entities": [
            [
                79,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "While most of the recordings for a corpus will be obtained by recording individuals with microphones, many corpora will contain sections of broadcast speech.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is an alternative, however: speakers sometimes use adverbs that explicitly refer to the type of beginning.",
        "entities": [
            [
                94,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "You should definitely also delete all numbers, unless you want to change the token definition to include those, but, as I pointed out before, numbers may take many different forms and their meaning may be difficult to identify.",
        "entities": [
            [
                77,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can turn this claim into a hypothesis involving two variables (Variety and Suffix Variant), but not one of the type \"All x are y\".",
        "entities": [
            [
                114,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, this enables users of the corpus to plan the construction of their queries targeting these annotations.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "Group the individual text types into larger categories based on their functional similarity.",
        "entities": [
            [
                21,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "We have a sample, for instance, of 30 Matukar Panau speakers, speaking for a total of 40 hours in a specific setting.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Corpus of Early English Correspondence (CEEC) project was the first and the work is still going on with a whole corpus family in the pipeline.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "The impossibility of this task is widely acknowledged in corpus linguistics.",
        "entities": [
            [
                57,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "Nevertheless, there are disadvantages to the corpus-based approach as well.",
        "entities": [
            [
                45,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "Different types of texts have different types of character encoding associated with them.",
        "entities": [
            [
                59,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "The right to anonymity of the persons mentioned in the corpus represents another important ethical problem.",
        "entities": [
            [
                55,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "Numerical sorting is one of the most straightforward approaches to working with quantitative data of a corpus.",
        "entities": [
            [
                103,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "Creating a new POS tagging model is often an iterative process: small samples of text are manually annotated and used as training data to create a provisional POS tagger, which then automatically annotates more texts.",
        "entities": [
            [
                19,
                26,
                "TERM"
            ],
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Size filters are designed to remove very short and very long documents from the corpus.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "This allows corpus linguistic methods to be used in uncovering at least some properties of that culture.",
        "entities": [
            [
                12,
                18,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, the word Mme in line 94 is an abbreviation, indicated in the corpus by the sequence \\0 preceding it.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "Among the paragraphs, we also encounter one special type, that of the heading, which acts as a kind of guide to the particular chapter or (sub-)section the individual paragraphs occur in.",
        "entities": [
            [
                52,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another issue related to corpus balance in your corpus relates to text types.",
        "entities": [
            [
                32,
                39,
                "TERM"
            ],
            [
                25,
                31,
                "TERM"
            ],
            [
                48,
                54,
                "TERM"
            ],
            [
                66,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "And this is especially true when the corpus is created by a small team and with limited resources.",
        "entities": [
            [
                37,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Also, even just in the sixth frequency band, the extreme range values that are observed are 85 / 905 = 9.4% vs. 733 / 905 = 81% of the corpus files, i.e. huge differences between words that in a less careful study that ignores dispersion would simply be considered 'similar in frequency'.",
        "entities": [
            [
                135,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to the corpus-informed books, we will also review four popular noncorpus-informed grammar books at this same upper-intermediate to advanced level.",
        "entities": [
            [
                19,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus used for this study is the American Nurse-Standardized Patient corpus (ANSP corpus).",
        "entities": [
            [
                4,
                10,
                "TERM"
            ],
            [
                74,
                80,
                "TERM"
            ],
            [
                87,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even more strikingly, the structure of the type then I appeared 10 times more frequently in the COBUILD corpus that the I then construction, repeatedly employed in the declaration.",
        "entities": [
            [
                104,
                110,
                "TERM"
            ],
            [
                43,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "The review in this section demonstrates that corpus linguistics has enabled large-scale collocation analysis and foregrounded collocation in linguistic research while corpus-based collocation studies over the past decades have uncovered a range of interesting collocational behavior and semantic prosody which have been hidden from intuition and can only be revealed by examining a large amount of attested data simultaneously.",
        "entities": [
            [
                45,
                63,
                "TERM"
            ],
            [
                167,
                179,
                "TERM"
            ],
            [
                88,
                99,
                "TERM"
            ],
            [
                126,
                137,
                "TERM"
            ],
            [
                180,
                191,
                "TERM"
            ]
        ]
    },
    {
        "text": "Underneath this waveform are two annotation tiers.",
        "entities": [
            [
                33,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "As I said before, there are now a number of options for sorting according to different fields, for instance comparing the ranks in one corpus against another or, perhaps more importantly, seeing whether certain words dominate to some extent in one corpus in comparison.",
        "entities": [
            [
                135,
                141,
                "TERM"
            ],
            [
                248,
                254,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, taking into account than young men are underrepresented in the corpus compared to old men, there is a clear preference of all men for the of -construction.",
        "entities": [
            [
                79,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, it performs the main action of the function, i.e., locating search term hits in the corpus files (via \"finditer\") and generating KWIC results for each of them (lines 35-51).",
        "entities": [
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the case of a spoken corpus in particular, it is essential for participants to know that they are being recorded and that their data will later be used for linguistic analyses.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "A second portion of the corpus focuses on advanced learners who have all lived in France, for a period ranging from 1-2 years to more than 30 years (see Chapter 3, section 3.3 for a study based on these data).",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpora, this assumption is usually violated to some extent due to the nature of language, where linguistic features are interconnected, and also due to corpus sampling that is done at the level of texts, not individual linguistic features.",
        "entities": [
            [
                156,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "Click on the bar for spoken discourse (SPOK) and that will give you 100 sample cases when the verb \"say\" occurs in spoken discourse.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "As was noted in Chapter 3, a corpus that is lexically tagged contains part-of-speech information for each word in the corpus.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ],
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, humans can also make mistakes due to fatigue, lack of attention or a poor understanding of the annotation instructions.",
        "entities": [
            [
                108,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "His MLU ranged from 1.17 at the start of the corpus to 3.78 at the end.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to do so, in the past corpus compilers have frequently resorted to using samples of approximately 2,000 words from different texts and genres to achieve balance, but both that number and 'cutting out' part of a text appear fairly arbitrary, and may in fact make such samples somewhat unrepresentative of the texts they're supposed to represent as a whole.",
        "entities": [
            [
                162,
                169,
                "TERM"
            ],
            [
                31,
                37,
                "TERM"
            ],
            [
                220,
                224,
                "TERM"
            ]
        ]
    },
    {
        "text": "Wireless microphones are appropriate in recording situations of this type too, and avoid the problem of the speaker being constrained by the length of the cord attaching the microphone and recorder.",
        "entities": [
            [
                69,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "By that I do not only mean that corpus linguists need to use more different statistical tests (while that is generally true, the choice of a particular test is of course mostly dictated by the particular research question), but also that there needs to be a growing awareness that some choices that corpus linguists traditionally make may be pro blematic and would benefit from a different perspective.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ],
            [
                299,
                305,
                "TERM"
            ]
        ]
    },
    {
        "text": "Select the 'Collocates' tab, type in fair as your search term and set the 'Min. Collocate Frequency' option to 2, in order to avoid one-off constructions, also known as singletons or hapax legomena.",
        "entities": [
            [
                29,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will turn to the role of corpus linguistics in sociolinguistics in Chapter 9.",
        "entities": [
            [
                28,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the stylistic analysis of one of Pope's poems, for instance, norms with varying contextual relationships include English eighteenth-century poetry, the corpus of Pope's work, all poems written in English in rhymed pentameter couplets, or, for greater contrast as well as comparison, the poetry of Wordsworth.",
        "entities": [
            [
                156,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "The route proposed should, in our view, maximise corpus linguistics' engagement with disciplines across the social sciences.",
        "entities": [
            [
                49,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to the corpus text data, modern corpora are closely interlinked with two further types of data, namely raw data and metadata.",
        "entities": [
            [
                128,
                136,
                "TERM"
            ],
            [
                19,
                25,
                "TERM"
            ],
            [
                26,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "And where the corpus text is in a language that is not known to the scientific community it needs to be translated to a more widely known language.",
        "entities": [
            [
                14,
                20,
                "TERM"
            ],
            [
                21,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "Since this is a written corpus, let us define Length in terms of letters and assume that this is a sufficiently close approximation to phonological length.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "The evidence suggests that corpus work is now ready to expand beyond the university ESP class, where it has largely been used to date, into mainstream second and foreign language learning -where, of course, its effects can continue to be investigated and the conditions of its success elaborated.",
        "entities": [
            [
                27,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "But the same normalized rate of occurrence value also applies to a text of 1,000 words which contains 200 first person pronouns.",
        "entities": [
            [
                67,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "Repeat this step for the frequency in the newspaper corpus, ensuring that the formula bar reads =D2/n_newspapers.",
        "entities": [
            [
                52,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "The DECTE data are generated by counting the frequency of phonetic segments in interviews, so completeness and accuracy should not be issues if the survey is carefully done using a reliable procedure; manual counting of features in physical text by direct observation is in general far less accurate than the software equivalent for electronic text.",
        "entities": [
            [
                241,
                245,
                "TERM"
            ],
            [
                344,
                348,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now, many computer programs designed to count words will split the input text on spaces and punctuation.",
        "entities": [
            [
                73,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "Put differently, if we go through the occurrences of -icle in the BNC item by item, the probability that the next item instantiating this suffix will be a type we have not seen before is 0.15 percent, so we will encounter a new type on average once 9 Morphology every 670 words.",
        "entities": [
            [
                155,
                159,
                "TERM"
            ],
            [
                228,
                232,
                "TERM"
            ]
        ]
    },
    {
        "text": "As for the literary genre, the Frantext corpus brings together many literary texts ranging from ancient to modern French, in a corpus which totals more than 250 million words.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ],
            [
                127,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is exactly what the methodology of corpus linguistics offers to researchers in disciplines beyond linguistics.",
        "entities": [
            [
                40,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "This parameter reflects the way in which word occurrences are distributed across the different portions of the corpus.",
        "entities": [
            [
                111,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, this type of information includes the date of a newspaper article, the place where a conversation was recorded or the characteristics of the speakers taking part in the dialogue.",
        "entities": [
            [
                18,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "While several international initiatives have attempted to standardise metadata formats (see Broeder and van Uytvanck 2014 for an overview), its divergent use across existing spoken corpora is pronounced.",
        "entities": [
            [
                70,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another criticism of academic corpus studies is that, until fairly recently, these have been largely text-focused so that features seem rather abstract and disembodied from real users.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ],
            [
                101,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "The CLAWS tagger, for example, assigns a hyphenated POS tag, referred to as an \"ambiguity tag\", when its tagging algorithm is unable to unambiguously assign a single POS to a word.",
        "entities": [
            [
                105,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "While many corpora contain only text samples, others contain entire texts.",
        "entities": [
            [
                32,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "Texts that exist only in printed or even handwritten form on paper require work on digitisation so that the text is machine-readable.",
        "entities": [
            [
                108,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "Ask a second person to make this annotation and calculate the percentage of agreement and the kappa coefficient.",
        "entities": [
            [
                33,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "The segments of speech that overlap need to be marked so that the eventual user of the corpus knows which parts overlap in the event that he or she wishes to study overlapping speech.",
        "entities": [
            [
                87,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "Altering the span of the window around the node word where possible collocate words are considered can also significantly affect the results.",
        "entities": [
            [
                43,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, as XML forbids the use of overlapping tags, and overlap passages span across different speaker turns, using <overlap>…</overlap> elements would break the document's well-formedness, so it's best to use the empty tags <overlap type=\"start\" /> and <overlap type=\"end\" />, possibly in combination with a number ('n') attribute.",
        "entities": [
            [
                235,
                239,
                "TERM"
            ],
            [
                264,
                268,
                "TERM"
            ],
            [
                12,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, any text, spoken or written, will lose not only its communicative context (the discourse of which it was originally a part), but also some of its linguistic and paralinguistic properties when it becomes part of a corpus.",
        "entities": [
            [
                220,
                226,
                "TERM"
            ],
            [
                11,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such semi-structured elicitation techniques may also be used where a phenomenon is frequent enough in a typical corpus, but where the researcher wants to vary certain aspects systematically, or where the researcher wants to achieve comparability across speakers or even across languages.",
        "entities": [
            [
                232,
                245,
                "TERM"
            ],
            [
                112,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, we know that the use of nouns and adjectives in text is strongly correlated.",
        "entities": [
            [
                61,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given these multiple indicators, in this situation in which large differences exist between the effect sizes of the studies included in the meta-analysis, the mean of the effect sizes from all studies obscure patterns in the sample.",
        "entities": [
            [
                225,
                231,
                "TERM"
            ]
        ]
    },
    {
        "text": "These are small assignments which you should try to complete before you read on; answers to them follow immediately in the text.",
        "entities": [
            [
                123,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "The chapter concludes with a detailed description of various kinds of textual markup and linguistic annotation that can be inserted into a text.",
        "entities": [
            [
                100,
                110,
                "TERM"
            ],
            [
                78,
                84,
                "TERM"
            ],
            [
                139,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a list of the ten most frequent words of a large English corpus, all of the words will be function words.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "Looking at the published corpus-linguistic literature, my impression is that for most linguistic phenomena that researchers are likely to want to investigate, these corpus sizes seem sufficient.",
        "entities": [
            [
                25,
                31,
                "TERM"
            ],
            [
                165,
                171,
                "TERM"
            ]
        ]
    },
    {
        "text": "In very basic cases, the language of the corpus is rearranged so that a reader is presented with an altered and focused view.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "Generally speaking, the larger and the more similar the reference corpus is to the corpus of interest the more reliable and focused the comparison is.",
        "entities": [
            [
                56,
                72,
                "TERM"
            ],
            [
                83,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "With corpus linguistics the basis has broadened and the focus has shifted to common features and everyday practices.",
        "entities": [
            [
                5,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "Type in \"say_spoken\" under \"Create new list\" above the sample concordance lines and save the list.",
        "entities": [
            [
                62,
                73,
                "TERM"
            ],
            [
                55,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "One way to answer this question is to examine the guidelines established by the Text Encoding Initiative (TEI) for the encoding of electronic texts, including linguistic corpora (www.tei-c.org/ release/doc/tei-p5-doc/en/html/CC.html).",
        "entities": [
            [
                119,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "From a qualitative perspective and using a close-reading method, as is often the case in literature research, the use of overlapping genre categorizations can provide a way of connecting the content and style of the text being read to different movements or periods from which the author might have drawn their inspiration or within which they might have been an active participant.",
        "entities": [
            [
                216,
                220,
                "TERM"
            ]
        ]
    },
    {
        "text": "Metadata is a key component of any corpus: users need to know precisely what is in a corpus.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ],
            [
                85,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first question we can ask about the content of a corpus is how much text it contains: its size.",
        "entities": [
            [
                53,
                59,
                "TERM"
            ],
            [
                72,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "While this workaround has been used for a long time to good effect, it is also not optimal, since in many cases it excludes a large majority of the text from the calculation.",
        "entities": [
            [
                148,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "These considerations are likely to explain why the Sakapultek corpus is among the very few corpora that show the postulated discourse-ergative pattern.",
        "entities": [
            [
                62,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we have described in previous chapters, one of the main focuses of corpus linguistic research is variation.",
        "entities": [
            [
                70,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "Anyone who decides to become involved in collocation research (or some of the large-scale lexical research areas described in the next chapter), should get acquainted at least with the simple options of automatizing statistical testing offered by spreadsheet applications.",
        "entities": [
            [
                41,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "In these cases, the classification is often based on common sense or on the pragmatism of the corpus designer, depending on the importance of subcategories for addressing the questions that the corpus is supposed to help study.",
        "entities": [
            [
                94,
                100,
                "TERM"
            ],
            [
                194,
                200,
                "TERM"
            ]
        ]
    },
    {
        "text": "You can verify this for sil by clicking on it in the 'Word' window, which will take you to a concordance view of the item, where you can also see that this annotation normally appears in angle brackets in the source texts.",
        "entities": [
            [
                93,
                104,
                "TERM"
            ],
            [
                156,
                166,
                "TERM"
            ]
        ]
    },
    {
        "text": "This collection of papers focuses on questions of standards for the construction, annotation, searching, archiving and sharing of spoken corpora used in conversation analysis, sociolinguistics, discourse analysis and pragmatics.",
        "entities": [
            [
                82,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this does not necessarily mean that the text must be excluded from the corpus, since there is annotation that can be included in a corpus indicating that certain sections of a sample are \"extra-corpus\" material; that is, material not considered part of the corpus for purposes of word counts, generating KWIC (key word in context), and so forth.",
        "entities": [
            [
                319,
                338,
                "TERM"
            ],
            [
                103,
                113,
                "TERM"
            ],
            [
                80,
                86,
                "TERM"
            ],
            [
                140,
                146,
                "TERM"
            ],
            [
                203,
                209,
                "TERM"
            ],
            [
                266,
                272,
                "TERM"
            ],
            [
                185,
                191,
                "TERM"
            ],
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "For a number of research questions, this type of information is crucial, for example, when it comes to determining the meaning of a derived word.",
        "entities": [
            [
                41,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "But linguistic corpora do not (and cannot) contain only well-known authors, and so checking the individual demographic data for every speaker in a corpus may be difficult to impossible.",
        "entities": [
            [
                147,
                153,
                "TERM"
            ]
        ]
    },
    {
        "text": "To illustrate this, we ran a lexical bundle search in a corpus of webtexts.",
        "entities": [
            [
                56,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "If one computes the MI of in spite of in the untagged Brown corpus by comparing the observed frequency of in spite of of 54 against an expected frequency based on complete independence, MI becomes an extremely high value of 12.25.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "Adding an option for this will then provide us with an improved solution for the regex, \\b(((assum|believ|guess|suppos|think)(e?[ds]? |ing)?)|thought)\\b, increasing the number of hits to 414, and indicating the importance of the past tense form of think in the text.",
        "entities": [
            [
                261,
                265,
                "TERM"
            ]
        ]
    },
    {
        "text": "A key items analysis is performed as follows: first, frequency lists are created for two texts or corpora -either two corpora which we wish to contrast, or a single text of interest and a generic reference corpus.",
        "entities": [
            [
                196,
                212,
                "TERM"
            ],
            [
                165,
                169,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, corpora including children's language or productions of foreign language learners may contain an annotation of errors.",
        "entities": [
            [
                106,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we will see throughout the chapter, creating a corpus is a challenging task and presents many difficulties.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Before this, even simple methods for studying language such as extracting a list of all the different words in a text and their immediate contexts was incredibly time consuming and costly in terms of human effort.",
        "entities": [
            [
                113,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "The special meaning of the angled brackets < and > means that actual less-than or greater-than signs in the text itself must be represented by the special codes &lt; and &gt;.",
        "entities": [
            [
                108,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even the resulting, somewhat weaker statement is quite clearly true, and will remain true no matter how large a corpus we are dealing with.",
        "entities": [
            [
                112,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "Try to access an annotated text and find the respective word for 'woman' .",
        "entities": [
            [
                27,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, from frequency rank number 4,077 onwards, the words in the corpus only have one occurrence.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition to these aspects, the corpus needs to be in electronic form since it will be almost impossible to cope with such vast data without the help of technology.",
        "entities": [
            [
                34,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "This should copy your text to the clipboard.",
        "entities": [
            [
                22,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "Many of the classic and larger corpora of English contain PoS tagging, for example, COCA or the Brown family corpora.",
        "entities": [
            [
                62,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "As an example of a pitfall related to text sampling, we discuss a particular usage of the complex adverb as well, which caught our attention some time ago.",
        "entities": [
            [
                38,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "The analysis of Trump Speak also contains a discussion of how to use concordancing programs to obtain, for instance, information on the frequency of specific constructions in a corpus as well as relevant examples that can be used in subsequent research conducted on a particular topic.",
        "entities": [
            [
                177,
                183,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, one cannot use a simple frequency list of an English engineering corpus, because its most frequent words would still be the, of, in, . . . -these are frequent everywhere.",
        "entities": [
            [
                33,
                47,
                "TERM"
            ],
            [
                74,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "The only thing that could happen is that you accidentally either delete an entry you hadn't intended to delete, in which case you'll need to re-run the concordance and delete more carefully, or that you may accidentally select too many hits before pressing Delete.",
        "entities": [
            [
                152,
                163,
                "TERM"
            ]
        ]
    },
    {
        "text": "LGSWE is more explicit about its methodology, which is based on the annotation of a corpus with the categories used in the book.",
        "entities": [
            [
                68,
                78,
                "TERM"
            ],
            [
                84,
                90,
                "TERM"
            ]
        ]
    },
    {
        "text": "During each iteration, we will use grep to find all corpus sentences.",
        "entities": [
            [
                52,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "Depending on the target size for each genre, it is necessary to determine the appropriate size for each sample.",
        "entities": [
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the case of children with ASD, it is important to write down the different indications regarding the linguistic profile of the recorded children and to include them in the metadata, since autism represents a broad spectrum of skills and deficits which could lead to comparing children with very different linguistic and cognitive profiles.",
        "entities": [
            [
                175,
                183,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will need the functions switch and menu (which you do not know yet so you may want to briefly look at their help pages -they are not difficult and the script will show you how they are used anyway) to prompt the user to choose the annotation format that will be processed, and we need a conditional with if to then define regular expressions for either choice.",
        "entities": [
            [
                234,
                244,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the rest of Chapter 4, we will describe example studies from all of these levels as well as corpus studies of sign and gesture.",
        "entities": [
            [
                95,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the latter, you could opt for only investigating the speech of men or women, or speakers from the same or different social classes, or create subcorpora for both, and then compare the language in some way, which makes it possible to carry out corpus-based sociolinguistic analyses on the data, as do the options for restricting speakers to particular education levels, etc.",
        "entities": [
            [
                247,
                259,
                "TERM"
            ]
        ]
    },
    {
        "text": "Looking now more closely at the list of lemmas, we note that among the 3,196 lemmas meeting our inclusion criterion there are 13 lemmas related to weather (this analysis had to be done manually by going through the lemma list): cloud, cold, flood, heat, hot, ice, rain, storm, sun, temperature, warm, weather and wind.",
        "entities": [
            [
                215,
                220,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, in a spoken corpus, who said what is often critical to an analysis: only the markup of utterance boundaries and speaker identities allows us to know this.",
        "entities": [
            [
                91,
                97,
                "TERM"
            ],
            [
                26,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "Typically, these measures take into account frequencies in the whole corpus.",
        "entities": [
            [
                69,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "Phenomena that can be researched with three text archives / Web 1.4.",
        "entities": [
            [
                44,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "This involves manually annotating samples of corpus text as examples of how the new annotation categories should be assigned.",
        "entities": [
            [
                84,
                94,
                "TERM"
            ],
            [
                45,
                51,
                "TERM"
            ],
            [
                52,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "This tool makes it possible to perform a time-aligned annotation with audio or video files, to insert metadata and to have access to the results of the annotation in different formats.",
        "entities": [
            [
                54,
                64,
                "TERM"
            ],
            [
                152,
                162,
                "TERM"
            ],
            [
                102,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "In contrast, the exploratory investigation that we present in our case study employs a corpus-driven approach to directly identify the important discontinuous frames in speech and writing.",
        "entities": [
            [
                87,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "A rhetorically developed text differs in choice of words, order of words, sentence structure, grammatical form, sense implication, and reference.",
        "entities": [
            [
                25,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "Conditional inference trees (CITs) and conditional random forests (CRFs) are gaining popularity in corpus linguistics.",
        "entities": [
            [
                99,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "All other cases are clearly figurative: a taste for excitement in (12a) means 'an experience', instantiating the metaphor experience is taste; transport sb. across the world in (12b) means 'make sb think of a distant location', instantiating the metaphor imaginary distance is physical distance, bulwark of society in (12c) means 'defender of society', instantiating the metaphor defense is a wall, give one's right arm to do sth in (12d) means 'want sth very much', instantiating the metonymy body part for personal value; be within arm's length in (12e) means 'be in close proximity', instantiating the metonymy arm's length for short distance; make sth serve one's aims in (12f) means 'put sth to use in achieving sth', instantiating the metaphor to be used is to serve; cash in in (12g) means 'be successful', instantiating the metaphor life is commercial transaction; hold gun to sb's head in (12h) means 'coerce sb to act', instantiating the metaphor power is physical force; (12j) is from a speech by the Soviet head of state Nikita Khrushchev in which he uses artillery to refer metonymically about nuclear missiles; you told me in (12k) means 'your co-employee told me', instantiating the metonymy employee for company; the superego is soluble in alcohol in (12l) means 'self-control disappears when drunk ', instantiating the metaphor character is a physical substance; balance the books in (12m) means 'make sure debits and credits match', instantiating the metaphor abstract entities are physical entities.",
        "entities": [
            [
                1380,
                1387,
                "TERM"
            ]
        ]
    },
    {
        "text": "This means that spoken and signed texts are not immediately available for inclusion in a corpus, but are transcribed, that is, what is being said or signed is written down according to specific conventions, for example, the conventions of the International Phonetic Association (IPA), which are in turn based on specific writing systems.",
        "entities": [
            [
                89,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "The smallest corpus in the list is CORE.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "If they are not, it is very easy to bracket corpus linguistics together with approaches to language data which, very often, are free of any serious reflection upon the nature of language in the social world.",
        "entities": [
            [
                44,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "Of course, some markup is probably better inserted after a text sample is computerized.",
        "entities": [
            [
                16,
                22,
                "TERM"
            ],
            [
                64,
                70,
                "TERM"
            ],
            [
                59,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "This section is tightly connected with Chapter 11 where we will explain various types of research that builds on these or similar types of annotation systems.",
        "entities": [
            [
                139,
                149,
                "TERM"
            ]
        ]
    },
    {
        "text": "The first one basically gave you a means of designing your own ways of classifying your data in a sensible manner, which then enables you to use the corpus-based analysis methods we've discussed throughout the course in order to extract and count relevant information.",
        "entities": [
            [
                149,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, subsets of the corpus comprising the documents with common agreement can be retrieved, and the rest of the documents can be analyzed.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because many modern-day corpus linguists have been trained as linguists, not statisticians, it is not surprising that they have been reluctant to use statistics in their studies.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Knowing all of this, you isolate this one pronoun type because you are interested in the use of first person pronouns (I, me, we, us).",
        "entities": [
            [
                50,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "These choices we have when using language can really only be investigated through finding ways of expressing this flexibility on the paradigmatic and syntagmatic axes in our corpus searches.",
        "entities": [
            [
                174,
                180,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the period coverage of a study is considerable and a great deal of societal or politico-cultural change has affected language users during that time, it is likely that registers will have gained new features and conventions, developed into other registers, been replaced by new registers, or fallen into oblivion; such shifts affect the comparability of period samples.",
        "entities": [
            [
                340,
                353,
                "TERM"
            ]
        ]
    },
    {
        "text": "An obvious area where a fruitful cross-fertilisation can occur between corpus linguistics and the social sciences relates to data processing and theory.",
        "entities": [
            [
                71,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, this step could involve calculating the number of sentences in the passive voice used in a corpus of journal articles.",
        "entities": [
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "CEA, on the other hand, provided the opportunity to ponder on the notion of error and introduce a higher degree of standardization at each level of the error analysis process: from error identification to error interpretation through error annotation and counting methods.",
        "entities": [
            [
                240,
                250,
                "TERM"
            ]
        ]
    },
    {
        "text": "The high quality of bootstrapping methods in corpus linguistic research may actually be due in part to the slow and cautious pace at which they have been adopted.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "Concordancers generally make it possible to export the data retrieved in text format.",
        "entities": [
            [
                73,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a matter of fact, a larger corpus increases the probability of finding more occurrences of a phenomenon.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "Anyone studying a corpus may like to know the frequency and patterns of use of each item in it.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the sample sentence, in winter is \"thematised,\" and Hoey shows that this phrase when occurring in Theme position collocates in his corpus with the verb be, and with the names of places, again proportionally more frequently than the alternative phrases.",
        "entities": [
            [
                134,
                140,
                "TERM"
            ],
            [
                7,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "That said, it requires more data to be able to make valid observations about a large group of people and a general type of discourse than a small group of people and a specific type of discourse.",
        "entities": [
            [
                115,
                119,
                "TERM"
            ],
            [
                177,
                181,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, once we have extracted and -if necessary -manually cleaned up our data set, we are faced with a problem that does not present itself when studying lexis or grammar: the very fact that affixes do not occur independently but always as parts of words, some of which (like wordform-centeredness in the first sentence of this chapter) have been created productively on the fly for a specific purpose, while others (like ingenuity in the same sentence) are conventionalized lexical items that are listed in dictionaries, even though they are theoretically the result of attaching an affix to a known stem (like ingen-, also found in ingenious and, confusingly, its almost-antonym ingenuous).",
        "entities": [
            [
                156,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "The area of the social sciences that arguably comes closest to some of the methodological concerns of corpus linguistics is demographic studies and the related area of social surveys.",
        "entities": [
            [
                102,
                120,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Section 2, we briefly present eight grammar textbooks (four corpus-informed and four non-corpus-informed); these textbooks are analyzed with a view to finding out the similarities and differences between these two types of materials and to answering the research questions presented in the introduction.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ],
            [
                92,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this chapter, we focus on how to write the 'Methods' and 'Results' sections of a quantitative corpus linguistic paper since the 'Introduction' and 'Discussion' sections are so phenomenon-dependent that, apart from the general guidelines above, they defy easy discipline-specific characterization.",
        "entities": [
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "On top of that, being a monitor corpus, it also makes it possible to track potential changes across different periods in the same way.",
        "entities": [
            [
                24,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "This combination across three dimensions will therefore allow a user to explore the corpus on many different interconnected levels and visualisations.",
        "entities": [
            [
                84,
                90,
                "TERM"
            ]
        ]
    },
    {
        "text": "A corpus can be representative of all the possible linguistic features of a language (covering all possible structures that are part of language user's competence), or it can be representative of all the external or situational variables of different texts that are produced in a given language.",
        "entities": [
            [
                2,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "This was done by filtering out those tweets which did not have the English (en) assigned by Twitter's machine language detection, as time zone and language features, which are used to infer locations. which is annotated in the tweet's metadata.",
        "entities": [
            [
                235,
                243,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, there is simply no space here to give a full account of all the areas of linguistics, and of other fields of study, where the methods of corpus linguistics have been productively applied.",
        "entities": [
            [
                152,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "Besides, it is also necessary to determine which metadata will be associated with each corpus sample.",
        "entities": [
            [
                49,
                57,
                "TERM"
            ],
            [
                87,
                93,
                "TERM"
            ],
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, it should start with a detailed description of the corpus used.",
        "entities": [
            [
                58,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "We then passed from the concordance to close reading of the co-text around occurrences of Mubarak, a very common process in corpus-assisted discourse studies.",
        "entities": [
            [
                24,
                35,
                "TERM"
            ],
            [
                124,
                130,
                "TERM"
            ],
            [
                63,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "This way we can investigate patterns in larger units such as a text.",
        "entities": [
            [
                63,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, though, this would leave us with some very strange 'words' (that superficially look like hyphenated compounds ), them-their and honey-moon-over, in any resulting word-frequency list.",
        "entities": [
            [
                182,
                196,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are many linguistic and technical issues relating to corpus sanitation (e.g., text normalization, orthographic error correction, spelling error correction, real word-error correction, grammatical error correction, punctuation error removal, and tokenization).",
        "entities": [
            [
                59,
                65,
                "TERM"
            ],
            [
                84,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "To do the latter on a subcorpus you've created, you can simply select your corpus from the BNCweb start page from the dropdown list next to where it reads 'Restrictions'.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "Concordance lines and short language samples (e.g., fewer than 25 words) are preferable over larger stretches of text.",
        "entities": [
            [
                113,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "These categories are called the sampling frame.",
        "entities": [
            [
                32,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "So it will be string, and it will be a nominal type of data (all strings are nominal).",
        "entities": [
            [
                47,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each sample was 2,000 words in length, enabling valid comparisons between the different registers in the corpus.",
        "entities": [
            [
                105,
                111,
                "TERM"
            ],
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a particular text is being worked on, a log is maintained that notes what work was done on the text and what work needs to be done.",
        "entities": [
            [
                16,
                20,
                "TERM"
            ],
            [
                98,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "Before opening one or more files for them to be processed with AntConc, we have to make sure that the encoding chosen in AntConc for reading the characters is suitable for reading the file correctly.",
        "entities": [
            [
                102,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "But these texts also tend to be long enough for reasonable quantitative corpus-linguistic analysis.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is also important to note that unlike English, in which different forms of a lemma may have different collocates and semantic prosodies (e.g. consequence vs. consequences), Chinese does not have a rich morphology which can affect collocation and semantic prosody in this way.",
        "entities": [
            [
                233,
                244,
                "TERM"
            ],
            [
                80,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "For languages with other scripts, for example, Cyrillic scripts in many languages of Eastern Europe and Central Asia or various scripts of East Asian languages (Mandarin, Japanese, etc.) corpus builders will either need to use encoding such as Unicode (cf. 5.11) or add a layer of transliteration to the corpus text.",
        "entities": [
            [
                227,
                235,
                "TERM"
            ],
            [
                187,
                193,
                "TERM"
            ],
            [
                304,
                310,
                "TERM"
            ],
            [
                311,
                315,
                "TERM"
            ]
        ]
    },
    {
        "text": "These techniques include frequency profiling: listing all of the words (types) in the corpus and how frequently they occur, and concordancing: listing each occurrence of a word (token) in a corpus along with the surrounding context.",
        "entities": [
            [
                86,
                92,
                "TERM"
            ],
            [
                190,
                196,
                "TERM"
            ],
            [
                178,
                183,
                "TERM"
            ]
        ]
    },
    {
        "text": "The database contains potentially relevant information about text categories under two headings: Document type contains information about \"the format, genre, or other characteristics of the document\", and Publication section allows users to limit searches to a specific section of the publication.",
        "entities": [
            [
                106,
                110,
                "TERM"
            ],
            [
                61,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "This raises the question as to why corpus creators go to the trouble of attempting to create representative corpora at all, and why some corpora seem to be more successful attempts than others.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if we observe that a node word almost always occurs after an adjective -even if no single adjective co-occurs frequently enough with the node to be considered a collocate -we could say that the category of adjective is a colligate of that node.",
        "entities": [
            [
                34,
                38,
                "TERM"
            ],
            [
                150,
                154,
                "TERM"
            ],
            [
                252,
                256,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, the notion \"hapax\" is only an operational definition for neologisms, based on the hope that the number of hapaxes in a corpus (or sub-corpus) is somehow indicative of the number of productive coinages.",
        "entities": [
            [
                128,
                134,
                "TERM"
            ],
            [
                143,
                149,
                "TERM"
            ]
        ]
    },
    {
        "text": "This part begins with chapters on the corpus-based description of spoken English, written academic English, and patterns of variation (synchronic and diachronic) among a wider range of spoken and written registers.",
        "entities": [
            [
                38,
                50,
                "TERM"
            ],
            [
                150,
                160,
                "TERM"
            ],
            [
                135,
                145,
                "TERM"
            ]
        ]
    },
    {
        "text": "Our main argument was that the recent trends and advances in the field, such as the publication of big-data corpora, the increased reliance on statistical approaches to linguistic data, and the exploitation of various kinds of metadata, require that the linguist should have a detailed understanding of the structure of the corpus, its sampling procedure, and the principles followed in the construction of the metadata.",
        "entities": [
            [
                227,
                235,
                "TERM"
            ],
            [
                411,
                419,
                "TERM"
            ],
            [
                324,
                330,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, for handwritten data, there is no solution other than to manually type it on the computer.",
        "entities": [
            [
                75,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "Indeed, it is no exaggeration to say that corpus linguistics using large computer-readable language data has established itself as the main methodology in historical pragmatics.",
        "entities": [
            [
                42,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "The text on the online page is editable, so you can also delete the u and see whether the quantification using the question mark still works, or even try some of your own words, if you know any other differences in spelling that relate to one character only.",
        "entities": [
            [
                4,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "For each category that we discuss, sample clusters of tweets are provided in order to illustrate the contrast between the contact-related use -the target of our analysis -and the noise that we identified along the way.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "The decision of the classification for each of these tokens from the corpora does require some subjective decision-making from the researcher, as is the case in many corpus studies.",
        "entities": [
            [
                166,
                172,
                "TERM"
            ]
        ]
    },
    {
        "text": "Elements, in their most basic form, are generally represented in markup languages by pairs of opening and closing angle brackets, i.e. < & >, with the name of the element appearing in between the two.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpus linguistics (and the social sciences more generally), hypotheses of this type are the exception rather than the norm -we are more likely to deal with statements about tendencies (think Most swans are white or Most examples of windscreen are British English), where the search for counterexamples is not a viable research strategy.",
        "entities": [
            [
                3,
                21,
                "TERM"
            ],
            [
                83,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "Exercise 6 has hopefully already alerted you to the fact that it isn't easily possible to just use any document that we can read in some way on the computer equally well as a source for our corpus-linguistic analysis, simply because it contains text.",
        "entities": [
            [
                190,
                196,
                "TERM"
            ],
            [
                245,
                249,
                "TERM"
            ]
        ]
    },
    {
        "text": "This corpus was collected and transcribed in 2012 and includes 50 interactions between registered nurses working at a US hospital and standardized patients (SPs).",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "An annotation is reliable if two annotators produce convergent annotations or if the same annotator produces convergent annotations at two different times.",
        "entities": [
            [
                3,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some countries also recognise the concept of fair use, which allows relatively insubstantial parts of copyrighted materials to be used for purposes such as research, education, review, etc. (Wikipedia: Fair Use), although, in practice, this will probably not allow you to include sufficient amounts of text or other materials in your corpus.",
        "entities": [
            [
                334,
                340,
                "TERM"
            ],
            [
                302,
                306,
                "TERM"
            ]
        ]
    },
    {
        "text": "Their frequency in that text is also shown.",
        "entities": [
            [
                24,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the study makes use of existing corpora, the possibility of investigating a certain question or not, or the manner in which it can be operationalized, depends on the characteristics of the corpus.",
        "entities": [
            [
                192,
                198,
                "TERM"
            ]
        ]
    },
    {
        "text": "Based on a comparison of our value (32.69) with the distribution, we can make a judgement about the statistical significance (pvalue) of the result.",
        "entities": [
            [
                100,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "A method for comparing use of collocations in translated and non-translated texts was applied to two monolingual comparable corpora of texts from the same domain and in the same language (finance/English) but varying in size and genre (a largish corpus of financial reports and a tiny corpus of shareholders' letters).",
        "entities": [
            [
                246,
                252,
                "TERM"
            ],
            [
                285,
                291,
                "TERM"
            ]
        ]
    },
    {
        "text": "Within a text, some words may be restricted to particular sections, which is also useful to know.",
        "entities": [
            [
                9,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such results can only be obtained by dense corpus studies allowing us to detect relatively rare phenomena such as passive constructions.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpora available range from a corpus of American English, the Corpus of Contemporary American English (COCA), to the Coronavirus Corpus, a corpus containing texts retrieved from the Web containing discussions of the Covid-19 virus.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ],
            [
                144,
                150,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, in the case of speech versus writing, we might propose a corpus that is 50 per cent spoken and 50 per cent written data (this is, in fact, the design of the International Corpus of English, ICE).",
        "entities": [
            [
                71,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "For Kindlemma, there are: Kindfreq (numeric, z-transformed), which encodes the lemma frequency; Kindgender (binary), which encodes the grammatical gender of the kind noun; Kindattraction (numeric, z-transformed), which encodes the influence of neighbouring constructions.",
        "entities": [
            [
                79,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "They offer an opportunity to look inside each diachronic sampling point and analyse variation between individual texts in the historical period.",
        "entities": [
            [
                46,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another distinguishing feature is that it is open to contributions by third parties, who can submit new material for inclusion in the corpus.",
        "entities": [
            [
                134,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we turn to the Wikipedia entries, we scan them, strsplit them into words, and create a sorted frequency list.",
        "entities": [
            [
                97,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "According to our design criteria and our generalised corpus-building scheme, we select and collect texts carefully following considerations of representativeness.",
        "entities": [
            [
                143,
                161,
                "TERM"
            ],
            [
                53,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some tools (e.g. the online XML and spreadsheet editor GitDox, Zhang and Zeldes 2017) are opting for online storage on GitHub and similar platforms as their exclusive file repository.",
        "entities": [
            [
                28,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, though, as useful as AntConc is for most purposes, since it's a stream-based concordancer it'll ignore all line breaks and match more than we want to see in our concordance, so using it here is not an option.",
        "entities": [
            [
                92,
                104,
                "TERM"
            ],
            [
                176,
                187,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the corpus has been annotated, this command also makes it possible to search for grammatical categories, speech acts or even errors.",
        "entities": [
            [
                7,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because the formatting and linking capabilities offered by HTML were not always sufficient for all needs in document handling, and SGML proved too unwieldy and error-prone, a new hypertext format, XML (eXtensible Markup Language) Version 1.0, was eventually created and released by the W3C (World Wide Web Consortium) in 1998.",
        "entities": [
            [
                197,
                200,
                "TERM"
            ]
        ]
    },
    {
        "text": "It also includes a much broader range of written text categories than previous corpora, including not just edited writing but also student writing and letters.",
        "entities": [
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "A corpus of 100-articles would suffice for meeting a hypothetical 85% threshold for a list of 750 words, and that level of reliability could be achieved even for a full 1,000 words with corpora of ≥ 200-articles.",
        "entities": [
            [
                2,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "It only means that they did not have an opportunity to produce them in the corpus.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, studies that attempt such segmentation currently require a combination of top-down and bottom-up approaches, using models from previous literature but making modifications based on the actual corpus in question.",
        "entities": [
            [
                198,
                204,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us assume that we find 67 hits in the female-speaker sample and 71 hits in the male-speaker sample to be such sentences.",
        "entities": [
            [
                57,
                63,
                "TERM"
            ],
            [
                96,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although it's of course somewhat easier to confine our corpus-based investigation to single lexical items, single words and their frequencies aren't the only interesting things we may want to analyse with the help of corpora.",
        "entities": [
            [
                55,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "At the time of creation, the NC was the first corpus of conversational narratives to be annotated, so there was no established practice to follow regarding what analytical categories to annotate.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "You are interested to see content words around the node rather than frequent grammatical words.",
        "entities": [
            [
                51,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let me finally very briefly mention the package xml2, which is useful to avoid the XML package's memory leak on Windows.",
        "entities": [
            [
                83,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "It has been argued that an explanation for cooccurrence of lexeme and structure may sometimes be found in the more extensive co-text.",
        "entities": [
            [
                128,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "Paste the data from the general subcorpus into the cells below rank_g, 'type', and freq_g, and the other data into the corresponding rows rank_n, type_n, and freq_n, for now leaving the cells in between the sets empty.",
        "entities": [
            [
                72,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "The starting point for research is the corpus itself, in order to be able to infer usage rules from its content.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "Our analysis also allows for a degree of uncertainty, as the annotation targets the predominant use in a cluster.",
        "entities": [
            [
                61,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "Linguistic annotation varies from corpus to corpus as well.",
        "entities": [
            [
                11,
                21,
                "TERM"
            ],
            [
                34,
                40,
                "TERM"
            ],
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "The integrity and representativeness of complete artefacts is far more important than the difficulty of reconciling texts of different dimensions.",
        "entities": [
            [
                18,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "Those compiling spoken corpora should therefore expect to gather much more speech than they will actually use to compensate for all the recordings they make that contain imperfections preventing their use in the ultimate corpus being created.",
        "entities": [
            [
                221,
                227,
                "TERM"
            ]
        ]
    },
    {
        "text": "The annotations are called 'tags' because they are appended to corpus words, as shown in example (7.5) from the Brown corpus.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ],
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "Despite its limitations, bootstrapping can provide a wealth of information about the distribution of a sample.",
        "entities": [
            [
                103,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "This may for example happen when the corpus is in a language that uses a different alphabet from the standard Western European ones that are supported on all computers by default.",
        "entities": [
            [
                37,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "The double quotes around the 1 and 2 indicate that these are now understood as character strings, which also means you cannot use them for calculations anymore (unless you change their data type back using as.numeric).",
        "entities": [
            [
                190,
                194,
                "TERM"
            ]
        ]
    },
    {
        "text": "This fully corpus-driven approach is rather resource-intensive, yet is theoretically important because it makes it possible to account for frequent discontinuous sequences of words that are not associated with a moderately frequent lexical bundle.",
        "entities": [
            [
                11,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "The review is in two main parts: the first part outlines work on quantitative methods in corpus linguistics to serve as a context for the second, which deals with the cluster analytic work specifically.",
        "entities": [
            [
                89,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, in the Littéracie avancée corpus, the five most frequent cooccurrences to the right of the word avis are avis sur, which appears 11 times and then avis et (six times), avis de (five times), avis divergent (four times) and avis des (three times).",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this will have the unfortunate consequence of skewing a lexical analysis of the corpus in which this utterance occurs, since all instances of the, police, and boat will be counted twice.",
        "entities": [
            [
                89,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus only shows you the result of the speakers' production, but not what led to these results.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "UDPipe uses two models that facilitate the tagging process and improve the overall accuracy by employing different classification feature sets.",
        "entities": [
            [
                43,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "This library is used to parse HTML files and extract plain text.",
        "entities": [
            [
                59,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another solution, which keeps the structural and discourse units of a text together even more, is to divide the text into its paragraphs, or multi-paragraph chunks.",
        "entities": [
            [
                70,
                74,
                "TERM"
            ],
            [
                112,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "As from the operationalization phase, it is also important to choose the corpus on which the study will be carried out.",
        "entities": [
            [
                73,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "This corpus contained one million words of edited written American English divided into 500 samples representing different types of writing (such as fiction, technical prose, and newspaper reportage).",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "When selecting the sampling frame we are often predisposed to see as salient the text types that have traditionally been included in language corpora such as those in the Brown family sampling frame (see • Legal considerations bias: corpus designers often face the problem of copy- right; this is especially the case when corpus creators want to share their corpora with other researchers.",
        "entities": [
            [
                19,
                33,
                "TERM"
            ],
            [
                184,
                198,
                "TERM"
            ],
            [
                233,
                239,
                "TERM"
            ],
            [
                322,
                328,
                "TERM"
            ],
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "By wrapping our text in the container element, we've effectively created the first (top) level of a hierarchy or categorisation, as well as a file that is now, at least technically, valid XML, despite the fact that it hasn't been sub-divided into meaningful parts yet.",
        "entities": [
            [
                16,
                20,
                "TERM"
            ],
            [
                188,
                191,
                "TERM"
            ]
        ]
    },
    {
        "text": "Renouf and Sinclair then point out that the frequency of these items in the collocational framework does not correspond to their frequency in the corpus as a whole, where, for example, man is the most frequent of their twenty words, and lot is only the ninth-most frequent.",
        "entities": [
            [
                146,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a result, nearly all concordancers and corpus linguistic tools will offer some assistance in the calculation of keyness.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "Users of the corpus will therefore be able to study the development over time of both individual words as well as a variety of different syntactic structures.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "While the chapters mostly concentrate on English corpora, many of the themes are relevant from a general corpus-linguistic point of view.",
        "entities": [
            [
                105,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "To get samples of roughly equal size for expository clarity, let us select every sixth case of the of -possessive, giving us 25 cases (note that in a real study, there would be no good reason to create such roughly equal sample sizes -we would simply use all the data we have).",
        "entities": [
            [
                221,
                227,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will then review the different types of annotations we can add to a corpus, briefly present some tools for performing some annotations automatically or for making manual annotations easier.",
        "entities": [
            [
                71,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "If a corpus samples only certain sections, e.g. by taking the first or the last 2,000 words of each text, these sections will be overrepresented.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ],
            [
                100,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "But most importantly, as discussed above, the issue of representativeness needs to be addressed before a corpus, regardless of size, can be considered appropriate for a given study.",
        "entities": [
            [
                55,
                73,
                "TERM"
            ],
            [
                105,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "In our case study, we illustrated how this distinction is not absolute: some previous studies of discontinuous lexical frames (like Biber 2009 and Ro ¨mer 2010) are intermediate along this continuum, beginning with a corpus-driven approach to identify a set of continuous lexical sequences, but carrying out the corpus-based investigation of only those sequences, to analyze the extent to which they occur as discontinuous frames.",
        "entities": [
            [
                217,
                230,
                "TERM"
            ],
            [
                312,
                324,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you still want to retain the original list without pruning, though, you can use a little trick and simply add a # symbol in front of the number indicating the rank, and when you later save the list as text, all lines marked thus will be excluded from the analysis when you use it in AntConc.",
        "entities": [
            [
                204,
                208,
                "TERM"
            ]
        ]
    },
    {
        "text": "The implementation of a corpus in the field of linguistics has grown rapidly over the decades.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Style sheet languages come in different flavours for different markup languages, namely DSSSL for SGML, CSS 1, 2 & 3 for HTML, and both CSS & XSL for XML.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ],
            [
                150,
                153,
                "TERM"
            ]
        ]
    },
    {
        "text": "Between 2002 and 2006, although researchers still cited corpus-based grammar references for their studies (e.g., Cambridge Grammar of the English Language), one group of researchers made use of newly developed datasets, both large or small, such as The CHILDES Corpus, Wordnet, and A New Academic Word List.",
        "entities": [
            [
                56,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "The question of representativeness is therefore essential so that a corpus can be used for answering a research question.",
        "entities": [
            [
                16,
                34,
                "TERM"
            ],
            [
                68,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are many applications of the principles and methods of bootstrapping that need to be further explored by corpus researchers.",
        "entities": [
            [
                111,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "A prototypical example of this would be a Twitter corpus that has been collected over a number of months or years.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most corpora use Standard Generalized Markup Language (SGML), Text Encoding Initiative (TEI), or Extensible Markup Language (XML) to have a unified structural markup system.",
        "entities": [
            [
                159,
                165,
                "TERM"
            ],
            [
                125,
                128,
                "TERM"
            ]
        ]
    },
    {
        "text": "Write three 5-gram sequences in English that you think may have a chance of being repeated more than once in a corpus.",
        "entities": [
            [
                111,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to make feature frequencies more comparable across text lengths, Liimatta (2020) proposes a family of methods called lengthwise scaling.",
        "entities": [
            [
                60,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is also important to be able to export annotations in a standardized format, based on the XML language, for example.",
        "entities": [
            [
                93,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is no alternative to knowing your corpora, this cannot be done more easily, and any concordance programs that come with more refined search options also require you to thoroughly consider the format of the corpus files even if their interface 'hides' such decisions behind clickable buttons with smiling corpus linguists on them, in settings, or in .ini files.",
        "entities": [
            [
                90,
                101,
                "TERM"
            ],
            [
                212,
                218,
                "TERM"
            ],
            [
                310,
                316,
                "TERM"
            ]
        ]
    },
    {
        "text": "The aim of this work is to spot the patterns of linguistic variation among registers in a corpus of English texts.",
        "entities": [
            [
                90,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "The major idea here is to avoid massive skewing in results by over-representing just a single or very few text types.",
        "entities": [
            [
                106,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, we may also sometimes want to look at the least frequent words first, assuming that they can possibly tell us something very specific about the terminology used, for instance in a highly technical text that contains a number of specialised words.",
        "entities": [
            [
                206,
                210,
                "TERM"
            ]
        ]
    },
    {
        "text": "As mentioned above, concordance lines highlight the word you pick and provide additional text around it.",
        "entities": [
            [
                20,
                31,
                "TERM"
            ],
            [
                89,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "AntConc uses a different concept of 'word' from BNCweb, based on the token definitions you've chosen, and may thus throw an error when it encounters something that doesn't fit this definition, aborting the keyword list comparison.",
        "entities": [
            [
                206,
                213,
                "TERM"
            ],
            [
                69,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "The differences seen in the rates of samurai in named entities potentially also reflect some cultural differences and the interests of the writers represented in the corpus: the named entities including samurai in the GB and US sections included more references to drama films (The Seven Samurai, The Last Samurai), the Asian sections featured references to food-related items, computer software (Market Samurai, a keyword research tool), action toy figures (Samurai Predator AC-01).",
        "entities": [
            [
                415,
                422,
                "TERM"
            ],
            [
                166,
                172,
                "TERM"
            ]
        ]
    },
    {
        "text": "The authors therefore coded every occurrence according to the type of process described: previous or past.",
        "entities": [
            [
                62,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is no node word and no directional influence, and the purpose is not to find out more about an individual word.",
        "entities": [
            [
                12,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "But this is not true for all written text, for example, text messages may be formulated fairly quickly and without much planning.",
        "entities": [
            [
                37,
                41,
                "TERM"
            ],
            [
                56,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "Much work has gone into developing efficient annotation strategies for differentiating items belonging to named entities from those representing regular uses of the words.",
        "entities": [
            [
                45,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "This first official type of markup language, however, as we'll see further below, was relatively complex and also had a number of serious drawbacks.",
        "entities": [
            [
                28,
                43,
                "TERM"
            ],
            [
                20,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order for the results to be replicable, corpus linguists need to make their choice of corpora and analytical techniques transparent.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "The process of analyzing a completed corpus is in many respects similar to the process of creating a corpus.",
        "entities": [
            [
                37,
                43,
                "TERM"
            ],
            [
                101,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, if the corpus is to be used primarily for grammatical analysis (e.g. the analysis of relative clauses or the structure of noun phrases), the corpus can consist simply of text excerpts rather than complete texts, and will minimally need part-of-speech tags.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ],
            [
                155,
                161,
                "TERM"
            ],
            [
                184,
                188,
                "TERM"
            ]
        ]
    },
    {
        "text": "The idea behind this sampling frame was to ensure that the corpus contained samples of speech representing the ways that people speak in different regions of the country and in different contexts.",
        "entities": [
            [
                21,
                35,
                "TERM"
            ],
            [
                59,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "In corpus linguistics the most useful ones are: mean, median and 20% trimmed mean.",
        "entities": [
            [
                3,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this encoding does not correspond to text files containing French characters, because of accented characters.",
        "entities": [
            [
                14,
                22,
                "TERM"
            ],
            [
                46,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "When you look at journal articles reporting on corpus linguistic studies where researchers are using multiple regression, you will see many ways to describe it.",
        "entities": [
            [
                47,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to determine whether the BNC can be considered a balanced corpus with respect to Speaker Sex, we can compare this observed distribution of speakers to the expected one more or less exactly in the way described in the previous sections except that we have two alternative ways of calculating the expected frequencies.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "Speech act participants (the first and second person) are significantly more likely to be expressed by a pronoun, and the first person even more so, as seen in node 10.",
        "entities": [
            [
                160,
                164,
                "TERM"
            ]
        ]
    },
    {
        "text": "What the checklist reveals is that some corpus-based information is rather coherent across the various books (get-passives are rare and are more commonly found in speech; agentless passives are more frequent than passives with by-agent, etc.).",
        "entities": [
            [
                40,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to illustrate some of the concepts in doing a situational and linguistic analysis along with a functional interpretation, we will refer to a small corpus of English as Second-Language writers who were asked to produce problem-solution paragraphs in two different conditions.",
        "entities": [
            [
                156,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the residence history on the biographical form is unclear, it is also possible to interview the individual afterwards, provided that he or she can be located; if the individual does not fit the criteria for inclusion, his or her text can be discarded.",
        "entities": [
            [
                232,
                236,
                "TERM"
            ]
        ]
    },
    {
        "text": "Should these standards be lacking, it would be a good idea to consider the annotation schemes used in previous studies.",
        "entities": [
            [
                75,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "In sum, there are compelling arguments to include type frequencies from theoretical considerations as well as from neighboring disciplines such as psycholinguistics or computational linguistics, and there are promising first results within corpus linguistics proper, but more exploration is definitely required.",
        "entities": [
            [
                240,
                258,
                "TERM"
            ],
            [
                50,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "This means that the probability of a given word occurring at some point in a text is influenced by the words that have occurred before and thus the words in a corpus are not random.",
        "entities": [
            [
                159,
                165,
                "TERM"
            ],
            [
                77,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "If possible, try to create a corpus that can be published freely under an open license.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "The data collection mode makes this corpus unsuitable for many types of research but provides a very useful interface for lexical searches, offering the possibility of looking for simple or compound words and having access to all the occurrences within the context, with an indication of the source for each occurrence.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "By bias we mean a systematic but often hidden deviation of the sample from the population.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "A by-product of this exercise is, of course, that you should now also have a number of Word and PDF documents that you can extract some text from later.",
        "entities": [
            [
                136,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "Studies are needed that do not just analyze text corpora but which involve the authors or the readers of the texts in the analysis by also collecting interview data.",
        "entities": [
            [
                44,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "It overestimates statistical significance (type I error) in cases where there is no real difference and the variation is purely due to chance; the type I error rates (false hits) ranged from 48 to 99% depending on the linguistic feature investigated.",
        "entities": [
            [
                17,
                41,
                "TERM"
            ],
            [
                43,
                47,
                "TERM"
            ],
            [
                147,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unlike the corpus-driven approaches illustrated in this book, more advanced corpus-driven register studies have identified co-occurring linguistic features that have emerged through corpus analyses.",
        "entities": [
            [
                11,
                24,
                "TERM"
            ],
            [
                76,
                89,
                "TERM"
            ],
            [
                182,
                188,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a nutshell, bigram types are first obtained from the corpora of translated and non-translated texts used for the study; they are then matched with frequency and Mutual Information data obtained from a reference corpus of English, and ranked according to these data.",
        "entities": [
            [
                204,
                220,
                "TERM"
            ]
        ]
    },
    {
        "text": "The shift of focus from morphosyntax to lexis and discourse has proved to be particularly fruitful for the analysis of advanced interlanguage.",
        "entities": [
            [
                40,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "We should also consider which words would get highlighted as keywords had we chosen a different reference corpus.",
        "entities": [
            [
                96,
                112,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter highlights genre categorizations as a pitfall at the intersection of corpus linguistics and literature and problematizes the use of the genre category tag from the perspectives afforded by both fields.",
        "entities": [
            [
                82,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "The following code extracts the Kindlemma random intercept for item 99, which is -0.159 for the lemma Wasser 'water'.",
        "entities": [
            [
                96,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, the dispersion of a collocation across a reference corpus had only a weak relationship with knowledge (more widely spread collocations were better recognized), and this relationship was significant only in the BNC.",
        "entities": [
            [
                50,
                66,
                "TERM"
            ],
            [
                29,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "By doing this, we can have a better view of the multilayered nature of the corpus.",
        "entities": [
            [
                75,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, the bigger the size of a corpus, the more is its utility, faithfulness, and reliability.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "Especially where the body of historical data is finite, disparate and severely biased, or where a corpus is to be used to study change over very long time periods, this is a perfectly defendable strategy.",
        "entities": [
            [
                98,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "Random effects reflect a random sample of the population we are interested in, for instance, a particular group of speakers from a population of all speakers, or a handful of texts from all texts that could be produced.",
        "entities": [
            [
                32,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "Please bear in mind, though, that for the former type of exercise, simply following the steps blindly without trying to understand why you're doing them will not allow you to learn properly.",
        "entities": [
            [
                49,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then, DP is computed like this: Simplifying a bit, DP ranges from 0 (a word is perfectly evenly distributed in the corpus, i.e., in accordance with the sizes of the corpus files) to 1 (a word is completely unevenly distributed in the corpus).",
        "entities": [
            [
                115,
                121,
                "TERM"
            ],
            [
                165,
                171,
                "TERM"
            ],
            [
                234,
                240,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the ICE Project, such incomplete utterances are given an orthographic spelling that best reflects the pronunciation of the incompletely uttered word, and then the incomplete utterance is enclosed in markup, <.> i </.>, that labels the expression as an instance of an incomplete word.",
        "entities": [
            [
                202,
                208,
                "TERM"
            ]
        ]
    },
    {
        "text": "When the sociological information about the speakers in a corpus is known, it is very easy to use this for comparing the productions of different categories of speakers such as men and women, people from different age groups, from different socio-economic backgrounds, etc.",
        "entities": [
            [
                58,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "Language documentation shares with corpus linguistics the basic goal of representativeness.",
        "entities": [
            [
                35,
                53,
                "TERM"
            ],
            [
                72,
                90,
                "TERM"
            ]
        ]
    },
    {
        "text": "As opposed to earlier LCR studies that did not include any statistics, most current studies now follow the general trend in corpus linguistics by providing some sort of statistical analysis.",
        "entities": [
            [
                124,
                142,
                "TERM"
            ]
        ]
    },
    {
        "text": "Furthermore, XML can not only be used in conjunction with CSS, but also has its own stylesheet language XSL, which far exceeds the capabilities of CSS in that it also provides mechanisms for transforming documents from XML into other forms of XML, as well as various other types of formats, for display and processing.",
        "entities": [
            [
                13,
                16,
                "TERM"
            ],
            [
                219,
                222,
                "TERM"
            ],
            [
                243,
                246,
                "TERM"
            ]
        ]
    },
    {
        "text": "In fact, interpreting other people's utterances, as we must do in corpus linguistic research, may actually lead to more intersubjectively stable results, as interpreting other people's utterances is a more natural activity than interpreting our own: the former is what we routinely engage in in communicative situations, the latter, while not exactly unnatural, is a rather exceptional activity.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "We will discuss this topic in Chapter 6, which is devoted to the methodological principles underlying the construction of a corpus.",
        "entities": [
            [
                124,
                130,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once the corpus is created and annotated, the most crucial part will be using the corpus for analysis.",
        "entities": [
            [
                9,
                15,
                "TERM"
            ],
            [
                82,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "Instead, the aim is to provide an overview of the main approaches to the problem and a discussion of the methods that are most often used and / or seem to the author to be most intuitively accessible and effective for corpus linguists.",
        "entities": [
            [
                218,
                224,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, a paragraph with the number 5 may be represented as <p n=\"5\">…</p>, where the ellipsis (…) stands for the text contained inside it, or as <para n=\"5\">…</para> or even <paragraph n=\"5\">…</paragraph>, if you want to be even more explicit about it being a paragraph.",
        "entities": [
            [
                117,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, random slopes (for situations where fixed effects vary per group) and multilevel models (for situations where group-wise tendencies can be predicted from other variables, for example when lemma frequency is useful to predict lemmaspecific tendencies) are also introduced.",
        "entities": [
            [
                197,
                202,
                "TERM"
            ]
        ]
    },
    {
        "text": "For expository reasons, let us distinguish between the rank value and the rank position of a data point: the rank value is the ordinal value it received during annotation (in our case, its value on the Animacy scale), its rank position is the position it occupies in an ordered list of all data points.",
        "entities": [
            [
                160,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if frequency counts are derived from a large representative corpus such as the British National Corpus (BNC), we may reasonably claim that high frequency words in the corpus may also have a similarly high usage in the language.",
        "entities": [
            [
                73,
                79,
                "TERM"
            ],
            [
                180,
                186,
                "TERM"
            ]
        ]
    },
    {
        "text": "Speaking meaningfully about corpus frequencies is not straightforward.",
        "entities": [
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "All XML documents minimally have to be well-formed, that is, no overlapping tags (as in HTML, e.g. <b>…<i>…</b>…</i>) are allowed.",
        "entities": [
            [
                4,
                7,
                "TERM"
            ]
        ]
    },
    {
        "text": "This corpus contains 400,000 words of spoken English from ICE-GB and an additional 400,000 spoken words from the London-Lund Corpus, a corpus that was based on texts recorded between 1960 and 1980.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ],
            [
                135,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "In short, corpus linguists were grouped into the same category as the structuralists -\"behaviorists\"that Chomsky had criticized in the early 1950s as he developed his theory of generative grammar.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Lists of high-frequency names are often used when designing automatic taggers, which might account for the fact that with names of lower frequencies, the tagging of white in names appears less systematic.",
        "entities": [
            [
                154,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a broad sample of the English language in general, it is suited to many different research aims.",
        "entities": [
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if you type in the word baby, you will see that it occurs over 60,000 times in the COCA corpus.",
        "entities": [
            [
                101,
                107,
                "TERM"
            ],
            [
                20,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "The final corpus-pragmatic work that we examine here is Ru ¨hlemann's (2007) unique study of the conversational subcorpus of the BNC.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, this type of test can be used in studies seeking to find out whether advanced learners produce significantly more discourse connectives than intermediate learners, or whether speakers produce more fallacious arguments when speaking at political party meetings or at electoral campaigns.",
        "entities": [
            [
                18,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "Look at your 100-item sample in each of the two registers and determine whether they are always at the beginning of a sentence or utterance.",
        "entities": [
            [
                22,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "Without access to tagged corpora, advanced programming and statistical knowledge, your corpusdriven research will be limited to focusing on word lists, keyword analyses, and n-grams.",
        "entities": [
            [
                152,
                159,
                "TERM"
            ]
        ]
    },
    {
        "text": "The present chapter begins by situating corpus stylistics within the context of corpus linguistics (Section 1) and computational stylistics (Section 2).",
        "entities": [
            [
                80,
                98,
                "TERM"
            ],
            [
                40,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, it is a good environment for adding annotations to a text, it has excellent multimedia capabilities, and it is XML-compatible.",
        "entities": [
            [
                66,
                70,
                "TERM"
            ],
            [
                124,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, privacy rights require corpus compilers to anonymise the disseminated data (cf. Chap. 1): while this is easily achieved in the transcriptions, where references to people and places can be removed, complete anonymization in audio files, i.e. the changing of the voice quality, would run counter and make impossible many research purposes of the corpus.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ],
            [
                354,
                360,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus was also divided into two sub-corpora: one consisting of collaboratively written essays (N = 51) and another consisting of individual essays (N = 102).",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "A typical example of this type of data is the corpus that contains newspaper archives or parliamentary debates.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ],
            [
                26,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "In multilingual translation projects, there are also cases where there is no single \"source\" text, as translators translate a given text while accessing some of its already available translations (e.g. when confronted with an ambiguous passage).",
        "entities": [
            [
                93,
                97,
                "TERM"
            ],
            [
                132,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "As I mentioned above, there exists recurring confusion regarding the distinction between annotation and markup.",
        "entities": [
            [
                89,
                99,
                "TERM"
            ],
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "They use a corpus to find out how these individual features vary across contexts/registers.",
        "entities": [
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given the wealth of speech that exists, as well as the logistical difficulties involved in recording and transcribing it, collecting data for the spoken part of a corpus is much more labor-intensive than collecting written samples.",
        "entities": [
            [
                163,
                169,
                "TERM"
            ]
        ]
    },
    {
        "text": "Upon closer inspection, however, it turns out that this type in most instances in both corpora in fact represents a typo, that is, the misspelt form of will, or in the science writing a mis-categorisation of the nominalised form of the verb wilt in two cases.",
        "entities": [
            [
                56,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "The header section contains metadata, a description of the file, the encoding, the text profile, mainly the language, the context or participants, and even a history of its revisions.",
        "entities": [
            [
                69,
                77,
                "TERM"
            ],
            [
                28,
                36,
                "TERM"
            ],
            [
                83,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "These corpora must also contain diachronic information, for example regarding the evolution of pronunciation from the second half of the 20th Century to the present day.",
        "entities": [
            [
                32,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "Due to these levels, it was claimed that corpus linguists give more importance to descriptive adequacy while generative grammarians focus on explanatory adequacy.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now, while of course it's generally not possible for us to directly change the design of any corpus tools we may be using to allow us to deal with this issue, we at least ought to bear this 'handicap' in mind in many of our analyses, and see whether at least some of the tools allow us to avoid any of these problems, or whether we may be able to find a way to work around certain issues by manipulating our data ourselves in simple ways.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "One of the major issues we've repeatedly encountered, especially concerning the mega corpora we've worked with, is that the creation of large-scale resources may frequently lead to the compilers taking shortcuts when it comes to ensuring the quality of the data in terms of tokenisation and annotation.",
        "entities": [
            [
                291,
                301,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the second part of the study, Granger and Lefer (2012) used the English part of the Label France translation corpus to identify frequent translation equivalents of two lexical bundles, i.e. de plus en plus (de) and sur le plan (de), and compare corpus-derived translation equivalents with those found in three French-English bilingual dictionaries: RC, HO, and the Larousse French-English Dictionary (LA).",
        "entities": [
            [
                112,
                118,
                "TERM"
            ],
            [
                248,
                254,
                "TERM"
            ]
        ]
    },
    {
        "text": "Therefore, we can furnish a general corpus with standard text samples of contemporary writings and a calculated and proportional representation of texts can suffice our requirement.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ],
            [
                57,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "Free software such as VocabProfile online (www.lexutor.ca/vp) or AntWordProfiler offline (www.antlab.sci.waseda.ac.jp/) allows a teacher to input a text which is then returned with the lexis color-coded according to the frequency of each word in the BNC or COCA corpus.",
        "entities": [
            [
                262,
                268,
                "TERM"
            ],
            [
                185,
                190,
                "TERM"
            ],
            [
                148,
                152,
                "TERM"
            ]
        ]
    },
    {
        "text": "Just as most corpus-linguistic work has been done on English, this chapter has so far also been rather Anglo/ASCII-centric.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, they are part of the text, they cannot simply be removed, as this may reduce the context or even render the text illegible.",
        "entities": [
            [
                40,
                44,
                "TERM"
            ],
            [
                127,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "LCR as a field only emerged and became visible in the course of the 1990s in the context of the popularization of corpus linguistics at large but has rapidly evolved and grown in scope and sophistication over the past four decades.",
        "entities": [
            [
                114,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "Deignan studies this potential difference systematically based on a sample of more than 1500 hits for flame/s in the Bank of English (a proprietary, non-accessible corpus owned by HarperCollins), from which she manually extracts all 153 metaphorical uses.",
        "entities": [
            [
                164,
                170,
                "TERM"
            ],
            [
                68,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "After identifying and reviewing four major pitfalls and suggesting possible ways of avoiding them, it is possible to offer some preliminary conclusions about the usefulness of the British Library Newspapers database for corpus linguistic research.",
        "entities": [
            [
                220,
                226,
                "TERM"
            ]
        ]
    },
    {
        "text": "The particular information collected will very much depend on the kind of corpus being created and the variables that future users of the corpus will want to investigate.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ],
            [
                138,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is especially important not to look at just the beginning of a concordance, as these early concordance lines may present examples from the early part of the corpus, which is not necessarily representative of the corpus as a whole.",
        "entities": [
            [
                66,
                77,
                "TERM"
            ],
            [
                94,
                105,
                "TERM"
            ],
            [
                160,
                166,
                "TERM"
            ],
            [
                215,
                221,
                "TERM"
            ]
        ]
    },
    {
        "text": "In their second case study, Biber et al. created different data sets with, therefore, known distributions of target words across different numbers of corpus parts, but the bottom line of this more controlled case study is in fact the same as that of the first.",
        "entities": [
            [
                150,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, Cowden-Clarke (1881) took sixteen years to manually produce a complete concordance of all words (apart from a small set of words considered insignificant and occurring frequently such as be, do, and have) in Shakespeare's writings.",
        "entities": [
            [
                84,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "In particular they need to be annotated, at least transcribed, and it is the transcription that will eventually resemble our corpus text.",
        "entities": [
            [
                125,
                131,
                "TERM"
            ],
            [
                132,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "The easiest option is to find an archive for the corpus, such as The Oxford Text Archive or CLARIN.",
        "entities": [
            [
                49,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "Corpus linguistics takes real samples that are used to generalise about language, and corpus-based typology helps us to confirm (or confront the idea) that these assumptions are applicable for a more diverse sample.",
        "entities": [
            [
                86,
                98,
                "TERM"
            ],
            [
                208,
                214,
                "TERM"
            ]
        ]
    },
    {
        "text": "A first technique involves choosing the samples completely at random, the idea being that out of the total number of samples in the corpus, the most frequent characteristics will eventually stand out on their own.",
        "entities": [
            [
                132,
                138,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, the ditransitive construction appears as the pattern \"verb phrase + noun phrase + noun phrase,\" but the interrogative construction has no pattern equivalent because there are no restrictions on the lexis with which it occurs.",
        "entities": [
            [
                211,
                216,
                "TERM"
            ]
        ]
    },
    {
        "text": "Obviously, the distribution of such pairs or sets with respect to other words in a corpus can provide insights into their similarities and differences.",
        "entities": [
            [
                83,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "Exclusivity refers to a specific aspect of the collocation relationship where words occur only or predominantly in each other's company.",
        "entities": [
            [
                47,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is for this reason that it is difficult to maintain a perfect balance between the different parts of these corpora, whose representativeness cannot be fully guaranteed.",
        "entities": [
            [
                125,
                143,
                "TERM"
            ],
            [
                65,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are ways to get transcriptions of spontaneous speech, but mainly from conversations broadcast on radio or television, a highly restricted type of language.",
        "entities": [
            [
                144,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "Given the vast range of corpus-linguistic research designs, these three tests will not always be the ideal choice.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "The most basic corpus-linguistic tool is the frequency list.",
        "entities": [
            [
                45,
                59,
                "TERM"
            ],
            [
                15,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section we look at the other side of the coin and discuss studies that begin with lexis and investigate grammatical aspects of their context.",
        "entities": [
            [
                90,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "For some initial practice, let's start by downloading a text from the Project Gutenberg website and taking a look at it.",
        "entities": [
            [
                56,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can also infer characteristics about the whole Matukar Panau speaking population in all instances of speech from that sample, that is, how frequently all speakers under all circumstances will use serial verb constructions.",
        "entities": [
            [
                121,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "Compare with the results for Max in the same corpus.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "Additionally, the corpus can be used only for academic research (www.english-corpora.org/copyright.asp).",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, the COCA treats all clitics as separate wordforms whereas the Brown corpus (and other corpora developed in that tradition) treat clitics plus their host as a wordform.",
        "entities": [
            [
                82,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, under the definition of corpus linguistics adopted in this book, Sinclair's observations would be just the first step towards a full analysis.",
        "entities": [
            [
                33,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "As previously mentioned, a better method might be to define a sampling frame and to divide the samples to be collected depending on the important properties of such a frame.",
        "entities": [
            [
                62,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "As is true for any corpora, when the metadata is provided in a separate file without using standoff techniques (e.g. IDs pointing from annotations to corresponding speaker metadata), it requires great manual effort to make use of it for automatic corpus searches (see also Chap. 3).",
        "entities": [
            [
                37,
                45,
                "TERM"
            ],
            [
                172,
                180,
                "TERM"
            ],
            [
                247,
                253,
                "TERM"
            ]
        ]
    },
    {
        "text": "But the same can apply to written data -we might be interested in differences in how a word is used paragraph-initially versus medially or finally, for instance, and this can only be automated if the corpus has paragraph breaks marked up.",
        "entities": [
            [
                200,
                206,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section, examples of recent corpus-based studies of prosody are described to provide a sense of the types of current work that are underway.",
        "entities": [
            [
                36,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "To prevent this, the ICE Project has special markup that encloses the entire sequence of repetitions (<}_><}/_>) and then places special markup (<=_>the police boat<=/>) around the last instance of the repetition, the only instance counted in analyses done by ICECUP, the text analysis program used in the ICE Project.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ],
            [
                137,
                143,
                "TERM"
            ],
            [
                272,
                276,
                "TERM"
            ]
        ]
    },
    {
        "text": "This part of the corpus contains a valid sampling of the English spoken by teenagers from various socioeconomic classes living in differing boroughs of London.",
        "entities": [
            [
                17,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "Yet beginning corpus users might benefit from learning about what may be regarded as tacit knowledge in corpus linguistics, and even the more advanced scholar may encounter issues new to them that have been addressed earlier.",
        "entities": [
            [
                104,
                122,
                "TERM"
            ],
            [
                14,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "MS Word formats are avoided, as these add various types of information to the file and do not work with corpus tools such as concordance programs.",
        "entities": [
            [
                125,
                136,
                "TERM"
            ],
            [
                104,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, ICE uses two more tags relevant to the present discussion: <foreign> (for a \"word or sequence of words that is foreign and non-naturalised\") and <indig> (marking words which are \"non-English but are indigenous to the country in which the corpus is being compiled\").",
        "entities": [
            [
                251,
                257,
                "TERM"
            ]
        ]
    },
    {
        "text": "To be representative, a spoken French corpus should include speakers from different regions, different ages, both male and female.",
        "entities": [
            [
                38,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "Compared to, say, the 1980s or even the 1990s, there is now a huge and constantly growing number of studies in corpus linguistics that tackle phenomena of interest with methods that allow researchers to study the effect of multiple independent variables, or predictors, on the dependent variable, or response, of interest.",
        "entities": [
            [
                111,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "To check on 'strange items' in the list, you can use a right mouse click on the frequency to display a concordance of the item in a new tab.",
        "entities": [
            [
                103,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "This might eventually become a problem with a corpus, including thousands of different files.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "The function str() can be used to see what type of data has been loaded: str(cl.order).",
        "entities": [
            [
                43,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "But there are other types of research question for which no standard corpus is available.",
        "entities": [
            [
                69,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "This data is often considered the best kind of language data available to understand how people really use language because it is less considered and belaboured than written text.",
        "entities": [
            [
                174,
                178,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, potentially conflicting desiderata such as comparability and representativeness make it necessary for scholars to consider carefully the make-up of their corpora and the extent to which results based on a selection of registers can be generalized to the language as a whole.",
        "entities": [
            [
                71,
                89,
                "TERM"
            ],
            [
                53,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "In these cases, quantitative corpus linguistics is essentially a variant of sociolinguistics, differing mainly in that the linguistic phenomena it pays most attention to are not necessarily those most central to sociolinguistic research in general.",
        "entities": [
            [
                29,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such disambiguation remains both a theoretical and practical challenge for corpus-based frequency list research.",
        "entities": [
            [
                88,
                102,
                "TERM"
            ],
            [
                75,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "Many examples of annotation manuals can be found online and are provided with all the corpora made available to the public.",
        "entities": [
            [
                17,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we will see below, in the field of stylistics, corpus linguistics tools do not seek to replace qualitative analysis, but only aim to guide the choice of themes and excerpts to analyze.",
        "entities": [
            [
                50,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can extend Script 3 in a different way to process an entire corpus.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "If I am interested in how local newspapers in Britain discussed the issue of crime in the years 2010 to 2013, I will almost certainly need to build a corpus myself for this specific purpose.",
        "entities": [
            [
                150,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "They overlap to greater or lesser degrees but share an essentially identical remit: to make interpretation of large collections of digital text tractable.",
        "entities": [
            [
                139,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "One point that is made in the chapters is that fewer letters written by women are in the corpus than letters written by men.",
        "entities": [
            [
                89,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "An example of a domain-specific literary corpus would be the collected works of an author, which can be used to investigate the style of this particular author, or even to verify disputes about the authorship of a piece of literature where this may be contentious.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then we use if and any (see the very simple definition at ?any ¶) to let R check whether the file has XML or SGML annotation; depending on that, search.expression.alph and search.expression.ord will be defined in the required way.",
        "entities": [
            [
                114,
                124,
                "TERM"
            ],
            [
                102,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, corpus tools can be applied to individual texts, in helping decide whether a text is appropriate and what elements to focus on.",
        "entities": [
            [
                7,
                13,
                "TERM"
            ],
            [
                84,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "With better metadata about individual texts and speakers, we will be in a better position to understand the data, not only to correlate metadata to variation, but also to see more precisely how corpora differ in the case of comparison.",
        "entities": [
            [
                12,
                20,
                "TERM"
            ],
            [
                136,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "Here's a little made-up example of a corpus with three files: the files make up 50 percent, 30 percent, and 20 percent of the corpus, and of all occurrences of the word in question, 70 percent, 20 percent and 10 percent are in the corresponding files.",
        "entities": [
            [
                37,
                43,
                "TERM"
            ],
            [
                126,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "The text should be free from any annotation that carries linguistic and extralinguistic information.",
        "entities": [
            [
                33,
                43,
                "TERM"
            ],
            [
                4,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "A node is a word that we want to search for and analyse.",
        "entities": [
            [
                2,
                6,
                "TERM"
            ]
        ]
    },
    {
        "text": "Section 3 focuses on some pitfalls related to big corpora, and our examples in this section concern both the reliability of the semi-automated sampling of such resources and the comparability of the research results when new genres are introduced to the corpus.",
        "entities": [
            [
                178,
                191,
                "TERM"
            ],
            [
                254,
                260,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another limitation of this corpus is that it is unidirectional.",
        "entities": [
            [
                27,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "This result may be taken to suggest that the method is not ideal for very small text collections, or that different parameters and thresholds should be used in these cases.",
        "entities": [
            [
                80,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "We could argue that we simply have to make sure that there are no errors in the construction of our corpus and that we have to classify all hits correctly as constituting a genuine counterexample or not.",
        "entities": [
            [
                100,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, some language varieties cannot be attributed to a single speaker at all -political speeches are often written by a team of speech writers that may or may not include the person delivering the speech, newspaper articles may include text from a number of journalists and press agencies, published texts in general are typically proof-read by people other than the author, and so forth.",
        "entities": [
            [
                240,
                244,
                "TERM"
            ]
        ]
    },
    {
        "text": "The top three interrogative words beginning a wh-embedded inversion are the same (in the same rank order) for both corpora: what (ELFA: 66% of all WH-embedded inversions, MICASE: 59%), how (ELFA: 15%, MICASE: 22%), and why (ELFA: 7%, MICASE: 10%), and for both speaker groups it is the cliticized what's that is especially closely associated with embedded inversions in the WH-type (what + BE is the most common wh-word + predicate combination in these embedded inversions, and in ELFA 22.6% of these are cliticized, in MICASE 29%).",
        "entities": [
            [
                377,
                381,
                "TERM"
            ]
        ]
    },
    {
        "text": "But while corpora are certainly essential linguistic resources, it is important to realize that no corpus, regardless of its size, will contain every relevant example of a particular linguistic construction or be able to provide a fully complete picture of how the construction is used.",
        "entities": [
            [
                99,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "Here the question of representation is not linked with the language as a whole but with the language used by a particular type of people who are primarily non-native speakers.",
        "entities": [
            [
                122,
                126,
                "TERM"
            ]
        ]
    },
    {
        "text": "Depending on how the tagging was done, there may just be simple categories such as verb, noun, adjective, or the categories may be more refined such as past tense verb, present tense verb, etc.",
        "entities": [
            [
                21,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some kinds of research questions are easy to explore with a basic corpus.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "After you have selected a corpus, you will need to create an account to use the corpus.",
        "entities": [
            [
                26,
                32,
                "TERM"
            ],
            [
                80,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "Studies with a focus on the development of grammar rely on grammatical annotations, especially lemmatization, parts of speech, and interlinear glossing (cf. below).",
        "entities": [
            [
                95,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "As pointed out above, spoken and signed texts need to be transcribed before they can be included in a corpus.",
        "entities": [
            [
                102,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "This goes to show that, by observing items in a frequency list, we may often be able to see things we might have overlooked or ignored while concordancing, simply because the results would have been easier to understand.",
        "entities": [
            [
                48,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "The query will capture interrogatives, imperatives, subordinate clauses and other contexts that cannot contain tag questions, so let us draw a sample of 100 hits from both samples and determine how many of the hits are in fact declarative sentences with positive polarity that could (or do) contain a tag question.",
        "entities": [
            [
                143,
                149,
                "TERM"
            ]
        ]
    },
    {
        "text": "These measures play a role in situations where a negative outcome of a test is relevant (for example, with medical diagnoses); in corpus linguistics, this is generally not the case.",
        "entities": [
            [
                130,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another way of dealing with the copyright problem during corpus distribution would be to allow users to search for concordances in the corpus, but not to visualize it in its entirety.",
        "entities": [
            [
                57,
                63,
                "TERM"
            ],
            [
                135,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus comprises selected extracts of narratives, 153 in all, for a total of around 150,000 words, taken from the demographically sampled 'casual conversations' section of the BNC, which is balanced by sex, age group, region and social class, and which totals approximately 4.5 million words.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "As an alternative, corpora can be stored in external data services such as clouds with corpus access for example by compressed media streaming.",
        "entities": [
            [
                87,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this corpus, there are 14,021 different words (types).",
        "entities": [
            [
                8,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "We then present an overview of several applications of bootstrapping that have been used in prior corpus linguistics research.",
        "entities": [
            [
                98,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "Instead of providing a range of methods and linguistic examples to demonstrate the usefulness of corpus stylistics more generally, the study creates a coherent argument for a theoretical approach to characterization in Dickens.",
        "entities": [
            [
                97,
                103,
                "TERM"
            ]
        ]
    },
    {
        "text": "As usual, we use rchoose.dir to define the directory containing the corpus files and dir to retrieve all the file names from that directory.",
        "entities": [
            [
                68,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "Indeed, we wish to emphasize that resources like COHA are invaluable for diachronic linguistic research, and that these resources are even more useful when one knows exactly how they are constructed and annotated.",
        "entities": [
            [
                73,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "These are just some of the issues we need to constantly be aware of when we use such tools, so the idea that 'bigger is better', even if it is indeed often important to work with very large amounts of data for such research as collocation analysis in order to be able to find rarer combinations, may not always be fully justified if the quantity of data isn't equally matched by quality.",
        "entities": [
            [
                227,
                238,
                "TERM"
            ]
        ]
    },
    {
        "text": "The next script does something seemingly elementary -we will create a frequency list of word-tag combinations (so as to be able to distinguish run as a noun from run as a verb) -but we will do it on a relatively large data set, the complete BNC World Edition with XML annotation, and we will use the annotation well by utilizing information provided by the BNC's multi-word tags, i.e., tags that mark multi-word units such as because of, in spite of, on behalf of, etc.",
        "entities": [
            [
                70,
                84,
                "TERM"
            ],
            [
                268,
                278,
                "TERM"
            ],
            [
                300,
                310,
                "TERM"
            ],
            [
                264,
                267,
                "TERM"
            ]
        ]
    },
    {
        "text": "Current conceptions of corpus linguistics started with the creation of the Quirk Corpus (which contained print samples of spoken and written English) in 1955 at the Survey of English Usage at University College London.",
        "entities": [
            [
                23,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "But as we will see in the next subsection, we can always specify the exact proportion of counterexamples that we would expect to find if there was a random relationship between our variables, and we can then use a sample whether such a random relationship holds (or rather, how probable it is to hold).",
        "entities": [
            [
                214,
                220,
                "TERM"
            ]
        ]
    },
    {
        "text": "The second hypothesis is confirmed for both observations: in the translated component, the most frequent word forms account for a significantly higher percentage of the corpus and the proportion of high-frequency to lowfrequency words is significantly higher.",
        "entities": [
            [
                169,
                175,
                "TERM"
            ]
        ]
    },
    {
        "text": "This may include new insights into collocation of multimodal units of meaning across interactions; acquisition of speech-gesture units; and insights into frequencies of specific multimodal units in different contexts.",
        "entities": [
            [
                35,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "When it comes to textual coherence (understood here as exercises which do not contain isolated and unrelated sentences), we note marked differences between the books, with EGT featuring only one-third of the exercises with textual coherence and G&B offering 100 percent of exercises displaying textual coherence (even if in some exercise sentences are numbered individually, they form a text or relate to one coherent topic).",
        "entities": [
            [
                387,
                391,
                "TERM"
            ]
        ]
    },
    {
        "text": "This word clearly refers to Tony Blair, a former Prime Minister of Great Britain, and will be more prominent in British than in American press reporting (64 times in nine texts versus one time in one text, respectively).",
        "entities": [
            [
                200,
                204,
                "TERM"
            ]
        ]
    },
    {
        "text": "Secondly, corpus linguists need to be clear when marking this distinction.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "The SHARLET corpus covers a prominent subgenre within the corporate financial report, namely that of shareholders' letters.",
        "entities": [
            [
                12,
                18,
                "TERM"
            ]
        ]
    },
    {
        "text": "In these cases, changes are natural and inevitable and, if they are carefully made, the integrity of the corpus will not be compromised.",
        "entities": [
            [
                105,
                111,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, he considered such factors as whether the formality of the particular type of writing influenced the choice of either retaining or deleting that; whether that deletion was less common in formal writing than in informal writing; whether the particular verb influenced use or non-use of that; and whether including or not including that resulted in a difference in meaning.",
        "entities": [
            [
                84,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "At the level of collocations, the very fact that punctuation occurs with a relatively high frequency in any orthographically transcribed corpus like the BNC almost guarantees that it'll be treated as collocating with genuine word types, something that simply doesn't make sense because the semantics and pragmatics of punctuation are very different from, and completely incomparable to, those of ordinary words.",
        "entities": [
            [
                137,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "Letters, for instance, have several advantages as a source of historical text material.",
        "entities": [
            [
                73,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "Second, as with key items, a rigorous collocation analysis will always go beyond the raw list of statistical collocates to look at actual instances of those collocates in usage alongside the node.",
        "entities": [
            [
                38,
                49,
                "TERM"
            ],
            [
                191,
                195,
                "TERM"
            ]
        ]
    },
    {
        "text": "Studies in lexical grammar are currently pulling in two directions, and any research project has to find a balance between the two.",
        "entities": [
            [
                107,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, although diachronic comparability improves, it may still not be optimal, because genres themselves tend to be moving targets.",
        "entities": [
            [
                30,
                43,
                "TERM"
            ],
            [
                19,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are 314.31 degrees of freedom in our sample (as calculated using the formula in 16), which means that 𝑝 < 0.001.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, you need to find something that distinguishes you code from any ordinary text, ideally by using characters that do not form a part of any normal text.",
        "entities": [
            [
                79,
                83,
                "TERM"
            ],
            [
                151,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "This study is based on BE06, a balanced corpus of contemporary British English, and AmE06, a balanced corpus of contemporary American English.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ],
            [
                102,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "It needs to be explained that pragmatic research which truly focuses on language in use has to be corpus-based because there is no convenient way of making speakers say what you want them to say where language is unpredictable, messy, and extended over many turns.",
        "entities": [
            [
                98,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "In any case, concordance lines serve to provide the lexical and/or grammatical context of a search term and thus can be needed at all stages of an analysis, from data coding to interpretation.",
        "entities": [
            [
                13,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "This form of standard deviation (SD p or σ [sigma]) differs slightly from the sample standard deviation (see below).",
        "entities": [
            [
                78,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "In direct commercialization of corpus, one should seek permission from legal copyright holders.",
        "entities": [
            [
                31,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "A plain text format (such as .txt) is often used for corpus files.",
        "entities": [
            [
                53,
                59,
                "TERM"
            ],
            [
                8,
                12,
                "TERM"
            ]
        ]
    },
    {
        "text": "With the state of the art in corpus-pragmatic research established, we now turn to a more fine-grained discussion of exemplar studies in the areas outlined above.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "In general, it is appropriate to choose a base of normalization close to the size of the smallest corpus examined.",
        "entities": [
            [
                98,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "Next, get the token count from the 'Make/edit subcorpora' page and paste it into the spreadsheet, ideally at the top and to the right of the second frequency list, as we may need to shift some items in the list down later to align the data.",
        "entities": [
            [
                148,
                162,
                "TERM"
            ],
            [
                14,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the first loop, we identify all cases of must + V so that, at the end of it, we know all verb types ever occurring after must, and then we can look for all occurrences of all of them in the whole corpus within the second loop.",
        "entities": [
            [
                199,
                205,
                "TERM"
            ]
        ]
    },
    {
        "text": "Our framework splits along three orthogonal dimensions: linguistic (lexical, grammar/syntax, semantics), structural (to permit sub-corpora) and temporal (for diachronic corpora).",
        "entities": [
            [
                158,
                168,
                "TERM"
            ]
        ]
    },
    {
        "text": "It can be used to rank-order words in a frequency list to highlight the most frequent and evenly dispersed items.",
        "entities": [
            [
                40,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "Their application tends to be in areas other than linguistics research but where language, texts, or documents are key sources, e.g. for political text analysis or other social science research questions.",
        "entities": [
            [
                147,
                151,
                "TERM"
            ]
        ]
    },
    {
        "text": "At the time, Rissanen was leading a group of scholars responsible for the compilation of the first diachronic corpus of English, the Helsinki Corpus of English Texts.",
        "entities": [
            [
                99,
                109,
                "TERM"
            ],
            [
                110,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "The keyword that we are searching for here and now is \"say\".",
        "entities": [
            [
                4,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the vast majority of corpus linguistic research issues, we will be dealing with designs that are at least bivariate (i.e., that involve the intersection of at least two variables), like the one discussed in the preceding section.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, before exiting this conditional expression, we delete the multi-word units from the corpus sentences so that their constituent words are not counted again.",
        "entities": [
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, even this relatively simple operation can raise issues regarding what is, and what is not, considered to be part of the same lemma.",
        "entities": [
            [
                134,
                139,
                "TERM"
            ]
        ]
    },
    {
        "text": "These contexts are not split further and constitute together a terminal node (Node 2) with 45 observations.",
        "entities": [
            [
                72,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each of the following sections is intended to illustrate one general problem associated with historical corpus linguistics by discussing individual studies that we have carried out previously.",
        "entities": [
            [
                104,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "Ironically, the corpus was created around the time when generative grammar completely changed the shape of linguistics.",
        "entities": [
            [
                16,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to encourage and enable the application of meta-analysis in corpus linguistics, we have also introduced and demonstrated the main procedures involved including how to (1) search for primary studies, (2) develop and implement a coding scheme, (3) aggregate effect sizes using different R packages to obtain estimates of the relationship in question as well as estimates of variance and of different moderator effects.",
        "entities": [
            [
                69,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "Uncheck the box for 'N-Grams', and type in fair as your search term.",
        "entities": [
            [
                35,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "Most recently (i.e., since the late 2000s), corpus tools were more commonly used by various groups, including not only researchers, but also language teachers and students, who finally had direct access to corpus.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ],
            [
                206,
                212,
                "TERM"
            ]
        ]
    },
    {
        "text": "The fully corpus-driven approach employed in this case study shows that some of the gaps in previous findings were simply an artifact of the corpusbased methodology at the first stage of the research.",
        "entities": [
            [
                10,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "It also fails to fully exploit the spoken corpus at hand, since we did not use the audio files, even though these would have been useful, for example, to disambiguate between the DM and non-DM uses of the six bigrams under study.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "Unfortunately, such calculations presuppose that one knows precisely what linguistic constructions will be studied in a corpus.",
        "entities": [
            [
                120,
                126,
                "TERM"
            ]
        ]
    },
    {
        "text": "One can test this by taking a corpus, establishing a catalogue of all structures from certain domains (sounds, words, sentence structures, etc.) attested, and then seeing to what extent the addition of any further text will expand the inventory of these structures.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ],
            [
                214,
                218,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, we will use sort and table to create our frequency list of the three-grams, quantile to explore their distribution, and plot with type=\"h\" again to visualize the results.",
        "entities": [
            [
                50,
                64,
                "TERM"
            ],
            [
                139,
                143,
                "TERM"
            ]
        ]
    },
    {
        "text": "Still, if we want to use this operational definition, we have to stick with it and define hapaxes strictly relative to whatever (sub-)corpus we are dealing with.",
        "entities": [
            [
                134,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we saw in Chapter 5, most concordancers (like AntConc) only read files in text format, which can include texts tagged in XML format.",
        "entities": [
            [
                77,
                81,
                "TERM"
            ],
            [
                124,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "In contrast, the type frequency of an affix is a fairly direct reflection of the importance of the affix for the lexicon of a language: obviously an affix that occurs in many different words is more important than one that occurs only in a few words.",
        "entities": [
            [
                17,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "Corpora containing syntactic annotation for constituent or dependency structure are called treebanks since syntactic structure is commonly visualised in the form of trees in models of syntax.",
        "entities": [
            [
                29,
                39,
                "TERM"
            ]
        ]
    },
    {
        "text": "This can be done by taking a random subsample of linguistic features from the corpus.",
        "entities": [
            [
                78,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "So far, this type of data is only available for a small number of participants in two languages.",
        "entities": [
            [
                13,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Annotation, by contrast, encodes into the corpus the results of some linguistic analysis which we have undertaken on the corpus text.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ],
            [
                121,
                127,
                "TERM"
            ],
            [
                128,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "The standard deviations are calculated according to equation (2.11) from Chapter 2 (standard deviation sample).",
        "entities": [
            [
                103,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus is made up of 11 sub-sections containing at least 10 texts each, produced under similar conditions, namely by students of the same level.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this language, the elements of a text are marked up using named tags including one or more attributes.",
        "entities": [
            [
                36,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "The results of searches can also help in establishing trends in a corpus.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "The following is a brief summary of desiderata for suitable plain-text editors.",
        "entities": [
            [
                66,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "Platforms which do limit posting length, such as Twitter (now X), usually limit the maximum length, confining all of their content into the range of short texts, which is mathematically difficult to work with in quantitative corpus linguistics.",
        "entities": [
            [
                225,
                243,
                "TERM"
            ]
        ]
    },
    {
        "text": "But as corpora have grown larger, it has become a much more complicated undertaking to ensure that a corpus is both balanced and representative.",
        "entities": [
            [
                101,
                107,
                "TERM"
            ]
        ]
    },
    {
        "text": "The keywords now convey a very specific idea of what the text is about: there are two proper names of rivers (the Neosho already seen on the frequency list and the Marais des Cygnes, represented by its constituents Cygnes, Marais and des), and there are a number of words for specific species of fish as well as the words river and channel.",
        "entities": [
            [
                141,
                155,
                "TERM"
            ],
            [
                57,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is a question that is shared by linguistics and other areas of the social sciences, so it is perhaps understandable that annotation schemes are another area where there has been a flow of ideas between corpus linguistics and the social sciences.",
        "entities": [
            [
                207,
                225,
                "TERM"
            ],
            [
                126,
                136,
                "TERM"
            ]
        ]
    },
    {
        "text": "In many early corpus linguistics works, you will find frequency tables as a primary account of data.",
        "entities": [
            [
                14,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such a corpus would make it possible to compare the ways of speaking in a similar context in two languages and two different cultures.",
        "entities": [
            [
                7,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "When annotating a corpus, we may also be interested in adding information about the relationships that exist between elements in our texts above the level of the individual word that may help shed light on larger patterns in our corpus.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ],
            [
                229,
                235,
                "TERM"
            ]
        ]
    },
    {
        "text": "A very large set of questions in corpus linguistics can be answered without going beyond standard, widely available corpora.",
        "entities": [
            [
                33,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "I then present what I take to be the methodological foundations that distinguish corpus linguistics from other, superficially Preface similar methodological frameworks, and discuss the steps necessary to build concrete research projects on these foundations -formulating the research question, operationalizing the relevant constructs and deriving quantitative predictions, extracting and annotating data, evaluating the results statistically and drawing conclusions.",
        "entities": [
            [
                81,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "Specialised corpus software and web interfaces also have means of finding examples and often have ways to save those examples to a new document or spreadsheet for further analysis.",
        "entities": [
            [
                12,
                18,
                "TERM"
            ]
        ]
    },
    {
        "text": "Go back to the COCA and the Brown corpus.",
        "entities": [
            [
                34,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is for this reason that the approach that we will adopt in this book corresponds to a corpus-based approach, considering these as available tools for linguists to be able to test their hypotheses.",
        "entities": [
            [
                89,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "Creating a machine-readable corpus can be a very costly and timeconsuming exercise.",
        "entities": [
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, when one uses a corpus to produce tools, systems, and resources and commercialize these, one has to face copyright problems.",
        "entities": [
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "Select one of the areas described in this section and briefly discuss how corpus methodology has changed the way that research is done in the area.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "The best way to do this is to save both sets of result to text files as we did earlier for our concordancing results.",
        "entities": [
            [
                58,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "At the end of the previous chapter, we defined corpus linguistics as \"the investigation of linguistic research questions that have been framed in terms of the conditional distribution of linguistic phenomena in a linguistic corpus\" and briefly discussed the individual steps necessary to conduct research on the basis of this discussion.",
        "entities": [
            [
                47,
                65,
                "TERM"
            ],
            [
                224,
                230,
                "TERM"
            ]
        ]
    },
    {
        "text": "While calibrating the performance of automatic tools is ultimately based on a reference human annotation, the question arises whether the annotations made by a human are necessarily 100% accurate.",
        "entities": [
            [
                94,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a result, corpus-driven studies of lexical phrases (both continuous and discontinuous) have shown that lexical patterning is ubiquitous in English, and basic to the discourse structure of both spoken and written texts.",
        "entities": [
            [
                13,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "This can also be advantageous with regard to the \"mystery of vanishing reliability\", that is, the phenomenon that each datapoint tends to become less reliable the more parameters (in corpus-linguistic terms, annotations) one adds.",
        "entities": [
            [
                183,
                189,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can thus annotate events described in a corpus, as well as the links between the various participants in these events.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, the linguist can compensate for this to some degree by acquiring a thorough understanding of the corpus and its description.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "So, to begin with, it is necessary to convert the files included in the corpus to text format.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ],
            [
                82,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "What is offered instead are detailed descriptions of a relatively small selection of methods which are likely to be of most use to corpus linguists, where usefulness is judged on criteria of intuitive accessibility, theoretically and empirically demonstrated effectiveness, and availability of software implementations for practical application.",
        "entities": [
            [
                131,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "While the purpose of the analysis of texts may vary between corpus linguistics and studies interested in style, the methods, however, can still be similar.",
        "entities": [
            [
                60,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus, which is expanded every year and currently contains over 129,000 tokens, is collected from eight open access sources: Wikinews news reports, biographies, fiction, reddit forum discussions, Wikimedia interviews, wikiHow how-to guides and Wikivoyage travel guides.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "The goals of the CHECL are to complement, but not duplicate, the coverage of existing textbooks and handbooks on corpus linguistics.",
        "entities": [
            [
                113,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "But there is another dimension to extensibility: The reliability of a particular annotation can also \"vanish\" because it turns out to be misguided, for whatever reason.",
        "entities": [
            [
                81,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "The table consists of 257 lines (one line per preposition type) and 19 columns (one column per variable).",
        "entities": [
            [
                58,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "Next, they look at concordances of the remaining words to determine first, which senses are most frequent and thus most relevant for the observed differences, and second, whether the words are actually distributed across the respective corpus, discarding those 10 Text whose overall frequency is simply due to their frequent occurrence in a single file (since those words would not tell us anything about cultural differences).",
        "entities": [
            [
                236,
                242,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, tools which provide Computer Assisted Qualitative Data Analysis (CAQDAS), such as ATLAS.ti, NVivo, QDA Miner, and Wordstat, incorporate some very similar methods to those described here but are not widely used in corpus linguistics.",
        "entities": [
            [
                220,
                238,
                "TERM"
            ]
        ]
    },
    {
        "text": "Bootstrapping could be used as a method for evaluating the linguistic representativeness of a corpus (cf. Chap. 1).",
        "entities": [
            [
                70,
                88,
                "TERM"
            ],
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is therefore crucial to the success of any corpus undertaking that accurate information be kept about each text to be considered for inclusion in the corpus.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ],
            [
                153,
                159,
                "TERM"
            ],
            [
                110,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, if you call up the concordances for these, you'll soon find out that they represent the initial parts of the negative contractions can't, won't, and shan't, which have been separated from the negation 'clitics' in the tagging process and are being treated as individual tokens.",
        "entities": [
            [
                227,
                234,
                "TERM"
            ]
        ]
    },
    {
        "text": "These main POS categories identify the word as you type it into the search box.",
        "entities": [
            [
                51,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some researchers have gone further still, dismissing the notion that representativeness is achievable or important in web corpora.",
        "entities": [
            [
                69,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "The metadata of such a corpus should at least include information of where the recording took place, its date, the context in which it happened, the conversation topic, the number of participants, the gender of the person recorded, his/her age and profession.",
        "entities": [
            [
                4,
                12,
                "TERM"
            ],
            [
                23,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us look at one example from the case study chapter below, the collocation of alphabetical order.",
        "entities": [
            [
                66,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "A 'random sample' is a sample where every member of the population has Random sample equal probability of being included in the sample.",
        "entities": [
            [
                10,
                16,
                "TERM"
            ],
            [
                23,
                29,
                "TERM"
            ],
            [
                78,
                84,
                "TERM"
            ],
            [
                128,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "This imbalance can take several forms: either there are simply fewer texts translated in one direction than in the other (especially when the language pair involves a less \"central\", or more \"peripheral\", language), or certain text types are only (or more frequently) translated in one of the two directions.",
        "entities": [
            [
                227,
                231,
                "TERM"
            ]
        ]
    },
    {
        "text": "Secondly, we only list monolingual concordancers, i.e. tools that let the user examine text from one corpus representing one language.",
        "entities": [
            [
                101,
                107,
                "TERM"
            ],
            [
                87,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, the most frequent equivalent in the translation corpus is increasingly, which is only mentioned in the LA.",
        "entities": [
            [
                57,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "Files saved in these formats can be easily transformed into text files thanks to specific options such as the \"save as\" command found in word processors.",
        "entities": [
            [
                60,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, in order to create a corpus of French, speakers from different regions should be included in the sample.",
        "entities": [
            [
                34,
                40,
                "TERM"
            ],
            [
                110,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "Similarly, the words mouse and mice are the singular and plural variants of the same lemma (mouse), whereas eat, eaten and eating are the conjugated forms of the lemma eat.",
        "entities": [
            [
                85,
                90,
                "TERM"
            ],
            [
                162,
                167,
                "TERM"
            ]
        ]
    },
    {
        "text": "A corpus is a principled collection of language data taken from real-life contexts.",
        "entities": [
            [
                2,
                8,
                "TERM"
            ]
        ]
    },
    {
        "text": "Imagine further that a number of corpus-based studies had examined this issue using different corpora, with each study yielding a result expressed in occurrences per million words.",
        "entities": [
            [
                33,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "During the process of reviewing the corpus-based research that uses bootstrapping, we have seen no evidence of bootstrapping results being misinterpreted or misrepresented.",
        "entities": [
            [
                36,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "Again, metonymy is a vastly under-researched area in corpus linguistics, so much work remains to be done.",
        "entities": [
            [
                53,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "Technical developments have brought along a rich array of corpus-linguistic applications, and corpus compilers have created a good selection of databases for public use.",
        "entities": [
            [
                58,
                64,
                "TERM"
            ],
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "The keywords in the corpus include proper nouns such as Edison, Funès, Fernandel, Gabin and Reynaud and also content words like cinéphile, cinéma and crédits.",
        "entities": [
            [
                20,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "Similarly, in the first half of the 20th Century in the United States, the so-called distributionist approach to syntax focused on the study of sentence formation in syntactic structures as they appeared in text corpora, and from there, tried to infer language's general functioning.",
        "entities": [
            [
                207,
                211,
                "TERM"
            ]
        ]
    },
    {
        "text": "Changing legislation in these areas might pose further difficulties for corpus-based research in the future.",
        "entities": [
            [
                72,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Base du français médiéval (Guillot-Barbance et al. 2017) offers access to different diachronic corpora.",
        "entities": [
            [
                88,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the end, balancing a corpus is never a perfect task.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "For this reason, rich annotation is best seen only as a means to facilitate querying a corpus.",
        "entities": [
            [
                22,
                32,
                "TERM"
            ],
            [
                87,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if a corpus-based analysis contains the length of a phrase as an independent variable, and we introduce the pronominality of that phrase as a second independent variable, these two variables might correlate significantly, since full lexical phrases are by necessity longer than single pronouns.",
        "entities": [
            [
                18,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "Conrad argued that three changes prompted by corpus-based studies of grammar had \"the potential to revolutionize the teaching of grammar\" (2000: 549): first, monolithic descriptions of English grammar would be replaced by register-specific descriptions; second, the teaching of grammar would become more integrated with the teaching of vocabulary; and third, the emphasis would shift from structural accuracy to the appropriate conditions of use for alternative grammatical constructions.",
        "entities": [
            [
                45,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can be sure about one thing: these criteria should not be related to the linguistic content of the samples, but rather to a classification made on the basis of external criteria, such as text genres and language registers.",
        "entities": [
            [
                190,
                194,
                "TERM"
            ]
        ]
    },
    {
        "text": "This may not seem like a great nuisance to you but, before you go on reading, look at the last word and think about in what way this may be problematic for further corpus-linguistic application.",
        "entities": [
            [
                164,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "Here items are classified according to a particular scheme, and an arithmetical count is made on the number of items that belong to each class in the scheme within a corpus.",
        "entities": [
            [
                166,
                172,
                "TERM"
            ]
        ]
    },
    {
        "text": "And, to be able to automatically keep the turn tags separated from the text, we can add new lines in the appropriate places.",
        "entities": [
            [
                71,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "In many ways we can then say that the challenges do not only relate to corpora and their use themselves, but also to how we educate new corpus users and inform them about the fundamental concepts and concerns.",
        "entities": [
            [
                136,
                142,
                "TERM"
            ]
        ]
    },
    {
        "text": "Not only does the corpus contain letters from the sixteenth to eighteenth century, it also covers four major English regions, as well as giving information on the social rank of the letter writers and how they relate to their addressees.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "This case study demonstrates that very large collections of citations can indeed be used as a corpus, as long as we are investigating phenomena that are likely to occur in citations collected to illustrate other phenomena; the results are very similar to those we get from well-constructed linguistic corpora.",
        "entities": [
            [
                94,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, they can be estimated with a certain degree of confidence from an observed sample drawn from the population.",
        "entities": [
            [
                84,
                90,
                "TERM"
            ]
        ]
    },
    {
        "text": "Standard deviation always needs to be considered in relation to the mean (the relative frequency of the word in the corpus overall).",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "Following the online tutorial on YouTube referenced above, identify the press reports sub-corpus in both the American and the British collections (AmE06_PressRep and BE-06_PressRep) and feed them into the tool.",
        "entities": [
            [
                90,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "A special computer program is often designed to process the text and to look at sequences of words in a window of text as they emerge in a corpus.",
        "entities": [
            [
                139,
                145,
                "TERM"
            ],
            [
                60,
                64,
                "TERM"
            ],
            [
                114,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section we outline annotation procedures that have been developed with a comparative perspective in mind.",
        "entities": [
            [
                27,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter focuses on the process of creating and annotating a corpus.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "All corpus studies of grammar inevitably make use of the evidence of grammatical usage as observed in corpora in order to arrive at some kind of description of what the corpus attests about some area(s) of grammar.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ],
            [
                169,
                175,
                "TERM"
            ]
        ]
    },
    {
        "text": "Learner corpora, particularly those containing academic texts, often include instances of multilingual practices, code-switching, and borrowed content, presenting difficulties for annotation and analysis.",
        "entities": [
            [
                180,
                190,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to promote and make better use of corpus enrichment, there is a need for collaborative work between linguists with a deep knowledge of the needs to different areas such as Second Language Acquisition or Historical Linguistics and experts in Computational Linguistics or Natural Language Processing.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "This topic has been extensively researched in corpus studies and, therefore, much is known about the use and also the lexical associations of the passive.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can call the first of these passive types, the long passive (a passive sentence that includes the \"by phrase\"), and the second type, the short passive (a passive sentence without the \"by phrase\").",
        "entities": [
            [
                130,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "Consequently, corpus linguists are very skeptical of the highly abstract and decontextualized discussions of language promoted by generative grammarians, largely because such discussions are too far removed from actual language usage.",
        "entities": [
            [
                14,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "As intuition is usually an unreliable guide to patterns of collocation and semantic prosody, this study takes a corpus-based approach to addressing these research questions.",
        "entities": [
            [
                112,
                124,
                "TERM"
            ],
            [
                59,
                70,
                "TERM"
            ]
        ]
    },
    {
        "text": "We do not share views here (occasionally uttered in corpus linguistics literature) that findings from any given corpus merely apply to this corpus and nothing beyond.",
        "entities": [
            [
                52,
                70,
                "TERM"
            ],
            [
                112,
                118,
                "TERM"
            ],
            [
                140,
                146,
                "TERM"
            ]
        ]
    },
    {
        "text": "Each MP sample was compared against every other MP using two similarity measures: Jaccard and Log Likelihood.",
        "entities": [
            [
                8,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "Results of this analysis demonstrate that the list performs considerably better coverage-wise in academic writing than in other written genres, in both in the academic portion of the corpus from which the list was constructed (13.8%), and a different academic sub-corpus from the BNC (13.7%) (compared to 8.0% for newspaper articles and 3.4% for fiction).",
        "entities": [
            [
                183,
                189,
                "TERM"
            ],
            [
                264,
                270,
                "TERM"
            ]
        ]
    },
    {
        "text": "Speech act studies represent function-to-form mapping, which is more difficult to deal with than the form-to-functions direction of fit with corpus-linguistic methods.",
        "entities": [
            [
                141,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "Second, subsequent corpus users can much more easily re-evaluate the accuracy of annotations and potentially modify them or add further annotation detail, as required for any research agenda.",
        "entities": [
            [
                136,
                146,
                "TERM"
            ],
            [
                19,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, some concordancing programs can detect prefixes and suffixes and irregular forms and sort words by \"lemmas\"; that is, words such as runs, running, and ran will not be counted as separate entries but rather as variable forms of the lemma run.",
        "entities": [
            [
                244,
                249,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, many ready-made corpus tools can only offer the functionality they aim to provide for corpora with particular formats, and then can only provide a small number of kinds of output.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "Essentially, a concordance is a listing of individual word forms in a given specific context, where the exact nature of the context depends on the requirements of the analysis and which particular program one may be using.",
        "entities": [
            [
                15,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "We need to do this because these line breaks, as indeed anything that doesn't really form part of our text, may in fact interfere with the processing of the text later and even create a number of problems that could affect the meaningfulness of at least part of your data for linguistic analyses.",
        "entities": [
            [
                102,
                106,
                "TERM"
            ],
            [
                157,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, this is the case of the Belgian Valibel database of spoken French (see section 5.3) or the SMS corpus in Switzerland's national languages, collected by the universities of Zurich and Neuchâtel (see section 5.5).",
        "entities": [
            [
                108,
                114,
                "TERM"
            ]
        ]
    },
    {
        "text": "The mathematical formulas used in probability sampling often produce very large sample sizes, as the example above with books illustrated.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ]
        ]
    },
    {
        "text": "A sampling frame is determined by identifying a specific population that one wishes to make generalizations about.",
        "entities": [
            [
                2,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "The authors examine a set of case studies, highlighting issues like part-of-speech annotation, miscategorization challenges, and problems related to metadata and digitized texts in historical databases, such as the 10.5-billion-word Eighteenth Century Collections Online, a database which was originally not compiled for linguistic purposes.",
        "entities": [
            [
                83,
                93,
                "TERM"
            ],
            [
                149,
                157,
                "TERM"
            ]
        ]
    },
    {
        "text": "Different XML tags are used for markup, metadata and annotation.",
        "entities": [
            [
                53,
                63,
                "TERM"
            ],
            [
                40,
                48,
                "TERM"
            ],
            [
                32,
                38,
                "TERM"
            ],
            [
                10,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "Metadata is also relevant to what kind of research we can do with a given corpus.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "Incidentally, the level of redundancy would increase even further if we analysed the whole text, including the front matter, because there the headings might show up once more inside the table of contents (TOC) of the document, where their meaning is 'purely' to serve as a navigational aid by listing them side by side with their respective page numbers.",
        "entities": [
            [
                91,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, a frame occurring 200 times with 25 distinct fillers would have a type-token ratio of .",
        "entities": [
            [
                79,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "Diachronic corpora sample different stages of language or discourse development across time.",
        "entities": [
            [
                19,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "Methods and tools for corpus linguistics have developed in tandem with the increasing power of computers and so it is to the computational side that I look in order to take a peek into the future of corpus software.",
        "entities": [
            [
                22,
                40,
                "TERM"
            ],
            [
                199,
                205,
                "TERM"
            ]
        ]
    },
    {
        "text": "This appears to be particularly true for fine-tuning, which noticeably struggles with low-frequency categories (e.g. MET for the lemma mass; f1 = 46.4).",
        "entities": [
            [
                129,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "As in the case of contrastive studies, translation studies has benefited from the availability of multilingual corpora, as well as theoretical and methodological advances in corpus linguistics.",
        "entities": [
            [
                174,
                192,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to address this question, historical corpus linguists need to intensify collaborations with researchers in sociolinguistics and psycholinguistics, who have long been concerned with the social and cognitive processes that shape grammar and that ultimately also shape grammatical change.",
        "entities": [
            [
                46,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "These features have resulted in Python becoming one of the most popular languages used in corpus linguistics work today.",
        "entities": [
            [
                90,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then we calculate the distances between the individual occurrences of the word (w 1 ) in the corpusto do this we need to use the corpus positions.",
        "entities": [
            [
                129,
                135,
                "TERM"
            ]
        ]
    },
    {
        "text": "When we call them 4-grams, it does not matter how often they occur in a corpus; they are still called 4-grams.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "An alternative approach to large indiscriminate crawls is to focus on specific websites, thus limiting the size of the textual universe and increasing the chances of building a representative corpus.",
        "entities": [
            [
                192,
                198,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can start enumerating the differences between the texts by pointing out that text A is about American politics, while text B is a part of a story about a person called Rincewind.",
        "entities": [
            [
                80,
                84,
                "TERM"
            ],
            [
                121,
                125,
                "TERM"
            ]
        ]
    },
    {
        "text": "The primary purpose of the annotation is to add additional information to a text so that future analysis and interpretation of a text becomes easy, accurate, and useful.",
        "entities": [
            [
                27,
                37,
                "TERM"
            ],
            [
                76,
                80,
                "TERM"
            ],
            [
                129,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, both Biber's and Leech's approaches to representativeness may lead the linguist into difficulties when s/he is confronted with historical material.",
        "entities": [
            [
                48,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a POS-tagged corpus, we could, for example, search for a sequence of a pronoun and a noun in addition to the sequence pronoun-determiner that we used above, which would give us cases like (12d), or we could search for forms of be followed by a past participle followed by a determiner or noun, which would give us passives like those in (12b).",
        "entities": [
            [
                16,
                22,
                "TERM"
            ]
        ]
    },
    {
        "text": "Meanwhile, publications by Mike Scott, Ken Hyland, and John Swales were first found in the middle time spans; their publications on corpus tools and discourse analysis in ESP or EAP were frequently cited.",
        "entities": [
            [
                132,
                138,
                "TERM"
            ]
        ]
    },
    {
        "text": "Contemporary corpora are used for studying language in a synchronic way, that is, at a given moment during its evolution, whereas historical corpora make it possible to carry out studies from a diachronic point of view, that is, on the evolution of language.",
        "entities": [
            [
                194,
                204,
                "TERM"
            ],
            [
                57,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "Attempts at creating such pre-fabricated word lists for EAP from corpus materials have already been made in the past.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "The Interfra corpus created by Inge Bartning and Fanny Forsberg Lundell focuses on Swedish learners of French at different levels.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, any of the articles could pretty much randomly occur in any position, as there is no relationship between the position and the type of article used.",
        "entities": [
            [
                143,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, all the corpus studies illustrated in this chapter were carried out on corpora of very diverse shape and size.",
        "entities": [
            [
                17,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "The purpose of your search for keywords could be that you analyze a) what kinds of words surround your keyword, b) how they are positioned in the sentence or in the phrase, or c) what the frequencies are of your keywords.",
        "entities": [
            [
                103,
                110,
                "TERM"
            ]
        ]
    },
    {
        "text": "The main advantage of downloadable corpora is their great flexibility for carrying out word or structure searches using a concordancer (see section 5.6).",
        "entities": [
            [
                122,
                134,
                "TERM"
            ]
        ]
    },
    {
        "text": "For other research questions, control of content is less of an issue: for instance, the relatively low lexicality of A-arguments should be observable in any text (but see below).",
        "entities": [
            [
                157,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "Regardless of the stylistic genre targeted, the use of quantitative methods linked to corpus linguistics has led to many advances in lexicography and has been one of its main application areas.",
        "entities": [
            [
                86,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "The observed proportions are calculated by taking, again one-by-one, the absolute frequencies of the word or phrase of interest in the corpus parts and dividing these by the absolute frequency of the word or phrase in the whole corpus.",
        "entities": [
            [
                135,
                141,
                "TERM"
            ],
            [
                228,
                234,
                "TERM"
            ]
        ]
    },
    {
        "text": "An important set of tools influencing the choice of corpus architecture is NLP pipelines and APIs, which allow users to construct automatically tagged and parsed representations with complex data models (and these can be manually corrected if needed).",
        "entities": [
            [
                52,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "The expected proportions are calculated by taking one-by-one the sizes of the corpus parts (number of tokens) and dividing them by the total number of tokens in the corpus; this is to establish their proportional contribution to the overall size of the corpus.",
        "entities": [
            [
                78,
                84,
                "TERM"
            ],
            [
                165,
                171,
                "TERM"
            ],
            [
                253,
                259,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although some of these regularities had been suggested a long time ago, corpus linguistic approaches are capable of discovering regularities that have not been dealt with in classic typological research.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, the mean dimension score for each register is calculated by taking all text dimension scores belonging to the same register and calculating the average value.",
        "entities": [
            [
                80,
                84,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter will guide you through the steps and procedures to actually put the corpus to use and to report on your research findings.",
        "entities": [
            [
                81,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, although authenticity is not a demarcation criterion for corpora, spoken texts in particular should come from common text varieties as well and not be restricted to scripted or semi-scripted TV, radio, or otherwise broadcasted texts or texts elicited in experimental setups.",
        "entities": [
            [
                127,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "Both word tokens and word types are identified based on the form of a word (external appearance, if you like). To identify lemmas and lexemes, we first need to perform linguistic analysis of the text; lemmas are based on grammatical (morphological) analysis, while lexemes are based on both grammatical and semantic analysis.",
        "entities": [
            [
                195,
                199,
                "TERM"
            ]
        ]
    },
    {
        "text": "In another type, such combinations generally create a complex meaning, as in, for example, up until or down below, where the resulting meaning is a mix of the semantic properties of both elements.",
        "entities": [
            [
                11,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "With a corpus such as the BNC, we know precisely what kinds and types of English are being analyzed.",
        "entities": [
            [
                7,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "Several special corpora contain only specific types of text, which could also be included in a general corpus.",
        "entities": [
            [
                103,
                109,
                "TERM"
            ],
            [
                55,
                59,
                "TERM"
            ]
        ]
    },
    {
        "text": "For several decades now, corpus linguists have discussed dozens of association measures that are used to rank-order, for instance, collocations by the attraction of their constituent words.",
        "entities": [
            [
                25,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "For some phenomena such as the annotation of morphosyntactic categories or speech acts, every word or sentence in the corpus will be involved.",
        "entities": [
            [
                31,
                41,
                "TERM"
            ],
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "And this one example from the domain of syntax can be multiplied endlessly for other variations in syntax, or in lexis, morphology, phraseology, or meaning.",
        "entities": [
            [
                113,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "We need to expand corpus studies into multimodal academic genres where writing is frequently used with graphical and visual semiotic forms, such as academic websites and textbooks.",
        "entities": [
            [
                18,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "To summarize, bootstrapping augments the amount and quality of information we can extract from the observed data in a sample.",
        "entities": [
            [
                118,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "Compared to carefully constructed traditional corpora with often hand-picked text samples, there is obviously much less control over individual choices, and the fact that the exact 8.",
        "entities": [
            [
                77,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "Also common in corpus linguistics is generalized linear regression.",
        "entities": [
            [
                15,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "It was created for lexicographers and computational linguists, using a custom-built corpus of 1.7 billion words uploaded in the Sketch Engine.",
        "entities": [
            [
                84,
                90,
                "TERM"
            ]
        ]
    },
    {
        "text": "Retrieval and annotation are discussed in detail in Chapter 4.",
        "entities": [
            [
                14,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to illustrate these types of data, let us turn to a linguistic phenomenon that is more complex than the distribution of words across varieties, and closer to the kind of phenomenon actually of interest to corpus linguists: that of the two English possessive constructions introduced in Section 4.2.3 of Chapter 4 above.",
        "entities": [
            [
                214,
                220,
                "TERM"
            ]
        ]
    },
    {
        "text": "Reflecting on the process, we can see that the corpus software aided our analysis but much of it had to be done manually.",
        "entities": [
            [
                47,
                53,
                "TERM"
            ]
        ]
    },
    {
        "text": "As noted above, LGSWE and the PG books have complementary approaches: LGSWE views lexis through the lens of grammar; the PG books arrive at grammar through a study of lexis.",
        "entities": [
            [
                82,
                87,
                "TERM"
            ],
            [
                167,
                172,
                "TERM"
            ]
        ]
    },
    {
        "text": "A second group of NLP techniques implemented is the identification of entities in the corpus, and that includes mentions of people, physical locations, and established organisations.",
        "entities": [
            [
                86,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "One is concerned with the fact that words can theoretically have identical type and token frequencies, but may still be very differently distributed.",
        "entities": [
            [
                84,
                89,
                "TERM"
            ],
            [
                75,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "A second round of proofreading is done after completion of the entire corpus so that the corpus can be viewed as a whole.",
        "entities": [
            [
                70,
                76,
                "TERM"
            ],
            [
                89,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "To a certain extent, restrictions on copyright may be alleviated through concepts such as 'fair use', as texts in a corpus are typically used for research or teaching purposes only, with no bearing on the market.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "After Tim Berners-Lee had invented the World Wide Web (WWW) in 1989, it was necessary to develop a new, and simpler, markup language in order to take full advantage of the new hypertext medium.",
        "entities": [
            [
                117,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is, however, more to explore before LLMs can be fully integrated into corpus linguistic research.",
        "entities": [
            [
                76,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "It involves the collection of data; spoken, written, or both, and collating it into one or more text files.",
        "entities": [
            [
                96,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "While an understanding of the principles, approaches, and advantages of using corpora provides the necessary foundational knowledge of this approach to language analysis, there is a technical side to corpus linguistics that is best acquired through practice and experience with corpora.",
        "entities": [
            [
                200,
                218,
                "TERM"
            ]
        ]
    },
    {
        "text": "When you release the mouse button, the spreadsheet application will automatically have calculated and filled in all the relative frequencies for the general corpus.",
        "entities": [
            [
                157,
                163,
                "TERM"
            ]
        ]
    },
    {
        "text": "By tracing these relationships, it is possible to extract features of corpus sentences-subjects of active and passive verbs, objects of prepositions, etc.-that would be difficult to retrieve from searches of unannotated text alone.",
        "entities": [
            [
                70,
                76,
                "TERM"
            ],
            [
                220,
                224,
                "TERM"
            ]
        ]
    },
    {
        "text": "Obviously, we need to be able to define the corpus files we want to search, which means it will be useful to use rchoose.dir to define the directory containing the corpus files; also, we will need to be able to retrieve all the file names from that directory using dir.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ],
            [
                164,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "In particular, all of the above approaches only deal with the minimal amount of information one should include-the more comprehensive information regarding token and type frequency distributions and entropies still awaits first exploration.",
        "entities": [
            [
                156,
                161,
                "TERM"
            ],
            [
                166,
                170,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this chapter, we use a fairly liberal definition of \"grammatical variation,\" including both genuinely variationist research -where grammatical variants are modeled as competing against each other -and text-linguistic research that explores variable text frequencies of particular grammatical constructions in corpora.",
        "entities": [
            [
                204,
                208,
                "TERM"
            ],
            [
                252,
                256,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, ready-made concordance tools often have slightly different settings that specify what 'a word' is, which means you can get different results if you have different programs perform the same search on the same corpus.",
        "entities": [
            [
                25,
                36,
                "TERM"
            ],
            [
                222,
                228,
                "TERM"
            ]
        ]
    },
    {
        "text": "The choice of lemmatization software often depends on the kinds of language found in the corpus materials.",
        "entities": [
            [
                14,
                27,
                "TERM"
            ],
            [
                89,
                95,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this book, we offer multiple opportunities to work on corpus projects by first including an entire chapter dedicated to smaller corpus projects (Chapter 4) and then providing students with information on how to build and analyze their own corpora (Part III).",
        "entities": [
            [
                57,
                63,
                "TERM"
            ],
            [
                131,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "For each spoken text, a record was kept of when the text was recorded, where the recording took place, who was recorded, who did the recording, and how long the recording was.",
        "entities": [
            [
                16,
                20,
                "TERM"
            ],
            [
                52,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you set the argument lines.around to a number greater than zero, then you increase the preceding and subsequent context by that number of corpus elements.",
        "entities": [
            [
                141,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "This, however, needs to be complemented with a careful description of the corpus of interest C in the Data subsection of the Method section.",
        "entities": [
            [
                74,
                80,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, we use abline and text to add some annotation into the plot; we use lines(lowess(...)) to add a trendline, and I introduce mtext to add colored axis labels.",
        "entities": [
            [
                44,
                54,
                "TERM"
            ],
            [
                27,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "Large text archives, such as Lexis-Nexis 5.",
        "entities": [
            [
                6,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "CIA studies raised the issue of the norm (native vs. non-native; novice vs. expert) and pointed to the benefit of relying on an explicit corpus-based norm rather than the implicit and intuitive norm that underlies many SLA studies.",
        "entities": [
            [
                137,
                149,
                "TERM"
            ]
        ]
    },
    {
        "text": "As a result, the British Library Newspapers database is an attractive alternative for the corpus-linguistic analysis of historical newspaper prose.",
        "entities": [
            [
                90,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "We conclude by reflecting on the nature of evidence, falsification and corroboration in corpus use in the social sciences.",
        "entities": [
            [
                88,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, we can calculate the mean rate of occurrence for nouns in a single corpus sample of size n.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ],
            [
                87,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, the focus on words is also due to the fact that the results of corpus linguistic research quickly showed that words (individually and in groups) are more interesting and show a more complex behavior than traditional, grammarfocused theories of language assumed.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "So, for example, bat is a lemma which can correspond to two different lexemes, as this word is polysemic and may either refer to a flying mamal or an object used to hit a ball.",
        "entities": [
            [
                26,
                31,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section, we will carry out a more in-depth and qualitative analysis of one of the features that distinguish corpus-informed from non-corpusinformed ones, i.e. the inclusion of lexical information.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "From a theoretical perspective, these results may seem to be of secondary interest, at least in the domain of lexis, since lexical differences between the major varieties of English are well documented.",
        "entities": [
            [
                110,
                115,
                "TERM"
            ]
        ]
    },
    {
        "text": "One final comment regarding these data: The use of the above data set is not to imply that a data set like this is typical for corpus-linguistic data in general or for tree-based analyses of such data in particular.",
        "entities": [
            [
                127,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "The advantage is that very detailed information about a spoken text is provided to the user, thus ensuring that a broad range of studies can be conducted on the corpus without any doubt about the authenticity of the data.",
        "entities": [
            [
                161,
                167,
                "TERM"
            ],
            [
                63,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "This difference does not necessarily reflect the analytic view of corpus compilers, but can often be due to technical conditions.",
        "entities": [
            [
                66,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "Lexical tagging is crucial because it will enable the factor analysis program to determine where the various parts of speech occur: e.g. first person pronouns in more interactive texts; passive verbs in more informational texts.",
        "entities": [
            [
                8,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "Researchers must simply be upfront about what makes up the corpus and be aware that not all corpora are appropriate for grand generalisations about a language.",
        "entities": [
            [
                59,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, it is possible to build a comparable corpus of parliamentary debates in France and the UK.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "Google Books (BYU) cannot generate these concordance lines, because it is based just on n-grams.",
        "entities": [
            [
                41,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, in some specific cases, a corpus can include the whole population.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now, even if you are aware of all the relevant forms you may need to identify, and search for each of these forms separately in a row in a concordance program, you can only save the results, maybe even print them out, and then compare them afterwards.",
        "entities": [
            [
                139,
                150,
                "TERM"
            ]
        ]
    },
    {
        "text": "All these decisions and the availability of existing conventions and annotation tools can make a significant difference to the overall process of annotation that follows.",
        "entities": [
            [
                69,
                79,
                "TERM"
            ],
            [
                146,
                156,
                "TERM"
            ]
        ]
    },
    {
        "text": "The main upside of the combining method, when compared to the exclusion method, is that no data is completely ignored: all text available for the analysis is included in the analysis.",
        "entities": [
            [
                123,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "The most frequent word in the corpus, that is, de, has 4,461 occurrences, whereas the 32nd word has only 499 occurrences, representing almost 10 times fewer occurrences.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, if we scroll further down the list until we find ranks 112-116, which all have the same token frequency of 20, we find that guess is in fact listed above OJ because it starts with letter g.",
        "entities": [
            [
                97,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "The replication crisis in linguistics is highly relevant to corpus-based research: Many corpus studies are not directly replicable as the data on which they are based are not readily available.",
        "entities": [
            [
                60,
                72,
                "TERM"
            ],
            [
                88,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, it might also be argued that the feature was not identified by previous corpus-based research so it is, by definition, not corpus-based.",
        "entities": [
            [
                91,
                103,
                "TERM"
            ],
            [
                142,
                154,
                "TERM"
            ]
        ]
    },
    {
        "text": "Essentially, the fact that the BNC is a mega corpus can easily be seen in the sheer number of words it contains.",
        "entities": [
            [
                45,
                51,
                "TERM"
            ]
        ]
    },
    {
        "text": "Stubbs, M. 2001. Words and phrases: corpus studies of lexical semantics.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "The use of rhetorics is a common practice in text generation.",
        "entities": [
            [
                45,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "The tasks of corpus linguists are manifold and complex.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "There may be more than one mode in a given sample.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, many journals specializing in different areas of linguistics, such as Journal of Pragmatics, Journal of Sociolinguistics and Journal of French Language Studies, regularly publish corpus studies.",
        "entities": [
            [
                192,
                198,
                "TERM"
            ]
        ]
    },
    {
        "text": "Data and information should be retrieved from a corpus.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "For our present purposes, it suffices to distinguish two broad varieties of concordancer that are used today.",
        "entities": [
            [
                76,
                88,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is for this reason that other computing tools, specifically devoted to corpus linguistics, have been developed.",
        "entities": [
            [
                74,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, there are textbooks that focus one or more specific corpus-based techniques, discussing very specific phenomena (often the research interests of the textbook authors themselves) using a narrow range of techniques (often involving specific software solutions).",
        "entities": [
            [
                71,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "Indeed, the corpus has such a flexible online interface that it allows the user to dynamically select a working corpus precisely tailored to their specific objectives.",
        "entities": [
            [
                12,
                18,
                "TERM"
            ],
            [
                112,
                118,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once annotated, the elements of the corpus can be searched by their POS tags by means of a concordancer.",
        "entities": [
            [
                91,
                103,
                "TERM"
            ],
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "As sources of data became computerized, concordancing programs were created that allow for various constructions (e.g. words or phrases) to be automatically retrieved from a corpus.",
        "entities": [
            [
                174,
                180,
                "TERM"
            ]
        ]
    },
    {
        "text": "For most of the questions addressed by corpus linguistics, it would be impossible to search through a paper database, and that is why having computerized corpora becomes essential.",
        "entities": [
            [
                39,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "Following this brief introduction, Section 2 explores the state of the art in collocation research, on the basis of which Section 3 presents a cross-linguistic study of the collocational behavior and semantic prosodies of a group of near synonyms in English and Chinese.",
        "entities": [
            [
                78,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "The researcher's control over the raw data production moreover influences the degree of variation that is represented in the corpus.",
        "entities": [
            [
                125,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "Modern technology allows one to store a corpus in such a manner that one can easily retrieve data from it.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "Since the data violated the assumption of normality, a U-test/Kruskal-Wallis test was computed, which showed that the difference between the two lengths is highly significant (for the U-test: W = 14,453, p < 0.001): In the population of English for which our sample is representative, direct objects are longer than subjects.",
        "entities": [
            [
                259,
                265,
                "TERM"
            ]
        ]
    },
    {
        "text": "The problem is that in a list of keyword results, mixing frequent items with very infrequent items often means mixing generalized phenomena with phenomena that are extremely localized, making an account of the keyword list problematic (see the following subsection for a statistical technique designed to reduce this problem).",
        "entities": [
            [
                33,
                40,
                "TERM"
            ],
            [
                210,
                217,
                "TERM"
            ]
        ]
    },
    {
        "text": "With written texts, if two line breaks are inserted between paragraphs while a text is being computerized, then paragraph tags can be inserted automatically at a later stage.",
        "entities": [
            [
                79,
                83,
                "TERM"
            ]
        ]
    },
    {
        "text": "Like its name suggests, the type-token ratio is the ratio of the number of different words in a text (types) to the number of all words in the text (tokens).",
        "entities": [
            [
                28,
                44,
                "TERM"
            ],
            [
                96,
                100,
                "TERM"
            ],
            [
                143,
                147,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section, we are discussing a few areas that we feel should be on corpus linguists' radar; they involve.",
        "entities": [
            [
                73,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "Until the 1980s, a corpus of a million words was considered to be a very large corpus.",
        "entities": [
            [
                19,
                25,
                "TERM"
            ],
            [
                79,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "Creating a corpus involves using (or even sharing with other researchers) language samples produced by third parties.",
        "entities": [
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Just seeing the results may also not yet allow you to see the usefulness of creating/using this type of class, but this will soon become clearer when we introduce quantification.",
        "entities": [
            [
                96,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "Corpus designers therefore need to reach out to different groups of contributors and use a range of incentives to obtain a representative sample.",
        "entities": [
            [
                138,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "The cross-sectional portion of the corpus includes 136 texts written based on the same image description task, by learners from the initial level to the advanced level, and by a control group of native speakers.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "What distinguishes then our 1 The type of content of social media platforms is not restricted to only one.",
        "entities": [
            [
                34,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "You generate a frequency list when you want to know how often something -usually words -occur in a corpus.",
        "entities": [
            [
                15,
                29,
                "TERM"
            ],
            [
                99,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "Other stages of building a corpus are also discussed, ranging from the administrative (how to keep records of texts that have been collected) to the practical, such as the various ways to transcribe recordings of speech.",
        "entities": [
            [
                27,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "Keyness in corpus linguistics is but the first statistical step in the analysis of texts.",
        "entities": [
            [
                11,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "When building general reference corpora from the web we need to choose seed words that are likely to appear across a wide range of topics, but there has been some debate about exactly what constitute good seeds for a corpus of this type.",
        "entities": [
            [
                217,
                223,
                "TERM"
            ],
            [
                232,
                236,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, for investigating the expression of subjectivity in journalistic discourse, a corpus entirely made up of editorials would not be appropriate, since this is only a sub-section of the genre, which incidentally is more likely to contain markers of subjectivity than other sub-genres, as dispatches for instance.",
        "entities": [
            [
                91,
                97,
                "TERM"
            ]
        ]
    },
    {
        "text": "Rather, they should explain what they want, e.g. an ordered list of important words in the corpus.",
        "entities": [
            [
                91,
                97,
                "TERM"
            ]
        ]
    },
    {
        "text": "The perspective of these studies tends to be descriptive, often with the aim of showing the usefulness of collocation research for some application area.",
        "entities": [
            [
                106,
                117,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, since this is an important issue, I would like to encourage you to not only get more familiar with this kind of encoding, but also do Exercise box 3.8 now.",
        "entities": [
            [
                121,
                129,
                "TERM"
            ]
        ]
    },
    {
        "text": "The standard deviation is an indicator of the amount of variation in a sample (or sub-sample) that is frequently reported; it is good practice to report standard deviations whenever we report means.",
        "entities": [
            [
                71,
                77,
                "TERM"
            ],
            [
                86,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "Constructions, however, can be difficult to search for unless they have a particular feature or string that can be searched for, or unless additional coding or annotation has already gone into the corpus, for example, in the form of GRAID annotations mentioned in 10.3.1 that enable searches for different types of clause constructions including the distinction between intransitive, (mono-) transitive, and ditransitive clause constructions.",
        "entities": [
            [
                160,
                170,
                "TERM"
            ],
            [
                197,
                203,
                "TERM"
            ]
        ]
    },
    {
        "text": "XML is a hierarchical format (that lends itself well to representation as a tree that does not allow cross-nesting/overlapping) in which you add to data markup and annotation in the form of either start and end tags (which may contain attribute-value pairs), or just start tags (with attribute-value pairs), and in fact you have seen examples above that are similar to that annotation already.",
        "entities": [
            [
                164,
                174,
                "TERM"
            ],
            [
                374,
                384,
                "TERM"
            ],
            [
                153,
                159,
                "TERM"
            ],
            [
                0,
                3,
                "TERM"
            ]
        ]
    },
    {
        "text": "We use lines to add the type-token ratio plot and add smoothers with lines(lowess(...)).",
        "entities": [
            [
                24,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, that demographers will have the answer to how to build a perfectly representative spoken corpus.",
        "entities": [
            [
                102,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "The primary aim of corpus linguistics is to understand linguistic patterns and explore how and why they occur.",
        "entities": [
            [
                19,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is not simply a matter of finding a balance, but constantly exploring new ways of approaching language so that possibilities of finding new knowledge constantly come into view.",
        "entities": [
            [
                41,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is a function file, which establishes a connection to a file and allows you to specify an encoding argument, and that connection will then be read with a function called readLines, which does exactly what its name suggests.",
        "entities": [
            [
                96,
                104,
                "TERM"
            ]
        ]
    },
    {
        "text": "A higher z-score indicates a greater degree of collocability of an item with the node word.",
        "entities": [
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, the high token frequency of -icle tells us nothing (or at least very little) about the importance of the affix; if anything, it tells us something about the importance of some of the words containing it.",
        "entities": [
            [
                25,
                30,
                "TERM"
            ]
        ]
    },
    {
        "text": "To do this, we create a new function (\"show corpus\") that finds the paths of all the corpus files in a folder (e.g. \"target_corpus\"), calls the \"get_file_content\" function on each file path, and then prints out the output of each file (lines 21-28).",
        "entities": [
            [
                44,
                50,
                "TERM"
            ],
            [
                85,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "The fourth component was the main reason to write this function: It returns for each match the corpus element in which it was found but also separates the match from its preceding and subsequent contexts with a tabstop (so that, if you print the content of exact. matches.2(...) [[4]] into a. txt or. csv file, you get a nice three-column output with the context preceding a match in a first column, the match in a second, and the context following a match in a third.",
        "entities": [
            [
                95,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "The right panel is a similar plot but it bins the words in the corpus (here into ten equally large parts), and again we can see that there are a lot of occurrences of \"Perl\" in the last 10 percent slice of the corpus.",
        "entities": [
            [
                63,
                69,
                "TERM"
            ],
            [
                210,
                216,
                "TERM"
            ]
        ]
    },
    {
        "text": "If the corpus is not suitable for the research questions, the corpus should be changed or retagged by the researcher.",
        "entities": [
            [
                7,
                13,
                "TERM"
            ],
            [
                62,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, what possibilities we have for the analysis of a corpus is inevitably a function of the affordances of the available software tools.",
        "entities": [
            [
                55,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "If encoding does not match, you will potentially not find relevant text.",
        "entities": [
            [
                3,
                11,
                "TERM"
            ],
            [
                67,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "These sequences seem easy enough to identify in a corpus (or in a list of hits for appropriately constructed queries), so a researcher studying the possessive may not even mention how they defined this construction.",
        "entities": [
            [
                50,
                56,
                "TERM"
            ]
        ]
    },
    {
        "text": "In (7) to (11), taken from COHA's sister corpus, the Corpus of Contemporary American English (COCA), all the \"nouns\" in boldface are used in a descriptive and non-referential function (i.e., similarly to key and fun in Examples (1) to (4) above), and yet none of them has been annotated as an adjective in the corpus.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ],
            [
                310,
                316,
                "TERM"
            ]
        ]
    },
    {
        "text": "Following the coding scheme described above, two independent raters coded a random sample of 100 concordance lines from a total of 1,053 containing the word religion in the corpus.",
        "entities": [
            [
                97,
                108,
                "TERM"
            ],
            [
                173,
                179,
                "TERM"
            ],
            [
                83,
                89,
                "TERM"
            ]
        ]
    },
    {
        "text": "Part of this information about the corpus is a citation so that it can be referenced, as we do in this book.",
        "entities": [
            [
                35,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "Subsequent sections discuss other topics relevant to planning the building of a corpus, such as defining exactly what a corpus is.",
        "entities": [
            [
                80,
                86,
                "TERM"
            ],
            [
                120,
                126,
                "TERM"
            ]
        ]
    },
    {
        "text": "These annotations thus abstract away from the language-specific structures that morphological glossing and most PoS-tagging capture.",
        "entities": [
            [
                116,
                123,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, whereas the data used in this sample meta-analysis is purely fictional, in a real meta-analysis, if you were to discover after exhaustively searching for and collecting previous research that the number of \"distant\" L1 studies was similarly small (e.g., k = 4), the study would also provide evidence of a need for further research in this area.",
        "entities": [
            [
                43,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "The 10 most frequent content words are the following: This list illustrates the fact that the most frequent words in a corpus are those belonging to functional categories such as prepositions and determiners.",
        "entities": [
            [
                119,
                125,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, fall, falling and fell occur always before the node love, while you occurs both before and after love with approximately the same frequency.",
        "entities": [
            [
                61,
                65,
                "TERM"
            ]
        ]
    },
    {
        "text": "In general, we should also be aware of the fact that distributing a corpus implicitly amounts to disseminating the ideas contained inside its texts.",
        "entities": [
            [
                68,
                74,
                "TERM"
            ]
        ]
    },
    {
        "text": "We can search for a specific lexeme in a corpus and determine its collocates, that is, a list of lexemes that co-occurs with it.",
        "entities": [
            [
                41,
                47,
                "TERM"
            ]
        ]
    },
    {
        "text": "The word context here refers to something different from what we discussed above, that is, not the situational usage in a particular place and time, but instead the immediately surrounding text, something we can also refer to as co-text in case of ambiguity.",
        "entities": [
            [
                189,
                193,
                "TERM"
            ],
            [
                232,
                236,
                "TERM"
            ]
        ]
    },
    {
        "text": "Metadata is what distinguishes a corpus from a random collection of texts by giving it explicit structure: minimally any user of a corpus will know what amount of text data is contained in it, what characteristics texts have, for example, whether they are written for a newspaper or spoken during a conversation with friends or colleagues, who produced the text, and so on.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ],
            [
                131,
                137,
                "TERM"
            ],
            [
                163,
                167,
                "TERM"
            ],
            [
                357,
                361,
                "TERM"
            ]
        ]
    },
    {
        "text": "The BNC is probably the most well-known corpus focused on a national variety.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "Indeed, such a corpus makes it possible to establish the degree of mutual correspondences between these connectives, by counting the number of times that they can be translated by each other.",
        "entities": [
            [
                15,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "Ultimately, the length of a corpus is best determined by its intended use.",
        "entities": [
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, the bulk of the corpus contains various kinds of informative prose, including press reportage, editorials, and reviews; government documents; differing types of learned writing; learned writing from, for instance, the humanities and social sciences.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "Yet, the building of an LD-based corpus faces particular challenges through the typically severer limitations of resources and the fact that potential academic users of the corpus have typically no prior knowledge.",
        "entities": [
            [
                33,
                39,
                "TERM"
            ],
            [
                173,
                179,
                "TERM"
            ]
        ]
    },
    {
        "text": "Often, however, such a search will come up empty, or existing annotation schemes will not be suitable for the specific data we plan to use or they may be incompatible with our theoretical assumptions.",
        "entities": [
            [
                62,
                72,
                "TERM"
            ]
        ]
    },
    {
        "text": "The absence of an annotation in the second slot is read as 'non-human' .",
        "entities": [
            [
                18,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "Whatever the annotation considered and the tag set chosen, the annotation of the first occurrences is generally difficult and many problems and borderline cases arise.",
        "entities": [
            [
                13,
                23,
                "TERM"
            ],
            [
                63,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even registers with a great deal of diachronic stability, such as religious writing, are subject to change in this regard.",
        "entities": [
            [
                36,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "Once generated, the concordance was saved and then a special command -\"delete to N\" -was used to reduce the concordance lines to a random sample of just 100.",
        "entities": [
            [
                20,
                31,
                "TERM"
            ],
            [
                108,
                119,
                "TERM"
            ],
            [
                138,
                144,
                "TERM"
            ]
        ]
    },
    {
        "text": "Furthermore, the question of sample and population is often quite complex in most real research projects and requires a lot more attention than what was given to it in section 6.",
        "entities": [
            [
                29,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, for the 90 texts labeled S1A-001 to S1A-090, the letter S indicates that each 2,000-word sample represents spoken English; the numerals 001-090 that it was a private conversation (either a spontaneous conversation or a telephone call); and the uppercase A that it was a dialogue.",
        "entities": [
            [
                103,
                109,
                "TERM"
            ]
        ]
    },
    {
        "text": "Simple type/token ratio (TTR) was used to compare the texts because they were of the same length (2,000 tokens).",
        "entities": [
            [
                12,
                17,
                "TERM"
            ],
            [
                7,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even for very restricted corpora in terms of text types, like ATC corpora, variability in situational features is relevant, and so these will have to contain text specimens produced by female and male pilots of different age groups, different linguistic backgrounds, and so forth.",
        "entities": [
            [
                45,
                49,
                "TERM"
            ],
            [
                158,
                162,
                "TERM"
            ]
        ]
    },
    {
        "text": "Corpus linguistics has long championed, and pioneered, markup schemes to permit the systematic encoding of metadata and interpretative analyses within corpora.",
        "entities": [
            [
                95,
                103,
                "TERM"
            ],
            [
                107,
                115,
                "TERM"
            ],
            [
                55,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "For the right panel, we will define a number of corpus parts we want (here ten) so that the script can easily be changed to accommodate different divisions of the corpus into parts.",
        "entities": [
            [
                48,
                54,
                "TERM"
            ],
            [
                163,
                169,
                "TERM"
            ]
        ]
    },
    {
        "text": "Likewise, the stylistic genre of the corpus should be compatible with the question under investigation.",
        "entities": [
            [
                37,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "But while printed texts can be easily included in a corpus, spoken texts still have to be manually transcribed: no voice recognition software can accurately produce a transcription because of the complexities of spoken language, particularly spontaneous conversation with its numerous hesitations, incomplete sentences, and reformulations.",
        "entities": [
            [
                52,
                58,
                "TERM"
            ]
        ]
    },
    {
        "text": "Indeed, we may well observe different tendencies in another corpus of British English.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter provides you with an opportunity to use readily available corpora to conduct corpus linguistics projects.",
        "entities": [
            [
                90,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "Often a concordance display gives information about the word by putting that word in the middle of a line with a certain amount of words preceding and following it.",
        "entities": [
            [
                8,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "In including short samples from many different texts, corpus compilers are assuming that it is better to include more texts from many different speakers and writers than fewer texts from a smaller number of speakers and writers.",
        "entities": [
            [
                54,
                60,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some concern methodology within corpus linguistics.",
        "entities": [
            [
                32,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "Yet the by far most serious issue is the presence of errors in the source material, which introduces errors to analyses, and, in the worst case, may compromise the representativeness of corpora.",
        "entities": [
            [
                164,
                182,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, two fixed effects candidates are annotated (the type of the head of the direct object and the logarithmised length of the direct object in words).",
        "entities": [
            [
                57,
                61,
                "TERM"
            ]
        ]
    },
    {
        "text": "Written texts, in contrast, are now widely available in digital formats and can easily be incorporated in a corpus after permission has been received to use a given text.",
        "entities": [
            [
                108,
                114,
                "TERM"
            ],
            [
                165,
                169,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are a number of reasons why a sample might be biased.",
        "entities": [
            [
                36,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you do have the relevant programs installed on your computer, you can also try to create more complex versions, containing more text and formatting, of the different document types yourself and then investigate them.",
        "entities": [
            [
                131,
                135,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, though, this makes it possible for the basic text to be linked to various types of data-enriching annotations, as well as to perform more complex search operations, or to store intermediate or final results of such searches for different users and for quicker access or export later.",
        "entities": [
            [
                64,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is referred to as lemmatisation (c.f. also Section 8.1.8, where we looked at lemma queries in BNCweb), and many programs that produce frequency lists offer this kind of facility.",
        "entities": [
            [
                23,
                36,
                "TERM"
            ],
            [
                82,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "Its wide temporal coverage and large scope of lexical types make the OED an ideal basis for studies that investigate diachronic type frequency changes in phenomena such as the way-construction.",
        "entities": [
            [
                117,
                127,
                "TERM"
            ],
            [
                128,
                132,
                "TERM"
            ]
        ]
    },
    {
        "text": "This statistical noise explains why the models' coefficients do not correspond exactly to the number of milliseconds that we specified for each type of example.",
        "entities": [
            [
                144,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because of the difficulties in obtaining permission to use copyrighted materials, most corpus compilers have found themselves collecting far more written material than they are able to obtain permission to use: for ICE-USA, permission had been obtained to use only about 25 percent of the written texts initially considered for inclusion in the corpus.",
        "entities": [
            [
                87,
                93,
                "TERM"
            ],
            [
                345,
                351,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, U. Gut the interoperability between tools is still one of the major challenges for spoken corpus use and re-use across linguistic subdisciplines as discussed in Sect. 11.3.",
        "entities": [
            [
                99,
                105,
                "TERM"
            ]
        ]
    },
    {
        "text": "A historical or diachronic corpus is a collection of texts from different periods.",
        "entities": [
            [
                16,
                26,
                "TERM"
            ],
            [
                27,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "Consider again the major difference between published and private texts: where a text is published it is fixed to some medium in some basic format, whether digital or analogue.",
        "entities": [
            [
                81,
                85,
                "TERM"
            ]
        ]
    },
    {
        "text": "This can be very simple, like counting all the words in a corpus or a specific word within a corpus, but can also become very complicated.",
        "entities": [
            [
                58,
                64,
                "TERM"
            ],
            [
                93,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, if one text is highly edited in style, and another one is highly casual, combining them together results in a loss of a lot of this information, and makes the combined text look somewhat average on both counts.",
        "entities": [
            [
                20,
                24,
                "TERM"
            ],
            [
                181,
                185,
                "TERM"
            ]
        ]
    },
    {
        "text": "These taggers and parsers and their associated annotation systems tend to be unable to support the analysis of language in use beyond spoken discourse.",
        "entities": [
            [
                47,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "If we calculate the normalized frequency of first-person pronouns in this text, we get as the result 200 first-person pronouns per 1,000 words.",
        "entities": [
            [
                74,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "I cannot think of any other scientific discipline whose textbook authors would feel compelled to begin their exposition by defending the use of observational data, and yet corpus linguistics textbooks often do exactly that.",
        "entities": [
            [
                172,
                190,
                "TERM"
            ]
        ]
    },
    {
        "text": "We showed how we can do a corpus-based study with already identified language features, whether doing a lexical study or searching for the use of particular grammatical patterns.",
        "entities": [
            [
                26,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "In one sense, the distinction between corpus-driven and corpus-based research methods can be misleading.",
        "entities": [
            [
                38,
                51,
                "TERM"
            ],
            [
                56,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "As we move through the text word by word, initially all words are new types and hapaxes, so the type-and hapax-counts rise at the same rate as the token counts.",
        "entities": [
            [
                147,
                152,
                "TERM"
            ],
            [
                96,
                100,
                "TERM"
            ],
            [
                23,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, at 1.9 billion words in length, the Corpus of Global Web-Based English is so lengthy that it would be impossible to determine not just the content of the corpus but the distribution of such variables as the gender of contributors, their ages, and so forth.",
        "entities": [
            [
                168,
                174,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because so much text is now available in computer-readable form, many stages of dictionary creation can be automated.",
        "entities": [
            [
                16,
                20,
                "TERM"
            ]
        ]
    },
    {
        "text": "Now, let us move on to the question of which samples to include in the corpus.",
        "entities": [
            [
                71,
                77,
                "TERM"
            ]
        ]
    },
    {
        "text": "Similarly, a person working on comparative studies between two or more languages requires a multilingual comparable corpus than a monitor one.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "In terms of attributes, you should be able to find 27, where 'n' represents numerical identifiers for all the 14 textual elements, 'pos' the 12 PoS categories for the words, and 'type' which type of punctuation is present at the end of the syntactic unit.",
        "entities": [
            [
                179,
                183,
                "TERM"
            ],
            [
                191,
                195,
                "TERM"
            ]
        ]
    },
    {
        "text": "The arrival of these tools has greatly accelerated research in corpus linguistics.",
        "entities": [
            [
                63,
                81,
                "TERM"
            ]
        ]
    },
    {
        "text": "A more complex parallel design is used by Øveras (1998), who searches for shifts in cohesion/coherence in the English-Norwegian Parallel Corpus, a bidirectional corpus including STs in English and their Norwegian TTs and (comparable) STs in Norwegian and their English TTs.",
        "entities": [
            [
                161,
                167,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is a variety of very good reasons for this, some of them related to corpus linguistics, some more general.",
        "entities": [
            [
                74,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "In fact a concordance of restraint and another of violen* in an 8-word span of on either/both/all sides yielded altogether 18 results, all of them contained in the Podium's turns.",
        "entities": [
            [
                10,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "This means that the number of the notional parts, and their length (v in equation (2.20)), depend on the frequency of the word in the corpus.",
        "entities": [
            [
                134,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "From the 1 million word Brown corpus of the 1960s to the 100 million word BNC of the 1990s, the resources used by researchers in the field have conventionally been of known (usually finite) size.",
        "entities": [
            [
                30,
                36,
                "TERM"
            ]
        ]
    },
    {
        "text": "Above, we mostly looked at retrieving the data values of our XML data, but of course we want to also use the often detailed annotation that is within the tags.",
        "entities": [
            [
                124,
                134,
                "TERM"
            ],
            [
                61,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "Both of these mistakes basically may cause you to lose valuable time that could be spent on actually analysing your data, thus 'throwing away' one of the most important advantages of using corpus linguistics as a methodology, which is that it allows you to save a significant amount of time finding a large amount of potentially relevant and interesting data quickly.",
        "entities": [
            [
                189,
                207,
                "TERM"
            ]
        ]
    },
    {
        "text": "In diachronic research, scholars may focus on the specific usage of a word or a structure.",
        "entities": [
            [
                3,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "This involves not only collecting data (speech and writing) but encoding it: transcribing recorded speech, for instance, as well as adding annotation to it, such as markup indicating in a conversation when one person's speech overlaps another speaker's, and in writing where such features as paragraph boundaries occur in written texts.",
        "entities": [
            [
                139,
                149,
                "TERM"
            ],
            [
                64,
                72,
                "TERM"
            ],
            [
                165,
                171,
                "TERM"
            ]
        ]
    },
    {
        "text": "Everybody who has ever worked in corpus linguistics knows that no corpus will ever be perfect, and that the quality of a corpus depends less on the competence of the researchers involved than on the resources they were able to put into it.",
        "entities": [
            [
                33,
                51,
                "TERM"
            ],
            [
                66,
                72,
                "TERM"
            ],
            [
                121,
                127,
                "TERM"
            ]
        ]
    },
    {
        "text": "Data retrieval and annotation for this task.",
        "entities": [
            [
                19,
                29,
                "TERM"
            ]
        ]
    },
    {
        "text": "Semantic feature annotation is separated from the form slot by a <.>.",
        "entities": [
            [
                17,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "This approach results from a combination of corpus-linguistic and literary arguments.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us further limit the category to verbs first documented before the 19th century, in order to leave a clear diachronic gap between the established types and the productive types.",
        "entities": [
            [
                111,
                121,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, note that -ify has a token frequency that is less than half of that of -ise/-ize, so the sample is much smaller: as in the example of lexical richness in Pride and Prejudice, this means that the TTR and the HTR of this smaller sample are exaggerated and our comparisons in Tables 9.4 and 9.5 as well as the accompanying statistics are, in fact, completely meaningless.",
        "entities": [
            [
                98,
                104,
                "TERM"
            ],
            [
                236,
                242,
                "TERM"
            ],
            [
                30,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "At 3 years and 5 months old, the most frequent word was ça with 54 occurrences, and her type/token ratio was 0.21.",
        "entities": [
            [
                93,
                98,
                "TERM"
            ],
            [
                88,
                92,
                "TERM"
            ]
        ]
    },
    {
        "text": "Without metadata, we cannot test whether differences between any of these categories are meaningful.",
        "entities": [
            [
                8,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even if works related to corpus linguistics have existed for a long time (such as the indexing of the Bible by theologians or the file-based construction of dictionaries by scholars like Antoine Furetière in French or Samuel Johnson in English), this discipline was only able to properly take off after the arrival of computing.",
        "entities": [
            [
                25,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "Comparing the texts shared by ECCO and ECCO-TCP, we find that more than 90% of the hapax legomena in the ECCO sample (henceforth ECCO-OCR) are not found in ECCO-TCP.",
        "entities": [
            [
                110,
                116,
                "TERM"
            ]
        ]
    },
    {
        "text": "Many corpus studies take a similar approach in looking at words or domains in the lexicon and comparing uses.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "There are several projects gathering very large corpora on a broader range of web-accessible text.",
        "entities": [
            [
                93,
                97,
                "TERM"
            ]
        ]
    },
    {
        "text": "For instance, while a draft version of a text in the category of business transactions is being created, the text is saved as \"S1B-071di\", the \"i\" indicating that work on the text is incomplete.",
        "entities": [
            [
                41,
                45,
                "TERM"
            ],
            [
                109,
                113,
                "TERM"
            ],
            [
                175,
                179,
                "TERM"
            ]
        ]
    },
    {
        "text": "Such studies have two nominal variables: Culture (operationalized as \"corpus containing language produced by members of the culture\") and Area of Life (operationalized as \"semantic field\").",
        "entities": [
            [
                70,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "As in all research, there is much in corpus linguistics that is subjective, including the choice of research question and of the procedures and software to employ, not to mention the interpretation of the output data.",
        "entities": [
            [
                37,
                55,
                "TERM"
            ]
        ]
    },
    {
        "text": "These 15 columns correspond to the 15 text categories.",
        "entities": [
            [
                38,
                42,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, even if the texts of the corpus have been selected randomly, the sentences and words are not random.",
        "entities": [
            [
                34,
                40,
                "TERM"
            ]
        ]
    },
    {
        "text": "Consequently, his style of speaking has drawn considerable interest from corpus linguists.",
        "entities": [
            [
                73,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "In principle this can be done by using the symbols of the IPA to render the corpus text.",
        "entities": [
            [
                76,
                82,
                "TERM"
            ],
            [
                83,
                87,
                "TERM"
            ]
        ]
    },
    {
        "text": "The n-gram procedure was applied to the full text of Alice's Adventures in Wonderland (one of the most frequently downloaded texts from the Internet Archive and Project Gutenburg) 13 using Ted Pedersen's N-gram Statistics Package (NSP).",
        "entities": [
            [
                45,
                49,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moon's analysis is particularly enlightening in that it offers a diachronic perspective to current lexicographic practice and places emphasis on \"the function of phraseological information in relation to the needs and interests of the target users\" (2008b: 333).",
        "entities": [
            [
                65,
                75,
                "TERM"
            ]
        ]
    },
    {
        "text": "We use a for-loop to scan and tolower the corpus files, and grep to get the sentences.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "Exploring a corpus qualitatively allows the analyst to provide descriptive information about the results that cannot be presented strictly quantitatively.",
        "entities": [
            [
                12,
                18,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the Helsinki Corpus, text samples range from 2,000 to 10,000 words in length.",
        "entities": [
            [
                24,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the final brief section (Chapter 11), I've tried to provide you with a short, but nevertheless highly practical, glimpse at what current technology in the form of XML has to offer to linguists who want to enrich their data and/or visualise important facts inherent in it.",
        "entities": [
            [
                166,
                169,
                "TERM"
            ]
        ]
    },
    {
        "text": "This allows for the corpus to be used for comparisons between the authors short stories and novels, as well as comparisons between different authors considered to belong within the same group.",
        "entities": [
            [
                20,
                26,
                "TERM"
            ]
        ]
    },
    {
        "text": "While the Web has increasingly become a corpus used for linguistic analysis, the other two sources of dataan archive of tweets and a collection of Trump's speeches and interviewsare specific to this particular analysis.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "This relationship is addressed by questions about what linguistic features are best regarded as register, genre or style features, but also by testing models originally designed for the analysis of literary texts on a larger corpus.",
        "entities": [
            [
                225,
                231,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, note that our final definition does distinguish corpus linguistics from other kinds of observational methods, such as text linguistics, discourse analysis, variationist sociolinguistics, etc., but it does so in a way that allows us to recognize the overlaps between these methods.",
        "entities": [
            [
                57,
                75,
                "TERM"
            ],
            [
                127,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "The last point to discuss in this section is the appropriate test for statistical significance that can be used with cross-tabulation; a statistical significance test evaluates the amount of evidence against the null hypothesis (see Section 1.3).",
        "entities": [
            [
                70,
                94,
                "TERM"
            ],
            [
                137,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "The attitudes of corpus linguists seem to include both a healthy sense of humility as regards what is possible to achieve, as well as an understanding of the need to continuously remind the scholarly community of the core concerns in the field.",
        "entities": [
            [
                17,
                23,
                "TERM"
            ]
        ]
    },
    {
        "text": "The best examples we've seen for this were the meta-textual choices BNCweb allowed us to make for selecting specific parts of the BNC for different analysis purposes, which were all made possible by the fact that the BNC (in its most recent version) is marked up in XML, albeit with somewhat over-elaborate header information, as we'll soon discuss.",
        "entities": [
            [
                266,
                269,
                "TERM"
            ]
        ]
    },
    {
        "text": "In the years before 2000 and the early 2000s, corpus linguistics tended to be studied by using enormous empirical datasets.",
        "entities": [
            [
                46,
                64,
                "TERM"
            ]
        ]
    },
    {
        "text": "Second, a corpus can contain either complete texts (e.g. a collection of newspaper articles) or parts of texts (e.g. 500-word samples from various newspaper articles).",
        "entities": [
            [
                10,
                16,
                "TERM"
            ]
        ]
    },
    {
        "text": "Especially over the last ten years or so, corpus linguists have begun to take this (in some sense obvious) fact into consideration and have followed the general development in linguistics towards more and more sophisticated quantitative methods.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter presents some of the key 50 A. Zeldes characteristics distinguishing different corpus architectures.",
        "entities": [
            [
                92,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "To be interpreted meaningfully, then, it must therefore nearly always be combined with some form of qualitative analysis -that is, an analysis that involves the linguist interacting with the actual discourse within the corpus and its structure and/or meaning.",
        "entities": [
            [
                219,
                225,
                "TERM"
            ]
        ]
    },
    {
        "text": "We simply take the size of the smaller of our two samples and draw a random sample of the same size from the larger of the two samples (if our data sets are large enough, it would be even better to draw random samples for both affixes).",
        "entities": [
            [
                76,
                82,
                "TERM"
            ]
        ]
    },
    {
        "text": "Plain-text files in general tend to be much smaller than other files because representing characters, even if some of them may take up six bytes in UTF-8 in some cases, does not require much space.",
        "entities": [
            [
                6,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "This kind of display is called keyword in context or KWIC.",
        "entities": [
            [
                31,
                38,
                "TERM"
            ]
        ]
    },
    {
        "text": "These all highlight the relationship between lexis and grammar and are useful to a language learner.",
        "entities": [
            [
                45,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "A very general precaution against this possibility is to make sure that the corpus (or our sample) is balanced with respect to all potentially confounding variables.",
        "entities": [
            [
                76,
                82,
                "TERM"
            ],
            [
                91,
                97,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, out of the total number of hits of royal in the corpus -14,628 hits in 1,825 texts -it appears with a capital initial as often as 10,237 times in 1,603 texts).",
        "entities": [
            [
                57,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "While one corpus can be compared to another reference corpus, these tools also make it possible to extract a list of keywords that are specific to the corpus studied.",
        "entities": [
            [
                44,
                60,
                "TERM"
            ],
            [
                10,
                16,
                "TERM"
            ],
            [
                151,
                157,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although they are not necessarily viewed as such, some existing techniques in corpus linguistics can be considered as visualisations.",
        "entities": [
            [
                78,
                96,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is chiefly due to the greater costs and challenges in terms of technology and time that are connected with the compilation and annotation of spoken corpora.",
        "entities": [
            [
                132,
                142,
                "TERM"
            ]
        ]
    },
    {
        "text": "In general, the investigation is top-down, in the sense that a question is asked of the corpus and means devised to find the answer to the question.",
        "entities": [
            [
                88,
                94,
                "TERM"
            ]
        ]
    },
    {
        "text": "This chapter has shown that corpus approaches to the study of literary style can take various forms.",
        "entities": [
            [
                28,
                34,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, this very heterogeneity could skew the results of our general collocational statistics rather strongly, especially in such a small corpus.",
        "entities": [
            [
                140,
                146,
                "TERM"
            ]
        ]
    },
    {
        "text": "In ECL1, it is noted that \"as more and more corpora have been created, we have gained considerable knowledge of how to construct a corpus that is balanced and representative and that will yield reliable grammatical information\" (138).",
        "entities": [
            [
                131,
                137,
                "TERM"
            ]
        ]
    },
    {
        "text": "He develops software programs that are extremely useful for corpus linguistic analyses and he makes them freely available (although you are able to make a donation should you choose to do so).",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, when dealing with diachronic comparisons, we need to assess whether the observed differences in frequencies are related to change in the discourse/language over time or whether these are related to other sources of variation.",
        "entities": [
            [
                31,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "A histogram is a type of bar graph that groups values into a series of intervals (or bins).",
        "entities": [
            [
                17,
                21,
                "TERM"
            ]
        ]
    },
    {
        "text": "They confirmed that some of the meanings frequently found in the corpus could not be adequately translated by their \"equivalent\".",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpora were compared qualitatively as well, by identifying patterns in the concordance lines and analysing the context (\"collocational profiles\") of the references to hosts, specifically of people and locals, which occurred in both corpora.",
        "entities": [
            [
                80,
                91,
                "TERM"
            ]
        ]
    },
    {
        "text": "A balanced news writing corpus would either include texts of sports, lifestyle, and general news texts or would select only one of these text types for analysis.",
        "entities": [
            [
                24,
                30,
                "TERM"
            ],
            [
                137,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "A random sample of 2,000 words was taken for each MP, with MPs excluded who had used less than 2,000 words (thereby removing only 3 MPs).",
        "entities": [
            [
                9,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "The SEC corpus is coded for these features as well as temporal alignment at the level of the phoneme.",
        "entities": [
            [
                8,
                14,
                "TERM"
            ]
        ]
    },
    {
        "text": "Providing this type of social background information of course poses new challenges, requiring a thorough knowledge of the social structure of past societies.",
        "entities": [
            [
                15,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "When we ask about word types we are asking about how many different word forms there are in the text/corpus.",
        "entities": [
            [
                101,
                107,
                "TERM"
            ],
            [
                96,
                100,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, this very redundancy may help us to classify -or even identify the exact genre ofa text better.",
        "entities": [
            [
                102,
                106,
                "TERM"
            ]
        ]
    },
    {
        "text": "Client-server tools currently in wide use include SketchEngine, Wmatrix and CQPweb; some of these allow users to upload their own data to the corpus server, while others restrict users to a static set of available corpora.",
        "entities": [
            [
                142,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us test this hypothesis using the Corpus of Historical American English, which includes language from the early nineteenth to the very early twenty-first century -in a large part of the corpus, the twentieth century was thus entirely or partly in the future.",
        "entities": [
            [
                190,
                196,
                "TERM"
            ]
        ]
    },
    {
        "text": "Essentially, the option we just explored has relatively little to do with keywords as calculated through the options from the top part of the same page, as all it really does is eliminate all word types both corpora share, and then display whatever remains as a frequency list.",
        "entities": [
            [
                262,
                276,
                "TERM"
            ]
        ]
    },
    {
        "text": "A thorough synthesis that answers this question would be very useful to corpus linguists.",
        "entities": [
            [
                72,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "Just as with auxiliaries and pronouns, we also ought to be very careful when eliminating prepositions and conjunctions from our frequency lists because they may equally tell us something about the domain or genre of a particular text. Imagine, for example, a text from the domain of finance about developments on the stock market, where certain values rise above/to or fall below/down to certain thresholds, etc., where the verbs on their own may not give us enough grounds to distinguish the type of domain, just like the verbs that form part of phrasal/prepositional verb combinations are often semantically relatively empty.",
        "entities": [
            [
                493,
                497,
                "TERM"
            ],
            [
                229,
                233,
                "TERM"
            ],
            [
                259,
                263,
                "TERM"
            ]
        ]
    },
    {
        "text": "In Section 2, an initial survey demonstrates the importance of the register factor in historical corpus linguistics and introduces a number of central matters that arise when the concept of register is applied to diachronic material.",
        "entities": [
            [
                97,
                115,
                "TERM"
            ],
            [
                213,
                223,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then, there is a difference between diachronic corpora and synchronic corpora.",
        "entities": [
            [
                36,
                46,
                "TERM"
            ],
            [
                59,
                69,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, unless we carefully search our corpus manually (a possibility I will return to below), there is typically a trade-off between the two.",
        "entities": [
            [
                40,
                46,
                "TERM"
            ]
        ]
    },
    {
        "text": "For example, s(CorpusTime, Speaker, bs = \"fs\", m = 1) requests wiggly curves for log odds as a function of CorpusTime for all speakers in the corpus.",
        "entities": [
            [
                142,
                148,
                "TERM"
            ]
        ]
    },
    {
        "text": "The final dimension incorporated into our proposed framework is time which will assist with the exploration and visualisation of diachronic corpora.",
        "entities": [
            [
                129,
                139,
                "TERM"
            ]
        ]
    },
    {
        "text": "An outline of collocation and the measurements used to strengthen assumptions will be made from the collocations.",
        "entities": [
            [
                14,
                25,
                "TERM"
            ]
        ]
    },
    {
        "text": "If you have chosen your favourite keyword list for American English, you might be interested in knowing which procedure was used to identify these keywords.",
        "entities": [
            [
                34,
                41,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a negative directional hypothesis, the sample group will perform worse than the population.",
        "entities": [
            [
                42,
                48,
                "TERM"
            ]
        ]
    },
    {
        "text": "To verify the results for any particular type in either subcorpus, you can use the hyperlinks in the columns labelled 'TOKENS 1' and 'TOKENS 2', respectively to have KWIC concordances displayed in the frame in the bottom half.",
        "entities": [
            [
                41,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "The article is especially interesting for its discourse-oriented perspective, starting from a rhetorical function rather than from one or two isolated items, as well as for its focus on scientific prose and its plea for more corpus-based English for Academic/Specific Purposes textbooks.",
        "entities": [
            [
                225,
                237,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, corpus linguistics needs to explore more adequate and conservative ways to extend AMs to n-grams.",
        "entities": [
            [
                6,
                24,
                "TERM"
            ]
        ]
    },
    {
        "text": "Logistic regression models are easier to fit and easier to interpret than multinomial regression, and are what you will see most commonly in multivariate quantitative corpus linguistics.",
        "entities": [
            [
                167,
                185,
                "TERM"
            ]
        ]
    },
    {
        "text": "Consequently, we suggest that it would be prudent to think about the principle of \"knowing one's data\" from a new perspective: as the sheer size of the modern mega-corpora prevents scholars from engaging with either all or the majority of the original source texts in as much detail as in the early days of historical corpus linguistics, they should strive for an intimate understanding of the historical corpora as mediators of the original texts.",
        "entities": [
            [
                318,
                336,
                "TERM"
            ]
        ]
    },
    {
        "text": "It does not influence the close-reading method in a meaningful way and does not indicate information that could tie the text(s) to a broader intellectual context.",
        "entities": [
            [
                120,
                124,
                "TERM"
            ]
        ]
    },
    {
        "text": "In addition, this program is able to show you how the word (or collocate or lexical bundle or any n-gram) is distributed within each of your texts (a concordance plot) as well as how many texts include examples of your search term.",
        "entities": [
            [
                150,
                161,
                "TERM"
            ]
        ]
    },
    {
        "text": "The assumption underlying basically all corpus-based analyses, however, is that formal differences reflect functional differences: Different frequencies of (co-)occurrences of formal elements are supposed to reflect functional regularities, where functional is understood here in a very broad sense as anything -be it semantic, discourse-pragmatic, etc. -that is intended to perform a particular communicative function.",
        "entities": [
            [
                40,
                52,
                "TERM"
            ]
        ]
    },
    {
        "text": "First, the corpus is tagged for linguistic features.",
        "entities": [
            [
                11,
                17,
                "TERM"
            ]
        ]
    },
    {
        "text": "Seeing the distributional patterns can also help in examining whether your findings for a given feature are, in fact, spread in your corpus or are found in a limited number of texts only.",
        "entities": [
            [
                133,
                139,
                "TERM"
            ]
        ]
    },
    {
        "text": "The extension of the corpus-linguistic paradigm to past stages of the English language has increased the attention given to sampling issues in the above regard.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ]
        ]
    },
    {
        "text": "A practical solution is to code these characteristics directly onto the file names: this is why these names are another important element that should be taken into account when creating the corpus.",
        "entities": [
            [
                190,
                196,
                "TERM"
            ]
        ]
    },
    {
        "text": "The processes of corpus sanitation start when a corpus is made ready for use.",
        "entities": [
            [
                17,
                23,
                "TERM"
            ],
            [
                48,
                54,
                "TERM"
            ]
        ]
    },
    {
        "text": "This makes a practical difference: recording e.g. a 5-hour sample within a predefined week of the month (the sample can be subdivided in several recordings of different length within this week) will on average be easier to accomplish than recording a 1-hour sample every week, which implies a high demand of discipline both of the recording assistant and the families.",
        "entities": [
            [
                59,
                65,
                "TERM"
            ],
            [
                109,
                115,
                "TERM"
            ],
            [
                258,
                264,
                "TERM"
            ]
        ]
    },
    {
        "text": "This handbook aims to address all these areas with contributions by many of their leading experts, to be a comprehensive practical resource for junior and more v vi Introduction senior corpus linguists, and to represent the whole research cycle from corpus creation, method, and analyses to reporting results for publication.",
        "entities": [
            [
                185,
                191,
                "TERM"
            ],
            [
                250,
                256,
                "TERM"
            ]
        ]
    },
    {
        "text": "In order to study the distribution and prevalence of this type of structure in the French spoken in Parisian suburbs, all the occurrences of indirect questions were collected in a small oral corpus of approximately 350,000 words.",
        "entities": [
            [
                191,
                197,
                "TERM"
            ],
            [
                58,
                62,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some programs (e.g. WordSmith, AntConc) run from the researcher's desktop computer; this means that the user can analyse any corpus they have available locally using these programs.",
        "entities": [
            [
                125,
                131,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this case, it is rare to be able to rely on automatic annotation tools.",
        "entities": [
            [
                57,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "Even though the basics of computerizing spoken and written data are the same, depending on the type of data (speech or written), the methods used for computerizing differ.",
        "entities": [
            [
                95,
                99,
                "TERM"
            ]
        ]
    },
    {
        "text": "To a large extent, these are reasons why the corpus-based approach is not more popular in dialectology and sociolinguistics today.",
        "entities": [
            [
                45,
                57,
                "TERM"
            ]
        ]
    },
    {
        "text": "The with an uppercase T does not occur in the tagged LOB corpus, because case is normalized such that only proper names are capitalized.",
        "entities": [
            [
                57,
                63,
                "TERM"
            ]
        ]
    },
    {
        "text": "In this section, we summarize the evidence gathered across the case studies, and show which classification method is expected to give strongest results in similar semi-automatic annotation setups.",
        "entities": [
            [
                178,
                188,
                "TERM"
            ]
        ]
    },
    {
        "text": "Two critical obstacles that need to be addressed in frequency list research is the handling of homoforms (e.g., river bank vs. investment bank vs. bank as a verb) and multi-word units (e.g., I didn't care for the movie at all vs.",
        "entities": [
            [
                52,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, by taking a small sample of the instances and going back to the document images, we discovered that about a third of the instances of \"economy\" were in fact OCR errors for \"oeconomy\".",
        "entities": [
            [
                27,
                33,
                "TERM"
            ]
        ]
    },
    {
        "text": "A final and very important point is to ensure that copyright is respected, either because the text is copyright-free or because the author has provided written consent granting permission to include their text in the corpus.",
        "entities": [
            [
                217,
                223,
                "TERM"
            ],
            [
                94,
                98,
                "TERM"
            ],
            [
                205,
                209,
                "TERM"
            ]
        ]
    },
    {
        "text": "On the other hand, the history of many fiction genres, including drama and short stories, is certainly longer than the coverage of COHA, so their proportions could have been more optimally balanced in the corpus; considering the automated sampling of COHA, their better representation in the most recent periods probably reflects their increased availability in digital form.",
        "entities": [
            [
                205,
                211,
                "TERM"
            ]
        ]
    },
    {
        "text": "Let us imagine, for example, that we wish to know how often French nouns such as ferme and car appear in a corpus.",
        "entities": [
            [
                107,
                113,
                "TERM"
            ]
        ]
    },
    {
        "text": "Relying on frequency data obtained from a large monolingual corpus, it was possible to show that translated financial reports are less collocational than comparable non-translated reports, while translated shareholders' letters seem to go in the opposite direction: they feature stronger collocations than non-translated letters, often resulting from explicitating or normalizing shifts.",
        "entities": [
            [
                60,
                66,
                "TERM"
            ]
        ]
    },
    {
        "text": "A related consideration is whether a study includes register comparisons: some studies compare phraseological patterns across two or more registers; others focus on phraseological patterns in a single register; while some studies analyze a general corpus and disregard the influence of register altogether.",
        "entities": [
            [
                248,
                254,
                "TERM"
            ]
        ]
    },
    {
        "text": "In other words, in the case of both royal and regal, substantial proportions of the occurrences of the words in the corpus appear in proper names, and it would be crucial to exclude such instances if we wanted to study of the use of the words as non-frozen elements.",
        "entities": [
            [
                116,
                122,
                "TERM"
            ]
        ]
    },
    {
        "text": "Complications may also arise if the character set is not directly supported by the computer the corpus is viewed on.",
        "entities": [
            [
                96,
                102,
                "TERM"
            ]
        ]
    },
    {
        "text": "Another scientific requirement corpus linguists follow in principle is replicability of results.",
        "entities": [
            [
                31,
                37,
                "TERM"
            ]
        ]
    },
    {
        "text": "The types of corpora (and corpus-related resources) that we consider are the following: 1   1. Small 1-5-million-word, first-generation corpora like the Brown Corpus (and others in the Brown \"family,\" such as the LOB, Frown, and FLOB) 2.",
        "entities": [
            [
                26,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "The three occurrences of that's are counted as three tokens, but as one type.",
        "entities": [
            [
                72,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "Specific requirements of diachronic research simply need to be met in different ways.",
        "entities": [
            [
                25,
                35,
                "TERM"
            ]
        ]
    },
    {
        "text": "Before these questions are answered, it is appropriate to introduce the corpora and data analysis method used in this study (Section 3.1), which is followed by a discussion of the collocation and semantic prosodies of the chosen group of near synonyms in English (Section 3.2) and a contrastive analysis of the Chinese group (Section 3.3).",
        "entities": [
            [
                180,
                191,
                "TERM"
            ]
        ]
    },
    {
        "text": "It is important to mention, however, that generalizing from a corpus will always be an extrapolation -it provides the evidence for interpretations about how language works.",
        "entities": [
            [
                62,
                68,
                "TERM"
            ]
        ]
    },
    {
        "text": "Much research has been done to automate the process of adding the most common forms of analysis, so that it is not necessary for a human being to read through the whole corpus and manually insert the tags.",
        "entities": [
            [
                169,
                175,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, with a small corpus, there is probably a lot less of this \"junk\" to throw out.",
        "entities": [
            [
                22,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "Obviously, we need rchoose.dir to define the directory containing the corpus files and dir to retrieve all the file names from that directory.",
        "entities": [
            [
                70,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, we show that cross-validated results also allow us to employ a powerful model comparison method that helps us determine which methods are worth deploying in future automatic annotation settings.",
        "entities": [
            [
                183,
                193,
                "TERM"
            ]
        ]
    },
    {
        "text": "But for others in the field, the insights into language that arise from the use of the corpus are so radically different from the traditional understanding of how language works that they consider corpus linguistics to constitute an independent field of study or theory of language.",
        "entities": [
            [
                197,
                215,
                "TERM"
            ],
            [
                87,
                93,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is particularly the case of requests concerning the attribution of a text to one or more alleged authors.",
        "entities": [
            [
                74,
                78,
                "TERM"
            ]
        ]
    },
    {
        "text": "An annotation of cleft structures in French can start by looking up structures containing the verb form c'est.",
        "entities": [
            [
                3,
                13,
                "TERM"
            ]
        ]
    },
    {
        "text": "This corpus can be downloaded from the Ortolang platform.",
        "entities": [
            [
                5,
                11,
                "TERM"
            ]
        ]
    },
    {
        "text": "Some common types of extralinguistic annotation include semantic annotation, anaphoric annotation, discourse annotation, etymological annotation, rhetoric annotation, and ethnographic annotation.",
        "entities": [
            [
                37,
                47,
                "TERM"
            ],
            [
                65,
                75,
                "TERM"
            ],
            [
                87,
                97,
                "TERM"
            ],
            [
                109,
                119,
                "TERM"
            ],
            [
                134,
                144,
                "TERM"
            ],
            [
                155,
                165,
                "TERM"
            ],
            [
                184,
                194,
                "TERM"
            ]
        ]
    },
    {
        "text": "There is no consistent terminology to describe research of this kind, but the phrase \"Lexical Grammar\" directs us to the combination of lexis and grammar embodied in it.",
        "entities": [
            [
                136,
                141,
                "TERM"
            ]
        ]
    },
    {
        "text": "A monitor corpus is a corpus allowing researchers to track current changes synchronically in a particular language.",
        "entities": [
            [
                2,
                16,
                "TERM"
            ],
            [
                22,
                28,
                "TERM"
            ]
        ]
    },
    {
        "text": "Finally, corpus architecture considerations also interact with the choice of search and visualization facilities that one intends to use.",
        "entities": [
            [
                9,
                15,
                "TERM"
            ]
        ]
    },
    {
        "text": "The web may not be a corpus in a conventional sense but, as we have seen, it can be a valuable corpus surrogate or, increasingly, a source of texts for the building of corpora.",
        "entities": [
            [
                21,
                27,
                "TERM"
            ],
            [
                95,
                101,
                "TERM"
            ]
        ]
    },
    {
        "text": "Thus, the hopefully not too high-flying goal of this paper is to become for corpus linguistics what the abovequoted papers have become for psycholinguistics: a first go-to resource that explains to corpus linguists what (generalised) linear mixed-effects/multilevel modelling ((G)LMM/MLM) has to offer and that provides them with a concrete example and some instructions on how to perform such analyses.",
        "entities": [
            [
                76,
                94,
                "TERM"
            ],
            [
                198,
                204,
                "TERM"
            ]
        ]
    },
    {
        "text": "For a fully automatic large-scale annotation of the syntax, speech acts, etc., you can also try my Dialogue Annotation and Research Tool (DART), which not only allows you to annotate hundreds of dialogues in this way within minutes, but also to post-edit/correct the annotations, as well as to carry out similar analysis operations to those we learnt how to perform in AntConc, including concordancing, n-gram analysis, etc.",
        "entities": [
            [
                34,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "Speech corpora are based on spoken language but necessitate detailed annotation including not only written transcription but transcription in phonetic alphabets and careful connections with the time course of speaking.",
        "entities": [
            [
                69,
                79,
                "TERM"
            ]
        ]
    },
    {
        "text": "The preparation of samples to be included in the corpus poses two important methodological questions: on the one hand, the appropriate size for each sample, and, on the other hand, how to balance the portions of the corpus in such a way that the result is truly representative of the genre.",
        "entities": [
            [
                188,
                195,
                "TERM"
            ],
            [
                49,
                55,
                "TERM"
            ],
            [
                216,
                222,
                "TERM"
            ],
            [
                149,
                155,
                "TERM"
            ]
        ]
    },
    {
        "text": "Further typical options include whether to consider punctuation as a boundary to collocation window spans or impose minimum frequencies on collocates or node words.",
        "entities": [
            [
                81,
                92,
                "TERM"
            ],
            [
                153,
                157,
                "TERM"
            ]
        ]
    },
    {
        "text": "Of course, the question is how important the role of 𝑝-values is in a design where our main aim is to identify collocates and order them in terms of their collocation strength.",
        "entities": [
            [
                155,
                166,
                "TERM"
            ]
        ]
    },
    {
        "text": "Moreover, if corpus pragmatics is concerned with the interpretation of meaning in context, another disadvantage associated with the relationship between corpus linguistics and pragmatics is that many larger corpora are impoverished both textually and contextually (Ru ¨hlemann 2010).",
        "entities": [
            [
                153,
                171,
                "TERM"
            ],
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "This allows us to draw conclusions about the population from the sample.",
        "entities": [
            [
                65,
                71,
                "TERM"
            ]
        ]
    },
    {
        "text": "One of the simplest ones is to count the number of portions of the corpus in which the word is present.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "Having said that, we hope to see both of these things happening in corpus linguistic research.",
        "entities": [
            [
                67,
                73,
                "TERM"
            ]
        ]
    },
    {
        "text": "As anyone who has ever transcribed speech knows, the flow of speech is much faster than the ability of the transcriber to type.",
        "entities": [
            [
                122,
                126,
                "TERM"
            ]
        ]
    },
    {
        "text": "The success of MD also directly depends on the reliability of the automatic identification of linguistic variables (tagging) in corpora.",
        "entities": [
            [
                116,
                123,
                "TERM"
            ]
        ]
    },
    {
        "text": "Essentially, being a concordance facility, too, some of its basic features are rather similar to the ones we've already discussed for AntConc.",
        "entities": [
            [
                21,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "In cases where researchers need to compile specialized corpora, the question of representativeness is posed a little differently.",
        "entities": [
            [
                80,
                98,
                "TERM"
            ]
        ]
    },
    {
        "text": "Because the sentences included in the corpus were taken from news stories, the sentences did occur in a natural communicative setting.",
        "entities": [
            [
                38,
                44,
                "TERM"
            ]
        ]
    },
    {
        "text": "Then, we will present two types of descriptive statistics that, respectively, make it possible to measure lexical diversity (the type/token ratio), and to calculate lexical dispersion in a corpus.",
        "entities": [
            [
                189,
                195,
                "TERM"
            ],
            [
                134,
                139,
                "TERM"
            ],
            [
                129,
                133,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a written corpus, we can thus query the sequence ⟨[word=\"''\"] [pos=\"pronoun\"] [pos=\"verb\"]⟩ to find the majority of examples of the construction.",
        "entities": [
            [
                13,
                19,
                "TERM"
            ]
        ]
    },
    {
        "text": "Regarding the latter, you may now, quite rightly, expect to find at least the other two question words what and who in the same concordance list, as they can certainly be followed by the same clitic, but, due to the tagging rules of CLAWS, these are in fact classified in different ways from the other question words.",
        "entities": [
            [
                128,
                139,
                "TERM"
            ],
            [
                216,
                223,
                "TERM"
            ]
        ]
    },
    {
        "text": "Although the texts are accessible, there are copyright restrictions in both cases, which limits the availability of published texts for corpus-building enterprises severely.",
        "entities": [
            [
                136,
                142,
                "TERM"
            ]
        ]
    },
    {
        "text": "After that I will reflect on the current state of the art in corpus tools and methods.",
        "entities": [
            [
                61,
                67,
                "TERM"
            ]
        ]
    },
    {
        "text": "The corpus can be queried online.",
        "entities": [
            [
                4,
                10,
                "TERM"
            ]
        ]
    },
    {
        "text": "In a research context, in contrast, especially when researchers want to make a claim for exhaustive data retrieval and/or when the sequencing of attestations in the corpus matters for the research question at hand, one would only delete concordance lines that contain false hits.",
        "entities": [
            [
                237,
                248,
                "TERM"
            ],
            [
                165,
                171,
                "TERM"
            ]
        ]
    },
    {
        "text": "The question of the optimal size for a corpus primarily depends on the nature of the linguistic phenomenon to be studied.",
        "entities": [
            [
                39,
                45,
                "TERM"
            ]
        ]
    },
    {
        "text": "To do this, in the spoken corpus InterFra, Forsberg Lundell et al. (2014) defined three groups of French non-native speakers whose mother tongue was Swedish.",
        "entities": [
            [
                26,
                32,
                "TERM"
            ]
        ]
    },
    {
        "text": "However, we sometimes have to work with the sample we happen to have available, like in historical linguistics.",
        "entities": [
            [
                44,
                50,
                "TERM"
            ]
        ]
    },
    {
        "text": "This is the case because the browser now assumes that, since you've 'told' it that you want to style the XML yourself, it should no longer apply its own built-in style sheet, but instead leave all the styling up to yours.",
        "entities": [
            [
                105,
                108,
                "TERM"
            ]
        ]
    },
    {
        "text": "On one level, researchers, language instructors and other users would like to be able to search through learner data directly: the base text is, trivially, whatever a learner may have written.",
        "entities": [
            [
                136,
                140,
                "TERM"
            ]
        ]
    },
    {
        "text": "The second independent variable is the type of newspaper, which is a categorical variable, since it falls into three distinct categories, namely The Times, the Daily Telegraph, and the Guardian.",
        "entities": [
            [
                39,
                43,
                "TERM"
            ]
        ]
    },
    {
        "text": "For some of these there is self-evident redundancy: between personality type and motivation, say, or between scholastic record and family background, where support for learning at home is reflected in performance in school.",
        "entities": [
            [
                72,
                76,
                "TERM"
            ]
        ]
    },
    {
        "text": "Attempting to transcribe speech of this nature in a purely linear manner is not only difficult but potentially misleading to future users of the corpus, especially if they have access only to the transcription of the conversation, and not the recording.",
        "entities": [
            [
                145,
                151,
                "TERM"
            ]
        ]
    }
]