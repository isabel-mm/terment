Introduction

For several decades now, corpus linguistics has been among the fastest-growing methodological disciplines in linguistics. For instance, in his outgoing column as the editor of Language,

In spite of this welcome development, change in the field of linguistics is slow, and corpus linguistics in particular is limited in two ways: First, in computational ways in the sense that probably the majority of corpus linguists are still relying on a small set of often commercial and proprietary point-and-click kind of corpus search tools (such as WordSmith Tools, MonoConc Pro, or AntConc); given the severe constraints that this results in (see

The second kind of limitation involves statistical methods: While the overall amount of statistical expertise in the field is growing, corpus linguists should both widen and deepen their expertise to go beyond the handful of widely used methods. By that I do not only mean that corpus linguists need to use more different statistical tests (while that is generally true, the choice of a particular test is of course mostly dictated by the particular research question), but also that there needs to be a growing awareness that some choices that corpus linguists traditionally make may be pro blematic and would benefit from a different perspective. In the next section of this paper, I want to exemplify several such problems and survey some solutions to them. Specifically, I shall discuss potentially problematic choices or omissions in the area of general corpus statistics, in particular the choice of association measures for co-occurrence data, that is, measures with which corpus linguists quantify the degree of association between two linguistic expressions (e.g. two words or a word and a syntactic pattern/construction). In addition, I shall briefly comment on the underutilized notion of dispersion, that is, a measure that quantifies how evenly distributed elements are in a corpus, and thus also relates to the notion of corpus homogeneity. Finally, I shall demonstrate how the current typical neglect of the hierarchical structure of corpora poses severe problems. More specialized areas are currently booming, it seems: diachronic corpus linguistics, which needs to deal with the problem of how temporally-ordered corpus data are grouped into temporal stages for subsequent analysis; and learner corpus research, which needs to move on from decontextualized studies of over-and underuse to more comprehensive models of learner language and its differences to native language.

General corpus statistics

1 Co-occurrence information

One of the most fundamental notions in corpus linguistics is the distributional hypothesis, that is, the working assumption that linguistic elements that are similar in terms of their distributional patterning in corpora also exhibit some semantic or functional similarity.

[i]f we consider words or morphemes A and B to be more different in meaning than A and C, then we will often find that the distributions of A and B are more different than the distributions of A and C. In other words, difference of meaning correlates with difference of distribution.

That is, a linguistic expression E-morphemes, words, constructions/patterns, . . .-can be studied by exploring what is co-occurring with E and how often. The simplest possible way to do this would be by raw co-occurrence frequency or, more likely, conditional probabilities such as p(function|E) or p(contextual element(s)|E). Since raw frequencies will be distorted by words that are highly frequent everywhere, a more frequent way is to use association measures (AMs), that is, statistics that quantify the strength of mutual association between two elements such as a function or a contextual element on the one hand and E on the other. Most AMs are based on co-occurrence tables of the kind exemplified in Table

Problems with the quantification of co-occurrence

Problem: multi-word AMs are not conservative enough

Despite their frequency of use, AMs of the above kind are not unproblematic. One smaller problem is the fact that they do not easily generalize to n-grams (uninterrupted strings of n words), or multi-word units (such as according to, in spite of, etc.). At this point, MI for n-gramslog 2 ( obs a / exp a )-is often simply computed on the basis of complete conditional independence, which will tend to underestimate expected frequencies of a and, thus, overestimate the strength of association. If one computes the MI of in spite of in the untagged Brown corpus by comparing the observed frequency of in spite of of 54 against an expected frequency based on complete independence, MI becomes an extremely high value of 12.25. However, if one computes MI by comparing the same observed frequency of in spite of to the one expected from the occurrences of in spite and of, then that MI-value decreases to 4.76. Thus, corpus linguistics needs to explore more adequate and conservative ways to extend AMs to n-grams.

Problem: nearly all AMs are symmetric/bidirectional

An even more important problem is that nearly all AMs are symmetric: the association of expression E to context C is presumed to be symmetric/bidirectional. However, associations in general and associative learning are certainly not (always) symmetric, which is why, ideally, corpus linguistics would explore the use of directional AMs. Some work on this area exists, in particular

First, they explore the correlation of conditional probabilities from adjective-noun collocations with the University of South Florida Association Norms, but find the measure lacking in identifying symmetric associations; in addition, conditional probabilities do not normalize the observed percentage against any baseline.

Second, they explore a measure based on the differences of ranks of AMs (such as chi-squared values). For such rank measures, a collocation x y is explored by -computing all AMs for collocations with x, ranking them, and noting the rank for x y; -computing all AMs for collocations with y, ranking them, and noting the rank for x y; -comparing the difference in ranks. In tests analogous to those of conditional probabilities, this rank measure does not perform well with asymmetric associations but a little better with symmetric ones; in the additional classification task, the rank measure came with an even higher error rate than conditional probabilities. In

T able 1: Schematic co-occurrence frequency table

While this sounds promising, the computational effort that goes into these calculations is immense, since the computation of one AM for the collocation x y requires the computation of all AMs for all collocations with x and then separately for all collocations with y. In addition, in spite of the huge computational effort involved in the thousands of ranked G 2 -values, they do not perform better than conditional probability

( 1) a.

For example, all traditional AMs would return a high value for of course (see Gries 2013:144), but it is ΔP that recognizes that the association between of and course is not symmetric: of is not a good predictor that course would follow whereas course is a strong predictor that of will precede. In fact,

(2) a. apart from, according to, upside down, contrary to, ipso facto, irrespective of b. at least, per annum, status quo, for instance, de facto, vice versa

In sum, ΔP is by design more sensitive than traditional AMs since it can tease apart directionality effects; it is very easy to understand and compute; its computation/interpretation does not require assumptions (such as normality, which is very rare in corpus data); it avoids problems of the Null Hypothesis Significance Testing paradigm because it does not test the observed distributional data against an illusionary null hypothesis distribution; finally, it has received experimental support both in psychology and in linguistic work by

Problem: nearly all AMs involve only token frequencies

The next AM problem to be discussed here is perhaps just as fundamental as the symmetry problem, but even less recognized and explored: namely that the computation of nearly all AMs involves only the four token frequencies represented in Table

Given the importance of type frequencies or entropies for many domains (productivity, language change, language acquisition, . . .), it is amazing how little alternatives to AMs that utilize type frequencies or entropies have been explored in corpus linguistics proper. Studies from neighboring disciplines

Within corpus linguistics,

(3) Grav ity G (w 1 , w 2 ) =

Unfortunately, there has been very little follow-up on this notion. Two exceptions are Gries (2010b) and

The latter study explores an extension of G to the identification of n-grams in different varieties of English. More precisely, it shows how one can use G to identify n-grams, and how a G-based cluster analysis of spoken and written data from four different varieties (British, Hong Kong, Indian, and Singaporean English) perfectly distinguishes speaking from writing.

In sum, there are compelling arguments to include type frequencies from theoretical considerations as well as from neighboring disciplines such as psycholinguistics or computational linguistics, and there are promising first results within corpus linguistics proper, but more exploration is definitely required. In particular, all of the above approaches only deal with the minimal amount of information one should include-the more comprehensive information regarding token and type frequency distributions and entropies still awaits first exploration.

Problems with ignoring distribution in the structure of the corpus

Pro blem: (co-)occurrence may be underdispersed

The next AM problem to be discussed here concerns another important dimension of corpus data that the traditional kind of AM approach based on Table

As for the implications for corpus-linguistic analysis, consider the question of which verbs are likely to be used in imperatives. A perfectly normal traditional corpus-linguistic account could approach that question by computing for each verb lemma in a corpus that occurs in the imperative at least once an AM that quantifies the association between that lemma and the imperative based on tables such as Table

As for the implications for psycholinguistic and more general (theoretical) applications, dispersion has by now been shown to be relevant in domains other than core corpus linguistics, too. For instance, Simpson-Vlach &

Proble m: ignoring the hierarchical structure of the corpus

The final problem to be discussed in this section is concerned with the fact that the vast majority of statistical analyses in corpus linguistics-be they chi-squared tests, simple correlations, generalized linear models (GLM, e.g. binary logistic regressions), . . .-violate a fundamental assumption of these statistical methods: that the data points are independent of each other. Rather, there are three different ways in which many corpus data points can be seen as related to each other, the first two of which are well-known from psycholinguistic work:

-Speakers/writers in corpus data/files often provide more than one data point in a concordance so that all data points from a particular speaker/writer are related to each other (as they may reflect that speaker's idiosyncratic behavioral patterns). In psycholinguistics, this is often addressed with F 1 -or related ANOVA statistics. -For many grammatical patterns, concordance lines will involve the same lexical item so that all data points with that lexical item are related to each other (as they may reflect that lexical item's idiosyncratic patterning). In psycholinguistics, this is often addressed with F 2 -or related ANOVA statistics. -Corpora often come with a hierarchically-nested structure in which speakers are nested into files, which in turn are nested into sub-registers, which in turn are nested into registers, which in turn are nested into modes (e.g. spoken versus written). Thus, there are multiple levels of corpus organization at which effects may be located, but these levels are typically not all tested.

While it is usually freely admitted that corpus data are much more messy/noisy than (often carefully) controlled psycholinguistic experimental data, the massive interrelatedness of corpus data along the above three lines is typically ignored. In this section, I exemplify how this is problematic by comparing an analysis that, as usual, ignores this interrelatedness to one that takes it into consideration. As a small example, whose actual linguistic implications I shall not be concerned with, let us consider the question of who is more likely to use I or you-men or women-and where/when (early/ late in a conversation and/or early/late in a sentence); maybe there is an assumption that women are generally less likely to use I . . . Using an R script (R Core Team 2014), I extracted all instances of I and you (when tagged as PNP) from all 21 files of the British National Corpus World Edition (XML) whose names begin with 'KR'. For each instance, I retrieved/annotated the following variables:

-MATCH: whether the speaker used I or you; -FILE: the name of the file in which a speaker used I or you; -SPEAKER: a unique identifier for the speaker who used I or you; -SEX: the sex of the speaker, female versus male; -SENTENCE: the square root of the ID number (from 1 to n) of the sentence in the files in which a speaker used I or you (the square root transformation was used to make the distribution of SENTENCE more normal);

-DISTANCE: the natural log of the number of characters in the sentence before the I or you in question (after tags etc. had been removed; the log transformation was used to make the distribution of DISTANCE more normal). This is a data set that requires a multifactorial method of analysis such as a binary logistic regression. Let us assume that one decided to begin with a first maximal model that tries to predict MATCH, that is, the choice of I and you on the basis of all fixed-effects predictors-SEX, SENTENCE, and DISTANCE-as well as their pairwise interactions, and that one used a backwards model selection process in which the least significant predictor is deleted till only significant predictors are left. It turns out that this model selection process involves the elimination of the interactions SENTENCE:DISTANCE (p = 0.058) and SEX:DISTANCE (p = 0.05) and results in a highly significant model (L.R chi-squared 881.9; df = 6, p < 0.0001); the coefficients of this model are listed in Table

Note that, while the regression model is highly significant, its predictive power is extremely weak: R 2 = 0.055, C = 0.613, and the classification accuracy is a mere 58.3%, which is not significantly better than chance. The nature of the effects is somewhat clear from Table

When one then does an analogous model selection process by eliminating non-significant fixed effects, once the same interactions are deleted as before-with very different p-values, though: SENTENCE:DISTANCE (p = 0.216) and SEX:DISTANCE (p = 0.224)-and one arrives at a final model with the coefficients represented in Table

What about the classificatory power of this model? While it is still not as good as one would theoretically want it to be, it is much higher than the previous one: marginal R 2 = 0.044 and conditional R 2 = 0.24, C = 0.717, and the classification accuracy is now at 65.7%, which is now highly significantly better than chance. 2 Before we compare the two models, let us again first look at the visualization of the significant highest-order effects, which are shown in Figure

As for the commonalities: both models contain the same fixed effects and in both models the effect of DISTANCE is probably the same. However, there are also many (more) marked differences. The most obvious was already mentioned: the GLMEM achieves a much higher and highly significant classification accuracy. Then, the GLMEM can see that, once file and speaker information is included, SENTENCE is not significant, whereas it is significant in the GLM. Most important, however, are the differences for the crucial interaction most of interest, SEX:SENTENCE. First, the GLM assigns to this interaction a p-value that is 24 orders of magnitude smaller (i.e. more significant) than the GLMEM. Second and more interestingly, the above two models were fitted with user-defined orthogonal contrasts-something else that happens way too rarely in corpus linguistics-to see easily (i) whether the speakers of an unknown sex are different from those where the sex is known, and (ii) whether female and male speakers behave differently. Since the GLM does not take the relatedness of the data points of each speaker into account, it returns results that are quite different from the more precise GLMEM:

-With regard to the contrast of female versus male, the GLM returns a highly significant coefficient that is ≈2 times as high as the non-significant coefficient for female versus male from the GLMEM. In other words, the GLM strongly overestimates this contrast, much of which is in fact due to speaker-specific behaviors. -With regard to the contrast of female versus male, the GLM returns a highly significant coefficient for female versus male that is >2 times as high as the highly significant coefficient for female versus male from the GLMER. Again, while the contrast is significant in both models, the GLM strongly overestimates its strength.

Space does not permit a more detailed discussion of these data or of the specifics of mixedeffects and multi-level modeling here (see Gries forthcoming for some more details in a corpuslinguistic context). It should have become clear, however, that much of what happens in corpus data is a result of word-/speaker-/file-/register-specific random effects rather than of the fixed effects we as corpus linguists are usually interested in. GLMs or any other statistical tool that does not take the relatedness of data points into consideration run the risk of severely overestimating the size and significance of effects. But to make matters worse, it is just as possible that GLMs underestimate the size and significance of effects-the problem is there is no way of knowing the direction of error of GLMs ahead of time. It is therefore imperative that corpus linguists follow the lead of recent developments in psycholinguistics and make mixed-effects/multi-level modeling a central analytical tool: without it, we will never know how much of an effect is interesting, and how much is just due to particular speakers sampled in a corpus.

Interim summary

Given the distributional hypothesis discussed above, the quantitative exploration of cooccurrence data is the most fundamental methodological tool in corpus linguistics and the last few decades have produced a plethora of papers and findings that are based on co-occurrence frequencies, co-occurrence probabilities, association measures, and other statistical approaches (most often regression-analytic methods). While much of that work has, of course, been successful because, for example, high token frequencies in b and c are positively correlated with high type frequencies, and high token frequencies in a are negatively correlated with clumpy distributions, it is unclear how potentially skewed the results are for cases where those correlations do not hold. A study that tries to identify multi-word units while at the same time trying to address all these AM issues mentioned above is Wahl (in progress).

In addition, ignoring the repeated-measurements nature as well as the hierarchical structure of the corpus data not only violates the fundamental assumptions of most statistical methods-the independence of data points-but also distorts our results in unpredictable ways. Thus, most of the approaches above are relatively easy ways in which we can try to make our co-occurrence-based studies more robust; there is no reason not to pursue those strategies if corpus linguistics as a whole wants to evolve in tandem with what happens in other disciplines.

More specialized applications

The three problems discussed above have implications for most corpus-linguistic studies: the issue of underdispersion, or clumpiness in distribution, is a threat to any statistic based on frequency data-because they all involve frequencies of occurrence and of co-occurrence. Likewise, the lack of bidirectionality and of type frequencies and their distributions in the computation of AMs is a threat to virtually all studies based on co-occurrence data. However, at this point in time, quantitative corpus linguistics is becoming more and more established also in specific linguistic subdisciplines, which raise their own, more specialized problems. In this section, I shall discuss one example each from two areas in which corpus research is currently booming. In §3.1, I shall discuss the issue of studying temporally-ordered corpus data in a way that is both bottom-up/exploratory and principled/objective; in §3.2, I shall turn to the field of learner corpus research and the question of how to make the best use of what native and non-native learner corpora have to offer.

Temporally-ordered data and the problem of identifying stages

Temporally-ordered corpus data play an important role in two different areas in linguistics. On the one hand, there is the area of first language acquisition. In that area, corpus data are both longitudinal and cross-sectional and in order: (i) to discern longitudinal trends in the data for one or more children, (ii) to identify children at comparable levels of development for cross-sectional analysis, or (iii) to increase sample sizes and/or filter out outliers, it is often useful to be able to group the temporal data for children into different stages.

On the other hand, there is the area of diachronic historical corpus linguistics, in which corpus data are-given the relevant time spans-usually cross-sectional, covering, for instance, several centuries of the history of a language. Given that historical data are not collected in the carefully controlled ways in which psycholinguists (try to) collect language acquisition corpus data, such historical data are often quite heterogeneous so that here, too, it is useful to be able to group temporal data and at the same time clean the data of outliers in a principled fashion. Figure

The fact that there are overall increasing trends can be easily tested with correlation coefficients such as Kendall's τ or others. However, not only can such data violate the assumptions of frequently used statistical tests such as linear regression, but many frequently used statistics also provide too little information about the data. In particular, such statistics do not necessarily answer questions such as: (i) Are there different stages in the data, and if so, how many?; (ii) Do these different stages exhibit kinds of trends?

A frequent exploratory method to answer the first question, namely to discern sub-structure(s) in corpus data, is hierarchical cluster analysis, a statistical tool that groups data points into clusters on the basis of the points' pairwise similarity (such as the differences between MLU values or differences between percentages of (e)s). However, such cluster analyses cannot straightforwardly be applied to such temporally-ordered data: The computation of the similarity matrix of, say, the percentages of (e)s will return extremely high similarities for data points 150 years or more apart. However, a cluster analysis should not group such distant data points together given that, in historical data, grouping data points that might be 150 or more years apart makes little sense linguistically just as, in language acquisition data, grouping data points that might be 2 or more years apart makes little sense cognitively. Thus, what is required is a modification of the cluster-analytic approach that makes it operate locally, rather than allow it to merge data points that are too far apart.

One such approach is variability-based neighbor clustering (VNC; see

Consider Figure

For example, Figure

-Zero becomes less frequent over time; -P becomes more frequent over time; -N and DP do not change much/markedly. In all of the above, VNC was used on data in which the measured data could be univariate (just one frequency as in the case of just because) or multivariate (several frequencies (of grammatical patterns) as in the language acquisition data), but where the dimension along which the clustering happened and along which VNC restricted it to neighboring elements was onedimensional: time. Another interesting extension is using VNC for the analysis of data where there is more than one dimension, as when one studies geographical data in a quantitative dialectology setting and wants to prevent a regular hierarchical cluster algorithm from merging geographically very distant regions. The VNC algorithm can be adjusted correspondingly. Figure

Figure

-In the left panel, some first smaller clusters have emerged mainly in the south (one in the Cornwall and Devon regions and one in the Kent, East Suffolk, and London regions) as well as one small one involving Dumfriesshire and a larger one around Manchester. -In the center panel most of the south is now interconnected (although Cornwall/Devon remain separate from the rest); not much has changed in the middle area. -In the right panel, most of the country is now inter-connected apart from the very northaround Banffshire, Sutherland, Ross, and the Hebrides. Thus, VNC can contribute to the (methodologically already quite sophisticated) domain of quantitative dialectology by helping to identify structures in corpus-linguistically described regions of a country or other larger regions that can then be interpreted against the background of other empirical or theoretical work. Given the increasing availability of historical corpora and regionally-stratified corpora, this method may therefore be a useful addition to the corpus-linguistic toolkit.

Learner corpus research and the problem of missing/impoverished context

The final corpus-linguistic domain to be discussed here is learner corpus research, that is, the branch of corpus linguistics exploring corpora containing non-native speaker (NNS) speech and/or writing. This field has become increasingly vibrant over the last 15 years or so, given the increasing availability of learner corpora. Much of this work is contrastive in the sense that NNS language is compared to the target of the learner as well as his L1(s), and an increasing amount of work approaches learner corpus data from a cognitively-informed perspective. Unfortunately, many studies in this field are quantitatively quite simplistic and restricted to the description of overand underuses of linguistic elements in NNS language, accompanied by univariate or bivariate chi-squared tests. Examples include: -

Typically, such quantitative analyses are lacking not only because of all the issues raised above, but also because they are not 'comparing/contrasting what non-native and native speakers of a language do in a comparable situation' (Péry-Woodley 1990:143, quoted from Granger 1996:43, our emphasis). This is because many studies reduce the notion of comparable situation to a single co-occurring factor/predictor, such as when

Thus, if the goal of learner corpus research is to determine how native speaker (NS) language and NNS language differ, a more comprehensive definition of comparable situation is needed, which will typically require the annotation of multiple features of the instances of the word/pattern in question. This in turn means that all these multiple features have to be included in the statistical analysis so as to determine which of these features has what kind of effect in the company of all other characteristics. Two main possibilities to do all this are available: both require corpus data on the element E under consideration that come from both NS and NNS data and that have been annotated with regard, ideally, to all the features that one has reason to believe affect the choice of E. Then, first, one can fit a regression in which:

-The dependent variable is either a binary or polytomous choice (for a binary or multinomial logistic regression) or a frequency (for a Poisson regression); for the choice of of-versus s-genitives, this would be the binary variable GENITIVE: of versus s. -The predictors are all the annotated features as well as their statistical interactions (usually only up to the second or third degree); for the choice of of-and s-genitives, these may include the animacy of the possessor and the possessed, the length of the possessor and the possessed, the givenness of the possessor and the possessed, and many more; ideally, this would be a mixed-effects/multi-level model with random effects as required by the data/ question(s). -All the predictors from the previous bullet point are also allowed to interact with a predictor called CORPUS or L1.

What is the rationale for the latter two guidelines? The rationale for the second guideline is that if one does not include the interaction, say, ANIMACYPOSSESSOR:ANIMACYPOSSESSED, then one has no way of finding out whether the preference of animate possessors for s-genitives holds regardless of whether the possessed is concrete or not. The rationale for the third guideline is that if one does not include the interaction, say, ANIMACYPOSSESSOR:L1, then one has no way of finding out whether the preference of animate possessors for s-genitives holds in both NS and one or more NNS groups to the same degree (given the presence of all other (significant) predictors), which is precisely the kind of question that much learner corpus research is interested in but can often not answer because too few relevant predictors have been included (see

There is a second approach (called MuPDAR, for Multifactorial Prediction and Deviation Analysis with Regressions) that is even more promising. It involves the following steps:

(i) Fit a first regression R 1 that conforms to the first two bullet points above, but only to the NS data. (ii) If and only if R 1 results in a good fit and classification accuracy, then apply the regression equation thus obtained from R 1 to the NNS data to obtain for every NNS data point a prediction of what a NS would have done in the very same situation, which will serve as the gold standard. (iii) If and only if R 1 's NS regression equation also results in a relatively good fit with the NNS data, fit a second regression R 2 in which the dependent variable now is either a binary variable specifying whether the NNS made the same choice as a NS (yes versus no) would have made, or a continuous variable quantifying how much of the NNS choice was compared to what an NS was expected to say/write (this variable is 0 if the NNS made the NS choice, and a number other than zero, but between -1 and +1 if not).

It is this regression approach that precisely answers the core question of learner corpus research-in this linguistically and maybe contextually complex situation where the NNS had to make a choice, did he make a nativelike choice, 'Yes or no?'. And it is this regression approach that requires and at the same time guarantees a comprehensive definition of comparable situationa hopefully large number of annotated factors describing the situation in which the NNS had to make a choice.

Gries & Adelman (

(i) Fit a first mixed-effects regression R 1 that models whether Japanese NS realize a subject in a sentence on the basis of whether the referent of the subject is contrastive (a variable called CONTRAST) and how given it is (a variable called GIVENNESS). (ii) Apply the regression equation thus obtained from R 1 to the non-native speakers of Japanese corpus data to obtain for every NNS data point a prediction of whether an NS would have realized the subject there, yes or no. (iii) Fit a second mixed-effects regression R 2 in which the dependent variable is a binary variable specifying whether the NNS made the same choice as an NS (yes versus no).

Using a polynomial to the second degree to model the predictor GIVENNESS, they find that the NNS are on the whole quite close to the NS behavior, but (i) different speakers exhibit quite different degrees of proficiency, and (ii) all NNS struggle most with making nativelike choices with intermediate degrees of givenness and non-contrastive referents:

-When the referent is contrastive, they realize it in the subject position as NS would.

-When the referent is non-contrastive and highly given or completely new, they do not realize it in the subject position or realize it in the subject positions as NS would. -When the referent is non-contrastive and somewhat given, then faced with this middleground degree of givenness, their degree of nativelikeness decreases.

This approach, too, needs to be refined and developed further, however. It goes without saying that it is cognitively and contextually much more realistic and statistically more appropriate than decontextualized frequencies and/or chi-squared tests. So, again, it remains to be hoped that analytical strategies like this one will gain more ground in learner corpus research, the research on varieties, and any other domain where one part of the corpus data can be considered a standard or target with which the others can be meaningfully compared.

Concluding remarks

By way of a brief conclusion, corpus linguistics has made enormous headway in the recent past. To grow from a not particularly widely used method, geographically somewhat restricted to several Northern and Central European countries, to one of the most widely applied methods in linguistics of all sorts of theoretical persuasions worldwide in 15 to 20 years is no small feat. However, this is no time to rest on our laurels-now that corpus linguistics has become mainstream, and that's a good thing, we too must continue to refine our methods just as other fields have to. Many areas in psycholinguistics and computational linguistics have made interesting discoveries, have developed useful tools, have adopted great methods from neighboring fields, but corpus linguistics is unfortunately not leading the pack and must take care not to lose momentum either in terms of its own evolution or in terms of how it helps to shape linguistics as a whole. The present paper is an attempt to provide a snapshot of current problems, both in corpus linguistics in general and in selected hot topic areas, as well as to provide ideas and (first) suggestions about how to cope with these problems; I hope it will succeed as a call to (methodological) arms, and thus trigger developments that will help our field advance once more.